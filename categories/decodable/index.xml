<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Decodable on rmoff&#39;s random ramblings</title>
    <link>https://rmoff.net/categories/decodable/</link>
    <description>Recent content in Decodable on rmoff&#39;s random ramblings</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 19 Nov 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://rmoff.net/categories/decodable/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Streaming Data from Postgres to Snowflake with CDC and Decodable</title>
      <link>https://rmoff.net/2024/11/19/streaming-data-from-postgres-to-snowflake-with-cdc-and-decodable/</link>
      <pubDate>Tue, 19 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://rmoff.net/2024/11/19/streaming-data-from-postgres-to-snowflake-with-cdc-and-decodable/</guid>
      <description>&lt;div class=&#34;admonitionblock note&#34;&gt;&#xA;&lt;table&gt;&#xA;&lt;tbody&gt;&lt;tr&gt;&#xA;&lt;td class=&#34;icon&#34;&gt;&#xA;&lt;div class=&#34;title&#34;&gt;Note&lt;/div&gt;&#xA;&lt;/td&gt;&#xA;&lt;td class=&#34;content&#34;&gt;&#xA;This post originally appeared on the &lt;a href=&#34;https://www.decodable.co/blog/streaming-data-from-postgres-to-snowflake&#34;&gt;Decodable blog&lt;/a&gt;.&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&lt;/table&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;In my  &lt;a href=&#34;https://rmoff.net/2024/10/15/why-do-i-need-cdc/&#34;&gt;last blog post&lt;/a&gt;  I looked at why you might need CDC.&#xA;In this post Iâ€™m going to put it into practice with probably the most common use caseâ€”extracting data from an operational transactional database to store somewhere else for analytics.&#xA;Iâ€™m going to show Postgres to Snowflake, but the pattern is the same for pretty much any combination, such as MySQL to BigQuery, SQL Server to Redshift, and so on.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Declarative Resource Management for Real-time ETL with Decodable</title>
      <link>https://rmoff.net/2024/08/14/declarative-resource-management-for-real-time-etl-with-decodable/</link>
      <pubDate>Wed, 14 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://rmoff.net/2024/08/14/declarative-resource-management-for-real-time-etl-with-decodable/</guid>
      <description>&lt;div class=&#34;admonitionblock note&#34;&gt;&#xA;&lt;table&gt;&#xA;&lt;tbody&gt;&lt;tr&gt;&#xA;&lt;td class=&#34;icon&#34;&gt;&#xA;&lt;div class=&#34;title&#34;&gt;Note&lt;/div&gt;&#xA;&lt;/td&gt;&#xA;&lt;td class=&#34;content&#34;&gt;&#xA;This post originally appeared on the &lt;a href=&#34;https://www.decodable.co/blog/declarative-resource-management&#34;&gt;Decodable blog&lt;/a&gt;.&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&lt;/table&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;So youâ€™ve built your first real-time ETL pipeline with Decodable: congratulations!&#xA;Now what?&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>How to Migrate from Amazon MSF</title>
      <link>https://rmoff.net/2024/07/30/how-to-migrate-from-amazon-msf/</link>
      <pubDate>Tue, 30 Jul 2024 00:00:00 +0000</pubDate>
      <guid>https://rmoff.net/2024/07/30/how-to-migrate-from-amazon-msf/</guid>
      <description>&lt;div class=&#34;admonitionblock note&#34;&gt;&#xA;&lt;table&gt;&#xA;&lt;tbody&gt;&lt;tr&gt;&#xA;&lt;td class=&#34;icon&#34;&gt;&#xA;&lt;div class=&#34;title&#34;&gt;Note&lt;/div&gt;&#xA;&lt;/td&gt;&#xA;&lt;td class=&#34;content&#34;&gt;&#xA;This post originally appeared on the &lt;a href=&#34;https://www.decodable.co/blog/migrating-apache-flink-jobs-from-amazon-msf-to-decodable&#34;&gt;Decodable blog&lt;/a&gt;.&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&lt;/table&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Amazon Managed Service for Apache Flink (MSF) is one of several providers of hosted Flink.&#xA;As my colleague Gunnar Morling described in  &lt;a href=&#34;https://www.decodable.co/blog/your-first-apache-flink-job&#34;&gt;his recent article&lt;/a&gt; , it can be used to run a Flink job that youâ€™ve written in Java or Python (PyFlink).&#xA;But did you know that this isnâ€™t the only wayâ€”or perhaps even the best wayâ€”to have your Flink jobs run for you?&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Decodable vs. Amazon MSF: Getting Started with Flink SQL</title>
      <link>https://rmoff.net/2024/07/02/decodable-vs.-amazon-msf-getting-started-with-flink-sql/</link>
      <pubDate>Tue, 02 Jul 2024 00:00:00 +0000</pubDate>
      <guid>https://rmoff.net/2024/07/02/decodable-vs.-amazon-msf-getting-started-with-flink-sql/</guid>
      <description>&lt;div class=&#34;admonitionblock note&#34;&gt;&#xA;&lt;table&gt;&#xA;&lt;tbody&gt;&lt;tr&gt;&#xA;&lt;td class=&#34;icon&#34;&gt;&#xA;&lt;div class=&#34;title&#34;&gt;Note&lt;/div&gt;&#xA;&lt;/td&gt;&#xA;&lt;td class=&#34;content&#34;&gt;&#xA;This post originally appeared on the &lt;a href=&#34;https://www.decodable.co/blog/decodable-vs-msf-getting-started-with-flink-sql&#34;&gt;Decodable blog&lt;/a&gt;.&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&lt;/table&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;One of the things that I love about SQL is the power that it gives you to work with data in a declarative manner.&#xA;I want this thingâ€¦go do it.&#xA;How should it do it?&#xA;Well thatâ€™s the problem for the particular engine, not me.&#xA;As a language with a pedigree of multiple decades and no sign of waning (despite a wobbly patch for some whilst NoSQL figured out they actually wanted to be NewSQL ðŸ˜‰), itâ€™s the &lt;em&gt;lingua franca&lt;/em&gt; of data systems.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>How to get data from Apache Kafka to Apache Iceberg on S3 with Decodable</title>
      <link>https://rmoff.net/2024/06/18/how-to-get-data-from-apache-kafka-to-apache-iceberg-on-s3-with-decodable/</link>
      <pubDate>Tue, 18 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://rmoff.net/2024/06/18/how-to-get-data-from-apache-kafka-to-apache-iceberg-on-s3-with-decodable/</guid>
      <description>&lt;div class=&#34;admonitionblock note&#34;&gt;&#xA;&lt;table&gt;&#xA;&lt;tbody&gt;&lt;tr&gt;&#xA;&lt;td class=&#34;icon&#34;&gt;&#xA;&lt;div class=&#34;title&#34;&gt;Note&lt;/div&gt;&#xA;&lt;/td&gt;&#xA;&lt;td class=&#34;content&#34;&gt;&#xA;This post originally appeared on the &lt;a href=&#34;https://www.decodable.co/blog/kafka-to-iceberg-with-decodable&#34;&gt;Decodable blog&lt;/a&gt;.&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&lt;/table&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://iceberg.apache.org/&#34;&gt;Apache Iceberg&lt;/a&gt;  is an open table format.&#xA;It combines the benefits of data lakes (open standards, cheap object storage) with the good things that data warehouses have, like first-class support for tables and SQL capabilities including updates to data in place, time-travel, and transactions.&#xA;With the recent  &lt;a href=&#34;https://www.databricks.com/company/newsroom/press-releases/databricks-agrees-acquire-tabular-company-founded-original-creators&#34;&gt;acquisition&lt;/a&gt;  by Databricks of Tabularâ€”one of the main companies that contribute to Icebergâ€”itâ€™s clear that Iceberg is winning out as one of the primary contenders in this space.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
  </channel>
</rss>
