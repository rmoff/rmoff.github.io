<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Snowflake on rmoff&#39;s random ramblings</title>
    <link>https://rmoff.net/categories/snowflake/</link>
    <description>Recent content in Snowflake on rmoff&#39;s random ramblings</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 19 Nov 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://rmoff.net/categories/snowflake/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Streaming Data from Postgres to Snowflake with CDC and Decodable</title>
      <link>https://rmoff.net/2024/11/19/streaming-data-from-postgres-to-snowflake-with-cdc-and-decodable/</link>
      <pubDate>Tue, 19 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://rmoff.net/2024/11/19/streaming-data-from-postgres-to-snowflake-with-cdc-and-decodable/</guid>
      <description>&lt;div class=&#34;admonitionblock note&#34;&gt;&#xA;&lt;table&gt;&#xA;&lt;tbody&gt;&lt;tr&gt;&#xA;&lt;td class=&#34;icon&#34;&gt;&#xA;&lt;i class=&#34;fa icon-note&#34; title=&#34;Note&#34;&gt;&lt;/i&gt;&#xA;&lt;/td&gt;&#xA;&lt;td class=&#34;content&#34;&gt;&#xA;This post originally appeared on the &lt;a href=&#34;https://www.decodable.co/blog/streaming-data-from-postgres-to-snowflake&#34;&gt;Decodable blog&lt;/a&gt;.&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&lt;/table&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;In my  &lt;a href=&#34;https://rmoff.net/2024/10/15/why-do-i-need-cdc/&#34;&gt;last blog post&lt;/a&gt;  I looked at why you might need CDC.&#xA;In this post I’m going to put it into practice with probably the most common use case—extracting data from an operational transactional database to store somewhere else for analytics.&#xA;I’m going to show Postgres to Snowflake, but the pattern is the same for pretty much any combination, such as MySQL to BigQuery, SQL Server to Redshift, and so on.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Streaming data from SQL Server to Kafka to Snowflake ❄️ with Kafka Connect</title>
      <link>https://rmoff.net/2019/11/20/streaming-data-from-sql-server-to-kafka-to-snowflake-with-kafka-connect/</link>
      <pubDate>Wed, 20 Nov 2019 17:59:50 +0000</pubDate>
      <guid>https://rmoff.net/2019/11/20/streaming-data-from-sql-server-to-kafka-to-snowflake-with-kafka-connect/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.snowflake.com/&#34;&gt;Snowflake&lt;/a&gt; is &lt;em&gt;the data warehouse built for the cloud&lt;/em&gt;, so let’s get all ☁️ cloudy and stream some data from Kafka running in &lt;a href=&#34;https://confluent.cloud&#34;&gt;Confluent Cloud&lt;/a&gt; to Snowflake!&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;What I’m showing also works just as well for an on-premises Kafka cluster. I’m using SQL Server as an example data source, with Debezium to capture and stream and changes from it into Kafka.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;imageblock&#34;&gt;&#xA;&lt;div class=&#34;content&#34;&gt;&#xA;&lt;img src=&#34;https://rmoff.net/images/2019/11/sf01.png&#34; alt=&#34;sf01&#34;/&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;I’m assuming that you’ve signed up for &lt;a href=&#34;https://confluent.cloud/&#34;&gt;Confluent Cloud&lt;/a&gt; and &lt;a href=&#34;https://www.snowflake.com/try-the-data-warehouse-built-for-the-cloud/&#34;&gt;Snowflake&lt;/a&gt; and are the proud owner of credentials for both. I’m going to use a demo rig based on Docker to provision SQL Server and a Kafka Connect worker, but you can use your own setup if you want.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
  </channel>
</rss>
