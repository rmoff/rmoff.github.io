<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>KSQL on rmoff&#39;s random ramblings</title>
    <link>https://rmoff.net/categories/ksql/</link>
    <description>Recent content in KSQL on rmoff&#39;s random ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 09 May 2019 10:01:50 +0100</lastBuildDate><atom:link href="https://rmoff.net/categories/ksql/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>A poor man&#39;s KSQL EXPLODE/UNNEST technique</title>
      <link>https://rmoff.net/2019/05/09/a-poor-mans-ksql-explode/unnest-technique/</link>
      <pubDate>Thu, 09 May 2019 10:01:50 +0100</pubDate>
      
      <guid>https://rmoff.net/2019/05/09/a-poor-mans-ksql-explode/unnest-technique/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;There is an &lt;a href=&#34;https://github.com/confluentinc/ksql/issues/527&#34;&gt;open issue for support of &lt;code&gt;EXPLODE&lt;/code&gt;/&lt;code&gt;UNNEST&lt;/code&gt; functionality in KSQL&lt;/a&gt;, and if you need it then do up-vote the issue. Here I detail a hacky, but effective, workaround for exploding arrays into multiple messages—so long as you know the upper-bound on your array.&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Pivoting Aggregates in Ksql</title>
      <link>https://rmoff.net/2019/04/17/pivoting-aggregates-in-ksql/</link>
      <pubDate>Wed, 17 Apr 2019 15:42:56 +0100</pubDate>
      
      <guid>https://rmoff.net/2019/04/17/pivoting-aggregates-in-ksql/</guid>
      <description>&lt;p&gt;Prompted by &lt;a href=&#34;https://stackoverflow.com/questions/55680719/aggregating-by-multiple-fields-and-map-to-one-result&#34;&gt;a question on StackOverflow&lt;/a&gt;, the requirement is to take a series of events related to a common key and for each key output a series of aggregates derived from a changing value in the events. I&amp;rsquo;ll use the data from the question, based on ticket statuses. Each ticket can go through various stages, and the requirement was to show, per customer, how many tickets are currently at each stage.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Connecting KSQL to a Secured Schema Registry</title>
      <link>https://rmoff.net/2019/04/12/connecting-ksql-to-a-secured-schema-registry/</link>
      <pubDate>Fri, 12 Apr 2019 12:59:33 +0100</pubDate>
      
      <guid>https://rmoff.net/2019/04/12/connecting-ksql-to-a-secured-schema-registry/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;See also : &lt;a href=&#34;https://docs.confluent.io/current/ksql/docs/installation/server-config/security.html#configuring-ksql-for-secured-sr-long&#34; class=&#34;bare&#34;&gt;https://docs.confluent.io/current/ksql/docs/installation/server-config/security.html#configuring-ksql-for-secured-sr-long&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Confluent Cloud now includes a secured Schema Registry, which you can use from external applications, including KSQL.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;To configure KSQL for it you need to set:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;ksql.schema.registry.url&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;https://&amp;lt;Schema Registry endpoint&amp;gt;
ksql.schema.registry.basic.auth.credentials.source&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;USER_INFO
ksql.schema.registry.basic.auth.user.info&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&amp;lt;Schema Registry API Key&amp;gt;:&amp;lt;Schema Registry API Secret&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Exploring KSQL Stream-Stream Joins</title>
      <link>https://rmoff.net/2019/03/28/exploring-ksql-stream-stream-joins/</link>
      <pubDate>Thu, 28 Mar 2019 14:46:24 +0000</pubDate>
      
      <guid>https://rmoff.net/2019/03/28/exploring-ksql-stream-stream-joins/</guid>
      <description>&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;What can you use stream-stream joins for? Can you use them to join between a stream of orders and stream of related shipments to do useful things? What’s not supported in KSQL, where are the cracks?&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Terminate All KSQL Queries</title>
      <link>https://rmoff.net/2019/03/25/terminate-all-ksql-queries/</link>
      <pubDate>Mon, 25 Mar 2019 16:45:40 +0000</pubDate>
      
      <guid>https://rmoff.net/2019/03/25/terminate-all-ksql-queries/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Before you can drop a stream or table that’s populated by a query in KSQL, you have to terminate any queries upon which the object is dependent. Here’s a bit of &lt;code&gt;jq&lt;/code&gt; &amp;amp; &lt;code&gt;xargs&lt;/code&gt; magic to terminate &lt;strong&gt;all&lt;/strong&gt; queries that are currently running&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>How KSQL handles case</title>
      <link>https://rmoff.net/2019/01/21/how-ksql-handles-case/</link>
      <pubDate>Mon, 21 Jan 2019 12:05:48 +0000</pubDate>
      
      <guid>https://rmoff.net/2019/01/21/how-ksql-handles-case/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.confluent.io/ksql&#34;&gt;KSQL&lt;/a&gt; is generally case-sensitive. Very sensitive, at times ;-)&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>KSQL REST API cheatsheet</title>
      <link>https://rmoff.net/2019/01/17/ksql-rest-api-cheatsheet/</link>
      <pubDate>Thu, 17 Jan 2019 12:12:11 +0000</pubDate>
      
      <guid>https://rmoff.net/2019/01/17/ksql-rest-api-cheatsheet/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Full reference is &lt;a href=&#34;https://docs.confluent.io/current/ksql/docs/developer-guide/api.html&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Docker Tips and Tricks with Kafka Connect, ksqlDB, and Kafka</title>
      <link>https://rmoff.net/2018/12/15/docker-tips-and-tricks-with-kafka-connect-ksqldb-and-kafka/</link>
      <pubDate>Sat, 15 Dec 2018 22:00:55 +0000</pubDate>
      
      <guid>https://rmoff.net/2018/12/15/docker-tips-and-tricks-with-kafka-connect-ksqldb-and-kafka/</guid>
      <description>A few years ago a colleague of mine told me about this thing called Docker, and I must admit I dismissed it as a fad…how wrong was I. Docker, and Docker Compose, are one of my key tools of the trade. With them I can build self-contained environments for tutorials, demos, conference talks etc. Tear it down, run it again, without worrying that somewhere a local config changed and will break things.</description>
    </item>
    
    <item>
      <title>Flatten CDC records in KSQL</title>
      <link>https://rmoff.net/2018/10/11/flatten-cdc-records-in-ksql/</link>
      <pubDate>Thu, 11 Oct 2018 15:13:59 +0000</pubDate>
      
      <guid>https://rmoff.net/2018/10/11/flatten-cdc-records-in-ksql/</guid>
      <description>&lt;h3 id=&#34;the-problem---nested-messages-in-kafka&#34;&gt;The problem - nested messages in Kafka&lt;/h3&gt;
&lt;p&gt;Data comes into Kafka in many shapes and sizes. Sometimes it&amp;rsquo;s from CDC tools, and may be nested like this:&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Exploring JMX with jmxterm</title>
      <link>https://rmoff.net/2018/09/19/exploring-jmx-with-jmxterm/</link>
      <pubDate>Wed, 19 Sep 2018 08:11:00 +0000</pubDate>
      
      <guid>https://rmoff.net/2018/09/19/exploring-jmx-with-jmxterm/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Check out the &lt;a href=&#34;https://github.com/jiaqi/jmxterm/&#34;&gt;jmxterm repository&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Download jmxterm from &lt;a href=&#34;https://docs.cyclopsgroup.org/jmxterm&#34;&gt;https://docs.cyclopsgroup.org/jmxterm&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Window Timestamps in KSQL / Integration with Elasticsearch</title>
      <link>https://rmoff.net/2018/09/03/window-timestamps-in-ksql-/-integration-with-elasticsearch/</link>
      <pubDate>Mon, 03 Sep 2018 16:16:30 +0000</pubDate>
      
      <guid>https://rmoff.net/2018/09/03/window-timestamps-in-ksql-/-integration-with-elasticsearch/</guid>
      <description>KSQL provides the ability to create windowed aggregations. For example, count the number of messages in a 1 minute window, grouped by a particular column:
CREATE TABLE RATINGS_BY_CLUB_STATUS AS \ SELECT CLUB_STATUS, COUNT(*) AS RATING_COUNT \ FROM RATINGS_WITH_CUSTOMER_DATA \ WINDOW TUMBLING (SIZE 1 MINUTES) \ GROUP BY CLUB_STATUS; How KSQL, and Kafka Streams, stores the window timestamp associated with an aggregate, has recently changed. See #1497 for details.
Whereas previously the Kafka message timestamp (accessible through the KSQL ROWTIME system column) stored the start of the window for which the aggregate had been calculated, this changed in July 2018 to instead be the timestamp of the latest message to update that aggregate value.</description>
    </item>
    
    <item>
      <title>Analysing Network Data with Apache Kafka, KSQL, and Elasticsearch</title>
      <link>https://rmoff.net/2018/06/17/analysing-network-data-with-apache-kafka-ksql-and-elasticsearch/</link>
      <pubDate>Sun, 17 Jun 2018 11:35:20 +0000</pubDate>
      
      <guid>https://rmoff.net/2018/06/17/analysing-network-data-with-apache-kafka-ksql-and-elasticsearch/</guid>
      <description>In this article I demonstrated how to use KSQL to filter streams of network event data. As well as filtering, KSQL can be used to easily enrich streams. In this article we&amp;rsquo;ll see how this enriched data can be used to drive analysis in Elasticsearch and Kibana—and how KSQL again came into use for building some stream processing as a result of the discovery made.
The data came from my home Ubiquiti router, and took two forms:</description>
    </item>
    
    <item>
      <title>Stream-Table Joins in KSQL: Stream events must be timestamped after the Table messages</title>
      <link>https://rmoff.net/2018/05/17/stream-table-joins-in-ksql-stream-events-must-be-timestamped-after-the-table-messages/</link>
      <pubDate>Thu, 17 May 2018 10:16:43 +0000</pubDate>
      
      <guid>https://rmoff.net/2018/05/17/stream-table-joins-in-ksql-stream-events-must-be-timestamped-after-the-table-messages/</guid>
      <description>(preserving this StackOverflow answer for posterity and future Googlers)
tl;dr When doing a stream-table join, your table messages must already exist (and must be timestamped) before the stream messages. If you re-emit your source stream messages, after the table topic is populated, the join will succeed.
Example data Use kafakcat to populate topics:
kafkacat -b localhost:9092 -P -t sessionDetails &amp;lt;&amp;lt;EOF {&amp;quot;Media&amp;quot;:&amp;quot;Foo&amp;quot;,&amp;quot;SessionIdTime&amp;quot;:&amp;quot;2018-05-17 11:25:33 BST&amp;quot;,&amp;quot;SessionIdSeq&amp;quot;:1} {&amp;quot;Media&amp;quot;:&amp;quot;Foo&amp;quot;,&amp;quot;SessionIdTime&amp;quot;:&amp;quot;2018-05-17 11:26:33 BST&amp;quot;,&amp;quot;SessionIdSeq&amp;quot;:2} EOF kafkacat -b localhost:9092 -P -t voipDetails &amp;lt;&amp;lt;EOF {&amp;quot;SessionIdTime&amp;quot;:&amp;quot;2018-05-17 11:25:33 BST&amp;quot;,&amp;quot;SessionIdSeq&amp;quot;:1,&amp;quot;Details&amp;quot;:&amp;quot;Bar1a&amp;quot;} {&amp;quot;SessionIdTime&amp;quot;:&amp;quot;2018-05-17 11:25:33 BST&amp;quot;,&amp;quot;SessionIdSeq&amp;quot;:1,&amp;quot;Details&amp;quot;:&amp;quot;Bar1b&amp;quot;} {&amp;quot;SessionIdTime&amp;quot;:&amp;quot;2018-05-17 11:26:33 BST&amp;quot;,&amp;quot;SessionIdSeq&amp;quot;:2,&amp;quot;Details&amp;quot;:&amp;quot;Bar2&amp;quot;} EOF  Validate topic contents:</description>
    </item>
    
  </channel>
</rss>
