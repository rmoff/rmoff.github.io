<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>etl on rmoff&#39;s random ramblings</title>
    <link>https://rmoff.net/categories/etl/</link>
    <description>Recent content in etl on rmoff&#39;s random ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 06 Mar 2018 22:18:00 +0000</lastBuildDate><atom:link href="https://rmoff.net/categories/etl/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Why Do We Need Streaming ETL?</title>
      <link>https://rmoff.net/2018/03/06/why-do-we-need-streaming-etl/</link>
      <pubDate>Tue, 06 Mar 2018 22:18:00 +0000</pubDate>
      
      <guid>https://rmoff.net/2018/03/06/why-do-we-need-streaming-etl/</guid>
      <description>(This is an expanded version of the intro to an article I posted over on the Confluent blog. Here I get to be as verbose as I like ;))
My first job from university was building a datawarehouse for a retailer in the UK. Back then, it was writing COBOL jobs to load tables in DB2. We waited for all the shops to close and do their end of day system processing, and send their data back to the central mainframe.</description>
    </item>
    
    <item>
      <title>Oracle 11g - How to force a sql_id to use a plan_hash_value using SQL Baselines</title>
      <link>https://rmoff.net/2011/06/28/oracle-11g-how-to-force-a-sql_id-to-use-a-plan_hash_value-using-sql-baselines/</link>
      <pubDate>Tue, 28 Jun 2011 00:00:00 +0000</pubDate>
      
      <guid>https://rmoff.net/2011/06/28/oracle-11g-how-to-force-a-sql_id-to-use-a-plan_hash_value-using-sql-baselines/</guid>
      <description>Here&amp;rsquo;s a scenario that&amp;rsquo;ll be depressingly familiar to most reading this: after ages of running fine, and no changes to the code, a query suddenly starts running for magnitudes longer than it used to.
In this instance it was an ETL step which used to take c.1 hour, and was now at 5 hours and counting. Since it still hadn&amp;rsquo;t finished, and the gods had conspired to bring down Grid too (unrelated), I generated a SQL Monitor report to see what was happening: [sourcecode language=&amp;ldquo;sql&amp;rdquo;] select DBMS_SQLTUNE.</description>
    </item>
    
    <item>
      <title>Data Warehousing and Statistics in Oracle 11g - incremental global statistics</title>
      <link>https://rmoff.net/2010/12/30/data-warehousing-and-statistics-in-oracle-11g-incremental-global-statistics/</link>
      <pubDate>Thu, 30 Dec 2010 00:00:00 +0000</pubDate>
      
      <guid>https://rmoff.net/2010/12/30/data-warehousing-and-statistics-in-oracle-11g-incremental-global-statistics/</guid>
      <description>This is a series of posts where I hope to humbly plug some gaps in the information available (or which has escaped my google-fu) regarding statistics management in Oracle 11g specific to Data Warehousing.
Incremental Global Statistics is new functionality in Oracle 11g (and 10.2.0.4?) and is explained in depth in several places including:
 OracleÂ® Database Performance Tuning Guide - Statistics on Partitioned Objects Greg Rahn - Oracle 11g: Incremental Global Statistics On Partitioned Tables Inside the Oracle Optimiser - Maintaining statistics on large partitioned tables Amit Poddar - One Pass Distinct Sampling (ppt - slides 52 onwards are most relevant)  In essence, Oracle maintains information about each partition when statistics is gathered on the partition, and it uses this to work out the global statistics - without having to scan the whole table.</description>
    </item>
    
    <item>
      <title>Analysing ODI batch performance</title>
      <link>https://rmoff.net/2010/11/03/analysing-odi-batch-performance/</link>
      <pubDate>Wed, 03 Nov 2010 00:00:00 +0000</pubDate>
      
      <guid>https://rmoff.net/2010/11/03/analysing-odi-batch-performance/</guid>
      <description>I&amp;rsquo;ve been involved with some performance work around an ODI DWH load batch. The batch comprises well over 1000 tasks in ODI, and whilst the Operator console is not a bad interface, it&amp;rsquo;s not very easy to spot the areas consuming the most runtime.
Here&amp;rsquo;s a set of SQL statements to run against the ODI work repository tables to help you methodically find the steps of most interest for tuning efforts.</description>
    </item>
    
    <item>
      <title>Mark Rittman&#39;s OBIEE repository for DAC</title>
      <link>https://rmoff.net/2009/07/23/mark-rittmans-obiee-repository-for-dac/</link>
      <pubDate>Thu, 23 Jul 2009 00:00:00 +0000</pubDate>
      
      <guid>https://rmoff.net/2009/07/23/mark-rittmans-obiee-repository-for-dac/</guid>
      <description>Mark Rittman has an excellent article about querying the DAC repository database tables, including a downloadable RPD file. Being new to working with RPDs I thought it would be good practise to explore this as well as hopefully get some useful information about our current ETL deployment.
I downloaded the RPD to c:\OracleBI\server\Repository and opened it up in the Admin tool (Administrator/Administrator).
First off I changed the connection pool to point to my DAC repository database, having setup a TNS entry for it first.</description>
    </item>
    
  </channel>
</rss>
