<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>jq on rmoff&#39;s random ramblings</title>
    <link>https://rmoff.net/categories/jq/</link>
    <description>Recent content in jq on rmoff&#39;s random ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 30 Sep 2020 20:54:09 +0100</lastBuildDate><atom:link href="https://rmoff.net/categories/jq/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Setting key value when piping from `jq` to `kafkacat`</title>
      <link>https://rmoff.net/2020/09/30/setting-key-value-when-piping-from-jq-to-kafkacat/</link>
      <pubDate>Wed, 30 Sep 2020 20:54:09 +0100</pubDate>
      
      <guid>https://rmoff.net/2020/09/30/setting-key-value-when-piping-from-jq-to-kafkacat/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;One of my favourite hacks for getting data into Kafka is using kafkacat and &lt;code&gt;stdin&lt;/code&gt;, often from &lt;code&gt;jq&lt;/code&gt;. You can see this in action with &lt;a href=&#34;https://rmoff.net/2020/03/11/streaming-wi-fi-trace-data-from-raspberry-pi-to-apache-kafka-with-confluent-cloud/&#34;&gt;Wi-Fi data&lt;/a&gt;, &lt;a href=&#34;https://rmoff.net/2020/01/21/monitoring-sonos-with-ksqldb-influxdb-and-grafana/&#34;&gt;IoT data&lt;/a&gt;, and data from a &lt;a href=&#34;https://rmoff.net/2018/05/10/quick-n-easy-population-of-realistic-test-data-into-kafka/&#34;&gt;REST endpoint&lt;/a&gt;. This is fine for getting values into a Kafka message - but Kafka messages are &lt;strong&gt;key&lt;/strong&gt;/value, and being able to specify a key is can often be important.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Here’s a way to do that, using a separator and some &lt;code&gt;jq&lt;/code&gt; magic. Note that at the moment &lt;a href=&#34;https://github.com/edenhill/kafkacat/issues/140&#34;&gt;kafkacat only supports single byte separator characters&lt;/a&gt;, so you need to choose carefully. If you pick a separator that also appears in your data, it’s possibly going to have unintended consequences.&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Kafka Connect CLI tricks</title>
      <link>https://rmoff.net/2018/12/03/kafka-connect-cli-tricks/</link>
      <pubDate>Mon, 03 Dec 2018 14:50:45 +0000</pubDate>
      
      <guid>https://rmoff.net/2018/12/03/kafka-connect-cli-tricks/</guid>
      <description>I do lots of work with Kafka Connect, almost entirely in Distributed mode—even just with 1 node -&amp;gt; makes scaling out much easier when/if needed. Because I&amp;rsquo;m using Distributed mode, I use the Kafka Connect REST API to configure and manage it. Whilst others might use GUI REST tools like Postman etc, I tend to just use the commandline. Here are some useful snippets that I use all the time.</description>
    </item>
    
    <item>
      <title>Syntax highlighting code for presentation slides</title>
      <link>https://rmoff.net/2018/06/20/syntax-highlighting-code-for-presentation-slides/</link>
      <pubDate>Wed, 20 Jun 2018 18:32:10 +0000</pubDate>
      
      <guid>https://rmoff.net/2018/06/20/syntax-highlighting-code-for-presentation-slides/</guid>
      <description>So you&amp;rsquo;ve got a code sample you want to share in a presentation, but whilst it looks beautiful in your text-editor with syntax highlighting, it&amp;rsquo;s fugly in Keynote? You could screenshot it and paste the image into your slide, but you just know that you&amp;rsquo;ll want to change that code, and end up re-snapshotting it…what a PITA.
Better to have a nicely syntax-highlighted code snippet that you can paste as formatted text into Keynote and amend from there as needed.</description>
    </item>
    
    <item>
      <title>Simple export/import of Data Sources in Grafana</title>
      <link>https://rmoff.net/2017/08/08/simple-export/import-of-data-sources-in-grafana/</link>
      <pubDate>Tue, 08 Aug 2017 19:32:00 +0000</pubDate>
      
      <guid>https://rmoff.net/2017/08/08/simple-export/import-of-data-sources-in-grafana/</guid>
      <description>Grafana API Reference
Export all Grafana data sources to data_sources folder mkdir -p data_sources &amp;amp;&amp;amp; curl -s &amp;quot;http://localhost:3000/api/datasources&amp;quot; -u admin:admin|jq -c -M &#39;.[]&#39;|split -l 1 - data_sources/  This exports each data source to a separate JSON file in the data_sources folder.
Load data sources back in from folder This submits every file that exists in the data_sources folder to Grafana as a new data source definition.
for i in data_sources/*; do \ curl -X &amp;quot;POST&amp;quot; &amp;quot;http://localhost:3000/api/datasources&amp;quot; \ -H &amp;quot;Content-Type: application/json&amp;quot; \ --user admin:admin \ --data-binary @$i done  </description>
    </item>
    
  </channel>
</rss>
