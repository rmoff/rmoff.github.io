<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Postgres on rmoff&#39;s random ramblings</title>
    <link>https://rmoff.net/categories/postgres/</link>
    <description>Recent content in Postgres on rmoff&#39;s random ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 03 Nov 2020 17:14:33 +0000</lastBuildDate><atom:link href="https://rmoff.net/categories/postgres/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Kafka Connect, ksqlDB, and Kafka Tombstone messages</title>
      <link>https://rmoff.net/2020/11/03/kafka-connect-ksqldb-and-kafka-tombstone-messages/</link>
      <pubDate>Tue, 03 Nov 2020 17:14:33 +0000</pubDate>
      
      <guid>https://rmoff.net/2020/11/03/kafka-connect-ksqldb-and-kafka-tombstone-messages/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;As you may already realise, Kafka is not just a fancy message bus, or a pipe for big data. It’s an event streaming platform! If this is news to you, I’ll wait here whilst you &lt;a href=&#34;https://www.confluent.io/learn/kafka-tutorial/&#34;&gt;read this&lt;/a&gt; or &lt;a href=&#34;https://rmoff.dev/kafka101&#34;&gt;watch this&lt;/a&gt;…&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Loading CSV data into Kafka</title>
      <link>https://rmoff.net/2020/06/17/loading-csv-data-into-kafka/</link>
      <pubDate>Wed, 17 Jun 2020 17:57:18 +0100</pubDate>
      
      <guid>https://rmoff.net/2020/06/17/loading-csv-data-into-kafka/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;For whatever reason, CSV still exists as a ubiquitous data interchange format. It doesn’t get much simpler: chuck some plaintext with fields separated by commas into a file and stick &lt;code&gt;.csv&lt;/code&gt; on the end. If you’re feeling helpful you can include a header row with field names in.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;pre&gt;&lt;code class=&#34;language-csv&#34; data-lang=&#34;csv&#34;&gt;order_id,customer_id,order_total_usd,make,model,delivery_city,delivery_company,delivery_address
1,535,190899.73,Dodge,Ram Wagon B350,Sheffield,DuBuque LLC,2810 Northland Avenue
2,671,33245.53,Volkswagen,Cabriolet,Edinburgh,Bechtelar-VonRueden,1 Macpherson Crossing&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In this article we’ll see how to load this CSV data into Kafka, without even needing to write any code&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Streaming messages from RabbitMQ into Kafka with Kafka Connect</title>
      <link>https://rmoff.net/2020/01/08/streaming-messages-from-rabbitmq-into-kafka-with-kafka-connect/</link>
      <pubDate>Wed, 08 Jan 2020 13:06:57 +0000</pubDate>
      
      <guid>https://rmoff.net/2020/01/08/streaming-messages-from-rabbitmq-into-kafka-with-kafka-connect/</guid>
      <description>This was prompted by a question on StackOverflow to which I thought the answer would be straightforward, but turned out not to be so. And then I got a bit carried away and ended up with a nice example of how you can handle schema-less data coming from a system such as RabbitMQ and apply a schema to it.
   Note  This same pattern for ingesting bytes and applying a schema will work with other connectors such as MQTT     What?</description>
    </item>
    
  </channel>
</rss>
