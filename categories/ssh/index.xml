<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>SSH on rmoff&#39;s random ramblings</title>
    <link>https://rmoff.net/categories/ssh/</link>
    <description>Recent content in SSH on rmoff&#39;s random ramblings</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 18 Dec 2019 17:23:40 +0000</lastBuildDate>
    <atom:link href="https://rmoff.net/categories/ssh/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Detecting and Analysing SSH Attacks with ksqlDB</title>
      <link>https://rmoff.net/2019/12/18/detecting-and-analysing-ssh-attacks-with-ksqldb/</link>
      <pubDate>Wed, 18 Dec 2019 17:23:40 +0000</pubDate>
      <guid>https://rmoff.net/2019/12/18/detecting-and-analysing-ssh-attacks-with-ksqldb/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;I’ve &lt;a href=&#34;https://www.confluent.io/blog/real-time-syslog-processing-apache-kafka-ksql-part-1-filtering/&#34;&gt;written previously&lt;/a&gt; about ingesting Syslog into Kafka and using KSQL to analyse it. I want to revisit the subject since it’s nearly two years since I wrote about it and some things have changed since then.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;ksqlDB now includes the ability to define connectors from within it, which makes setting things up loads easier.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;You can find the &lt;a href=&#34;https://github.com/confluentinc/demo-scene/tree/master/syslog&#34;&gt;full rig to run this on GitHub&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;sect1&#34;&gt;&#xA;&lt;h2 id=&#34;_create_and_configure_the_syslog_connector&#34;&gt;Create and configure the Syslog connector&lt;/h2&gt;&#xA;&lt;div class=&#34;sectionbody&#34;&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;To start with, create a source connector:&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Copy MongoDB collections from remote to local instance</title>
      <link>https://rmoff.net/2019/12/17/copy-mongodb-collections-from-remote-to-local-instance/</link>
      <pubDate>Tue, 17 Dec 2019 20:23:49 +0000</pubDate>
      <guid>https://rmoff.net/2019/12/17/copy-mongodb-collections-from-remote-to-local-instance/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;This is revisiting &lt;a href=&#34;https://rmoff.net/2018/03/27/cloning-ubiquitis-mongodb-instance-to-a-separate-server/&#34;&gt;the blog I wrote a while back&lt;/a&gt;, which showed using &lt;code&gt;mongodump&lt;/code&gt; and &lt;code&gt;mongorestore&lt;/code&gt; to copy a MongoDB database from one machine (a Unifi CloudKey) to another. This time instead of a manual lift and shift, I wanted a simple way to automate the update of the target with changes made on the source.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;The source is as before, &lt;a href=&#34;https://www.ui.com/unifi/unifi-cloud-key/&#34;&gt;Unifi’s CloudKey&lt;/a&gt;, which runs MongoDB to store its data about the network - devices, access points, events, and so on.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
  </channel>
</rss>
