<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>JSON on rmoff&#39;s random ramblings</title>
    <link>https://rmoff.net/categories/json/</link>
    <description>Recent content in JSON on rmoff&#39;s random ramblings</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 03 Jul 2020 08:16:36 +0100</lastBuildDate>
    <atom:link href="https://rmoff.net/categories/json/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Why JSON isn&#39;t the same as JSON Schema in Kafka Connect converters and ksqlDB (Viewing Kafka messages bytes as hex)</title>
      <link>https://rmoff.net/2020/07/03/why-json-isnt-the-same-as-json-schema-in-kafka-connect-converters-and-ksqldb-viewing-kafka-messages-bytes-as-hex/</link>
      <pubDate>Fri, 03 Jul 2020 08:16:36 +0100</pubDate>
      <guid>https://rmoff.net/2020/07/03/why-json-isnt-the-same-as-json-schema-in-kafka-connect-converters-and-ksqldb-viewing-kafka-messages-bytes-as-hex/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Iâ€™ve been playing around with the new SerDes (serialisers/deserialisers) that shipped with Confluent Platform 5.5 - &lt;a href=&#34;https://docs.confluent.io/current/schema-registry/serdes-develop/index.html&#34;&gt;Protobuf, and JSON Schema&lt;/a&gt; (these were added to the existing support for Avro). The serialisers (and associated &lt;a href=&#34;https://docs.confluent.io/current/schema-registry/connect.html&#34;&gt;Kafka Connect converters&lt;/a&gt;) take a payload and serialise it into bytes for sending to Kafka, and I was interested in what those bytes look like. For that I used my favourite Kafka swiss-army knife: kafkacat.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Spark sqlContext.read.json - java.io.IOException: No input paths specified in job</title>
      <link>https://rmoff.net/2016/07/13/spark-sqlcontext.read.json-java.io.ioexception-no-input-paths-specified-in-job/</link>
      <pubDate>Wed, 13 Jul 2016 04:50:16 +0000</pubDate>
      <guid>https://rmoff.net/2016/07/13/spark-sqlcontext.read.json-java.io.ioexception-no-input-paths-specified-in-job/</guid>
      <description>&lt;p&gt;Trying to use &lt;a href=&#34;http://spark.apache.org/docs/latest/sql-programming-guide.html#json-datasets&#34;&gt;SparkSQL to read a JSON file&lt;/a&gt;, from either pyspark or spark-shell, I got this error:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;java.io.IOException: No input paths specified in job&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;scala&amp;gt; sqlContext.read.json(&amp;#34;/u02/custom/twitter/twitter.json&amp;#34;)&#xA;java.io.IOException: No input paths specified in job&#xA;        at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:202)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Despite the reference articles that I found using this local path syntax (&lt;code&gt;/u02/custom/twitter/twitter.json&lt;/code&gt;), it turned out that I needed to prefix it with &lt;code&gt;file://&lt;/code&gt;:&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;scala&amp;gt; sqlContext.read.json(&amp;#34;file:///u02/custom/twitter/twitter.json&amp;#34;)&#xA;res3: org.apache.spark.sql.DataFrame = [@timestamp: string, @version: string, contributors: string, coordinates: string, created_at: string, entities: struct&amp;lt;hashtags:array&amp;lt;struct&amp;lt;indices:array&amp;lt;bigint&amp;gt;,text:string&amp;gt;&amp;gt;,media:array&amp;lt;struct&amp;lt;display_url:string,expanded_url:string,id:bigint,id_str:string,indices:array&amp;lt;bigint&amp;gt;,media_url:string,media_url_https:string,sizes:struct&amp;lt;large:struct&amp;lt;h:bigint,resize:string,w:bigint&amp;gt;,medium:struct&amp;lt;h:bigint,resize:string,w:bigint&amp;gt;,small:struct&amp;lt;h:bigint,resize:string,w:bigint&amp;gt;,thumb:struct&amp;lt;h:bigint,resize:string,w:bigint&amp;gt;&amp;gt;,source_status_id:bigint,source_status_id_str:string,source_user_id:bigint,source_user_id_str:string,type:string,url:string&amp;gt;&amp;gt;,symbols:array&amp;lt;struct&amp;lt;indices:array&amp;lt;bigint&amp;gt;,text:string&amp;gt;&amp;gt;,urls:array&amp;lt;struct&amp;lt;display_url:string,expanded_url:string...&#xA;scala&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;An alternative to &lt;code&gt;file://&lt;/code&gt; is &lt;code&gt;hdfs://&lt;/code&gt;, assuming you have some data residing there too:&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
