<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws on rmoff&#39;s random ramblings</title>
    <link>https://rmoff.github.io/categories/aws/</link>
    <description>Recent content in Aws on rmoff&#39;s random ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 02 Aug 2018 19:38:00 +0000</lastBuildDate>
    
	<atom:link href="https://rmoff.github.io/categories/aws/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Kafka Listeners - Explained</title>
      <link>https://rmoff.github.io/2018/08/02/kafka-listeners-explained/</link>
      <pubDate>Thu, 02 Aug 2018 19:38:00 +0000</pubDate>
      
      <guid>https://rmoff.github.io/2018/08/02/kafka-listeners-explained/</guid>
      <description>This question comes up on StackOverflow and such places a lot, so here&amp;rsquo;s something to try and help.
tl;dr : You need to set advertised.listeners (or KAFKA_ADVERTISED_LISTENERS if you&amp;rsquo;re using Docker images) to the external address (host/IP) so that clients can correctly connect to it. Otherwise they&amp;rsquo;ll try to connect to the internal host address–and if that&amp;rsquo;s not reachable then problems ensue.
In this post I&amp;rsquo;ll talk about why this is necessary, and then show how to do it, based on a couple of scenarios - Docker, and AWS.</description>
    </item>
    
    <item>
      <title>Kafka Listeners - Explained</title>
      <link>https://rmoff.github.io/2018/08/02/kafka-listeners-explained/</link>
      <pubDate>Thu, 02 Aug 2018 19:38:00 +0000</pubDate>
      
      <guid>https://rmoff.github.io/2018/08/02/kafka-listeners-explained/</guid>
      <description>This question comes up on StackOverflow and such places a lot, so here&amp;rsquo;s something to try and help.
tl;dr : You need to set advertised.listeners (or KAFKA_ADVERTISED_LISTENERS if you&amp;rsquo;re using Docker images) to the external address (host/IP) so that clients can correctly connect to it. Otherwise they&amp;rsquo;ll try to connect to the internal host address–and if that&amp;rsquo;s not reachable then problems ensue.
In this post I&amp;rsquo;ll talk about why this is necessary, and then show how to do it, based on a couple of scenarios - Docker, and AWS.</description>
    </item>
    
    <item>
      <title>Install qemu on AWS EC2 Amazon Linux</title>
      <link>https://rmoff.github.io/2017/03/11/install-qemu-on-aws-ec2-amazon-linux/</link>
      <pubDate>Sat, 11 Mar 2017 15:04:00 +0000</pubDate>
      
      <guid>https://rmoff.github.io/2017/03/11/install-qemu-on-aws-ec2-amazon-linux/</guid>
      <description>Mucking about with virtual disks, I wanted to install qemu on a AWS EC2 instance in order to use qemu-img.
Not finding it in a yum repo, I built it from scratch:
$ uname -a Linux ip-10-0-1-238 4.4.41-36.55.amzn1.x86_64 #1 SMP Wed Jan 18 01:03:26 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux  Steps:
sudo yum install -y ghc-glib-devel ghc-glib autoconf autogen intltool libtool wget http://download.qemu-project.org/qemu-2.8.0.tar.xz tar xvJf qemu-2.8.0.tar.xz cd qemu-2.8.0 ./configure make sudo make install  I hit a few errors, recorded here for passing Googlers:</description>
    </item>
    
    <item>
      <title>Mount VMDK/OVF/OVA on Amazon Web Services (AWS) EC2</title>
      <link>https://rmoff.github.io/2017/03/11/mount-vmdk-ovf-ova-on-amazon-web-services-aws-ec2/</link>
      <pubDate>Sat, 11 Mar 2017 14:21:00 +0000</pubDate>
      
      <guid>https://rmoff.github.io/2017/03/11/mount-vmdk-ovf-ova-on-amazon-web-services-aws-ec2/</guid>
      <description>So you&amp;rsquo;ve got a Linux VM that you want to access the contents of in EC2 - how do you do it? Let&amp;rsquo;s see how. First up, convert the VMDK to raw image file. If you&amp;rsquo;ve got a ova/ovf then just untar it first (tar -xvf my_vm.ova), from which you should get the VMDK. With that, convert it using qemu-img:
$ time qemu-img convert -f vmdk -O raw SampleAppv607p-appliance-disk1.vmdk SampleAppv607p-appliance-disk1.raw real 16m36.</description>
    </item>
    
    <item>
      <title>boto / S3 errors</title>
      <link>https://rmoff.github.io/2016/10/14/boto-s3-errors/</link>
      <pubDate>Fri, 14 Oct 2016 08:41:30 +0000</pubDate>
      
      <guid>https://rmoff.github.io/2016/10/14/boto-s3-errors/</guid>
      <description>Presented without comment, warranty, or context - other than these might help a wandering code hacker.
When using SigV4, you must specify a &amp;lsquo;host&amp;rsquo; parameter boto.s3.connection.HostRequiredError: BotoClientError: When using SigV4, you must specify a &#39;host&#39; parameter.  To fix, switch
conn_s3 = boto.connect_s3()  for
conn_s3 = boto.connect_s3(host=&#39;s3.amazonaws.com&#39;)  You can see a list of endpoints here.
boto.exception.S3ResponseError: S3ResponseError: 400 Bad Request Make sure you&amp;rsquo;re specifying the correct hostname (see above) for the bucket&amp;rsquo;s region.</description>
    </item>
    
  </channel>
</rss>