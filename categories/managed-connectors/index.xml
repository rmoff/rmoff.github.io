<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Managed Connectors on rmoff&#39;s random ramblings</title>
    <link>https://rmoff.net/categories/managed-connectors/</link>
    <description>Recent content in Managed Connectors on rmoff&#39;s random ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 13 Mar 2025 11:29:40 +0000</lastBuildDate><atom:link href="https://rmoff.net/categories/managed-connectors/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Creating an HTTP Source connector on Confluent Cloud</title>
      <link>https://rmoff.net/2025/03/13/creating-an-http-source-connector-on-confluent-cloud/</link>
      <pubDate>Thu, 13 Mar 2025 11:29:40 +0000</pubDate>
      
      <guid>https://rmoff.net/2025/03/13/creating-an-http-source-connector-on-confluent-cloud/</guid>
      <description>In this blog article I’ll show you how you can use the confluent CLI to set up a Kafka cluster on Confluent Cloud, the necessary API keys, and then a managed connector. The connector I’m setting up is the HTTP Source (v2) connector.
It’s part of a pipeline that I’m working on to pull in a feed of data from the UK Environment Agency for processing. The data is spread across three endpoints, and one of the nice features of the HTTP Source (v2) connector is that one connector can pull data from more than one endpoint.</description>
    </item>
    
  </channel>
</rss>
