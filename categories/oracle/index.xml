<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Oracle on rmoff&#39;s random ramblings</title>
    <link>https://rmoff.github.io/categories/oracle/</link>
    <description>Recent content in Oracle on rmoff&#39;s random ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 12 Dec 2018 09:49:04 +0000</lastBuildDate>
    
	<atom:link href="https://rmoff.github.io/categories/oracle/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Streaming data from Oracle into Kafka (December 2018)</title>
      <link>https://rmoff.github.io/2018/12/12/streaming-data-from-oracle-into-kafka-december-2018/</link>
      <pubDate>Wed, 12 Dec 2018 09:49:04 +0000</pubDate>
      
      <guid>https://rmoff.github.io/2018/12/12/streaming-data-from-oracle-into-kafka-december-2018/</guid>
      <description>This is a short summary discussing what the options are for integrating Oracle RDBMS into Kafka, as of December 2018. For a more detailed background to why and how at a broader level for all databases (not just Oracle) see this blog and these slides.
What techniques &amp;amp; tools are there? As of December 2018, this is what the line-up looks like:
 Query-based CDC  The JDBC Connector for Kafka Connect, polls the database for new or changed data based on an incrementing ID column and/or update timestamp  Log-based CDC</description>
    </item>
    
    <item>
      <title>Logging in as root on Oracle Database Docker image</title>
      <link>https://rmoff.github.io/2018/11/30/logging-in-as-root-on-oracle-database-docker-image/</link>
      <pubDate>Fri, 30 Nov 2018 12:13:41 +0000</pubDate>
      
      <guid>https://rmoff.github.io/2018/11/30/logging-in-as-root-on-oracle-database-docker-image/</guid>
      <description>&lt;p&gt;tl;dr:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;docker &lt;span style=&#34;color:#008000&#34;&gt;exec&lt;/span&gt; --interactive &lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;&lt;/span&gt;            --tty &lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;&lt;/span&gt;            --user root &lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;&lt;/span&gt;            --workdir / &lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;&lt;/span&gt;            oracle-container-name bash&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Kafka Connect and Oracle data types</title>
      <link>https://rmoff.github.io/2018/05/21/kafka-connect-and-oracle-data-types/</link>
      <pubDate>Mon, 21 May 2018 08:59:00 +0000</pubDate>
      
      <guid>https://rmoff.github.io/2018/05/21/kafka-connect-and-oracle-data-types/</guid>
      <description>The Kafka Connect JDBC Connector by default does not cope so well with:
 NUMBER columns with no defined precision/scale. You may end up with apparent junk (bytes) in the output, or just errors. TIMESTAMP WITH LOCAL TIME ZONE. Throws JDBC type -102 not currently supported warning in the log.  Read more about NUMBER data type in the Oracle docs.
tl;dr : How do I make it work? There are several options:</description>
    </item>
    
    <item>
      <title>Streaming data from Kafka into Elasticsearch</title>
      <link>https://rmoff.github.io/2018/03/06/streaming-data-from-kafka-into-elasticsearch/</link>
      <pubDate>Tue, 06 Mar 2018 22:21:00 +0000</pubDate>
      
      <guid>https://rmoff.github.io/2018/03/06/streaming-data-from-kafka-into-elasticsearch/</guid>
      <description>This article is part of a series exploring Streaming ETL in practice. You can read about setting up the ingest of realtime events from a standard Oracle platform, and building streaming ETL using KSQL.
This post shows how we take data streaming in from an Oracle transactional system into Kafka, and simply stream it onwards into Elasticsearch. This is a common pattern, for enabling rapid search or analytics against data held in systems elsewhere.</description>
    </item>
    
    <item>
      <title>HOWTO: Oracle GoldenGate &#43; Apache Kafka &#43; Schema Registry &#43; Swingbench</title>
      <link>https://rmoff.github.io/2018/02/01/howto-oracle-goldengate-apache-kafka-schema-registry-swingbench/</link>
      <pubDate>Thu, 01 Feb 2018 23:15:00 +0000</pubDate>
      
      <guid>https://rmoff.github.io/2018/02/01/howto-oracle-goldengate-apache-kafka-schema-registry-swingbench/</guid>
      <description>This is the detailed step-by-step if you want to recreate the process I describe in the Confluent blog here
I used Oracle&amp;rsquo;s Oracle Developer Days VM, which comes preinstalled with Oracle 12cR2. You can see the notes on how to do this here. These notes take you through installing and configuring:
 Swingbench, to create a sample &amp;ldquo;Order Entry&amp;rdquo; schema and simulate events on the Oracle database Oracle GoldenGate (OGG, forthwith) and Oracle GoldenGate for Big Data (OGG-BD, forthwith)  I&amp;rsquo;m using Oracle GoldenGate 12.</description>
    </item>
    
    <item>
      <title>Installing Oracle GoldenGate for Big Data 12.3.1 with Kafka Connect and Confluent Platform</title>
      <link>https://rmoff.github.io/2017/11/21/installing-oracle-goldengate-for-big-data-12.3.1-with-kafka-connect-and-confluent-platform/</link>
      <pubDate>Tue, 21 Nov 2017 17:31:00 +0000</pubDate>
      
      <guid>https://rmoff.github.io/2017/11/21/installing-oracle-goldengate-for-big-data-12.3.1-with-kafka-connect-and-confluent-platform/</guid>
      <description>Some notes that I made on installing and configuring Oracle GoldenGate with Confluent Platform. Excuse the brevity, but hopefully useful to share!
I used the Oracle Developer Days VM for this - it&amp;rsquo;s preinstalled with Oracle 12cR2. Big Data Lite is nice but currently has an older version of GoldenGate.
Login to the VM (oracle/oracle) and then install some useful things:
sudo rpm -Uvh https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm sudo yum install -y screen htop collectl rlwrap p7zip unzip sysstat perf iotop sudo su - cd /etc/yum.</description>
    </item>
    
    <item>
      <title>Where will I be at OpenWorld / Oak Table World?</title>
      <link>https://rmoff.github.io/2017/09/29/where-will-i-be-at-openworld-oak-table-world/</link>
      <pubDate>Fri, 29 Sep 2017 19:02:55 +0000</pubDate>
      
      <guid>https://rmoff.github.io/2017/09/29/where-will-i-be-at-openworld-oak-table-world/</guid>
      <description>Here&amp;rsquo;s where I&amp;rsquo;ll be!
 If you use Google Calendar you can click on individual entries above and select copy to my calendar - which of course you&amp;rsquo;ll want to do for all the ones I&amp;rsquo;ve marked as [SPEAKING] :-)
Here&amp;rsquo;s a list of all the Apache Kafka talks at OpenWorld and JavaOne, most of which I&amp;rsquo;ll be trying to get to.</description>
    </item>
    
    <item>
      <title>Oracle GoldenGate / Kafka Connect Handler troubleshooting</title>
      <link>https://rmoff.github.io/2017/09/12/oracle-goldengate-kafka-connect-handler-troubleshooting/</link>
      <pubDate>Tue, 12 Sep 2017 21:55:16 +0000</pubDate>
      
      <guid>https://rmoff.github.io/2017/09/12/oracle-goldengate-kafka-connect-handler-troubleshooting/</guid>
      <description>The Replicat was kapput:
GGSCI (localhost.localdomain) 3&amp;gt; info rkconnoe REPLICAT RKCONNOE Last Started 2017-09-12 17:06 Status ABENDED Checkpoint Lag 00:00:00 (updated 00:46:34 ago) Log Read Checkpoint File /u01/app/ogg/dirdat/oe000000 First Record RBA 0  So checking the OGG error log ggserr.log showed
2017-09-12T17:06:17.572-0400 ERROR OGG-15051 Oracle GoldenGate Delivery, rkconnoe.prm: Java or JNI exception: oracle.goldengate.util.GGException: Error detected handling operation added event. 2017-09-12T17:06:17.572-0400 ERROR OGG-01668 Oracle GoldenGate Delivery, rkconnoe.prm: PROCESS ABENDING.  So checking the replicat log dirrpt/RKCONNOE_info_log4j.</description>
    </item>
    
    <item>
      <title>Kafka Connect JDBC - Oracle - Number of groups must be positive</title>
      <link>https://rmoff.github.io/2016/07/27/kafka-connect-jdbc-oracle-number-of-groups-must-be-positive/</link>
      <pubDate>Wed, 27 Jul 2016 15:23:14 +0000</pubDate>
      
      <guid>https://rmoff.github.io/2016/07/27/kafka-connect-jdbc-oracle-number-of-groups-must-be-positive/</guid>
      <description>There are various reasons for this error, but the one I hit was that the table name is case sensitive, and returned from Oracle by the JDBC driver in uppercase.
If you specify the tablename in your connecter config in lowercase, it won&amp;rsquo;t be matched, and this error is thrown. You can validate this by setting debug logging (edit etc/kafka/connect-log4j.properties to set log4j.rootLogger=DEBUG, stdout), and observe: (I&amp;rsquo;ve truncated some of the output for legibility)</description>
    </item>
    
    <item>
      <title>New version of BigDataLite VM from Oracle</title>
      <link>https://rmoff.github.io/2016/06/06/new-version-of-bigdatalite-vm-from-oracle/</link>
      <pubDate>Mon, 06 Jun 2016 22:28:25 +0000</pubDate>
      
      <guid>https://rmoff.github.io/2016/06/06/new-version-of-bigdatalite-vm-from-oracle/</guid>
      <description>Oracle&amp;rsquo;s excellent Big Data Lite VM has been updated, to version 4.5.
Download it here
Changes:
 CDH 5.5 -&amp;gt; 5.7 Big Data Spatial and Graph 1.1 -&amp;gt; 1.2 Big Data Discovery 1.1 -&amp;gt; 1.2 Oracle Big Data Connectors 4.4 -&amp;gt; 4.5 Oracle NoSQL 3.5 -&amp;gt; 4.0 GoldenGate 12.2.0.1 -&amp;gt; 12.2.0.1.1  </description>
    </item>
    
    <item>
      <title>Streaming Data through Oracle GoldenGate to Elasticsearch</title>
      <link>https://rmoff.github.io/2016/04/14/streaming-data-through-oracle-goldengate-to-elasticsearch/</link>
      <pubDate>Thu, 14 Apr 2016 22:51:43 +0000</pubDate>
      
      <guid>https://rmoff.github.io/2016/04/14/streaming-data-through-oracle-goldengate-to-elasticsearch/</guid>
      <description>Recently added to the oracledi project over at java.net is an adaptor enabling Oracle GoldenGate (OGG) to send data to Elasticsearch. This adds a powerful alternative to [micro-]batch extract via JDBC from Oracle to Elasticsearch, which I wrote about recently over at the Elastic blog.
Elasticsearch is a &amp;lsquo;document store&amp;rsquo; widely used for both search and analytics. It&amp;rsquo;s something I&amp;rsquo;ve written a lot about (here and here for archives), as well as spoken about - preaching the good word, as it were, since the Elastic stack as a whole is very very good at what it does and a pleasure to work with.</description>
    </item>
    
  </channel>
</rss>