<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Number on rmoff&#39;s random ramblings</title>
    <link>https://rmoff.net/categories/number/</link>
    <description>Recent content in Number on rmoff&#39;s random ramblings</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 21 May 2018 08:59:00 +0000</lastBuildDate>
    <atom:link href="https://rmoff.net/categories/number/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Kafka Connect and Oracle data types</title>
      <link>https://rmoff.net/2018/05/21/kafka-connect-and-oracle-data-types/</link>
      <pubDate>Mon, 21 May 2018 08:59:00 +0000</pubDate>
      <guid>https://rmoff.net/2018/05/21/kafka-connect-and-oracle-data-types/</guid>
      <description>&lt;p&gt;The &lt;a href=&#34;https://docs.confluent.io/current/connect/connect-jdbc/docs/source_connector.html&#34;&gt;Kafka Connect JDBC Connector&lt;/a&gt; by default does not cope so well with:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;NUMBER&lt;/code&gt; columns with no defined precision/scale. You may end up with apparent junk (&lt;code&gt;bytes&lt;/code&gt;) in the output, or just errors.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;TIMESTAMP WITH LOCAL TIME ZONE&lt;/code&gt;. Throws &lt;code&gt;JDBC type -102 not currently supported&lt;/code&gt; warning in the log.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Read more about &lt;code&gt;NUMBER&lt;/code&gt; data type in the &lt;a href=&#34;https://docs.oracle.com/database/121/SQLRF/sql_elements001.htm#SQLRF002220&#34;&gt;Oracle docs&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h3 id=&#34;tldr--how-do-i-make-it-work&#34;&gt;tl;dr : How do I make it work?&lt;/h3&gt;&#xA;&lt;p&gt;There are several options:&lt;/p&gt;&#xA;&lt;h4 id=&#34;new-in-confluent-platform-411--numericmapping&#34;&gt;New in Confluent Platform 4.1.1 : &lt;code&gt;numeric.mapping&lt;/code&gt;&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;In the connector configuration, set &lt;code&gt;&amp;quot;numeric.mapping&amp;quot;:&amp;quot;best_fit&amp;quot;&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;New in Confluent Platform 4.1.1 (&lt;a href=&#34;https://docs.confluent.io/current/connect/connect-jdbc/docs/source_config_options.html#database&#34;&gt;Doc&lt;/a&gt;)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;avoid-the-problem-in-the-first-place&#34;&gt;Avoid the problem in the first place&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Change the DDL of the source object. For example:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;refine the &lt;code&gt;NUMBER&lt;/code&gt; &amp;rsquo;s precision and scale&lt;/li&gt;&#xA;&lt;li&gt;Use a &lt;code&gt;TIMESTAMP&lt;/code&gt; type that is supported&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;cast-the-datatypes-in-the-query&#34;&gt;CAST the datatypes in the &lt;code&gt;query&lt;/code&gt;&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Pull from the object directly, and use &lt;code&gt;query&lt;/code&gt; in the JDBC connector (instead of &lt;code&gt;table.whitelist&lt;/code&gt;)â€”and cast the columns appropriately:&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
