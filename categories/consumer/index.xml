<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Consumer on rmoff&#39;s random ramblings</title>
    <link>https://rmoff.net/categories/consumer/</link>
    <description>Recent content in Consumer on rmoff&#39;s random ramblings</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 09 Aug 2019 16:32:46 +0200</lastBuildDate>
    <atom:link href="https://rmoff.net/categories/consumer/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Resetting a Consumer Group in Kafka</title>
      <link>https://rmoff.net/2019/08/09/resetting-a-consumer-group-in-kafka/</link>
      <pubDate>Fri, 09 Aug 2019 16:32:46 +0200</pubDate>
      <guid>https://rmoff.net/2019/08/09/resetting-a-consumer-group-in-kafka/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;I’ve been using &lt;a href=&#34;https://docs.confluent.io/current/connect/kafka-connect-replicator/index.html&#34;&gt;Replicator&lt;/a&gt; as a powerful way to copy data from my Kafka rig at home onto my laptop’s Kafka environment. It means that when I’m on the road I can continue to work with the same set of data and develop pipelines etc. With a VPN back home I can even keep them in sync directly if I want to.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;I hit a problem the other day where Replicator was running, but I had no data in my target topics on my laptop. After a bit of head-scratching I realised that my local Kafka environment had been rebuilt (I use Docker Compose so complete rebuilds to start from scratch are easy), hence no data in the topic. But, even after restarting the Replicator Kafka Connect worker, I still had no data loaded into the empty topics. What was going on? Well Replicator acts as a consumer from the source Kafka cluster (on my home server), and so far as that Kafka cluster was concerned, Replicator had already read the messages. It thought that because even though I’d rebuilt everything on my laptop, Replicator was using the same connector name as before, and the connector name is used as the Consumer group name - which is how the &lt;em&gt;source&lt;/em&gt; Kafka cluster keeps track of the offsets. So my &amp;#34;new&amp;#34; Kafka environment was going back to the source, which viewed it as the existing &amp;#34;old&amp;#34; one, which had already received the messages.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
  </channel>
</rss>
