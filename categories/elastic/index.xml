<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Elastic on rmoff&#39;s random ramblings</title>
    <link>https://rmoff.net/categories/elastic/</link>
    <description>Recent content in Elastic on rmoff&#39;s random ramblings</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 24 Apr 2016 12:22:12 +0000</lastBuildDate>
    <atom:link href="https://rmoff.net/categories/elastic/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Using R to Denormalise Data for Analysis in Kibana</title>
      <link>https://rmoff.net/2016/04/24/using-r-to-denormalise-data-for-analysis-in-kibana/</link>
      <pubDate>Sun, 24 Apr 2016 12:22:12 +0000</pubDate>
      <guid>https://rmoff.net/2016/04/24/using-r-to-denormalise-data-for-analysis-in-kibana/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/products/kibana&#34;&gt;Kibana&lt;/a&gt; is a tool from &lt;a href=&#34;https://www.elastic.co/&#34;&gt;Elastic&lt;/a&gt; that makes analysis of data held in &lt;a href=&#34;https://www.elastic.co/products/elasticsearch&#34;&gt;Elasticsearch&lt;/a&gt; really easy and very powerful. Because Elasticsearch has very loose schema that can evolve on demand it makes it very quick to get up and running with some cool visualisations and analysis on any set of data. I demonstrated this in a &lt;a href=&#34;http://www.rittmanmead.com/2015/04/using-the-elk-stack-to-analyse-donors-choose-data/&#34;&gt;blog post last year&lt;/a&gt;, taking a CSV file and loading it into Elasticsearch via Logstash.&lt;/p&gt;&#xA;&lt;p&gt;This is all great, but the one real sticking point with analytics in Elasticsearch/Kibana is that it needs the data to be &lt;strong&gt;denormalised&lt;/strong&gt;. That is, you can&amp;rsquo;t give it a bunch of sources of data and it perform the joins for you in Kibana - it just doesn&amp;rsquo;t work like that. If you&amp;rsquo;re using Elasticsearch alone for analytics, maybe with a bespoke application, &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/guide/current/relations.html&#34;&gt;there are ways of approaching it&lt;/a&gt;, but not through Kibana. Now, depending on where the data is coming from, this may not be a problem. For example, if you use the &lt;a href=&#34;https://www.elastic.co/guide/en/logstash/current/plugins-inputs-jdbc.html&#34;&gt;JDBC Logstash input&lt;/a&gt; to pull from an RDBMS source you can specify a complex SQL query going across multiple tables, so that the data when it hits Elasticsearch is nice and denormalised and ready for fun in Kibana. But, source data doesn&amp;rsquo;t always come this way, and it&amp;rsquo;s useful to have a way to work with the data still when it is like this.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Decoupling the Data Pipeline with Kafka - A (Very) Simple Real Life Example</title>
      <link>https://rmoff.net/2016/04/12/decoupling-the-data-pipeline-with-kafka-a-very-simple-real-life-example/</link>
      <pubDate>Tue, 12 Apr 2016 21:50:46 +0000</pubDate>
      <guid>https://rmoff.net/2016/04/12/decoupling-the-data-pipeline-with-kafka-a-very-simple-real-life-example/</guid>
      <description>&lt;p&gt;I&amp;rsquo;ve recently been playing around with the ELK stack (&lt;a href=&#34;https://www.elastic.co/blog/heya-elastic-stack-and-x-pack&#34;&gt;now officially known as the Elastic stack&lt;/a&gt;) collecting data from &lt;a href=&#34;https://rmoff.net/2016/03/03/obihackers-irc-channel/&#34;&gt;an IRC channel&lt;/a&gt; with Elastic&amp;rsquo;s Logstash, storing it in Elasticsearch and &lt;a href=&#34;https://rmoff.net/2016/03/24/my-latest-irc-client-kibana/&#34;&gt;analysing it with Kibana&lt;/a&gt;. But, this isn&amp;rsquo;t an &amp;ldquo;ELK&amp;rdquo; post - this is a Kafka post! ELK is just some example data manipulation tooling that helps demonstrate the principles.&lt;/p&gt;&#xA;&lt;p&gt;As I &lt;a href=&#34;http://www.rittmanmead.com/2015/10/forays-into-kafka-enabling-flexible-data-pipelines/&#34;&gt;wrote about last year&lt;/a&gt;, Apache Kafka provides a handy way to build flexible &amp;ldquo;pipelines&amp;rdquo;. Today I&amp;rsquo;m writing up a short real-world example of this in practice. There are three elements to the flexibility that I really want to highlight:&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
