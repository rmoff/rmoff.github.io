<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Engineering on rmoff&#39;s random ramblings</title>
    <link>https://rmoff.net/categories/data-engineering/</link>
    <description>Recent content in Data Engineering on rmoff&#39;s random ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 24 Oct 2022 12:27:14 +0000</lastBuildDate><atom:link href="https://rmoff.net/categories/data-engineering/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Data Engineering in 2022: Wrangling the feedback data from Current 22 with dbt</title>
      <link>https://rmoff.net/2022/10/24/data-engineering-in-2022-wrangling-the-feedback-data-from-current-22-with-dbt/</link>
      <pubDate>Mon, 24 Oct 2022 12:27:14 +0000</pubDate>
      
      <guid>https://rmoff.net/2022/10/24/data-engineering-in-2022-wrangling-the-feedback-data-from-current-22-with-dbt/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I started my dbt journey by &lt;a href=&#34;https://rmoff.net/2022/10/20/data-engineering-in-2022-exploring-dbt-with-duckdb/&#34;&gt;poking and pulling at the pre-built jaffle_shop demo running with DuckDB as its data store&lt;/a&gt;. Now I want to see if I can put it to use myself to wrangle the session feedback data that came in from &lt;a href=&#34;https://2022.currentevent.io/&#34;&gt;Current 2022&lt;/a&gt;. Iâ€™ve &lt;a href=&#34;https://rmoff.net/2022/10/14/current-22-session-analysis-with-duckdb-and-jupyter-notebook/&#34;&gt;analysed&lt;/a&gt; this already, but it struck me that a particular part of it would benefit from some tidying up - and be a good excuse to see what itâ€™s like using dbt to do so.&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Data Engineering in 2022: Exploring dbt with DuckDB</title>
      <link>https://rmoff.net/2022/10/20/data-engineering-in-2022-exploring-dbt-with-duckdb/</link>
      <pubDate>Thu, 20 Oct 2022 17:07:04 +0000</pubDate>
      
      <guid>https://rmoff.net/2022/10/20/data-engineering-in-2022-exploring-dbt-with-duckdb/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Iâ€™ve been wanting to try out dbt for some time now, and a recent long-haul flight seemed like the obvious opportunity to do so. Except many of the tutorials with dbt that I found were based on using Cloud, and airplane WiFi is generally sucky or non-existant. Then I found the &lt;a href=&#34;https://github.com/dbt-labs/jaffle_shop_duckdb&#34;&gt;DuckDB-based demo of dbt&lt;/a&gt;, which seemed to fit the bill (ðŸ¦† geddit?!) perfectly, since DuckDB runs locally. In addition, &lt;a href=&#34;https://duckdb.org/&#34;&gt;DuckDB&lt;/a&gt; had appeared on my radar recently and I was keen to check it out.&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Data Engineering in 2022: Architectures &amp; Terminology</title>
      <link>https://rmoff.net/2022/10/02/data-engineering-in-2022-architectures-terminology/</link>
      <pubDate>Sun, 02 Oct 2022 10:50:56 +0000</pubDate>
      
      <guid>https://rmoff.net/2022/10/02/data-engineering-in-2022-architectures-terminology/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This is one of those &lt;em&gt;you had to be there&lt;/em&gt; moments. If you come into the world of data and analytics engineering today, ELT is just what it is and is pretty much universally understood. But if youâ€™ve been around for â€¦&lt;em&gt;waves hands&lt;/em&gt;â€¦ longer than that, you might be confused by what people are calling ELT and ETL. Well, I was âœ‹.&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Data Engineering in 2022: Exploring LakeFS with Jupyter and PySpark</title>
      <link>https://rmoff.net/2022/09/16/data-engineering-in-2022-exploring-lakefs-with-jupyter-and-pyspark/</link>
      <pubDate>Fri, 16 Sep 2022 08:54:45 +0000</pubDate>
      
      <guid>https://rmoff.net/2022/09/16/data-engineering-in-2022-exploring-lakefs-with-jupyter-and-pyspark/</guid>
      <description>&lt;p&gt;With my &lt;a href=&#34;https://rmoff.net/2022/09/14/stretching-my-legs-in-the-data-engineering-ecosystem-in-2022/&#34;&gt;foray&lt;/a&gt; into the current world of data engineering I wanted to get my hands dirty with some of the tools and technologies I&amp;rsquo;d been reading about. The vehicle for this was trying to understand more about LakeFS, but along the way dabbling with PySpark and S3 (MinIO) too.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;d forgotten how amazingly useful notebooks are. It&amp;rsquo;s &lt;a href=&#34;https://www.rittmanmead.com/blog/2016/12/etl-offload-with-spark-and-amazon-emr-part-2-code-development-with-notebooks-and-docker/&#34;&gt;six years since I wrote about them last&lt;/a&gt; (and the last time I tried my hand at PySpark). This blog is basically the notebook, with some more annotations.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Data Engineering: Resources</title>
      <link>https://rmoff.net/2022/09/14/data-engineering-resources/</link>
      <pubDate>Wed, 14 Sep 2022 20:57:21 +0000</pubDate>
      
      <guid>https://rmoff.net/2022/09/14/data-engineering-resources/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;As Iâ€™ve been reading and exploring the current world of data engineering Iâ€™ve been adding links to my &lt;a href=&#34;https://raindrop.io/rmoff/data-engineering-23335742&#34;&gt;Raindrop.io collection&lt;/a&gt;, so check that out. In addition, below are some specific resources that Iâ€™d recommend.&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Data Engineering in 2022: Storage and Access</title>
      <link>https://rmoff.net/2022/09/14/data-engineering-in-2022-storage-and-access/</link>
      <pubDate>Wed, 14 Sep 2022 17:07:04 +0000</pubDate>
      
      <guid>https://rmoff.net/2022/09/14/data-engineering-in-2022-storage-and-access/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In this article I look at where we store our analytical data, how we organise it, and how we enable access to it. Iâ€™m considering here potentially large volumes of data for access throughout an organisation. Iâ€™m not looking at data stores that are used for specific purposes (caches, low-latency analytics, graph etc).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The article is &lt;a href=&#34;https://rmoff.net/2022/09/14/stretching-my-legs-in-the-data-engineering-ecosystem-in-2022/&#34;&gt;part of a series&lt;/a&gt; in which I explore the world of data engineering in 2022 and how it has changed from when I started my career in data warehousing 20+ years ago. Read the &lt;a href=&#34;https://rmoff.net/2022/09/14/stretching-my-legs-in-the-data-engineering-ecosystem-in-2022/&#34;&gt;introduction&lt;/a&gt; for more context and background.&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Stretching my Legs in the Data Engineering Ecosystem in 2022</title>
      <link>https://rmoff.net/2022/09/14/stretching-my-legs-in-the-data-engineering-ecosystem-in-2022/</link>
      <pubDate>Wed, 14 Sep 2022 10:42:30 +0000</pubDate>
      
      <guid>https://rmoff.net/2022/09/14/stretching-my-legs-in-the-data-engineering-ecosystem-in-2022/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;For the past 5.5 years Iâ€™ve been head-down in the exciting area of stream processing and events, and I realised recently that the world of data and analytics that I worked in up to 2017 which was changing significantly back then (Big Data, yâ€™all!) has evolved and, dare I say it, matured somewhat - and Iâ€™ve not necessarily kept up with it. In this series of posts you can follow along as I start to reacquaint myself with where itâ€™s got to these days.&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Loading delimited data into Kafka - quick &amp; dirty (but effective)</title>
      <link>https://rmoff.net/2021/02/26/loading-delimited-data-into-kafka-quick-dirty-but-effective/</link>
      <pubDate>Fri, 26 Feb 2021 22:45:36 +0000</pubDate>
      
      <guid>https://rmoff.net/2021/02/26/loading-delimited-data-into-kafka-quick-dirty-but-effective/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Whilst Apache Kafka is an event streaming platform designed for, well, &lt;em&gt;streams&lt;/em&gt; of events, itâ€™s perfectly valid to use it as a store of data which perhaps changes only occasionally (or even never). Iâ€™m thinking here of reference data (lookup data) thatâ€™s used to enrich regular streams of events.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;You might well get your reference data from a database where it resides and do so effectively &lt;a href=&#34;https://rmoff.dev/no-more-silos&#34;&gt;using CDC&lt;/a&gt; - but sometimes it comes down to those pesky CSV files that we all know and love/hate. Simple, awful, but effective. I wrote previously about &lt;a href=&#34;https://rmoff.net/2020/06/17/loading-csv-data-into-kafka/&#34;&gt;loading CSV data into Kafka from files that are updated frequently&lt;/a&gt;, but here I want to look at CSV files that are not changing. Kafka Connect simplifies getting data in to (and out of) Kafka but even Kafka Connect becomes a bit of an overhead when you just have a single file that you want to load into a topic and then never deal with again. I spent this afternoon wrangling with a couple of CSV-ish files, and building on my previous article about &lt;a href=&#34;https://rmoff.net/2021/02/02/performing-a-group-by-on-data-in-bash/&#34;&gt;neat tricks you can do in bash with data&lt;/a&gt;, I have some more to share with you here :)&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Performing a GROUP BY on data in bash</title>
      <link>https://rmoff.net/2021/02/02/performing-a-group-by-on-data-in-bash/</link>
      <pubDate>Tue, 02 Feb 2021 17:23:21 +0000</pubDate>
      
      <guid>https://rmoff.net/2021/02/02/performing-a-group-by-on-data-in-bash/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;One of the fun things about working with data over the years is learning how to use the tools of the dayâ€”but also learning to fall back on the tools that are always there for you - and one of those is bash and its wonderful library of shell tools.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;admonitionblock note&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td class=&#34;icon&#34;&gt;
&lt;i class=&#34;fa icon-note&#34; title=&#34;Note&#34;&gt;&lt;/i&gt;
&lt;/td&gt;
&lt;td class=&#34;content&#34;&gt;
Thereâ€™s an even better way than Iâ€™ve described here, and itâ€™s called &lt;code&gt;visidata&lt;/code&gt;. &lt;a href=&#34;https://rmoff.net/2021/03/04/quick-profiling-of-data-in-apache-kafka-using-kafkacat-and-visidata/&#34;&gt;Iâ€™ve written about it more over here&lt;/a&gt;.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Iâ€™ve been playing around with a new data source recently, and needed to understand more about its structure. Within a single stream there were multiple message types.&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
  </channel>
</rss>
