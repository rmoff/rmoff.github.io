<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Engineering on rmoff&#39;s random ramblings</title>
    <link>https://rmoff.net/categories/data-engineering/</link>
    <description>Recent content in Data Engineering on rmoff&#39;s random ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 02 Oct 2022 10:50:56 +0000</lastBuildDate><atom:link href="https://rmoff.net/categories/data-engineering/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Data Engineering in 2022: Architectures &amp; Terminology</title>
      <link>https://rmoff.net/2022/10/02/data-engineering-in-2022-architectures-terminology/</link>
      <pubDate>Sun, 02 Oct 2022 10:50:56 +0000</pubDate>
      
      <guid>https://rmoff.net/2022/10/02/data-engineering-in-2022-architectures-terminology/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This is one of those &lt;em&gt;you had to be there&lt;/em&gt; moments. If you come into the world of data and analytics engineering today, ELT is just what it is and is pretty much universally understood. But if you’ve been around for …&lt;em&gt;waves hands&lt;/em&gt;… longer than that, you might be confused by what people are calling ELT and ETL. Well, I was ✋.&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Data Engineering in 2022: Exploring LakeFS with Jupyter and PySpark</title>
      <link>https://rmoff.net/2022/09/16/data-engineering-in-2022-exploring-lakefs-with-jupyter-and-pyspark/</link>
      <pubDate>Fri, 16 Sep 2022 08:54:45 +0000</pubDate>
      
      <guid>https://rmoff.net/2022/09/16/data-engineering-in-2022-exploring-lakefs-with-jupyter-and-pyspark/</guid>
      <description>&lt;p&gt;With my &lt;a href=&#34;https://rmoff.net/2022/09/14/stretching-my-legs-in-the-data-engineering-ecosystem-in-2022/&#34;&gt;foray&lt;/a&gt; into the current world of data engineering I wanted to get my hands dirty with some of the tools and technologies I&amp;rsquo;d been reading about. The vehicle for this was trying to understand more about LakeFS, but along the way dabbling with PySpark and S3 (MinIO) too.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;d forgotten how amazingly useful notebooks are. It&amp;rsquo;s &lt;a href=&#34;https://www.rittmanmead.com/blog/2016/12/etl-offload-with-spark-and-amazon-emr-part-2-code-development-with-notebooks-and-docker/&#34;&gt;six years since I wrote about them last&lt;/a&gt; (and the last time I tried my hand at PySpark). This blog is basically the notebook, with some more annotations.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Data Engineering: Resources</title>
      <link>https://rmoff.net/2022/09/14/data-engineering-resources/</link>
      <pubDate>Wed, 14 Sep 2022 20:57:21 +0000</pubDate>
      
      <guid>https://rmoff.net/2022/09/14/data-engineering-resources/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;As I’ve been reading and exploring the current world of data engineering I’ve been adding links to my &lt;a href=&#34;https://raindrop.io/rmoff/data-engineering-23335742&#34;&gt;Raindrop.io collection&lt;/a&gt;, so check that out. In addition, below are some specific resources that I’d recommend.&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Data Engineering in 2022: Storage and Access</title>
      <link>https://rmoff.net/2022/09/14/data-engineering-in-2022-storage-and-access/</link>
      <pubDate>Wed, 14 Sep 2022 17:07:04 +0000</pubDate>
      
      <guid>https://rmoff.net/2022/09/14/data-engineering-in-2022-storage-and-access/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In this article I look at where we store our analytical data, how we organise it, and how we enable access to it. I’m considering here potentially large volumes of data for access throughout an organisation. I’m not looking at data stores that are used for specific purposes (caches, low-latency analytics, graph etc).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The article is &lt;a href=&#34;https://rmoff.net/2022/09/14/stretching-my-legs-in-the-data-engineering-ecosystem-in-2022/&#34;&gt;part of a series&lt;/a&gt; in which I explore the world of data engineering in 2022 and how it has changed from when I started my career in data warehousing 20+ years ago. Read the &lt;a href=&#34;https://rmoff.net/2022/09/14/stretching-my-legs-in-the-data-engineering-ecosystem-in-2022/&#34;&gt;introduction&lt;/a&gt; for more context and background.&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Stretching my Legs in the Data Engineering Ecosystem in 2022</title>
      <link>https://rmoff.net/2022/09/14/stretching-my-legs-in-the-data-engineering-ecosystem-in-2022/</link>
      <pubDate>Wed, 14 Sep 2022 10:42:30 +0000</pubDate>
      
      <guid>https://rmoff.net/2022/09/14/stretching-my-legs-in-the-data-engineering-ecosystem-in-2022/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;For the past 5.5 years I’ve been head-down in the exciting area of stream processing and events, and I realised recently that the world of data and analytics that I worked in up to 2017 which was changing significantly back then (Big Data, y’all!) has evolved and, dare I say it, matured somewhat - and I’ve not necessarily kept up with it. In this series of posts you can follow along as I start to reacquaint myself with where it’s got to these days.&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Loading delimited data into Kafka - quick &amp; dirty (but effective)</title>
      <link>https://rmoff.net/2021/02/26/loading-delimited-data-into-kafka-quick-dirty-but-effective/</link>
      <pubDate>Fri, 26 Feb 2021 22:45:36 +0000</pubDate>
      
      <guid>https://rmoff.net/2021/02/26/loading-delimited-data-into-kafka-quick-dirty-but-effective/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Whilst Apache Kafka is an event streaming platform designed for, well, &lt;em&gt;streams&lt;/em&gt; of events, it’s perfectly valid to use it as a store of data which perhaps changes only occasionally (or even never). I’m thinking here of reference data (lookup data) that’s used to enrich regular streams of events.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;You might well get your reference data from a database where it resides and do so effectively &lt;a href=&#34;https://rmoff.dev/no-more-silos&#34;&gt;using CDC&lt;/a&gt; - but sometimes it comes down to those pesky CSV files that we all know and love/hate. Simple, awful, but effective. I wrote previously about &lt;a href=&#34;https://rmoff.net/2020/06/17/loading-csv-data-into-kafka/&#34;&gt;loading CSV data into Kafka from files that are updated frequently&lt;/a&gt;, but here I want to look at CSV files that are not changing. Kafka Connect simplifies getting data in to (and out of) Kafka but even Kafka Connect becomes a bit of an overhead when you just have a single file that you want to load into a topic and then never deal with again. I spent this afternoon wrangling with a couple of CSV-ish files, and building on my previous article about &lt;a href=&#34;https://rmoff.net/2021/02/02/performing-a-group-by-on-data-in-bash/&#34;&gt;neat tricks you can do in bash with data&lt;/a&gt;, I have some more to share with you here :)&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Performing a GROUP BY on data in bash</title>
      <link>https://rmoff.net/2021/02/02/performing-a-group-by-on-data-in-bash/</link>
      <pubDate>Tue, 02 Feb 2021 17:23:21 +0000</pubDate>
      
      <guid>https://rmoff.net/2021/02/02/performing-a-group-by-on-data-in-bash/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;One of the fun things about working with data over the years is learning how to use the tools of the day—but also learning to fall back on the tools that are always there for you - and one of those is bash and its wonderful library of shell tools.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;admonitionblock note&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td class=&#34;icon&#34;&gt;
&lt;i class=&#34;fa icon-note&#34; title=&#34;Note&#34;&gt;&lt;/i&gt;
&lt;/td&gt;
&lt;td class=&#34;content&#34;&gt;
There’s an even better way than I’ve described here, and it’s called &lt;code&gt;visidata&lt;/code&gt;. &lt;a href=&#34;https://rmoff.net/2021/03/04/quick-profiling-of-data-in-apache-kafka-using-kafkacat-and-visidata/&#34;&gt;I’ve written about it more over here&lt;/a&gt;.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I’ve been playing around with a new data source recently, and needed to understand more about its structure. Within a single stream there were multiple message types.&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
  </channel>
</rss>
