<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Apache Iceberg on rmoff&#39;s random ramblings</title>
    <link>https://rmoff.net/categories/apache-iceberg/</link>
    <description>Recent content in Apache Iceberg on rmoff&#39;s random ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 18 Aug 2025 13:43:31 +0000</lastBuildDate><atom:link href="https://rmoff.net/categories/apache-iceberg/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Kafka to Iceberg - Exploring the Options</title>
      <link>https://rmoff.net/2025/08/18/kafka-to-iceberg-exploring-the-options/</link>
      <pubDate>Mon, 18 Aug 2025 13:43:31 +0000</pubDate>
      
      <guid>https://rmoff.net/2025/08/18/kafka-to-iceberg-exploring-the-options/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Youâ€™ve got data in &lt;a href=&#34;https://www.youtube.com/watch?v=9CrlA0Wasvk&#34;&gt;Apache Kafka&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;You want to get that data into &lt;a href=&#34;https://www.youtube.com/watch?v=TsmhRZElPvM&#34;&gt;Apache Iceberg&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Whatâ€™s the best way to do it?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2025/08/kafka-to-iceberg.png&#34; alt=&#34;kafka to iceberg&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Perhaps invariably, the answer is: &lt;strong&gt;IT DEPENDS&lt;/strong&gt;.
But fear not: here is a guide to help you navigate your way to choosing the best solution &lt;em&gt;for you&lt;/em&gt; ðŸ«µ.&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Keeping your Data Lakehouse in Order: Table Maintenance in Apache Iceberg</title>
      <link>https://rmoff.net/2025/07/14/keeping-your-data-lakehouse-in-order-table-maintenance-in-apache-iceberg/</link>
      <pubDate>Mon, 14 Jul 2025 14:43:04 +0000</pubDate>
      
      <guid>https://rmoff.net/2025/07/14/keeping-your-data-lakehouse-in-order-table-maintenance-in-apache-iceberg/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Iceberg nicely decouples storage from ingest and query (yay!).
When we say &amp;#34;decouples&amp;#34; itâ€™s a fancy way of saying &amp;#34;doesnâ€™t do&amp;#34;.
Which, in the case of ingest and query, is really powerful.
It means that we can store data in an open format, populated by one or more tools, and queried by the same, or other tools.
Iceberg gets to be very opinionated and optimised around what it was built for (storing tabular data in a flexible way that can be efficiently queried).
This is amazing!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;But, what Iceberg doesnâ€™t do is any housekeeping on its data and metadata.
This means that getting data in and out of Apache Iceberg isnâ€™t where the story stops.&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Writing to Apache Iceberg on S3 using Kafka Connect with Glue catalog</title>
      <link>https://rmoff.net/2025/07/04/writing-to-apache-iceberg-on-s3-using-kafka-connect-with-glue-catalog/</link>
      <pubDate>Fri, 04 Jul 2025 15:36:21 +0000</pubDate>
      
      <guid>https://rmoff.net/2025/07/04/writing-to-apache-iceberg-on-s3-using-kafka-connect-with-glue-catalog/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Without wanting to mix my temperature metaphors, Iceberg is the new hawtness, and getting data into it from other places is a common task.
I &lt;a href=&#34;https://rmoff.net/2025/06/24/writing-to-apache-iceberg-on-s3-using-flink-sql-with-glue-catalog/&#34;&gt;wrote previously about using Flink SQL to do this&lt;/a&gt;, and today Iâ€™m going to look at doing the same using Kafka Connect.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Kafka Connect can send data to Iceberg from any Kafka topic.
The source Kafka topic(s) can be populated by a Kafka Connect source connector (such as Debezium), or a regular application producing directly to it.&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Writing to Apache Iceberg on S3 using Flink SQL with Glue catalog</title>
      <link>https://rmoff.net/2025/06/24/writing-to-apache-iceberg-on-s3-using-flink-sql-with-glue-catalog/</link>
      <pubDate>Tue, 24 Jun 2025 17:12:50 +0000</pubDate>
      
      <guid>https://rmoff.net/2025/06/24/writing-to-apache-iceberg-on-s3-using-flink-sql-with-glue-catalog/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In this blog post Iâ€™ll show how you can use Flink SQL to write to Iceberg on S3, storing metadata about the Iceberg tables in the &lt;a href=&#34;https://docs.aws.amazon.com/glue/latest/dg/components-overview.html#data-catalog-intro&#34;&gt;AWS Glue Data Catalog&lt;/a&gt;.
First off, Iâ€™ll walk through the dependencies and a simple smoke-test, and then put it into practice using it to write data from a Kafka topic to Iceberg.&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Sending Data to Apache Iceberg from Apache Kafka with Apache Flink</title>
      <link>https://rmoff.net/2024/07/18/sending-data-to-apache-iceberg-from-apache-kafka-with-apache-flink/</link>
      <pubDate>Thu, 18 Jul 2024 00:00:00 +0000</pubDate>
      
      <guid>https://rmoff.net/2024/07/18/sending-data-to-apache-iceberg-from-apache-kafka-with-apache-flink/</guid>
      <description>&lt;div class=&#34;admonitionblock note&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td class=&#34;icon&#34;&gt;
&lt;div class=&#34;title&#34;&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&#34;content&#34;&gt;
This post originally appeared on the &lt;a href=&#34;https://www.decodable.co/blog/kafka-to-iceberg-with-flink&#34;&gt;Decodable blog&lt;/a&gt;.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;Sometimes itâ€™s not possible to have too much of a good thing, and whilst this blog may look at first-glance rather similar to the one that&lt;/em&gt; &lt;a href=&#34;https://rmoff.net/2024/06/18/how-to-get-data-from-apache-kafka-to-apache-iceberg-on-s3-with-decodable/&#34;&gt;I published just recently&lt;/a&gt; &lt;em&gt;, today weâ€™re looking at a 100% pure Apache solution.&lt;/em&gt;
&lt;em&gt;Because who knows, maybe you prefer rolling your own tech stacks instead of letting Decodable do it for you ðŸ˜‰.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>How to get data from Apache Kafka to Apache Iceberg on S3 with Decodable</title>
      <link>https://rmoff.net/2024/06/18/how-to-get-data-from-apache-kafka-to-apache-iceberg-on-s3-with-decodable/</link>
      <pubDate>Tue, 18 Jun 2024 00:00:00 +0000</pubDate>
      
      <guid>https://rmoff.net/2024/06/18/how-to-get-data-from-apache-kafka-to-apache-iceberg-on-s3-with-decodable/</guid>
      <description>&lt;div class=&#34;admonitionblock note&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td class=&#34;icon&#34;&gt;
&lt;div class=&#34;title&#34;&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&#34;content&#34;&gt;
This post originally appeared on the &lt;a href=&#34;https://www.decodable.co/blog/kafka-to-iceberg-with-decodable&#34;&gt;Decodable blog&lt;/a&gt;.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://iceberg.apache.org/&#34;&gt;Apache Iceberg&lt;/a&gt;  is an open table format.
It combines the benefits of data lakes (open standards, cheap object storage) with the good things that data warehouses have, like first-class support for tables and SQL capabilities including updates to data in place, time-travel, and transactions.
With the recent  &lt;a href=&#34;https://www.databricks.com/company/newsroom/press-releases/databricks-agrees-acquire-tabular-company-founded-original-creators&#34;&gt;acquisition&lt;/a&gt;  by Databricks of Tabularâ€”one of the main companies that contribute to Icebergâ€”itâ€™s clear that Iceberg is winning out as one of the primary contenders in this space.&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Data Engineering in 2022: Storage and Access</title>
      <link>https://rmoff.net/2022/09/14/data-engineering-in-2022-storage-and-access/</link>
      <pubDate>Wed, 14 Sep 2022 17:07:04 +0000</pubDate>
      
      <guid>https://rmoff.net/2022/09/14/data-engineering-in-2022-storage-and-access/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In this article I look at where we store our analytical data, how we organise it, and how we enable access to it. Iâ€™m considering here potentially large volumes of data for access throughout an organisation. Iâ€™m not looking at data stores that are used for specific purposes (caches, low-latency analytics, graph etc).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The article is &lt;a href=&#34;https://rmoff.net/2022/09/14/stretching-my-legs-in-the-data-engineering-ecosystem-in-2022/&#34;&gt;part of a series&lt;/a&gt; in which I explore the world of data engineering in 2022 and how it has changed from when I started my career in data warehousing 20+ years ago. Read the &lt;a href=&#34;https://rmoff.net/2022/09/14/stretching-my-legs-in-the-data-engineering-ecosystem-in-2022/&#34;&gt;introduction&lt;/a&gt; for more context and background.&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
  </channel>
</rss>
