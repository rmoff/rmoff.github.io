<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Log4j on rmoff&#39;s random ramblings</title>
    <link>https://rmoff.net/categories/log4j/</link>
    <description>Recent content in Log4j on rmoff&#39;s random ramblings</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 16 Jan 2020 22:50:45 +0000</lastBuildDate>
    <atom:link href="https://rmoff.net/categories/log4j/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Changing the Logging Level for Kafka Connect Dynamically</title>
      <link>https://rmoff.net/2020/01/16/changing-the-logging-level-for-kafka-connect-dynamically/</link>
      <pubDate>Thu, 16 Jan 2020 22:50:45 +0000</pubDate>
      <guid>https://rmoff.net/2020/01/16/changing-the-logging-level-for-kafka-connect-dynamically/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Logs are magical things. They tell us what an application is doing—or not doing. They help us debug problems. As it happens, they also underpin the &lt;a href=&#34;https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying&#34;&gt;entire philosophy of Apache Kafka&lt;/a&gt;, but that’s a story for another day. Today we’re talking about logs written by Kafka Connect, and how we can change the amount of detail written.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;By default, Kafka Connect will write logs at &lt;code&gt;INFO&lt;/code&gt; and above. So when it starts up, the settings that it’s using, and any &lt;code&gt;WARN&lt;/code&gt; or &lt;code&gt;ERROR&lt;/code&gt; messages along the way - a missing configuration, a broken connector, and so on. If you want to peer under the covers of what’s happening, perhaps in a given connector, you’d want to see &lt;code&gt;DEBUG&lt;/code&gt; or even &lt;code&gt;TRACE&lt;/code&gt; messages too.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Configuring Kafka Connect to log REST HTTP messages to a separate file</title>
      <link>https://rmoff.net/2017/06/12/configuring-kafka-connect-to-log-rest-http-messages-to-a-separate-file/</link>
      <pubDate>Mon, 12 Jun 2017 15:28:15 +0000</pubDate>
      <guid>https://rmoff.net/2017/06/12/configuring-kafka-connect-to-log-rest-http-messages-to-a-separate-file/</guid>
      <description>&lt;p&gt;Kafka&amp;rsquo;s Connect API is a wondrous way of easily bringing data in and out of Apache Kafka without having to write a line of code. By choosing a Connector from &lt;a href=&#34;https://www.confluent.io/product/connectors/&#34;&gt;the many available&lt;/a&gt;, it&amp;rsquo;s possible to set up and end-to-end data pipeline with just a few lines of configuration. You can configure this by hand, or you can use the &lt;a href=&#34;https://www.confluent.io/product/control-center/&#34;&gt;Confluent Control Center&lt;/a&gt;, for both management and monitoring:&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2017/05/Control_Center.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;BUT &amp;hellip; there are times when not all goes well - perhaps your source has gone offline, or one of your targets has been misconfigured. What then? Well of course, it&amp;rsquo;s diagnostics time! And for diagnostics, you need logs. When you launch Kafka Connect it logs everything to &lt;code&gt;stdout&lt;/code&gt;, and this output includes content from the Kafka Connect &lt;a href=&#34;http://docs.confluent.io/current/connect/restapi.html&#34;&gt;REST interface&lt;/a&gt;. This REST interface is for configuration and control of the connectors (status/pause/resume) - and whilst Control Center is being used on the Connect configuration screens, you&amp;rsquo;ll notice that the REST interface gets polled frequently - every couple of seconds, with a greater number of requests the more connectors you have. All of this goes into the log:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Kafka Connect JDBC - Oracle - Number of groups must be positive</title>
      <link>https://rmoff.net/2016/07/27/kafka-connect-jdbc-oracle-number-of-groups-must-be-positive/</link>
      <pubDate>Wed, 27 Jul 2016 15:23:14 +0000</pubDate>
      <guid>https://rmoff.net/2016/07/27/kafka-connect-jdbc-oracle-number-of-groups-must-be-positive/</guid>
      <description>&lt;p&gt;There are &lt;a href=&#34;https://groups.google.com/forum/#!searchin/confluent-platform/%22Number$20of$20groups$20must$20be$20positive%22&#34;&gt;various reasons for this error&lt;/a&gt;, but the one I hit was that &lt;strong&gt;the table name is case sensitive&lt;/strong&gt;, and returned from Oracle by the JDBC driver in uppercase.&lt;/p&gt;&#xA;&lt;p&gt;If you specify the tablename in your connecter config in lowercase, it won&amp;rsquo;t be matched, and this error is thrown. You can validate this by setting debug logging (edit &lt;code&gt;etc/kafka/connect-log4j.properties&lt;/code&gt; to set &lt;code&gt;log4j.rootLogger=DEBUG, stdout&lt;/code&gt;), and observe:  (&lt;em&gt;I&amp;rsquo;ve truncated some of the output for legibility&lt;/em&gt;)&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
