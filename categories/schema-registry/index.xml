<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Schema Registry on rmoff&#39;s random ramblings</title>
    <link>https://rmoff.net/categories/schema-registry/</link>
    <description>Recent content in Schema Registry on rmoff&#39;s random ramblings</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 17 Jan 2019 11:25:40 +0000</lastBuildDate>
    <atom:link href="https://rmoff.net/categories/schema-registry/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Confluent Schema Registry REST API cheatsheet</title>
      <link>https://rmoff.net/2019/01/17/confluent-schema-registry-rest-api-cheatsheet/</link>
      <pubDate>Thu, 17 Jan 2019 11:25:40 +0000</pubDate>
      <guid>https://rmoff.net/2019/01/17/confluent-schema-registry-rest-api-cheatsheet/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;The &lt;a href=&#34;https://docs.confluent.io/current/schema-registry/docs/index.html&#34;&gt;Schema Registry&lt;/a&gt; support a &lt;a href=&#34;https://docs.confluent.io/current/schema-registry/docs/api.html&#34;&gt;REST API&lt;/a&gt; for finding out information about the schemas within it. Hereâ€™s a quick cheatsheat with REST calls that I often use.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>HOWTO: Oracle GoldenGate &#43; Apache Kafka &#43; Schema Registry &#43; Swingbench</title>
      <link>https://rmoff.net/2018/02/01/howto-oracle-goldengate--apache-kafka--schema-registry--swingbench/</link>
      <pubDate>Thu, 01 Feb 2018 23:15:00 +0000</pubDate>
      <guid>https://rmoff.net/2018/02/01/howto-oracle-goldengate--apache-kafka--schema-registry--swingbench/</guid>
      <description>&lt;p&gt;&lt;em&gt;This is the detailed step-by-step if you want to recreate the process I describe in the &lt;a href=&#34;https://www.confluent.io/blog/ksql-in-action-real-time-streaming-etl-from-oracle-transactional-data&#34;&gt;Confluent blog here&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;I used Oracle&amp;rsquo;s &lt;a href=&#34;http://www.oracle.com/technetwork/database/enterprise-edition/databaseappdev-vm-161299.html&#34;&gt;Oracle Developer Days VM&lt;/a&gt;, which comes preinstalled with Oracle 12cR2. You can see the notes on &lt;a href=&#34;https://rmoff.net/2017/11/21/installing-oracle-goldengate-for-big-data-12.3.1-with-kafka-connect-and-confluent-platform/&#34;&gt;how to do this here&lt;/a&gt;. These notes take you through installing and configuring:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Swingbench, to create a sample &amp;ldquo;Order Entry&amp;rdquo; schema and simulate events on the Oracle database&lt;/li&gt;&#xA;&lt;li&gt;Oracle GoldenGate (OGG, forthwith) and Oracle GoldenGate for Big Data (OGG-BD, forthwith)&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I&amp;rsquo;m using Oracle GoldenGate 12.3.1 which includes the Kafka Connect handler as part of its distribution. A connector for earlier versions can be &lt;a href=&#34;http://www.oracle.com/technetwork/middleware/goldengate/oracle-goldengate-exchange-3805527.html&#34;&gt;found here&lt;/a&gt;. Some of the syntax may differ in the configuration below - if you hit problems then check out &lt;a href=&#34;&#34;&gt;an article that I wrote&lt;/a&gt; with an earlier version of the tool.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;OGG &lt;code&gt;extract&lt;/code&gt; from the Order Entry schema&lt;/li&gt;&#xA;&lt;li&gt;Confluent Platform&lt;/li&gt;&#xA;&lt;li&gt;KSQL&lt;/li&gt;&#xA;&lt;li&gt;Elasticsearch&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;From this point, I&amp;rsquo;ll now walk through configuring OGG-BD with the Kafka Connect handler&lt;/p&gt;</description>
    </item>
    <item>
      <title>Oracle GoldenGate / Kafka Connect Handler troubleshooting</title>
      <link>https://rmoff.net/2017/09/12/oracle-goldengate-/-kafka-connect-handler-troubleshooting/</link>
      <pubDate>Tue, 12 Sep 2017 21:55:16 +0000</pubDate>
      <guid>https://rmoff.net/2017/09/12/oracle-goldengate-/-kafka-connect-handler-troubleshooting/</guid>
      <description>&lt;p&gt;The Replicat was kapput:&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;GGSCI (localhost.localdomain) 3&amp;gt; info rkconnoe&#xA;&#xA;REPLICAT   RKCONNOE  Last Started 2017-09-12 17:06   Status ABENDED&#xA;Checkpoint Lag       00:00:00 (updated 00:46:34 ago)&#xA;Log Read Checkpoint  File /u01/app/ogg/dirdat/oe000000&#xA;                     First Record  RBA 0&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So checking the OGG error log &lt;code&gt;ggserr.log&lt;/code&gt; showed&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;2017-09-12T17:06:17.572-0400  ERROR   OGG-15051  Oracle GoldenGate Delivery, rkconnoe.prm:  Java or JNI exception:&#xA;                              oracle.goldengate.util.GGException: Error detected handling operation added event.&#xA;2017-09-12T17:06:17.572-0400  ERROR   OGG-01668  Oracle GoldenGate Delivery, rkconnoe.prm:  PROCESS ABENDING.&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So checking the replicat log &lt;code&gt;dirrpt/RKCONNOE_info_log4j.log&lt;/code&gt; showed:&lt;/p&gt;</description>
    </item>
    <item>
      <title>kafka-avro-console-producer - Error registering Avro schema / io.confluent.kafka.schemaregistry.client.rest.exceptions.RestClientException</title>
      <link>https://rmoff.net/2016/12/02/kafka-avro-console-producer-error-registering-avro-schema-/-io.confluent.kafka.schemaregistry.client.rest.exceptions.restclientexception/</link>
      <pubDate>Fri, 02 Dec 2016 11:35:57 +0000</pubDate>
      <guid>https://rmoff.net/2016/12/02/kafka-avro-console-producer-error-registering-avro-schema-/-io.confluent.kafka.schemaregistry.client.rest.exceptions.restclientexception/</guid>
      <description>&lt;p&gt;By default, the &lt;code&gt;kafka-avro-console-producer&lt;/code&gt; will assume that the schema registry is on port 8081, and happily connect to it. Unfortunately, this can lead to some weird errors if another process happens to be listening on port 8081 &lt;em&gt;already&lt;/em&gt;!&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;[oracle@bigdatalite tmp]$ kafka-avro-console-producer \&#xA;&amp;gt;  --broker-list localhost:9092 --topic kudu_test \&#xA;&amp;gt;  --property value.schema=&amp;#39;{&amp;#34;type&amp;#34;:&amp;#34;record&amp;#34;,&amp;#34;name&amp;#34;:&amp;#34;myrecord&amp;#34;,&amp;#34;fields&amp;#34;:[{&amp;#34;name&amp;#34;:&amp;#34;id&amp;#34;,&amp;#34;type&amp;#34;:&amp;#34;int&amp;#34;},{&amp;#34;name&amp;#34;:&amp;#34;random_field&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;string&amp;#34;}]}&amp;#39;&#xA;&#xA;{&amp;#34;id&amp;#34;: 999, &amp;#34;random_field&amp;#34;: &amp;#34;foo&amp;#34;}&#xA;&#xA;org.apache.kafka.common.errors.SerializationException: Error registering Avro schema: {&amp;#34;type&amp;#34;:&amp;#34;record&amp;#34;,&amp;#34;name&amp;#34;:&amp;#34;myrecord&amp;#34;,&amp;#34;fields&amp;#34;:[{&amp;#34;name&amp;#34;:&amp;#34;id&amp;#34;,&amp;#34;type&amp;#34;:&amp;#34;int&amp;#34;},{&amp;#34;name&amp;#34;:&amp;#34;random_field&amp;#34;,&amp;#34;type&amp;#34;:&amp;#34;string&amp;#34;}]}&#xA;Caused by: io.confluent.kafka.schemaregistry.client.rest.exceptions.RestClientException: Unexpected character (&amp;#39;&amp;lt;&amp;#39; (code 60)): expected a valid value (number, String, array, object, &amp;#39;true&amp;#39;, &amp;#39;false&amp;#39; or &amp;#39;null&amp;#39;)&#xA; at [Source: sun.net.www.protocol.http.HttpURLConnection$HttpInputStream@4e0ae11f; line: 1, column: 2]; error code: 50005&#xA;        at io.confluent.kafka.schemaregistry.client.rest.RestService.sendHttpRequest(RestService.java:170)&#xA;        at io.confluent.kafka.schemaregistry.client.rest.RestService.httpRequest(RestService.java:187)&#xA;        at io.confluent.kafka.schemaregistry.client.rest.RestService.registerSchema(RestService.java:238)&#xA;        at io.confluent.kafka.schemaregistry.client.rest.RestService.registerSchema(RestService.java:230)&#xA;        at io.confluent.kafka.schemaregistry.client.rest.RestService.registerSchema(RestService.java:225)&#xA;        at io.confluent.kafka.schemaregistry.client.CachedSchemaRegistryClient.registerAndGetId(CachedSchemaRegistryClient.java:59)&#xA;        at io.confluent.kafka.schemaregistry.client.CachedSchemaRegistryClient.register(CachedSchemaRegistryClient.java:91)&#xA;        at io.confluent.kafka.serializers.AbstractKafkaAvroSerializer.serializeImpl(AbstractKafkaAvroSerializer.java:72)&#xA;        at io.confluent.kafka.formatter.AvroMessageReader.readMessage(AvroMessageReader.java:158)&#xA;        at kafka.tools.ConsoleProducer$.main(ConsoleProducer.scala:55)&#xA;        at kafka.tools.ConsoleProducer.main(ConsoleProducer.scala)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Solution? Make sure you specify the schema URL when you launch the producer, using &lt;code&gt;--property schema.registry.url=http://localhost:18081&lt;/code&gt; :&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
