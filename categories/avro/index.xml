<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Avro on rmoff&#39;s random ramblings</title>
    <link>https://rmoff.net/categories/avro/</link>
    <description>Recent content in Avro on rmoff&#39;s random ramblings</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 12 Sep 2017 21:55:16 +0000</lastBuildDate>
    <atom:link href="https://rmoff.net/categories/avro/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Oracle GoldenGate / Kafka Connect Handler troubleshooting</title>
      <link>https://rmoff.net/2017/09/12/oracle-goldengate-/-kafka-connect-handler-troubleshooting/</link>
      <pubDate>Tue, 12 Sep 2017 21:55:16 +0000</pubDate>
      <guid>https://rmoff.net/2017/09/12/oracle-goldengate-/-kafka-connect-handler-troubleshooting/</guid>
      <description>&lt;p&gt;The Replicat was kapput:&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;GGSCI (localhost.localdomain) 3&amp;gt; info rkconnoe&#xA;&#xA;REPLICAT   RKCONNOE  Last Started 2017-09-12 17:06   Status ABENDED&#xA;Checkpoint Lag       00:00:00 (updated 00:46:34 ago)&#xA;Log Read Checkpoint  File /u01/app/ogg/dirdat/oe000000&#xA;                     First Record  RBA 0&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So checking the OGG error log &lt;code&gt;ggserr.log&lt;/code&gt; showed&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;2017-09-12T17:06:17.572-0400  ERROR   OGG-15051  Oracle GoldenGate Delivery, rkconnoe.prm:  Java or JNI exception:&#xA;                              oracle.goldengate.util.GGException: Error detected handling operation added event.&#xA;2017-09-12T17:06:17.572-0400  ERROR   OGG-01668  Oracle GoldenGate Delivery, rkconnoe.prm:  PROCESS ABENDING.&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So checking the replicat log &lt;code&gt;dirrpt/RKCONNOE_info_log4j.log&lt;/code&gt; showed:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Oracle GoldenGate -&gt; Kafka Connect - &#34;Failed to serialize Avro data&#34;</title>
      <link>https://rmoff.net/2016/11/29/oracle-goldengate-kafka-connect-failed-to-serialize-avro-data/</link>
      <pubDate>Tue, 29 Nov 2016 22:04:38 +0000</pubDate>
      <guid>https://rmoff.net/2016/11/29/oracle-goldengate-kafka-connect-failed-to-serialize-avro-data/</guid>
      <description>&lt;p&gt;&lt;strong&gt;tl;dr&lt;/strong&gt; &lt;em&gt;Make sure that &lt;code&gt;key.converter.schema.registry.url&lt;/code&gt; and &lt;code&gt;value.converter.schema.registry.url&lt;/code&gt; are specified, and that there are no trailing whitespaces.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;I&amp;rsquo;ve been building on &lt;a href=&#34;https://www.confluent.io/blog/streaming-data-oracle-using-oracle-goldengate-kafka-connect/&#34;&gt;previous work&lt;/a&gt; I&amp;rsquo;ve done with Oracle GoldenGate and Kafka Connect, looking at how to have the change records from the Oracle database come through to Kafka in Avro format rather than the default JSON that the &lt;a href=&#34;https://java.net/projects/oracledi/downloads/directory/GoldenGate/Oracle%20GoldenGate%20Adapter%20for%20Kafka%20Connect&#34;&gt;sample configuration&lt;/a&gt; gives.&lt;/p&gt;&#xA;&lt;p&gt;Simply changing the Kafka Connect OGG configuration file (&lt;code&gt;confluent.properties&lt;/code&gt;) from&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;value.converter=org.apache.kafka.connect.json.JsonConverter&#xA;key.converter=org.apache.kafka.connect.json.JsonConverter&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;to&lt;/p&gt;</description>
    </item>
    <item>
      <title>Kafka Connect - HDFS with Hive Integration - SchemaProjectorException - Schema version required</title>
      <link>https://rmoff.net/2016/07/19/kafka-connect-hdfs-with-hive-integration-schemaprojectorexception-schema-version-required/</link>
      <pubDate>Tue, 19 Jul 2016 14:36:52 +0000</pubDate>
      <guid>https://rmoff.net/2016/07/19/kafka-connect-hdfs-with-hive-integration-schemaprojectorexception-schema-version-required/</guid>
      <description>&lt;p&gt;I&amp;rsquo;ve been doing some noodling around with Confluent&amp;rsquo;s Kafka Connect recently, as part of gaining a wider understanding into Kafka. If you&amp;rsquo;re not familiar with Kafka Connect &lt;a href=&#34;http://docs.confluent.io/3.0.0/connect/design.html&#34;&gt;this page&lt;/a&gt; gives a good idea of the thinking behind it.&lt;/p&gt;&#xA;&lt;p&gt;One issue that I hit defeated my Google-fu so I&amp;rsquo;m recording it here to hopefully help out fellow n00bs.&lt;/p&gt;&#xA;&lt;p&gt;The pipeline that I&amp;rsquo;d set up looked like this:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/Eneco/kafka-connect-twitter&#34;&gt;Eneco&amp;rsquo;s Twitter Source&lt;/a&gt; streaming tweets to a Kafka topic&lt;/li&gt;&#xA;&lt;li&gt;Confluent&amp;rsquo;s &lt;a href=&#34;https://docs.confluent.io/current/connect/kafka-connect-hdfs/index.html&#34;&gt;HDFS Sink&lt;/a&gt; to stream tweets to HDFS and define Hive table automagically over them&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;It worked great, but only if I didn&amp;rsquo;t enable the Hive integration part. For me the integration with Hive to automatically define schemas was one of the key interests for this platform, so I wanted to see if I could get it to work. The error I got was&lt;/p&gt;</description>
    </item>
    <item>
      <title>Fun and Games with Oracle GoldenGate, Kafka, and Logstash on BigDataLite 4.4</title>
      <link>https://rmoff.net/2016/03/16/fun-and-games-with-oracle-goldengate-kafka-and-logstash-on-bigdatalite-4.4/</link>
      <pubDate>Wed, 16 Mar 2016 22:01:00 +0000</pubDate>
      <guid>https://rmoff.net/2016/03/16/fun-and-games-with-oracle-goldengate-kafka-and-logstash-on-bigdatalite-4.4/</guid>
      <description>&lt;p&gt;The Oracle by Example (ObE) &lt;a href=&#34;http://www.oracle.com/webfolder/technetwork/tutorials/obe/fmw/odi/odi_12c/DI_BDL_Guide/BigDataIntegration_Demo.html?cid=10235&amp;amp;ssid=0&#34;&gt;here&lt;/a&gt; demonstrating how to use &lt;a href=&#34;https://docs.oracle.com/goldengate/bd1221/gg-bd/GBDIN/intro_adapter.htm#GBDIN101&#34;&gt;Goldengate to replicate transactions big data targets&lt;/a&gt; such as HDFS is written for the BigDataLite &lt;a href=&#34;http://www.oracle.com/technetwork/database/bigdata-appliance/oracle-bigdatalite421-2843803.html&#34;&gt;4.2.1&lt;/a&gt;, and for me didn&amp;rsquo;t work on the current latest version, &lt;a href=&#34;http://www.oracle.com/technetwork/database/bigdata-appliance/oracle-bigdatalite-2104726.html&#34;&gt;4.4.0&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;The OBE (and similar &lt;a href=&#34;http://www.oracle.com/webfolder/technetwork/odi/ODI_BigData_HOL.pdf&#34;&gt;Hands On Lab&lt;/a&gt; PDF) assume the presence of &lt;code&gt;pmov.prm&lt;/code&gt; and &lt;code&gt;pmov.properties&lt;/code&gt; in &lt;code&gt;/u01/ogg/dirprm/&lt;/code&gt;. On BDL 4.4 there&amp;rsquo;s only the extract to from Oracle configuration, &lt;code&gt;emov&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Fortunately it&amp;rsquo;s still possible to run this setup out of the box in BDL 4.4, with bells on because it includes &lt;a href=&#34;http://kafka.apache.org/&#34;&gt;Kafka&lt;/a&gt; too. And, who doesn&amp;rsquo;t like a bit of Kafka nowadays?&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
