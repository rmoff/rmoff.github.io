<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8" />

  
  <title>
  Category → kafka
  
   | rmoff.net
</title>

  
  
  <link href="//cdn.jsdelivr.net" rel="dns-prefetch">
  <link href="//cdnjs.cloudflare.com" rel="dns-prefetch">
  <link href="//at.alicdn.com" rel="dns-prefetch">
  <link href="//fonts.googleapis.com" rel="dns-prefetch">
  <link href="//fonts.gstatic.com" rel="dns-prefetch">
  <link href="///disqus.com" rel="dns-prefetch">
  <link href="//c.disquscdn.com" rel="dns-prefetch">
  
  
  

  

  
  
  

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="@gohugoio">
  <meta name="twitter:title" content="rmoff.net">
  
  <meta name="twitter:image" content="/images/avatar.jpg">

  
  <meta property="og:type" content="website">
  <meta property="og:title" content="rmoff.net">
  
  <meta property="og:url" content="https://rmoff.github.io/categories/kafka/">
  <meta property="og:image" content="/images/avatar.jpg">




<meta name="generator" content="Hugo 0.52">


<link rel="canonical" href="https://rmoff.github.io/categories/kafka/">
<link rel="alternate" type="application/rss+xml" href="https://rmoff.github.io/categories/kafka/index.xml" title="rmoff.net">

<meta name="renderer" content="webkit">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="format-detection" content="telephone=no,email=no,adress=no">
<meta http-equiv="Cache-Control" content="no-transform">


<meta name="robots" content="index,follow">
<meta name="referrer" content="origin-when-cross-origin">







<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="apple-mobile-web-app-title" content="rmoff.net">
<meta name="msapplication-tooltip" content="rmoff.net">
<meta name='msapplication-navbutton-color' content="#5fbf5e">
<meta name="msapplication-TileColor" content="#5fbf5e">
<meta name="msapplication-TileImage" content="/images/tile-image-windows.png">
<link rel="icon" href="/images/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
<link rel="icon" sizes="192x192" href="/images/touch-icon-android.png">
<link rel="apple-touch-icon" href="/images/touch-icon-apple.png">


<link rel="preload" href="/styles/main.min.css" as="style">
<link rel="preload" href="https://fonts.googleapis.com/css?family=Lobster" as="style">
<link rel="preload" href="/images/avatar.jpg" as="image">
<link rel="preload" href="/images/grey-prism.svg" as="image">


<style>
  body {
    background: rgb(244, 243, 241) url('/images/grey-prism.svg') repeat fixed;
  }
</style>
<link rel="stylesheet" href="/styles/main.min.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lobster">


<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.2/dist/medium-zoom.min.js"></script>





  
  
<!--[if lte IE 8]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/videojs-ie8@1.1.2/dist/videojs-ie8.min.js"></script>
<![endif]-->

<!--[if lte IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/eligrey-classlist-js-polyfill@1.2.20180112/classList.min.js"></script>
<![endif]-->


<script src="https://cdn.jsdelivr.net/npm/smooth-scroll@14.2.1/dist/smooth-scroll.polyfills.min.js"></script>


</head>
  <body>
    
    <div class="suspension">
      <a title="Go to top" class="to-top is-hide"><span class="icon icon-up"></span></a>
      
    </div>
    
    
  <header class="site-header">
  <img class="avatar" src="/images/avatar.jpg" alt="Avatar">
  
  <h2 class="title">rmoff.net</h2>
  
  <p class="subtitle"></p>
  <button class="menu-toggle" type="button">
    <span class="icon icon-menu"></span>
  </button>
  <nav class="site-menu collapsed">
    <h2 class="offscreen">Main Menu</h2>
    <ul class="menu-list">
      
      
      
      
        <li class="menu-item
            
            
            ">
            <a href="/about-me/">about me</a>
          </li>
      
        <li class="menu-item
            
            
            ">
            <a href="/presentations/">presentations</a>
          </li>
      
    </ul>
  </nav>
  <nav class="social-menu collapsed">
    <h2 class="offscreen">Social Networks</h2>
    <ul class="social-list"></ul>
  </nav>
</header>

  <section class="main post-list">
    <header class="list-header offscreen">
      <h2 class="list-label">Posts List</h2>
    </header>
    
    
      
        <article class="post-entry">
  <header class="post-header">
    <h3 class="post-title"><a href="https://rmoff.github.io/2018/10/11/flatten-cdc-records-in-ksql/" class="post-link">Flatten CDC records in KSQL</a></h3>
    <p class="post-meta">@Robin Moffatt · Oct 11, 2018 · 3 min read</p>
  </header>
  
  <p class="post-summary">The problem - nested messages in Kafka Data comes into Kafka in many shapes and sizes. Sometimes it’s from CDC tools, and may be nested like this:
{ &#34;SCN&#34;: 12206116841348, &#34;SEG_OWNER&#34;: &#34;KFKUSER&#34;, &#34;TABLE_NAME&#34;: &#34;CDCTAB2&#34;, &#34;TIMESTAMP&#34;: 1539162785000, &#34;SQL_REDO&#34;: &#34;insert into \&#34;KFKUSER\&#34;.\&#34;CDCTAB2\&#34;(\&#34;ID\&#34;,\&#34;CITY\&#34;,\&#34;NATIONALITY\&#34;) values (634789,&#39;AHMEDABAD&#39;,&#39;INDIA&#39;)&#34;, &#34;OPERATION&#34;: &#34;INSERT&#34;, &#34;data&#34;: { &#34;value&#34;: { &#34;ID&#34;: 634789, &#34;CITY&#34;: { &#34;string&#34;: &#34;AHMEDABAD&#34; }, &#34;NATIONALITY&#34;: { &#34;string&#34;: &#34;INDIA&#34; } } }, &#34;before&#34;: null }  Note that the ‘payload’ is nested under data-&gt;value.</p>
  <footer class="post-footer">
    <a class="read-more" href="https://rmoff.github.io/2018/10/11/flatten-cdc-records-in-ksql/">Read More →</a>
  </footer>
</article>

      
        <article class="post-entry">
  <header class="post-header">
    <h3 class="post-title"><a href="https://rmoff.github.io/2018/10/05/streaming-geopoint-data-from-kafka-to-elasticsearch/" class="post-link">Streaming geopoint data from Kafka to Elasticsearch</a></h3>
    <p class="post-meta">@Robin Moffatt · Oct 5, 2018 · 3 min read</p>
  </header>
  
  <p class="post-summary">Using the Elasticsearch Kafka Connect connector to stream events from a Kafka topic to Elasticsearch.
curl -X &#34;POST&#34; &#34;http://kafka-connect:8083/connectors/&#34; \ -H &#34;Content-Type: application/json&#34; \ -d &#39;{ &#34;name&#34;: &#34;es_sink_ATM_POSSIBLE_FRAUD&#34;, &#34;config&#34;: { &#34;topics&#34;: &#34;ATM_POSSIBLE_FRAUD&#34;, &#34;key.converter&#34;: &#34;org.apache.kafka.connect.storage.StringConverter&#34;, &#34;value.converter&#34;: &#34;org.apache.kafka.connect.json.JsonConverter&#34;, &#34;value.converter.schemas.enable&#34;: false, &#34;connector.class&#34;: &#34;io.confluent.connect.elasticsearch.ElasticsearchSinkConnector&#34;, &#34;key.ignore&#34;: &#34;true&#34;, &#34;schema.ignore&#34;: &#34;true&#34;, &#34;type.name&#34;: &#34;type.name=kafkaconnect&#34;, &#34;topic.index.map&#34;: &#34;ATM_POSSIBLE_FRAUD:atm_possible_fraud&#34;, &#34;connection.url&#34;: &#34;http://elasticsearch:9200&#34; } }&#39;  Dynamic mapping setup in Elasticsearch (before running the Connector) to force columns to a given type:
curl -XPUT &#34;http://elasticsearch:9200/_template/kafkaconnect/&#34; -H &#39;Content-Type: application/json&#39; -d&#39; { &#34;index_patterns&#34;: &#34;*&#34;, &#34;settings&#34;: { &#34;number_of_shards&#34;: 1, &#34;number_of_replicas&#34;: 0 }, &#34;mappings&#34;: { &#34;_default_&#34;: { &#34;dynamic_templates&#34;: [ { &#34;dates&#34;: { &#34;match&#34;: &#34;*TIMESTAMP&#34;, &#34;mapping&#34;: { &#34;type&#34;: &#34;date&#34; } } }, { &#34;geopoint&#34;: { &#34;match&#34;: &#34;*LOCATION&#34;, &#34;mapping&#34;: { &#34;type&#34;: &#34;geo_point&#34; } } }, { &#34;geopoint2&#34;: { &#34;match&#34;: &#34;location&#34;, &#34;mapping&#34;: { &#34;type&#34;: &#34;geo_point&#34; } } }, { &#34;non_analysed_string_template&#34;: { &#34;match&#34;: &#34;account_id, atm, transaction_id&#34;, &#34;match_mapping_type&#34;: &#34;string&#34;, &#34;mapping&#34;: { &#34;type&#34;: &#34;keyword&#34; } } } ] } } }&#39;  Sample JSON message from Kafka: (pretty-printed)</p>
  <footer class="post-footer">
    <a class="read-more" href="https://rmoff.github.io/2018/10/05/streaming-geopoint-data-from-kafka-to-elasticsearch/">Read More →</a>
  </footer>
</article>

      
        <article class="post-entry">
  <header class="post-header">
    <h3 class="post-title"><a href="https://rmoff.github.io/2018/09/19/exploring-jmx-with-jmxterm/" class="post-link">Exploring JMX with jmxterm</a></h3>
    <p class="post-meta">@Robin Moffatt · Sep 19, 2018 · 2 min read</p>
  </header>
  
  <p class="post-summary">Check out the jmxterm repository / Download jmxterm from http://wiki.cyclopsgroup.org/jmxterm/
Launch:
java -jar ~/Downloads/jmxterm-1.0.0-uber.jar --url localhost:30002  You can pass the jmx host/port directly, or use the open command once jmxterm launches.
Once connected, use domains to list available domains
$&gt;domains #following domains are available JMImplementation com.sun.management io.confluent.ksql.metrics io.confluent.rest java.lang java.nio java.util.logging kafka.admin.client kafka.consumer kafka.producer kafka.streams [...]  Switch to a particular domain:
$&gt;domain io.confluent.ksql.metrics #domain is set to io.confluent.ksql.metrics  List the available MBeans in a the selected domain (you can also run this without choosing a domain first, to see every MBean, but it’s a long list):</p>
  <footer class="post-footer">
    <a class="read-more" href="https://rmoff.github.io/2018/09/19/exploring-jmx-with-jmxterm/">Read More →</a>
  </footer>
</article>

      
        <article class="post-entry">
  <header class="post-header">
    <h3 class="post-title"><a href="https://rmoff.github.io/2018/09/17/accessing-kafka-docker-containers-jmx-from-host/" class="post-link">Accessing Kafka Docker containers&#39; JMX from host</a></h3>
    <p class="post-meta">@Robin Moffatt · Sep 17, 2018 · 2 min read</p>
  </header>
  
  <p class="post-summary">To help future Googlers… with the Confluent docker images for Kafka, KSQL, Kafka Connect, etc, if you want to access JMX metrics from within, you just need to pass two environment variables:
 KSQL_JMX_HOSTNAME - the hostname/IP of the host machine. This is used by the JMX client to connect back into JMX, so must be accessible from the host machine running the JMX client. If you’re just running your JMX client locally on the Docker host, you can set this to 127.</p>
  <footer class="post-footer">
    <a class="read-more" href="https://rmoff.github.io/2018/09/17/accessing-kafka-docker-containers-jmx-from-host/">Read More →</a>
  </footer>
</article>

      
        <article class="post-entry">
  <header class="post-header">
    <h3 class="post-title"><a href="https://rmoff.github.io/2018/09/04/sending-multiline-messages-to-kafka/" class="post-link">Sending multiline messages to Kafka</a></h3>
    <p class="post-meta">@Robin Moffatt · Sep 4, 2018 · 1 min read</p>
  </header>
  
  <p class="post-summary">(SO answer repost)
You can use kafkacat to send messages to Kafka that include line breaks. To do this, use its -D operator to specify a custom message delimiter (in this example /):
kafkacat -b kafka:29092 \ -t test_topic_01 \ -D/ \ -P &lt;&lt;EOF this is a string message with a line break/this is another message with two line breaks! EOF  Note that the delimiter must be a single byte - multi-byte chars will end up getting included in the resulting message See issue #140</p>
  <footer class="post-footer">
    <a class="read-more" href="https://rmoff.github.io/2018/09/04/sending-multiline-messages-to-kafka/">Read More →</a>
  </footer>
</article>

      
        <article class="post-entry">
  <header class="post-header">
    <h3 class="post-title"><a href="https://rmoff.github.io/2018/08/02/kafka-listeners-explained/" class="post-link">Kafka Listeners - Explained</a></h3>
    <p class="post-meta">@Robin Moffatt · Aug 2, 2018 · 11 min read</p>
  </header>
  
  <p class="post-summary">This question comes up on StackOverflow and such places a lot, so here’s something to try and help.
tl;dr : You need to set advertised.listeners (or KAFKA_ADVERTISED_LISTENERS if you’re using Docker images) to the external address (host/IP) so that clients can correctly connect to it. Otherwise they’ll try to connect to the internal host address–and if that’s not reachable then problems ensue.
In this post I’ll talk about why this is necessary, and then show how to do it, based on a couple of scenarios - Docker, and AWS.</p>
  <footer class="post-footer">
    <a class="read-more" href="https://rmoff.github.io/2018/08/02/kafka-listeners-explained/">Read More →</a>
  </footer>
</article>

      
        <article class="post-entry">
  <header class="post-header">
    <h3 class="post-title"><a href="https://rmoff.github.io/2018/05/10/quick-n-easy-population-of-realistic-test-data-into-kafka/" class="post-link">Quick &#39;n Easy Population of Realistic Test Data into Kafka</a></h3>
    <p class="post-meta">@Robin Moffatt · May 10, 2018 · 3 min read</p>
  </header>
  
  <p class="post-summary">tl;dr Use curl to pull data from the Mockaroo REST endpoint, and pipe it into kafkacat, thus:
curl -s &#34;https://api.mockaroo.com/api/d5a195e0?count=2&amp;key=ff7856d0&#34;| \ kafkacat -b localhost:9092 -t purchases -P  Three things I love…Kafka, kafkacat, and Mockaroo. And in this post I get to show all three 😁
Mockaroo is a very cool online service that lets you quickly mock up test data. What sets it apart from SELECT RANDOM(100) FROM DUMMY; is that it has lots of different classes of test data for you to choose from.</p>
  <footer class="post-footer">
    <a class="read-more" href="https://rmoff.github.io/2018/05/10/quick-n-easy-population-of-realistic-test-data-into-kafka/">Read More →</a>
  </footer>
</article>

      
        <article class="post-entry">
  <header class="post-header">
    <h3 class="post-title"><a href="https://rmoff.github.io/2018/03/24/streaming-data-from-mysql-into-kafka-with-kafka-connect-and-debezium/" class="post-link">Streaming Data from MySQL into Kafka with Kafka Connect and Debezium</a></h3>
    <p class="post-meta">@Robin Moffatt · Mar 24, 2018 · 6 min read</p>
  </header>
  
  <p class="post-summary">Debezium is a CDC tool that can stream changes from MySQL, MongoDB, and PostgreSQL into Kafka, using Kafka Connect. In this article we’ll see how to set it up and examine the format of the data. A subsequent article will show using this realtime stream of data from a RDBMS and join it to data originating from other sources, using KSQL.
The software versions used here are:
 Confluent Platform 4.</p>
  <footer class="post-footer">
    <a class="read-more" href="https://rmoff.github.io/2018/03/24/streaming-data-from-mysql-into-kafka-with-kafka-connect-and-debezium/">Read More →</a>
  </footer>
</article>

      
        <article class="post-entry">
  <header class="post-header">
    <h3 class="post-title"><a href="https://rmoff.github.io/2018/03/06/streaming-data-from-kafka-into-elasticsearch/" class="post-link">Streaming data from Kafka into Elasticsearch</a></h3>
    <p class="post-meta">@Robin Moffatt · Mar 6, 2018 · 2 min read</p>
  </header>
  
  <p class="post-summary">This article is part of a series exploring Streaming ETL in practice. You can read about setting up the ingest of realtime events from a standard Oracle platform, and building streaming ETL using KSQL.
This post shows how we take data streaming in from an Oracle transactional system into Kafka, and simply stream it onwards into Elasticsearch. This is a common pattern, for enabling rapid search or analytics against data held in systems elsewhere.</p>
  <footer class="post-footer">
    <a class="read-more" href="https://rmoff.github.io/2018/03/06/streaming-data-from-kafka-into-elasticsearch/">Read More →</a>
  </footer>
</article>

      
        <article class="post-entry">
  <header class="post-header">
    <h3 class="post-title"><a href="https://rmoff.github.io/2018/03/06/installing-the-python-kafka-library-from-confluent-troubleshooting-some-silly-errors/" class="post-link">Installing the Python Kafka library from Confluent - troubleshooting some silly errors…</a></h3>
    <p class="post-meta">@Robin Moffatt · Mar 6, 2018 · 3 min read</p>
  </header>
  
  <p class="post-summary">System:
rmoff@proxmox01:~$ uname -a Linux proxmox01 4.4.6-1-pve #1 SMP Thu Apr 21 11:25:40 CEST 2016 x86_64 GNU/Linux rmoff@proxmox01:~$ head -n1 /etc/os-release PRETTY_NAME=&#34;Debian GNU/Linux 8 (jessie)&#34; rmoff@proxmox01:~$ python --version Python 2.7.9  Following:
 https://www.confluent.io/blog/introduction-to-apache-kafka-for-python-programmers/ https://github.com/confluentinc/confluent-kafka-python  Install librdkafka, which is a pre-req for the Python library:
wget -qO - https://packages.confluent.io/deb/4.0/archive.key | sudo apt-key add - sudo add-apt-repository &#34;deb [arch=amd64] https://packages.confluent.io/deb/4.0 stable main&#34; sudo apt-get install librdkafka-dev python-dev  Setup virtualenv:</p>
  <footer class="post-footer">
    <a class="read-more" href="https://rmoff.github.io/2018/03/06/installing-the-python-kafka-library-from-confluent-troubleshooting-some-silly-errors/">Read More →</a>
  </footer>
</article>

      
    
    
      <footer class="list-footer">
        <nav class="pagination">
          <h3 class="offscreen">Pagination</h3>
          
          
            <a class="pagination-next" href="/categories/kafka/page/2/">Older Posts →</a>
          
        </nav>
      </footer>
    
  </section>
  


<footer class="site-footer">
  <p>© 2017-2018 rmoff.net</p>
  <p>Powered by <a href="https://gohugo.io/" target="_blank">Hugo</a> with theme <a href="https://github.com/laozhu/hugo-nuo" target="_blank">Nuo</a>.</p>
  
</footer>








<script src="/scripts/index.min.js"></script>








  </body>
</html>
