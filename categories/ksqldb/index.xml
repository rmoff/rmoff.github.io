<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>KsqlDB on rmoff&#39;s random ramblings</title>
    <link>https://rmoff.net/categories/ksqldb/</link>
    <description>Recent content in KsqlDB on rmoff&#39;s random ramblings</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 01 Apr 2021 23:06:22 +0100</lastBuildDate>
    <atom:link href="https://rmoff.net/categories/ksqldb/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>A bash script to deploy ksqlDB queries automagically</title>
      <link>https://rmoff.net/2021/04/01/a-bash-script-to-deploy-ksqldb-queries-automagically/</link>
      <pubDate>Thu, 01 Apr 2021 23:06:22 +0100</pubDate>
      <guid>https://rmoff.net/2021/04/01/a-bash-script-to-deploy-ksqldb-queries-automagically/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;There‚Äôs &lt;a href=&#34;https://github.com/spena/ksql/blob/7bc5875896c0206574e096c0ead808b5a87caa89/design-proposals/klip-42-schema-migrations-tool.md&#34;&gt;a bunch of improvements&lt;/a&gt; in the works for how ksqlDB handles code deployments and migrations. For now though, for deploying queries there‚Äôs the option of using &lt;a href=&#34;https://docs.ksqldb.io/en/latest/operate-and-deploy/installation/server-config/#non-interactive-headless-ksqldb-usage&#34;&gt;headless mode&lt;/a&gt; (which is limited to one query file and disables subsequent interactive work on the server from a CLI), manually running commands (yuck), or using the REST endpoint to deploy queries automagically. Here‚Äôs an example of doing that.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Connecting to managed ksqlDB in Confluent Cloud with REST and ksqlDB CLI</title>
      <link>https://rmoff.net/2021/03/24/connecting-to-managed-ksqldb-in-confluent-cloud-with-rest-and-ksqldb-cli/</link>
      <pubDate>Wed, 24 Mar 2021 09:36:43 +0000</pubDate>
      <guid>https://rmoff.net/2021/03/24/connecting-to-managed-ksqldb-in-confluent-cloud-with-rest-and-ksqldb-cli/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Using ksqlDB in &lt;a href=&#34;https://www.confluent.io/confluent-cloud/tryfree?utm_source=rmoff&amp;amp;utm_medium=blog&amp;amp;utm_campaign=tm.devx_ch.rmoff_ksqldb-local-to-cloud&amp;amp;utm_term=rmoff-devx&#34;&gt;Confluent Cloud&lt;/a&gt; makes things a whole bunch easier because now you just get to build apps and streaming pipelines, instead of having to run and manage a bunch of infrastructure yourself.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Once you‚Äôve got ksqlDB provisioned on Confluent Cloud you can use the web-based editor to build and run queries. You can also connect to it using the &lt;a href=&#34;https://docs.ksqldb.io/en/latest/developer-guide/ksqldb-rest-api/?utm_source=rmoff&amp;amp;utm_medium=blog&amp;amp;utm_campaign=tm.devx_ch.rmoff_ksqldb-local-to-cloud&amp;amp;utm_term=rmoff-devx&#34;&gt;REST API&lt;/a&gt; and the ksqlDB CLI tool. Here‚Äôs how.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Using ksqlDB to process data ingested from ActiveMQ with Kafka Connect</title>
      <link>https://rmoff.net/2021/03/19/using-ksqldb-to-process-data-ingested-from-activemq-with-kafka-connect/</link>
      <pubDate>Fri, 19 Mar 2021 10:30:47 +0000</pubDate>
      <guid>https://rmoff.net/2021/03/19/using-ksqldb-to-process-data-ingested-from-activemq-with-kafka-connect/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;The ActiveMQ source connector creates a &lt;a href=&#34;https://docs.confluent.io/kafka-connect-activemq-source/current/index.html#io-confluent-connect-jms-value&#34;&gt;Struct holding the value&lt;/a&gt; of the message from ActiveMQ (as well as its &lt;a href=&#34;https://docs.confluent.io/kafka-connect-activemq-source/current/index.html#io-confluent-connect-jms-key&#34;&gt;key&lt;/a&gt;). This is as would be expected. However, you can encounter &lt;em&gt;challenges&lt;/em&gt; in working with the data if the ActiveMQ data of interest within the payload is complex. Things like converters and schemas can get really funky, really quick.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Loading delimited data into Kafka - quick &amp; dirty (but effective)</title>
      <link>https://rmoff.net/2021/02/26/loading-delimited-data-into-kafka-quick-dirty-but-effective/</link>
      <pubDate>Fri, 26 Feb 2021 22:45:36 +0000</pubDate>
      <guid>https://rmoff.net/2021/02/26/loading-delimited-data-into-kafka-quick-dirty-but-effective/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Whilst Apache Kafka is an event streaming platform designed for, well, &lt;em&gt;streams&lt;/em&gt; of events, it‚Äôs perfectly valid to use it as a store of data which perhaps changes only occasionally (or even never). I‚Äôm thinking here of reference data (lookup data) that‚Äôs used to enrich regular streams of events.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;You might well get your reference data from a database where it resides and do so effectively &lt;a href=&#34;https://rmoff.dev/no-more-silos&#34;&gt;using CDC&lt;/a&gt; - but sometimes it comes down to those pesky CSV files that we all know and love/hate. Simple, awful, but effective. I wrote previously about &lt;a href=&#34;https://rmoff.net/2020/06/17/loading-csv-data-into-kafka/&#34;&gt;loading CSV data into Kafka from files that are updated frequently&lt;/a&gt;, but here I want to look at CSV files that are not changing. Kafka Connect simplifies getting data in to (and out of) Kafka but even Kafka Connect becomes a bit of an overhead when you just have a single file that you want to load into a topic and then never deal with again. I spent this afternoon wrangling with a couple of CSV-ish files, and building on my previous article about &lt;a href=&#34;https://rmoff.net/2021/02/02/performing-a-group-by-on-data-in-bash/&#34;&gt;neat tricks you can do in bash with data&lt;/a&gt;, I have some more to share with you here :)&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>üìº ksqlDB HOWTO - A mini video series üìº</title>
      <link>https://rmoff.net/2021/02/17/ksqldb-howto-a-mini-video-series/</link>
      <pubDate>Wed, 17 Feb 2021 23:12:33 +0000</pubDate>
      <guid>https://rmoff.net/2021/02/17/ksqldb-howto-a-mini-video-series/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Some people learn through doing - and for that there‚Äôs a bunch of good ksqlDB tutorials &lt;a href=&#34;https://docs.ksqldb.io/en/latest/tutorials/?utm_source=rmoff&amp;amp;utm_medium=blog&amp;amp;utm_campaign=tm.devx_ch.rmoff_ksqldb-howto&amp;amp;utm_term=rmoff-devx&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://kafka-tutorials.confluent.io/?utm_source=rmoff&amp;amp;utm_medium=blog&amp;amp;utm_campaign=tm.devx_ch.rmoff_ksqldb-howto&amp;amp;utm_term=rmoff-devx&#34;&gt;here&lt;/a&gt;. Others may prefer to watch and listen first, before getting hands on. And for that, I humbly offer you this little series of videos all about ksqlDB. They‚Äôre all based on a set of demo scripts that you can &lt;a href=&#34;https://github.com/confluentinc/demo-scene/blob/master/introduction-to-ksqldb/demo_introduction_to_ksqldb_02.adoc&#34;&gt;run for yourself and try out&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;üö® Make sure you &lt;a href=&#34;http://youtube.com/rmoff?sub_confirmation=1&#34;&gt;subscribe to my YouTube channel&lt;/a&gt; so that you don‚Äôt miss more videos like these!&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Kafka Connect, ksqlDB, and Kafka Tombstone messages</title>
      <link>https://rmoff.net/2020/11/03/kafka-connect-ksqldb-and-kafka-tombstone-messages/</link>
      <pubDate>Tue, 03 Nov 2020 17:14:33 +0000</pubDate>
      <guid>https://rmoff.net/2020/11/03/kafka-connect-ksqldb-and-kafka-tombstone-messages/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;As you may already realise, Kafka is not just a fancy message bus, or a pipe for big data. It‚Äôs an event streaming platform! If this is news to you, I‚Äôll wait here whilst you &lt;a href=&#34;https://www.confluent.io/learn/kafka-tutorial/&#34;&gt;read this&lt;/a&gt; or &lt;a href=&#34;https://rmoff.dev/kafka101&#34;&gt;watch this&lt;/a&gt;‚Ä¶&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Streaming Geopoint data from Kafka to Elasticsearch</title>
      <link>https://rmoff.net/2020/11/03/streaming-geopoint-data-from-kafka-to-elasticsearch/</link>
      <pubDate>Tue, 03 Nov 2020 10:36:18 +0000</pubDate>
      <guid>https://rmoff.net/2020/11/03/streaming-geopoint-data-from-kafka-to-elasticsearch/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Streaming data from Kafka to Elasticsearch is easy with Kafka Connect - you can see how in this &lt;a href=&#34;https://rmoff.dev/kafka-elasticsearch&#34;&gt;tutorial&lt;/a&gt; and &lt;a href=&#34;https://rmoff.dev/kafka-elasticsearch-video&#34;&gt;video&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;One of the things that sometimes causes issues though is how to get location data correctly indexed into Elasticsearch as &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/geo-point.html&#34;&gt;&lt;code&gt;geo_point&lt;/code&gt;&lt;/a&gt; fields to enable all that lovely location analysis. Unlike data types like dates and numerics, Elasticsearch‚Äôs &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic-field-mapping.html&#34;&gt;Dynamic Field Mapping&lt;/a&gt; won‚Äôt automagically pick up &lt;code&gt;geo_point&lt;/code&gt; data, and so you have to do two things:&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>ksqlDB - How to model a variable number of fields in a nested value (`STRUCT`)</title>
      <link>https://rmoff.net/2020/10/07/ksqldb-how-to-model-a-variable-number-of-fields-in-a-nested-value-struct/</link>
      <pubDate>Wed, 07 Oct 2020 11:44:51 +0100</pubDate>
      <guid>https://rmoff.net/2020/10/07/ksqldb-how-to-model-a-variable-number-of-fields-in-a-nested-value-struct/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;There was a &lt;a href=&#34;https://stackoverflow.com/questions/64241285/kafka-topic-with-variable-nested-json-object-as-ksql-db-stream/64242383#64242383&#34;&gt;good question on StackOverflow&lt;/a&gt; recently in which someone was struggling to find the appropriate ksqlDB DDL to model a source topic in which there was a variable number of fields in a &lt;code&gt;STRUCT&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>üìå    üéÅ A collection of Kafka-related talks üíù</title>
      <link>https://rmoff.net/2020/09/23/a-collection-of-kafka-related-talks/</link>
      <pubDate>Wed, 23 Sep 2020 15:00:05 +0100</pubDate>
      <guid>https://rmoff.net/2020/09/23/a-collection-of-kafka-related-talks/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Here‚Äôs a collection of Kafka-related talks, &lt;em&gt;just for you.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Each one has üçøüé• a recording, üìî slides, and üëæ code to go and try out.¬†&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Using the Debezium MS SQL connector with ksqlDB embedded Kafka Connect</title>
      <link>https://rmoff.net/2020/09/18/using-the-debezium-ms-sql-connector-with-ksqldb-embedded-kafka-connect/</link>
      <pubDate>Fri, 18 Sep 2020 10:00:05 +0100</pubDate>
      <guid>https://rmoff.net/2020/09/18/using-the-debezium-ms-sql-connector-with-ksqldb-embedded-kafka-connect/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Prompted by &lt;a href=&#34;https://stackoverflow.com/questions/63946368/how-to-use-the-debezium-sql-server-connector-with-ksqldb-embedded-connect&#34;&gt;a question on StackOverflow&lt;/a&gt; I thought I‚Äôd take a quick look at setting up &lt;a href=&#34;https://ksqldb.io&#34;&gt;ksqlDB&lt;/a&gt; to ingest CDC events from Microsoft SQL Server using &lt;a href=&#34;https://debezium.io/&#34;&gt;Debezium&lt;/a&gt;. Some of this is based on my previous article, &lt;a href=&#34;https://rmoff.net/2019/11/20/streaming-data-from-sql-server-to-kafka-to-snowflake-with-kafka-connect/&#34;&gt;Streaming data from SQL Server to Kafka to Snowflake ‚ùÑÔ∏è with Kafka Connect&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;sect1&#34;&gt;&#xA;&lt;h2 id=&#34;_setting_up_the_docker_compose&#34;&gt;Setting up the Docker Compose&lt;/h2&gt;&#xA;&lt;div class=&#34;sectionbody&#34;&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;I like standalone, repeatable, demo code. For that reason I love using Docker Compose and I embed everything in there - connector installation, the kitchen sink - the works.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Counting the number of messages in a Kafka topic</title>
      <link>https://rmoff.net/2020/09/08/counting-the-number-of-messages-in-a-kafka-topic/</link>
      <pubDate>Tue, 08 Sep 2020 10:00:05 +0100</pubDate>
      <guid>https://rmoff.net/2020/09/08/counting-the-number-of-messages-in-a-kafka-topic/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;There‚Äôs ways, and then there‚Äôs ways, to count the number of records/events/messages in a Kafka topic. Most of them are potentially inaccurate, or inefficient, or both. Here‚Äôs one that falls into the &lt;em&gt;potentially inefficient&lt;/em&gt; category, using &lt;code&gt;kafkacat&lt;/code&gt; to read all the messages and pipe to &lt;code&gt;wc&lt;/code&gt; which with the &lt;code&gt;-l&lt;/code&gt; will tell you how many lines there are, and since each message is a line, how many messages you have in the Kafka topic:&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;listingblock&#34;&gt;&#xA;&lt;div class=&#34;content&#34;&gt;&#xA;&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;$ &lt;/span&gt;kafkacat &lt;span style=&#34;color: #f92672&#34;&gt;-b&lt;/span&gt; broker:29092 &lt;span style=&#34;color: #f92672&#34;&gt;-t&lt;/span&gt; mytestopic &lt;span style=&#34;color: #f92672&#34;&gt;-C&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;-e&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;-q&lt;/span&gt;| &lt;span style=&#34;color: #f8f8f2&#34;&gt;wc&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;-l&lt;/span&gt;&#xA;       3&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>ü§ñBuilding a Telegram bot with Apache Kafka, Go, and ksqlDB</title>
      <link>https://rmoff.net/2020/08/20/building-a-telegram-bot-with-apache-kafka-go-and-ksqldb/</link>
      <pubDate>Thu, 20 Aug 2020 10:00:05 +0100</pubDate>
      <guid>https://rmoff.net/2020/08/20/building-a-telegram-bot-with-apache-kafka-go-and-ksqldb/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;I had the pleasure of presenting at &lt;a href=&#34;https://dataengconf.com.au/&#34;&gt;DataEngBytes&lt;/a&gt; recently, and am delighted to share with you the &lt;strong&gt;üóíÔ∏è slides, üëæ code, and üé• recording&lt;/strong&gt; of my ‚ú®brand new talk‚ú®:&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://rmoff.dev/carpark-telegram-bot&#34;&gt;ü§ñBuilding a Telegram bot with Apache Kafka, Go, and ksqlDB&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Learning Golang (some rough notes) - S02E09 - Processing chunked responses before EOF is reached</title>
      <link>https://rmoff.net/2020/07/23/learning-golang-some-rough-notes-s02e09-processing-chunked-responses-before-eof-is-reached/</link>
      <pubDate>Thu, 23 Jul 2020 10:00:05 +0100</pubDate>
      <guid>https://rmoff.net/2020/07/23/learning-golang-some-rough-notes-s02e09-processing-chunked-responses-before-eof-is-reached/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;The server sends &lt;code&gt;Transfer-Encoding: chunked&lt;/code&gt; data, and you want to work with the data &lt;strong&gt;as you get it&lt;/strong&gt;, instead of waiting for the server to finish, the EOF to fire, and &lt;em&gt;then&lt;/em&gt; process the data?&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Why JSON isn&#39;t the same as JSON Schema in Kafka Connect converters and ksqlDB (Viewing Kafka messages bytes as hex)</title>
      <link>https://rmoff.net/2020/07/03/why-json-isnt-the-same-as-json-schema-in-kafka-connect-converters-and-ksqldb-viewing-kafka-messages-bytes-as-hex/</link>
      <pubDate>Fri, 03 Jul 2020 08:16:36 +0100</pubDate>
      <guid>https://rmoff.net/2020/07/03/why-json-isnt-the-same-as-json-schema-in-kafka-connect-converters-and-ksqldb-viewing-kafka-messages-bytes-as-hex/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;I‚Äôve been playing around with the new SerDes (serialisers/deserialisers) that shipped with Confluent Platform 5.5 - &lt;a href=&#34;https://docs.confluent.io/current/schema-registry/serdes-develop/index.html&#34;&gt;Protobuf, and JSON Schema&lt;/a&gt; (these were added to the existing support for Avro). The serialisers (and associated &lt;a href=&#34;https://docs.confluent.io/current/schema-registry/connect.html&#34;&gt;Kafka Connect converters&lt;/a&gt;) take a payload and serialise it into bytes for sending to Kafka, and I was interested in what those bytes look like. For that I used my favourite Kafka swiss-army knife: kafkacat.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Loading CSV data into Kafka</title>
      <link>https://rmoff.net/2020/06/17/loading-csv-data-into-kafka/</link>
      <pubDate>Wed, 17 Jun 2020 17:57:18 +0100</pubDate>
      <guid>https://rmoff.net/2020/06/17/loading-csv-data-into-kafka/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;For whatever reason, CSV still exists as a ubiquitous data interchange format. It doesn‚Äôt get much simpler: chuck some plaintext with fields separated by commas into a file and stick &lt;code&gt;.csv&lt;/code&gt; on the end. If you‚Äôre feeling helpful you can include a header row with field names in.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-csv&#34; data-lang=&#34;csv&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;order_id&lt;/span&gt;,&lt;span style=&#34;color:#ba2121&#34;&gt;customer_id&lt;/span&gt;,&lt;span style=&#34;color:#ba2121&#34;&gt;order_total_usd&lt;/span&gt;,&lt;span style=&#34;color:#ba2121&#34;&gt;make&lt;/span&gt;,&lt;span style=&#34;color:#ba2121&#34;&gt;model&lt;/span&gt;,&lt;span style=&#34;color:#ba2121&#34;&gt;delivery_city&lt;/span&gt;,&lt;span style=&#34;color:#ba2121&#34;&gt;delivery_company&lt;/span&gt;,&lt;span style=&#34;color:#ba2121&#34;&gt;delivery_address&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ba2121&#34;&gt;535&lt;/span&gt;,&lt;span style=&#34;color:#ba2121&#34;&gt;190899.73&lt;/span&gt;,&lt;span style=&#34;color:#ba2121&#34;&gt;Dodge&lt;/span&gt;,&lt;span style=&#34;color:#ba2121&#34;&gt;Ram Wagon B350&lt;/span&gt;,&lt;span style=&#34;color:#ba2121&#34;&gt;Sheffield&lt;/span&gt;,&lt;span style=&#34;color:#ba2121&#34;&gt;DuBuque LLC&lt;/span&gt;,&lt;span style=&#34;color:#ba2121&#34;&gt;2810 Northland Avenue&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ba2121&#34;&gt;671&lt;/span&gt;,&lt;span style=&#34;color:#ba2121&#34;&gt;33245.53&lt;/span&gt;,&lt;span style=&#34;color:#ba2121&#34;&gt;Volkswagen&lt;/span&gt;,&lt;span style=&#34;color:#ba2121&#34;&gt;Cabriolet&lt;/span&gt;,&lt;span style=&#34;color:#ba2121&#34;&gt;Edinburgh&lt;/span&gt;,&lt;span style=&#34;color:#ba2121&#34;&gt;Bechtelar-VonRueden&lt;/span&gt;,&lt;span style=&#34;color:#ba2121&#34;&gt;1 Macpherson Crossing&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;In this article we‚Äôll see how to load this CSV data into Kafka, without even needing to write any code&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Working with JSON nested arrays in ksqlDB - example</title>
      <link>https://rmoff.net/2020/05/26/working-with-json-nested-arrays-in-ksqldb-example/</link>
      <pubDate>Tue, 26 May 2020 10:02:48 +0100</pubDate>
      <guid>https://rmoff.net/2020/05/26/working-with-json-nested-arrays-in-ksqldb-example/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Question from the Confluent Community Slack group:&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;quoteblock&#34;&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;How can I access the data in object in an array like below using ksqlDB stream&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;listingblock&#34;&gt;&#xA;&lt;div class=&#34;content&#34;&gt;&#xA;&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code data-lang=&#34;json&#34;&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;&#xA;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;font-weight: bold&#34;&gt;&amp;#34;Total&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;&#xA;        &lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;&#xA;          &lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;font-weight: bold&#34;&gt;&amp;#34;TotalType&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;Standard&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;&#xA;          &lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;font-weight: bold&#34;&gt;&amp;#34;TotalAmount&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;15.99&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;&#xA;        &lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;},&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;&#xA;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;&#xA;          &lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;font-weight: bold&#34;&gt;&amp;#34;TotalType&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;Old Standard&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;&#xA;          &lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;font-weight: bold&#34;&gt;&amp;#34;TotalAmount&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;16&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;&#xA;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;font-weight: bold&#34;&gt;&amp;#34; STID&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;56&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;&#xA;        &lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;&#xA;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Building a Telegram bot with Apache Kafka and ksqlDB</title>
      <link>https://rmoff.net/2020/05/18/building-a-telegram-bot-with-apache-kafka-and-ksqldb/</link>
      <pubDate>Mon, 18 May 2020 11:28:15 +0100</pubDate>
      <guid>https://rmoff.net/2020/05/18/building-a-telegram-bot-with-apache-kafka-and-ksqldb/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Imagine you‚Äôve got a stream of data; it‚Äôs not ‚Äúbig data,‚Äù but it‚Äôs certainly a lot. Within the data, you‚Äôve got some bits you‚Äôre interested in, and of those bits, you‚Äôd like to be able to query information about them at any point. Sounds fun, right?&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;imageblock&#34;&gt;&#xA;&lt;div class=&#34;content&#34;&gt;&#xA;&lt;img src=&#34;https://rmoff.net/images/2020/05/telegram_arch02.png&#34; alt=&#34;Architecture high-level view&#34;/&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;What if you didn‚Äôt need any datastore other than Apache Kafka itself to be able to do this? What if you could ingest, filter, enrich, aggregate, and query data with just Kafka? With ksqlDB we can do just this, and I want to show you exactly how, using a Telegram bot as the application looking up state from the inbound stream of events:&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Adventures in the Cloud, Part 94: ECS</title>
      <link>https://rmoff.net/2020/02/13/adventures-in-the-cloud-part-94-ecs/</link>
      <pubDate>Thu, 13 Feb 2020 00:12:23 +0000</pubDate>
      <guid>https://rmoff.net/2020/02/13/adventures-in-the-cloud-part-94-ecs/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;My name‚Äôs Robin, and I‚Äôm a Developer Advocate. What that means in part is that I build a ton of demos, and Docker Compose is my jam. I love using Docker Compose for the same reasons that many people do:&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;ulist&#34;&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Spin up and tear down fully-functioning multi-component environments with ease. No bespoke builds, no cloning of VMs to preserve &amp;#34;that magic state where everything works&amp;#34;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Repeatability. It‚Äôs the same each time.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Portability. I can point someone at a &lt;code&gt;docker-compose.yml&lt;/code&gt; that I‚Äôve written and they can run the same on their machine with the same results almost guaranteed.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Primitive Keys in ksqlDB</title>
      <link>https://rmoff.net/2020/02/07/primitive-keys-in-ksqldb/</link>
      <pubDate>Fri, 07 Feb 2020 10:58:06 +0000</pubDate>
      <guid>https://rmoff.net/2020/02/07/primitive-keys-in-ksqldb/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;ksqlDB 0.7 will add support for message keys as primitive data types beyond just &lt;code&gt;STRING&lt;/code&gt; (which is all we‚Äôve had to date). That means that Kafka messages are going to be much easier to work with, and require less wrangling to get into the form in which you need them. Take an example of a database table that you‚Äôve ingested into a Kafka topic, and want to join to a stream of events. Previously you‚Äôd have had to take the Kafka topic into which the table had been ingested and run a ksqlDB processor to re-key the messages such that ksqlDB could join on them. &lt;em&gt;Friends, I am here to tell you that this is no longer needed!&lt;/em&gt;&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Monitoring Sonos with ksqlDB, InfluxDB, and Grafana</title>
      <link>https://rmoff.net/2020/01/21/monitoring-sonos-with-ksqldb-influxdb-and-grafana/</link>
      <pubDate>Tue, 21 Jan 2020 22:47:35 +0000</pubDate>
      <guid>https://rmoff.net/2020/01/21/monitoring-sonos-with-ksqldb-influxdb-and-grafana/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;I‚Äôm quite a fan of Sonos audio equipment but recently had some trouble with some of the devices glitching and even cutting out whilst playing. Under the covers Sonos stuff is running Linux (of course) and exposes some diagnostics through a rudimentary frontend that you can access at &lt;code&gt;http://&amp;lt;sonos player IP&amp;gt;:1400/support/review&lt;/code&gt;:&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;imageblock&#34;&gt;&#xA;&lt;div class=&#34;content&#34;&gt;&#xA;&lt;img src=&#34;https://rmoff.net/images/2020/01/sonos00.png&#34; alt=&#34;Sonos Network Matrix&#34;/&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Whilst this gives you the current state, you can‚Äôt get historical data on it. It &lt;em&gt;felt&lt;/em&gt; like the problems were happening &amp;#34;all the time&amp;#34;, but &lt;strong&gt;were they actually&lt;/strong&gt;? For that, we need some cold, hard, data! Something like this, in fact:&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Exploring ksqlDB window start time</title>
      <link>https://rmoff.net/2020/01/09/exploring-ksqldb-window-start-time/</link>
      <pubDate>Thu, 09 Jan 2020 14:25:01 +0000</pubDate>
      <guid>https://rmoff.net/2020/01/09/exploring-ksqldb-window-start-time/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Prompted by &lt;a href=&#34;https://stackoverflow.com/questions/59629748/ksql-aggregating-data-based-on-last-1-year-365-days&#34;&gt;a question on StackOverflow&lt;/a&gt; I had a bit of a dig into how windows behave in ksqlDB, specifically with regards to their start time. This article shows also how to create test data in ksqlDB and create data to be handled with a timestamp in the past.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;For a general background to windowing in ksqlDB see &lt;a href=&#34;https://docs.ksqldb.io/en/latest/concepts/time-and-windows-in-ksqldb-queries/&#34;&gt;the excellent docs&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;The nice thing about recent releases of ksqlDB/KSQL is that you can create and populate streams directly with &lt;code&gt;CREATE STREAM&lt;/code&gt; and &lt;code&gt;INSERT INTO&lt;/code&gt; respectively. Much as I love kafkacat, being able to build a whole example within the ksqlDB CLI is very useful.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Streaming messages from RabbitMQ into Kafka with Kafka Connect</title>
      <link>https://rmoff.net/2020/01/08/streaming-messages-from-rabbitmq-into-kafka-with-kafka-connect/</link>
      <pubDate>Wed, 08 Jan 2020 13:06:57 +0000</pubDate>
      <guid>https://rmoff.net/2020/01/08/streaming-messages-from-rabbitmq-into-kafka-with-kafka-connect/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;This was prompted by &lt;a href=&#34;https://stackoverflow.com/questions/59632068/kafka-connect-is-sending-a-malformed-json&#34;&gt;a question&lt;/a&gt; on StackOverflow to which I thought the answer would be straightforward, but turned out not to be so. And then I got a bit carried away and ended up with a nice example of how you can handle schema-less data coming from a system such as RabbitMQ and apply a schema to it.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;admonitionblock note&#34;&gt;&#xA;&lt;table&gt;&#xA;&lt;tbody&gt;&lt;tr&gt;&#xA;&lt;td class=&#34;icon&#34;&gt;&#xA;&lt;i class=&#34;fa icon-note&#34; title=&#34;Note&#34;&gt;&lt;/i&gt;&#xA;&lt;/td&gt;&#xA;&lt;td class=&#34;content&#34;&gt;&#xA;This same pattern for ingesting bytes and applying a schema will work with other connectors such as &lt;a href=&#34;https://www.confluent.io/hub/confluentinc/kafka-connect-mqtt&#34;&gt;MQTT&lt;/a&gt;&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&lt;/table&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Analysing network behaviour with ksqlDB and MongoDB</title>
      <link>https://rmoff.net/2019/12/20/analysing-network-behaviour-with-ksqldb-and-mongodb/</link>
      <pubDate>Fri, 20 Dec 2019 17:23:40 +0000</pubDate>
      <guid>https://rmoff.net/2019/12/20/analysing-network-behaviour-with-ksqldb-and-mongodb/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;In this post I want to build on &lt;a href=&#34;https://rmoff.net/2019/12/18/detecting-and-analysing-ssh-attacks-with-ksqldb/&#34;&gt;my previous one&lt;/a&gt; and show another use of the Syslog data that I‚Äôm capturing. Instead of looking for &lt;a href=&#34;https://rmoff.net/2019/12/18/detecting-and-analysing-ssh-attacks-with-ksqldb/&#34;&gt;SSH attacks&lt;/a&gt;, I‚Äôm going to analyse the behaviour of my networking components.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;admonitionblock note&#34;&gt;&#xA;&lt;table&gt;&#xA;&lt;tbody&gt;&lt;tr&gt;&#xA;&lt;td class=&#34;icon&#34;&gt;&#xA;&lt;i class=&#34;fa icon-note&#34; title=&#34;Note&#34;&gt;&lt;/i&gt;&#xA;&lt;/td&gt;&#xA;&lt;td class=&#34;content&#34;&gt;&#xA;You can find all the code to run this on &lt;a href=&#34;https://github.com/confluentinc/demo-scene/tree/master/syslog&#34;&gt;GitHub&lt;/a&gt;.&#xA;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&lt;/table&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;sect1&#34;&gt;&#xA;&lt;h2 id=&#34;_getting_syslog_data_into_kafka&#34;&gt;Getting Syslog data into Kafka&lt;/h2&gt;&#xA;&lt;div class=&#34;sectionbody&#34;&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;As before, let‚Äôs create ourselves a &lt;a href=&#34;https://www.confluent.io/hub/confluentinc/kafka-connect-syslog&#34;&gt;syslog connector&lt;/a&gt; in ksqlDB:&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;listingblock&#34;&gt;&#xA;&lt;div class=&#34;content&#34;&gt;&#xA;&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;SOURCE&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;CONNECTOR&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;SOURCE_SYSLOG_UDP_01&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;WITH&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt;&#xA;    &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;tasks.max&amp;#39;&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;1&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;&#xA;    &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;connector.class&amp;#39;&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;io.confluent.connect.syslog.SyslogSourceConnector&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;&#xA;    &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;topic&amp;#39;&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;syslog&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;&#xA;    &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;syslog.port&amp;#39;&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;42514&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;&#xA;    &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;syslog.listener&amp;#39;&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;UDP&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;&#xA;    &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;syslog.reverse.dns.remote.ip&amp;#39;&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;true&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;&#xA;    &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;confluent.license&amp;#39;&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;&#xA;    &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;confluent.topic.bootstrap.servers&amp;#39;&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;kafka:29092&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;&#xA;    &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;confluent.topic.replication.factor&amp;#39;&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;1&amp;#39;&lt;/span&gt;&#xA;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Detecting and Analysing SSH Attacks with ksqlDB</title>
      <link>https://rmoff.net/2019/12/18/detecting-and-analysing-ssh-attacks-with-ksqldb/</link>
      <pubDate>Wed, 18 Dec 2019 17:23:40 +0000</pubDate>
      <guid>https://rmoff.net/2019/12/18/detecting-and-analysing-ssh-attacks-with-ksqldb/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;I‚Äôve &lt;a href=&#34;https://www.confluent.io/blog/real-time-syslog-processing-apache-kafka-ksql-part-1-filtering/&#34;&gt;written previously&lt;/a&gt; about ingesting Syslog into Kafka and using KSQL to analyse it. I want to revisit the subject since it‚Äôs nearly two years since I wrote about it and some things have changed since then.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;ksqlDB now includes the ability to define connectors from within it, which makes setting things up loads easier.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;You can find the &lt;a href=&#34;https://github.com/confluentinc/demo-scene/tree/master/syslog&#34;&gt;full rig to run this on GitHub&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;sect1&#34;&gt;&#xA;&lt;h2 id=&#34;_create_and_configure_the_syslog_connector&#34;&gt;Create and configure the Syslog connector&lt;/h2&gt;&#xA;&lt;div class=&#34;sectionbody&#34;&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;To start with, create a source connector:&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>A poor man&#39;s KSQL EXPLODE/UNNEST technique</title>
      <link>https://rmoff.net/2019/05/09/a-poor-mans-ksql-explode/unnest-technique/</link>
      <pubDate>Thu, 09 May 2019 10:01:50 +0100</pubDate>
      <guid>https://rmoff.net/2019/05/09/a-poor-mans-ksql-explode/unnest-technique/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;There is an &lt;a href=&#34;https://github.com/confluentinc/ksql/issues/527&#34;&gt;open issue for support of &lt;code&gt;EXPLODE&lt;/code&gt;/&lt;code&gt;UNNEST&lt;/code&gt; functionality in KSQL&lt;/a&gt;, and if you need it then do up-vote the issue. Here I detail a hacky, but effective, workaround for exploding arrays into multiple messages‚Äîso long as you know the upper-bound on your array.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Pivoting Aggregates in Ksql</title>
      <link>https://rmoff.net/2019/04/17/pivoting-aggregates-in-ksql/</link>
      <pubDate>Wed, 17 Apr 2019 15:42:56 +0100</pubDate>
      <guid>https://rmoff.net/2019/04/17/pivoting-aggregates-in-ksql/</guid>
      <description>&lt;p&gt;Prompted by &lt;a href=&#34;https://stackoverflow.com/questions/55680719/aggregating-by-multiple-fields-and-map-to-one-result&#34;&gt;a question on StackOverflow&lt;/a&gt;, the requirement is to take a series of events related to a common key and for each key output a series of aggregates derived from a changing value in the events. I&amp;rsquo;ll use the data from the question, based on ticket statuses. Each ticket can go through various stages, and the requirement was to show, per customer, how many tickets are currently at each stage.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Connecting KSQL to a Secured Schema Registry</title>
      <link>https://rmoff.net/2019/04/12/connecting-ksql-to-a-secured-schema-registry/</link>
      <pubDate>Fri, 12 Apr 2019 12:59:33 +0100</pubDate>
      <guid>https://rmoff.net/2019/04/12/connecting-ksql-to-a-secured-schema-registry/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;See also : &lt;a href=&#34;https://docs.confluent.io/current/ksql/docs/installation/server-config/security.html#configuring-ksql-for-secured-sr-long&#34; class=&#34;bare&#34;&gt;https://docs.confluent.io/current/ksql/docs/installation/server-config/security.html#configuring-ksql-for-secured-sr-long&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Confluent Cloud now includes a secured Schema Registry, which you can use from external applications, including KSQL.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;To configure KSQL for it you need to set:&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ksql.schema.registry.url&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;https://&amp;lt;Schema Registry endpoint&amp;gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ksql.schema.registry.basic.auth.credentials.source&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;USER_INFO&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ksql.schema.registry.basic.auth.user.info&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&amp;lt;Schema Registry API Key&amp;gt;:&amp;lt;Schema Registry API Secret&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Exploring KSQL Stream-Stream Joins</title>
      <link>https://rmoff.net/2019/03/28/exploring-ksql-stream-stream-joins/</link>
      <pubDate>Thu, 28 Mar 2019 14:46:24 +0000</pubDate>
      <guid>https://rmoff.net/2019/03/28/exploring-ksql-stream-stream-joins/</guid>
      <description>&lt;div class=&#34;sect1&#34;&gt;&#xA;&lt;h2 id=&#34;_introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;div class=&#34;sectionbody&#34;&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;What can you use stream-stream joins for? Can you use them to join between a stream of orders and stream of related shipments to do useful things? What‚Äôs not supported in KSQL, where are the cracks?&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Terminate All KSQL Queries</title>
      <link>https://rmoff.net/2019/03/25/terminate-all-ksql-queries/</link>
      <pubDate>Mon, 25 Mar 2019 16:45:40 +0000</pubDate>
      <guid>https://rmoff.net/2019/03/25/terminate-all-ksql-queries/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Before you can drop a stream or table that‚Äôs populated by a query in KSQL, you have to terminate any queries upon which the object is dependent. Here‚Äôs a bit of &lt;code&gt;jq&lt;/code&gt; &amp;amp; &lt;code&gt;xargs&lt;/code&gt; magic to terminate &lt;strong&gt;all&lt;/strong&gt; queries that are currently running&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>How KSQL handles case</title>
      <link>https://rmoff.net/2019/01/21/how-ksql-handles-case/</link>
      <pubDate>Mon, 21 Jan 2019 12:05:48 +0000</pubDate>
      <guid>https://rmoff.net/2019/01/21/how-ksql-handles-case/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.confluent.io/ksql&#34;&gt;KSQL&lt;/a&gt; is generally case-sensitive. Very sensitive, at times ;-)&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>KSQL REST API cheatsheet</title>
      <link>https://rmoff.net/2019/01/17/ksql-rest-api-cheatsheet/</link>
      <pubDate>Thu, 17 Jan 2019 12:12:11 +0000</pubDate>
      <guid>https://rmoff.net/2019/01/17/ksql-rest-api-cheatsheet/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Full reference is &lt;a href=&#34;https://docs.confluent.io/current/ksql/docs/developer-guide/api.html&#34;&gt;here&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Streaming data from Oracle into Kafka</title>
      <link>https://rmoff.net/2018/12/12/streaming-data-from-oracle-into-kafka/</link>
      <pubDate>Wed, 12 Dec 2018 09:49:04 +0000</pubDate>
      <guid>https://rmoff.net/2018/12/12/streaming-data-from-oracle-into-kafka/</guid>
      <description>&lt;p&gt;&lt;em&gt;This is a short summary discussing what the options are for integrating Oracle RDBMS into Kafka, as of December 2018 (refreshed June 2020). For a more detailed background to why and how at a broader level for all databases (not just Oracle) see &lt;a href=&#34;http://cnfl.io/kafka-cdc&#34;&gt;this blog&lt;/a&gt; and &lt;a href=&#34;http://rmoff.dev/ksny19-no-more-silos&#34;&gt;this talk&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;&#xA;      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/LAoepZTapMM?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;&#xA;    &lt;/div&gt;&#xA;&#xA;&lt;h3 id=&#34;what-techniques--tools-are-there&#34;&gt;What techniques &amp;amp; tools are there?&lt;/h3&gt;&#xA;&lt;p&gt;&lt;em&gt;Franck Pachot has written up an excellent analysis of the options available &lt;a href=&#34;https://medium.com/@FranckPachot/ideas-for-event-sourcing-in-oracle-d4e016e90af6&#34;&gt;here&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
