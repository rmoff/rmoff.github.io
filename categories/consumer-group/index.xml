<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Consumer Group on rmoff&#39;s random ramblings</title>
    <link>https://rmoff.net/categories/consumer-group/</link>
    <description>Recent content in Consumer Group on rmoff&#39;s random ramblings</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 15 Oct 2019 09:58:38 +0100</lastBuildDate>
    <atom:link href="https://rmoff.net/categories/consumer-group/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Skipping bad records with the Kafka Connect JDBC sink connector</title>
      <link>https://rmoff.net/2019/10/15/skipping-bad-records-with-the-kafka-connect-jdbc-sink-connector/</link>
      <pubDate>Tue, 15 Oct 2019 09:58:38 +0100</pubDate>
      <guid>https://rmoff.net/2019/10/15/skipping-bad-records-with-the-kafka-connect-jdbc-sink-connector/</guid>
      <description>&lt;div id=&#34;preamble&#34;&gt;&#xA;&lt;div class=&#34;sectionbody&#34;&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;The Kafka Connect framework provides generic &lt;a href=&#34;https://www.confluent.io/blog/kafka-connect-deep-dive-error-handling-dead-letter-queues&#34;&gt;error handling and dead-letter queue capabilities&lt;/a&gt; which are available for problems with [de]serialisation and Single Message Transforms. When it comes to errors that a connector may encounter doing the actual &lt;code&gt;pull&lt;/code&gt; or &lt;code&gt;put&lt;/code&gt; of data from the source/target system, it’s down to the connector itself to implement logic around that. For example, the Elasticsearch sink connector provides configuration (&lt;code&gt;behavior.on.malformed.documents&lt;/code&gt;) that can be set so that a single bad record won’t halt the pipeline. Others, such as the JDBC Sink connector, don’t provide this &lt;a href=&#34;https://github.com/confluentinc/kafka-connect-jdbc/issues/721&#34;&gt;yet&lt;/a&gt;. That means that if you hit this problem, you need to manually unblock it yourself. One way is to manually move the offset of the consumer on past the bad message.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt; : You can use &lt;code&gt;kafka-consumer-groups --reset-offsets --to-offset &amp;lt;x&amp;gt;&lt;/code&gt; to manually move the connector past a bad message&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Resetting a Consumer Group in Kafka</title>
      <link>https://rmoff.net/2019/08/09/resetting-a-consumer-group-in-kafka/</link>
      <pubDate>Fri, 09 Aug 2019 16:32:46 +0200</pubDate>
      <guid>https://rmoff.net/2019/08/09/resetting-a-consumer-group-in-kafka/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;I’ve been using &lt;a href=&#34;https://docs.confluent.io/current/connect/kafka-connect-replicator/index.html&#34;&gt;Replicator&lt;/a&gt; as a powerful way to copy data from my Kafka rig at home onto my laptop’s Kafka environment. It means that when I’m on the road I can continue to work with the same set of data and develop pipelines etc. With a VPN back home I can even keep them in sync directly if I want to.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;I hit a problem the other day where Replicator was running, but I had no data in my target topics on my laptop. After a bit of head-scratching I realised that my local Kafka environment had been rebuilt (I use Docker Compose so complete rebuilds to start from scratch are easy), hence no data in the topic. But, even after restarting the Replicator Kafka Connect worker, I still had no data loaded into the empty topics. What was going on? Well Replicator acts as a consumer from the source Kafka cluster (on my home server), and so far as that Kafka cluster was concerned, Replicator had already read the messages. It thought that because even though I’d rebuilt everything on my laptop, Replicator was using the same connector name as before, and the connector name is used as the Consumer group name - which is how the &lt;em&gt;source&lt;/em&gt; Kafka cluster keeps track of the offsets. So my &amp;#34;new&amp;#34; Kafka environment was going back to the source, which viewed it as the existing &amp;#34;old&amp;#34; one, which had already received the messages.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
  </channel>
</rss>
