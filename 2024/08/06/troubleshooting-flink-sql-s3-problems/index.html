<!DOCTYPE html>
<html lang="en">
	<head>
		<meta http-equiv=X-Clacks-Overhead content="GNU Terry Pratchett">
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		
		<link rel="preconnect" href="https://fonts.googleapis.com">
		<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
		<link rel="preload" as="image" href="https://rmoff.net/images/2024/08/flinksql-s3.jpg" >
		
		<title>Troubleshooting Flink SQL S3 problems</title>
		<link rel="alternate" type="application/rss+xml" title="RSS" href="https://rmoff.net/index.xml">
		<link rel="canonical" href="https://rmoff.net/2024/08/06/troubleshooting-flink-sql-s3-problems/">
		
		

		
		<meta property="og:title" content="Troubleshooting Flink SQL S3 problems" />
		<meta property="og:type" content="article" />
		<meta property="og:image" content="https://rmoff.net/images/2024/08/flinksql-s3.jpg" />
		<meta property="og:description" content="" />
		<meta property="og:url" content="https://rmoff.net/2024/08/06/troubleshooting-flink-sql-s3-problems/" />
		<meta property="og:site_name" content="Troubleshooting Flink SQL S3 problems" />
		<meta name="twitter:card" content="summary_large_image" />
		<meta name="twitter:site" content="@" />


		
		<style>
			html { background-color: #FAF8F5; color: #2D2926; }
			body { opacity: 0; transition: opacity 0.1s ease; }
			body.loaded { opacity: 1; }
			.site-header { height: 60px; background-color: #FAF8F5; border-bottom: 1px solid #E8421E; }
		</style>

		
		
		<link rel="stylesheet" href="https://rmoff.net/css/redesign.css" />
		
		<link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Bricolage+Grotesque:opsz,wght@12..96,400;12..96,600;12..96,700;12..96,800&family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&family=JetBrains+Mono:wght@400;500&family=Outfit:wght@400;500;600&display=swap">
		<link href="https://fonts.googleapis.com/css2?family=Bricolage+Grotesque:opsz,wght@12..96,400;12..96,600;12..96,700;12..96,800&family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&family=JetBrains+Mono:wght@400;500&family=Outfit:wght@400;500;600&display=swap" rel="stylesheet" media="print" onload="this.media='all'">
		<noscript><link href="https://fonts.googleapis.com/css2?family=Bricolage+Grotesque:opsz,wght@12..96,400;12..96,600;12..96,700;12..96,800&family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&family=JetBrains+Mono:wght@400;500&family=Outfit:wght@400;500;600&display=swap" rel="stylesheet"></noscript>
		

		
		<script src="/js/copy-code.js"></script>
		

		
		<script>
			!function(t,e){var o,n,p,r;e.__SV||(window.posthog=e,e._i=[],e.init=function(i,s,a){function g(t,e){var o=e.split(".");2==o.length&&(t=t[o[0]],e=o[1]),t[e]=function(){t.push([e].concat(Array.prototype.slice.call(arguments,0)))}}(p=t.createElement("script")).type="text/javascript",p.crossOrigin="anonymous",p.async=!0,p.src=s.api_host.replace(".i.posthog.com","-assets.i.posthog.com")+"/static/array.js",(r=t.getElementsByTagName("script")[0]).parentNode.insertBefore(p,r);var u=e;for(void 0!==a?u=e[a]=[]:a="posthog",u.people=u.people||[],u.toString=function(t){var e="posthog";return"posthog"!==a&&(e+="."+a),t||(e+=" (stub)"),e},u.people.toString=function(){return u.toString(1)+".people (stub)"},o="init capture register register_once register_for_session unregister unregister_for_session getFeatureFlag getFeatureFlagPayload isFeatureEnabled reloadFeatureFlags updateEarlyAccessFeatureEnrollment getEarlyAccessFeatures on onFeatureFlags onSessionId getSurveys getActiveMatchingSurveys renderSurvey canRenderSurvey getNextSurveyStep identify setPersonProperties group resetGroups setPersonPropertiesForFlags resetPersonPropertiesForFlags setGroupPropertiesForFlags resetGroupPropertiesForFlags reset get_distinct_id getGroups get_session_id get_session_replay_url alias set_config startSessionRecording stopSessionRecording sessionRecordingStarted captureException loadToolbar get_property getSessionProperty createPersonProfile opt_in_capturing opt_out_capturing has_opted_in_capturing has_opted_out_capturing clear_opt_in_out_capturing debug".split(" "),n=0;n<o.length;n++)g(u,o[n]);e._i.push([i,s,a])},e.__SV=1)}(document,window.posthog||[]);
            posthog.init('phc_93NEP79Ju4xqXYWXnoLbr4HMW0Iaepj1BGOVoEXYX6P',{api_host:'https://eu.i.posthog.com', person_profiles: 'identified_only'})
		</script>

		
		<script src="https://rmoff.net/js/story.js"></script>
		<script src="https://rmoff.net/js/toc.js"></script>
		<script src="https://rmoff.net/js/medium-mirror.js"></script>
	</head>
	<body class="ma0 section-post page-kind-page is-page-true ">
		<script>document.body.classList.add('loaded');</script>

		<header class="site-header hide-print">
	<div class="site-header-inner">
		<a href="https://rmoff.net/" class="site-title">rmoff's random ramblings</a>
		<nav class="site-nav">
			<a href="/categories/interesting-links/" class="nav-il"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"/><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"/></svg> Interesting Links</a>
			<span class="nav-sep"></span>
			<a href="/categories/"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"/><line x1="7" y1="7" x2="7.01" y2="7"/></svg> Categories</a>
			<a href="https://rmoff.net/search/"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="11" cy="11" r="8"/><line x1="21" y1="21" x2="16.65" y2="16.65"/></svg> Search</a>
			<a href="https://rmoff.net/index.xml"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 11a9 9 0 0 1 9 9"/><path d="M4 4a16 16 0 0 1 16 16"/><circle cx="5" cy="19" r="1"/></svg> RSS</a>
			<div class="nav-social">
				<a href="https://www.linkedin.com/in/robinmoffatt/" title="linkedin"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433a2.062 2.062 0 0 1-2.063-2.065 2.064 2.064 0 1 1 2.063 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg></a>
				<a href="https://twitter.com/rmoff/" title="twitter"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"/></svg></a>
				<a href="https://bsky.app/profile/rmoff.net" title="bluesky"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 568 501" fill="currentColor"><path d="M123.121 33.664C188.241 82.553 258.281 181.68 284 234.873c25.719-53.192 95.759-152.32 160.879-201.21C491.866-1.611 568-28.906 568 57.947c0 17.346-9.945 145.713-15.778 166.555-20.275 72.453-94.155 90.933-159.875 79.748C507.222 323.8 536.444 388.56 473.333 453.32c-119.86 122.992-172.272-30.859-185.702-70.281-2.462-7.227-3.614-10.608-3.631-7.733-.017-2.875-1.169.506-3.631 7.733-13.43 39.422-65.842 193.273-185.702 70.281-63.111-64.76-33.89-129.52 80.986-149.071-65.72 11.185-139.6-7.295-159.875-79.748C10.945 203.659 1 75.291 1 57.946 1-28.906 76.135-1.612 123.121 33.664z"/></svg></a>
				<a href="https://www.youtube.com/c/rmoff" title="youtube"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M23.498 6.186a3.016 3.016 0 0 0-2.122-2.136C19.505 3.545 12 3.545 12 3.545s-7.505 0-9.377.505A3.017 3.017 0 0 0 .502 6.186C0 8.07 0 12 0 12s0 3.93.502 5.814a3.016 3.016 0 0 0 2.122 2.136c1.871.505 9.376.505 9.376.505s7.505 0 9.377-.505a3.015 3.015 0 0 0 2.122-2.136C24 15.93 24 12 24 12s0-3.93-.502-5.814zM9.545 15.568V8.432L15.818 12l-6.273 3.568z"/></svg></a>
				<a href="https://talks.rmoff.net" title="talks"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><rect x="2" y="3" width="20" height="14" rx="0"/><line x1="12" y1="17" x2="12" y2="22"/><line x1="8" y1="22" x2="16" y2="22"/><polyline points="7 8 12 12 17 8"/></svg></a>
				<a href="https://github.com/rmoff/" title="github"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a>
			</div>
		</nav>
		<button class="nav-toggle" onclick="document.querySelector('.mobile-nav').classList.toggle('open')" aria-label="Menu">
			<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="18" x2="21" y2="18"/></svg>
		</button>
	</div>
	<nav class="mobile-nav">
		<a href="https://rmoff.net/">Home</a>
		<a href="/categories/">Categories</a>
		<a href="/categories/interesting-links/">Interesting Links</a>
		<a href="https://rmoff.net/search/">Search</a>
		<a href="https://rmoff.net/index.xml">RSS</a>
		<a href="https://www.linkedin.com/in/robinmoffatt/">linkedin</a>
		<a href="https://twitter.com/rmoff/">twitter</a>
		<a href="https://bsky.app/profile/rmoff.net">bluesky</a>
		<a href="https://www.youtube.com/c/rmoff">youtube</a>
		<a href="https://talks.rmoff.net">talks</a>
		<a href="https://github.com/rmoff/">github</a>
	</nav>
</header>


		<main role="main">
		

<div class="article-hero" style="background-image: url('https://rmoff.net/images/2024/08/flinksql-s3.jpg');">
	<div class="article-hero-overlay">
		<div class="article-hero-content">
			<h1>Troubleshooting Flink SQL S3 problems</h1>
			<p class="article-hero-meta">
				
					<time datetime="2024-08-06T00:00:00Z">06 Aug 2024</time>
					<span class="display-print">by </span>
					 &middot; <a href="https://rmoff.net/categories/apache-flink">Apache Flink</a>
					<span class="display-print">at https://rmoff.net/2024/08/06/troubleshooting-flink-sql-s3-problems/</span>
				
			</p>
		</div>
	</div>
</div>


<details class="toc-mobile">
	<summary>Table of Contents</summary>
	<nav id="TableOfContents">
  <ul>
    <li><a href="#_test_rig">Test rig</a></li>
    <li><a href="#_logging">Logging</a></li>
    <li><a href="#_dependency_hadoop_s3_plugin">Dependency: Hadoop S3 plugin</a></li>
    <li><a href="#_log_file_diving">Log File Diving</a></li>
    <li><a href="#_credentials_and_configuration">Credentials and Configuration</a></li>
    <li><a href="#_configuring_an_s3_endpoint_for_minio">Configuring an S3 endpoint for MinIO</a></li>
    <li><a href="#_configuring_path_style_access_for_minio_from_flink_s3">Configuring path-style access for MinIO from Flink S3</a></li>
    <li><a href="#_configuration_stuff">Configuration stuff</a></li>
    <li><a href="#_references">References</a></li>
  </ul>
</nav>
</details>

<div class="container-fluid docs">
	<div class="row">
		<main class="docs-content" role="main">

<article class="article" data-pagefind-body>
	<span data-pagefind-filter="category" style="display:none">Apache Flink</span>
	<img data-pagefind-meta="image[src]" src="https://rmoff.net/images/2024/08/flinksql-s3.jpg" style="display:none" alt="">
	<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
This post originally appeared on the <a href="https://www.decodable.co/blog/troubleshooting-flink-sql-s3-problems">Decodable blog</a>.
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>Youâ€™d think once was enough.
Having  <a href="/2024/04/17/flink-sqlmisconfiguration-misunderstanding-and-mishaps/">already written</a>  about the trouble that I had getting Flink SQL to write to S3 (including on MinIO) this should now be a moot issue for me.
Right?
RIGHT?!</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/2024/08/66aabfa7e81909a15d284954_AD_4nXdtJWckCxLMlmZKB9S85ciylYJTvAfq9iGlDu9efH-lJs4oauf4GkxkGUTIlHFQKgDCvL7iZPuRyIbFTYpZD0X_ch8C8QlxZU3I9LifU2Sk8YWxdiYTxUHdwD9JD5Rb8_LIkl9EqehmCVmB8TDO0_0xiTNm.gif" alt="giphy"/>
</div>
</div>
<div class="paragraph">
<p>Well perhaps it is.
Iâ€™m not yet sure.
But whatâ€™s led me down this path again is trying to get the Delta Lake connector to work in Flink SQL, and butting up against S3 problems.
In troubleshooting those I ended up back at trying to understand in more detail what a functioning S3 configuration looks like so that I could rule out issues other than the Delta Lake connector.</p>
</div>
<div class="paragraph">
<p><em>For Delta Lake and Flink itself youâ€™ll need to stay tuned to the blog, as I write about that in a separate article.</em>
<em>Today weâ€™re just looking at some troubleshooting tips for S3 access in Flink SQL in general.</em></p>
</div>
<div class="paragraph">
<p>So what weâ€™ve got here is a methodical explanation of how I understand the S3 configuration and libraries to work, keeping things as vanilla as possible to start with.
Filesystem connector, JSON format.</p>
</div>
<div class="paragraph">
<p><em>Huge caveat: I am just a humble end-user of this stuff.</em>
<em>I donâ€™t code Java.</em>
<em>I donâ€™t actually know what Iâ€™m doing half the time ðŸ˜‰.</em></p>
</div>
<div class="sect1">
<h2 id="_test_rig">Test rig&nbsp;<a class="headline-hash" href="#_test_rig">ðŸ”—</a> </h2>
<div class="sectionbody">
<div class="paragraph">
<p>Iâ€™m using Flink 1.18.1, with MinIO providing S3-compatible storage, running locally in a Docker container and available on port 9000.</p>
</div>
<div class="paragraph">
<p>This is my test statement:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="sql"><span style="color: #66d9ef;font-weight: bold">CREATE</span> <span style="color: #66d9ef;font-weight: bold">TABLE</span> <span style="color: #f8f8f2;background-color: #49483e">t_foo_fs</span> <span style="color: #f8f8f2;background-color: #49483e">(</span><span style="color: #f8f8f2;background-color: #49483e">c1</span> <span style="color: #f8f8f2">varchar</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">c2</span> <span style="color: #f8f8f2">int</span><span style="color: #f8f8f2;background-color: #49483e">)</span>
     <span style="color: #66d9ef;font-weight: bold">WITH</span> <span style="color: #f8f8f2;background-color: #49483e">(</span>
      <span style="color: #e6db74">&#39;connector&#39;</span> <span style="color: #f92672;font-weight: bold">=</span> <span style="color: #e6db74">&#39;filesystem&#39;</span><span style="color: #f8f8f2;background-color: #49483e">,</span>
      <span style="color: #e6db74">&#39;path&#39;</span> <span style="color: #f92672;font-weight: bold">=</span> <span style="color: #e6db74">&#39;s3a://warehouse/t_foo_fs/&#39;</span><span style="color: #f8f8f2;background-color: #49483e">,</span>
      <span style="color: #e6db74">&#39;format&#39;</span> <span style="color: #f92672;font-weight: bold">=</span> <span style="color: #e6db74">&#39;json&#39;</span>
     <span style="color: #f8f8f2;background-color: #49483e">);</span>

<span style="color: #66d9ef;font-weight: bold">INSERT</span> <span style="color: #66d9ef;font-weight: bold">INTO</span> <span style="color: #f8f8f2;background-color: #49483e">t_foo_fs</span> <span style="color: #66d9ef;font-weight: bold">VALUES</span> <span style="color: #f8f8f2;background-color: #49483e">(</span><span style="color: #e6db74">&#39;a&#39;</span><span style="color: #f8f8f2;background-color: #49483e">,</span><span style="color: #ae81ff">42</span><span style="color: #f8f8f2;background-color: #49483e">);</span></code></pre>
</div>
</div>
<div class="paragraph">
<p><em>Iâ€™m using json format not because itâ€™s a good idea, but because it doesnâ€™t need any further dependencies installed, and I want to keep this as small and easily-reproduced as possible.</em></p>
</div>
<div class="paragraph">
<p>Iâ€™m using the default ephemeral in-memory catalog, so each time I restart my session I have to define the table again.</p>
</div>
<div class="paragraph">
<p>Once the table is created I run the <code>INSERT</code>, which the SQL Client passes as a job to the Job Manager to run (<code>Submitting SQL update statement to the clusterâ€¦</code>).
This means that the SQL Client will say <code>successfully</code> in the message after running the <code>INSERT</code> but if you look carefully itâ€™s just saying itâ€™s <em>submitted</em> successfully:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="shell"><span style="color: #f92672;font-weight: bold">[</span>INFO] Submitting SQL update statement to the cluster...
<span style="color: #f92672;font-weight: bold">[</span>INFO] SQL update statement has been successfully submitted to the cluster:
Job ID: 34f3b66a1a6f89bea83145af8289aca5</code></pre>
</div>
</div>
<div class="paragraph">
<p>Thus, you have to then go and check if the job itself actually worked.</p>
</div>
<div class="paragraph">
<p>To make this reproducible I ran the following:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="shell"><span style="color: #f8f8f2">rm </span>log/<span style="color: #66d9ef;font-weight: bold">*</span>.<span style="color: #66d9ef;font-weight: bold">*</span> <span style="color: #f92672;font-weight: bold">&amp;&amp;</span>
  ./bin/start-cluster.sh <span style="color: #f92672;font-weight: bold">&amp;&amp;</span>
  ./bin/sql-client.sh <span style="color: #f92672;font-weight: bold">&amp;&amp;</span>
  ./bin/stop-cluster.sh <span style="color: #f92672;font-weight: bold">&amp;&amp;</span>
  ps <span style="color: #f92672">-ef</span>|grep java|grep flink|awk <span style="color: #e6db74">&#39;{print $2}&#39;</span>|xargs <span style="color: #f92672">-Ifoo</span> <span style="color: #f8f8f2">kill</span> <span style="color: #f92672">-9</span> foo <span style="color: #f92672;font-weight: bold">&amp;&amp;</span>
  jps</code></pre>
</div>
</div>
<div class="paragraph">
<p>This clears out the log directory, starts Flink and the SQL Client, and then waits for the client to exit.
Here I run the <code>CREATE TABLE</code> and <code>INSERT</code>, and then exit the client.
This then causes the remainder of the statements to run, which shuts down the Flink cluster, kills any hanging processes, and runs <code>jps</code> to confirm this.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_logging">Logging&nbsp;<a class="headline-hash" href="#_logging">ðŸ”—</a> </h2>
<div class="sectionbody">
<div class="paragraph">
<p>Getting an insight into whatâ€™s going is a two-fold process:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>What is running where (across SQL Client, Job Manager, and other components such as catalog metastores)</p>
</li>
<li>
<p>Logs!</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>To enable logging on Flink when running it as a local binary started with <code>./start-cluster.sh</code> with SQL Client change the two files:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><code>./conf/log4j.properties</code></p>
</li>
<li>
<p><code>./conf/log4j-cli.properties</code></p>
</li>
</ol>
</div>
<div class="paragraph">
<p>To both of these I added: ( <a href="https://logging.apache.org/log4j/2.x/manual/configuration.html">Ref</a> )</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="shell">logger.fs.name <span style="color: #f92672;font-weight: bold">=</span> org.apache.hadoop.fs
logger.fs.level <span style="color: #f92672;font-weight: bold">=</span> TRACE
logger.fs2.name <span style="color: #f92672;font-weight: bold">=</span> org.apache.flink.fs
logger.fs2.level <span style="color: #f92672;font-weight: bold">=</span> TRACE
logger.aws.name <span style="color: #f92672;font-weight: bold">=</span> software.amazon
logger.aws.level <span style="color: #f92672;font-weight: bold">=</span> TRACE</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_dependency_hadoop_s3_plugin">Dependency: Hadoop S3 plugin&nbsp;<a class="headline-hash" href="#_dependency_hadoop_s3_plugin">ðŸ”—</a> </h2>
<div class="sectionbody">
<div class="paragraph">
<p>If you donâ€™t include this and try to write to an <code>s3://</code> path youâ€™ll get this error:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="shell">org.apache.flink.core.fs.UnsupportedFileSystemSchemeException: Could not find a file system implementation <span style="color: #66d9ef;font-weight: bold">for </span>scheme <span style="color: #e6db74">&#39;s3&#39;</span><span style="color: #f8f8f2">.</span>
The scheme is directly supported by Flink through the following plugin<span style="color: #f92672;font-weight: bold">(</span>s<span style="color: #f92672;font-weight: bold">)</span>: flink-s3-fs-hadoop, flink-s3-fs-presto.
Please ensure that each plugin resides within its own subfolder within the plugins directory. See https://nightlies.apache.org/flink/flink-docs-stable/docs/deployment/filesystems/plugins/ <span style="color: #66d9ef;font-weight: bold">for </span>more information.
If you want to use a Hadoop file system <span style="color: #66d9ef;font-weight: bold">for </span>that scheme, please add the scheme to the configuration fs.allowed-fallback-filesystems.
For a full list of supported file systems, please see https://nightlies.apache.org/flink/flink-docs-stable/ops/filesystems/.</code></pre>
</div>
</div>
<div class="paragraph">
<p>For an <code>s3a://</code> path youâ€™ll get basically the same:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="shell">org.apache.flink.core.fs.UnsupportedFileSystemSchemeException: Could not find a file system implementation <span style="color: #66d9ef;font-weight: bold">for </span>scheme <span style="color: #e6db74">&#39;s3a&#39;</span><span style="color: #f8f8f2">.</span>
The scheme is directly supported by Flink through the following plugin<span style="color: #f92672;font-weight: bold">(</span>s<span style="color: #f92672;font-weight: bold">)</span>: flink-s3-fs-hadoop.
<span style="color: #f92672;font-weight: bold">[</span>â€¦]</code></pre>
</div>
</div>
<div class="paragraph">
<p>So per  <a href="https://nightlies.apache.org/flink/flink-docs-stable/docs/deployment/filesystems/plugins/">the docs</a> , you need the Hadoop S3 plugin, which ships with Flink but isnâ€™t in place by default.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="shell"><span style="color: #f8f8f2">mkdir</span> ./plugins/s3-fs-hadoop <span style="color: #f92672;font-weight: bold">&amp;&amp;</span> <span style="color: #ae81ff">\</span>
<span style="color: #f8f8f2">cp</span> ./opt/flink-s3-fs-hadoop-1.18.1.jar ./plugins/s3-fs-hadoop/</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_log_file_diving">Log File Diving&nbsp;<a class="headline-hash" href="#_log_file_diving">ðŸ”—</a> </h2>
<div class="sectionbody">
<div class="paragraph">
<p>With the log levels set to <code>TRACE</code>, letâ€™s go and have a look at what we get.
Hereâ€™s the output from the <code>taskexecutor</code> log (in the Flink <code>./log</code> folder).</p>
</div>
<div class="paragraph">
<p>The first entry we have is the S3 filesystem libraries starting.
<code>org.apache.flink.fs.s3</code> handles the s3 schema and hands this off to <code>org.apache.hadoop.fs.s3a.S3AFileSystem</code> which does most of the rest of the work.</p>
</div>
<div class="paragraph">
<p>The Hadoop <code>S3AFileSystem</code> is shown as <code>Initializing</code> for <code>warehouse</code>, where <code>warehouse</code> is the name of the bucket thatâ€™s been specified for writing the table data to (<code>&#39;path&#39; = &#39;s3a://warehouse/t_foo_fs/&#39;</code>).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="shell">DEBUG org.apache.flink.fs.s3.common.AbstractS3FileSystemFactory    <span style="color: #f92672;font-weight: bold">[]</span> - Creating S3 file system backed by Hadoop s3a file system
DEBUG org.apache.flink.fs.s3.common.AbstractS3FileSystemFactory    <span style="color: #f92672;font-weight: bold">[]</span> - Loading Hadoop configuration <span style="color: #66d9ef;font-weight: bold">for </span>Hadoop s3a file system
DEBUG org.apache.flink.fs.s3hadoop.S3FileSystemFactory             <span style="color: #f92672;font-weight: bold">[]</span> - Using scheme s3a://warehouse/t_foo_fs <span style="color: #66d9ef;font-weight: bold">for </span>s3a file system backing the S3 File System
DEBUG org.apache.hadoop.fs.s3a.S3AFileSystem                       <span style="color: #f92672;font-weight: bold">[]</span> - Initializing S3AFileSystem <span style="color: #66d9ef;font-weight: bold">for </span>warehouse</code></pre>
</div>
</div>
<div class="paragraph">
<p>Next up is a bunch of entries covering config values etc.
One point to note is <code>Propagating entries under</code> which ties into the idea of  <a href="https://hadoop.apache.org/docs/stable/hadoop-aws/tools/hadoop-aws/index.html#Configuring_different_S3_buckets_with_Per-Bucket_Configuration">per-bucket configuration</a> .</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="shell">DEBUG org.apache.hadoop.fs.s3a.S3AUtils                            <span style="color: #f92672;font-weight: bold">[]</span> - Propagating entries under fs.s3a.bucket.warehouse.
DEBUG org.apache.hadoop.fs.s3a.S3AUtils                            <span style="color: #f92672;font-weight: bold">[]</span> - Data is unencrypted
DEBUG org.apache.hadoop.fs.s3a.S3ARetryPolicy                      <span style="color: #f92672;font-weight: bold">[]</span> - Retrying on recoverable AWS failures 7 <span style="color: #f8f8f2">times </span>with an initial interval of 500ms
INFO  org.apache.hadoop.metrics2.impl.MetricsConfig                <span style="color: #f92672;font-weight: bold">[]</span> - Loaded properties from hadoop-metrics2.properties
INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl            <span style="color: #f92672;font-weight: bold">[]</span> - Scheduled Metric snapshot period at 10 second<span style="color: #f92672;font-weight: bold">(</span>s<span style="color: #f92672;font-weight: bold">)</span><span style="color: #f8f8f2">.</span>
INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl            <span style="color: #f92672;font-weight: bold">[]</span> - s3a-file-system metrics system started
DEBUG org.apache.hadoop.fs.s3a.S3AFileSystem                       <span style="color: #f92672;font-weight: bold">[]</span> - Client Side Encryption enabled: <span style="color: #f8f8f2">false
</span>WARN  org.apache.hadoop.util.NativeCodeLoader                      <span style="color: #f92672;font-weight: bold">[]</span> - Unable to load native-hadoop library <span style="color: #66d9ef;font-weight: bold">for </span>your platform... using builtin-java classes where applicable
DEBUG org.apache.hadoop.fs.s3a.S3ARetryPolicy                      <span style="color: #f92672;font-weight: bold">[]</span> - Retrying on recoverable AWS failures 7 <span style="color: #f8f8f2">times </span>with an initial interval of 500ms
DEBUG org.apache.hadoop.fs.s3a.S3GuardExistsRetryPolicy            <span style="color: #f92672;font-weight: bold">[]</span> - Retrying on recoverable S3Guard table/S3 inconsistencies 7 <span style="color: #f8f8f2">times </span>with an initial interval of 2000ms
DEBUG org.apache.hadoop.fs.s3a.S3AUtils                            <span style="color: #f92672;font-weight: bold">[]</span> - Value of fs.s3a.paging.maximum is 5000
DEBUG org.apache.hadoop.fs.s3a.S3AUtils                            <span style="color: #f92672;font-weight: bold">[]</span> - Value of fs.s3a.block.size is 33554432
DEBUG org.apache.hadoop.fs.s3a.S3AUtils                            <span style="color: #f92672;font-weight: bold">[]</span> - Value of fs.s3a.readahead.range is 65536
DEBUG org.apache.hadoop.fs.s3a.S3AUtils                            <span style="color: #f92672;font-weight: bold">[]</span> - Value of fs.s3a.max.total.tasks is 32
DEBUG org.apache.hadoop.fs.s3a.S3AUtils                            <span style="color: #f92672;font-weight: bold">[]</span> - Value of fs.s3a.threads.keepalivetime is 60
DEBUG org.apache.hadoop.fs.s3a.S3AUtils                            <span style="color: #f92672;font-weight: bold">[]</span> - Value of fs.s3a.executor.capacity is 16
DEBUG org.apache.hadoop.fs.s3a.auth.SignerManager                  <span style="color: #f92672;font-weight: bold">[]</span> - No custom signers specified
DEBUG org.apache.hadoop.fs.s3a.audit.AuditIntegration              <span style="color: #f92672;font-weight: bold">[]</span> - auditing is disabled
DEBUG org.apache.hadoop.fs.s3a.audit.AuditIntegration              <span style="color: #f92672;font-weight: bold">[]</span> - Started Audit Manager Service NoopAuditManagerS3A <span style="color: #66d9ef;font-weight: bold">in </span>state NoopAuditManagerS3A: STARTED
DEBUG org.apache.hadoop.fs.s3a.S3AUtils                            <span style="color: #f92672;font-weight: bold">[]</span> - Value of fs.s3a.internal.upload.part.count.limit is 10000
DEBUG org.apache.hadoop.fs.s3a.S3ARetryPolicy                      <span style="color: #f92672;font-weight: bold">[]</span> - Retrying on recoverable AWS failures 7 <span style="color: #f8f8f2">times </span>with an initial interval of 500ms
DEBUG org.apache.hadoop.fs.s3a.S3AUtils                            <span style="color: #f92672;font-weight: bold">[]</span> - Credential provider class is org.apache.flink.fs.s3.common.token.DynamicTemporaryAWSCredentialsProvider
DEBUG org.apache.hadoop.fs.s3a.S3AUtils                            <span style="color: #f92672;font-weight: bold">[]</span> - Credential provider class is org.apache.hadoop.fs.s3a.TemporaryAWSCredentialsProvider
DEBUG org.apache.hadoop.fs.s3a.S3AUtils                            <span style="color: #f92672;font-weight: bold">[]</span> - Credential provider class is org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
DEBUG org.apache.hadoop.fs.s3a.S3AUtils                            <span style="color: #f92672;font-weight: bold">[]</span> - Credential provider class is com.amazonaws.auth.EnvironmentVariableCredentialsProvider
DEBUG org.apache.hadoop.fs.s3a.S3AUtils                            <span style="color: #f92672;font-weight: bold">[]</span> - Credential provider class is org.apache.hadoop.fs.s3a.auth.IAMInstanceCredentialsProvider
DEBUG org.apache.hadoop.fs.s3a.S3AUtils                            <span style="color: #f92672;font-weight: bold">[]</span> - For URI s3a://warehouse/t_foo_fs, using credentials AWSCredentialProviderList[refcount<span style="color: #f92672;font-weight: bold">=</span> 1: <span style="color: #f92672;font-weight: bold">[</span>org.apache.flink.fs.s3.common.token.DynamicTemporaryAWSCredentialsProvider@1376bee, TemporaryAWSCredentialsProvider, SimpleAWSCredentialsProvider, EnvironmentVariableCredentialsProvider, org.apache.hadoop.fs.s3a.auth.IAMInstanceCredentialsProvider@4f2b477b]
DEBUG org.apache.hadoop.fs.s3a.S3AFileSystem                       <span style="color: #f92672;font-weight: bold">[]</span> - Using credential provider AWSCredentialProviderList[refcount<span style="color: #f92672;font-weight: bold">=</span> 1: <span style="color: #f92672;font-weight: bold">[</span>org.apache.flink.fs.s3.common.token.DynamicTemporaryAWSCredentialsProvider@1376bee, TemporaryAWSCredentialsProvider, SimpleAWSCredentialsProvider, EnvironmentVariableCredentialsProvider, org.apache.hadoop.fs.s3a.auth.IAMInstanceCredentialsProvider@4f2b477b]
DEBUG org.apache.hadoop.fs.s3a.S3AUtils                            <span style="color: #f92672;font-weight: bold">[]</span> - Value of fs.s3a.connection.maximum is 96</code></pre>
</div>
</div>
<div class="paragraph">
<p>Next is another <code>DEBUG</code> entry but with something that looks like an error:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="shell">DEBUG org.apache.hadoop.fs.s3a.impl.NetworkBinding                 <span style="color: #f92672;font-weight: bold">[]</span> - Unable to create class org.apache.hadoop.fs.s3a.impl.ConfigureShadedAWSSocketFactory, value of fs.s3a.ssl.channel.mode will be ignored
java.lang.NoClassDefFoundError: com/amazonaws/thirdparty/apache/http/conn/socket/ConnectionSocketFactory
    at java.lang.Class.forName0<span style="color: #f92672;font-weight: bold">(</span>Native Method<span style="color: #f92672;font-weight: bold">)</span> ~[?:?]
    at java.lang.Class.forName<span style="color: #f92672;font-weight: bold">(</span>Class.java:315<span style="color: #f92672;font-weight: bold">)</span> ~[?:?]
    at org.apache.hadoop.fs.s3a.impl.NetworkBinding.bindSSLChannelMode<span style="color: #f92672;font-weight: bold">(</span>NetworkBinding.java:89<span style="color: #f92672;font-weight: bold">)</span> ~[flink-s3-fs-hadoop-1.18.1.jar:1.18.1]
    at org.apache.hadoop.fs.s3a.S3AUtils.initProtocolSettings<span style="color: #f92672;font-weight: bold">(</span>S3AUtils.java:1347<span style="color: #f92672;font-weight: bold">)</span> ~[flink-s3-fs-hadoop-1.18.1.jar:1.18.1]
<span style="color: #f92672;font-weight: bold">[</span>â€¦]
Caused by: java.lang.ClassNotFoundException: com.amazonaws.thirdparty.apache.http.conn.socket.ConnectionSocketFactory
<span style="color: #f92672;font-weight: bold">[</span>â€¦]</code></pre>
</div>
</div>
<div class="paragraph">
<p>I guess this is actually just some internal stuff, since itâ€™s not raised as an error, so weâ€™ll ignore it for now.</p>
</div>
<div class="paragraph">
<p>Then some more config values, and then an interesting one (since weâ€™re using MinIO)â€”the endpoint configuration.
Since weâ€™ve not yet set it, itâ€™s unsurprising to see that itâ€™s using the default (<code>Using default endpoint</code>):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="shell">DEBUG org.apache.hadoop.fs.s3a.DefaultS3ClientFactory              <span style="color: #f92672;font-weight: bold">[]</span> - Creating endpoint configuration <span style="color: #66d9ef;font-weight: bold">for</span> <span style="color: #e6db74">&#34;&#34;</span>
DEBUG org.apache.hadoop.fs.s3a.DefaultS3ClientFactory              <span style="color: #f92672;font-weight: bold">[]</span> - Using default endpoint <span style="color: #f92672">-no</span> need to generate a configuration
DEBUG org.apache.hadoop.fs.s3a.DefaultS3ClientFactory              <span style="color: #f92672;font-weight: bold">[]</span> - fs.s3a.endpoint.region<span style="color: #f92672;font-weight: bold">=</span><span style="color: #e6db74">&#34;us-east-1&#34;</span>
DEBUG org.apache.hadoop.fs.s3a.DefaultS3ClientFactory              <span style="color: #f92672;font-weight: bold">[]</span> - Using default endpoint<span style="color: #f8f8f2;background-color: #49483e">;</span> setting region to us-east-1</code></pre>
</div>
</div>
<div class="paragraph">
<p>Iâ€™ll skip over a bit more of the same kind of background <code>DEBUG</code> stuff, and highlight this bit where we start to see the file paths mentioned.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="shell">DEBUG org.apache.hadoop.fs.s3a.WriteOperationHelper                <span style="color: #f92672;font-weight: bold">[]</span> - Initiating Multipart upload to t_foo_fs/part-5d498f53-ec06-4ee4-9fe2-5c7763755200-0-0
DEBUG org.apache.hadoop.fs.s3a.Invoker                             <span style="color: #f92672;font-weight: bold">[]</span> - Starting: initiate MultiPartUpload
DEBUG org.apache.hadoop.fs.s3a.S3AFileSystem                       <span style="color: #f92672;font-weight: bold">[]</span> - Initiate multipart upload to t_foo_fs/part-5d498f53-ec06-4ee4-9fe2-5c7763755200-0-0
DEBUG org.apache.hadoop.fs.statistics.impl.IOStatisticsStoreImpl   <span style="color: #f92672;font-weight: bold">[]</span> - Incrementing counter object_multipart_initiated by 1 with final value 1</code></pre>
</div>
</div>
<div class="paragraph">
<p>Remembering the value of <code>path (&#39;path&#39; = &#39;s3a://warehouse/t_foo_fs/&#39;)</code> we can see the bucket has been stripped away to give us just the &#39;folder&#39; (which isnâ€™t, on S3) of <code>t_foo_fs</code>, and then the actual data for Flink to upload (<code>part-5d498f53-ec06-4ee4-9fe2-5c7763755200-0-0</code>).</p>
</div>
<div class="paragraph">
<p>So weâ€™re now at the part of the S3 process where it wants to write the data.
We kinda know itâ€™s going to fail anyway because we didnâ€™t configure the endpoint; but we also didnâ€™t configure any credentials and itâ€™s going to be that which trips things up first:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="shell">DEBUG org.apache.hadoop.fs.s3a.AWSCredentialProviderList           <span style="color: #f92672;font-weight: bold">[]</span> - No credentials from org.apache.flink.fs.s3.common.token.DynamicTemporaryAWSCredentialsProvider@1376bee: org.apache.hadoop.fs.s3a.auth.NoAwsCredentialsException: Dynamic session credentials <span style="color: #66d9ef;font-weight: bold">for </span>Flink: No AWS Credentials
DEBUG org.apache.hadoop.fs.s3a.Invoker                             <span style="color: #f92672;font-weight: bold">[]</span> - Starting: create credentials
DEBUG org.apache.hadoop.fs.s3a.Invoker                             <span style="color: #f92672;font-weight: bold">[]</span> - create credentials: duration 0:00.001s
DEBUG org.apache.hadoop.fs.s3a.AWSCredentialProviderList           <span style="color: #f92672;font-weight: bold">[]</span> - No credentials from TemporaryAWSCredentialsProvider: org.apache.hadoop.fs.s3a.auth.NoAwsCredentialsException: Session credentials <span style="color: #66d9ef;font-weight: bold">in </span>Hadoop configuration: No AWS Credentials
DEBUG org.apache.hadoop.fs.s3a.AWSCredentialProviderList           <span style="color: #f92672;font-weight: bold">[]</span> - No credentials from SimpleAWSCredentialsProvider: org.apache.hadoop.fs.s3a.auth.NoAwsCredentialsException: SimpleAWSCredentialsProvider: No AWS credentials <span style="color: #66d9ef;font-weight: bold">in </span>the Hadoop configuration
DEBUG org.apache.hadoop.fs.s3a.AWSCredentialProviderList           <span style="color: #f92672;font-weight: bold">[]</span> - No credentials provided by EnvironmentVariableCredentialsProvider: com.amazonaws.SdkClientException: Unable to load AWS credentials from environment variables <span style="color: #f92672;font-weight: bold">(</span>AWS_ACCESS_KEY_ID <span style="color: #f92672;font-weight: bold">(</span>or AWS_ACCESS_KEY<span style="color: #f92672;font-weight: bold">)</span> and AWS_SECRET_KEY <span style="color: #f92672;font-weight: bold">(</span>or AWS_SECRET_ACCESS_KEY<span style="color: #f92672;font-weight: bold">))</span>
com.amazonaws.SdkClientException: Unable to load AWS credentials from environment variables <span style="color: #f92672;font-weight: bold">(</span>AWS_ACCESS_KEY_ID <span style="color: #f92672;font-weight: bold">(</span>or AWS_ACCESS_KEY<span style="color: #f92672;font-weight: bold">)</span> and AWS_SECRET_KEY <span style="color: #f92672;font-weight: bold">(</span>or AWS_SECRET_ACCESS_KEY<span style="color: #f92672;font-weight: bold">))</span>
    at com.amazonaws.auth.EnvironmentVariableCredentialsProvider.getCredentials<span style="color: #f92672;font-weight: bold">(</span>EnvironmentVariableCredentialsProvider.java:49<span style="color: #f92672;font-weight: bold">)</span> ~[?:?]
<span style="color: #f92672;font-weight: bold">[</span>â€¦]
DEBUG org.apache.hadoop.fs.s3a.AWSCredentialProviderList           <span style="color: #f92672;font-weight: bold">[]</span> - No credentials from org.apache.hadoop.fs.s3a.auth.IAMInstanceCredentialsProvider@4f2b477b: org.apache.hadoop.fs.s3a.auth.NoAwsCredentialsException: IAMInstanceCredentialsProvider: Failed to connect to service endpoint:</code></pre>
</div>
</div>
<div class="paragraph">
<p>Whatâ€™s useful here is you can see the code go through the different credential source options, including environment variables (<code>EnvironmentVariableCredentialsProvider</code>) and config file (<code>SimpleAWSCredentialsProvider</code>).</p>
</div>
<div class="paragraph">
<p>With the credentials unavailable, the Flink job then fails:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="shell">WARN  org.apache.flink.runtime.taskmanager.Task                    <span style="color: #f92672;font-weight: bold">[]</span> - Source: Values[1] -&gt; StreamingFileWriter -&gt; Sink: end <span style="color: #f92672;font-weight: bold">(</span>1/1<span style="color: #f92672;font-weight: bold">)</span><span style="color: #75715e;font-style: italic">#0 (25de23919c70373c90645ab5b7bb1b8a_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to FAILED with failure cause:</span>
java.nio.file.AccessDeniedException: t_foo_fs/part-5d498f53-ec06-4ee4-9fe2-5c7763755200-0-0:
org.apache.hadoop.fs.s3a.auth.NoAuthWithAWSException:
No AWS Credentials provided by DynamicTemporaryAWSCredentialsProvider TemporaryAWSCredentialsProvider SimpleAWSCredentialsProvider EnvironmentVariableCredentialsProvider IAMInstanceCredentialsProvider :
com.amazonaws.SdkClientException: Unable to load AWS credentials from environment variables <span style="color: #f92672;font-weight: bold">(</span>AWS_ACCESS_KEY_ID <span style="color: #f92672;font-weight: bold">(</span>or AWS_ACCESS_KEY<span style="color: #f92672;font-weight: bold">)</span> and AWS_SECRET_KEY <span style="color: #f92672;font-weight: bold">(</span>or AWS_SECRET_ACCESS_KEY<span style="color: #f92672;font-weight: bold">))</span>
<span style="color: #f92672;font-weight: bold">[</span>â€¦]</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_credentials_and_configuration">Credentials and Configuration&nbsp;<a class="headline-hash" href="#_credentials_and_configuration">ðŸ”—</a> </h2>
<div class="sectionbody">
<div class="paragraph">
<p>As we saw from the log above, without any configuration for S3 provided the job fails.
So letâ€™s rectify that and tell Flink how to authorise to S3 (MinIO).
Per  <a href="https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/filesystems/s3/#configure-access-credentials">the docs</a> , this is done as part of  <a href="https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/config/#flink-configuration-file">the Flink config file</a> :</p>
</div>
<div class="paragraph">
<p><strong>/conf/flink-conf.yaml</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="yaml"><span style="color: #f8f8f2;background-color: #49483e">[</span><span style="color: #f8f8f2">â€¦</span><span style="color: #f8f8f2;background-color: #49483e">]</span>
<span style="color: #a6e22e">s3.access.key</span><span style="color: #f8f8f2;background-color: #49483e">:</span> <span style="color: #e6db74">admin</span>
<span style="color: #a6e22e">s3.secret.key</span><span style="color: #f8f8f2;background-color: #49483e">:</span> <span style="color: #e6db74">password</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Now we see from the log file that these credentials are picked up by <code>SimpleAWSCredentialsProvider</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="shell">DEBUG org.apache.hadoop.fs.s3a.AWSCredentialProviderList           <span style="color: #f92672;font-weight: bold">[]</span> - No credentials from TemporaryAWSCredentialsProvider: org.apache.hadoop.fs.s3a.auth.NoAwsCredentialsException: Session credentials <span style="color: #66d9ef;font-weight: bold">in </span>Hadoop configuration: No AWS Credentials
DEBUG org.apache.hadoop.fs.s3a.AWSCredentialProviderList           <span style="color: #f92672;font-weight: bold">[]</span> - Using credentials from SimpleAWSCredentialsProvider</code></pre>
</div>
</div>
<div class="paragraph">
<p>What happens next is interesting.
We see the actual call from the AWS library to S3 itself:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="shell">DEBUG com.amazonaws.request                                        <span style="color: #f92672;font-weight: bold">[]</span> - Sending Request: HEAD https://warehouse.s3.amazonaws.com / Headers: <span style="color: #f92672;font-weight: bold">(</span>amz-sdk-invocation-id: e887a1da-8ab6-26aa-20a7-7626c5e75a18, Content-Type: application/octet-stream, User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.319 Mac_OS_X/14.5 OpenJDK_64-Bit_Server_VM/11.0.21+9 java/11.0.21 vendor/Eclipse_Adoptium cfg/retry-mode/legacy, <span style="color: #f92672;font-weight: bold">)</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Note the hostname there, <code>HEAD <a href="https://warehouse.s3.amazonaws.com" class="bare">https://warehouse.s3.amazonaws.com</a></code>.
This is actually going out to S3 itself.
Which since weâ€™re using the credentials for MinIO, isnâ€™t going to work.</p>
</div>
<div class="paragraph">
<p>The <code>HEAD</code> fails with HTTP 400 error:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="shell">DEBUG com.amazonaws.request                                        <span style="color: #f92672;font-weight: bold">[]</span> - Received error response: com.amazonaws.services.s3.model.AmazonS3Exception: Bad Request <span style="color: #f92672;font-weight: bold">(</span>Service: Amazon S3<span style="color: #f8f8f2;background-color: #49483e">;</span> Status Code: 400<span style="color: #f8f8f2;background-color: #49483e">;</span> Error Code: 400 Bad Request<span style="color: #f8f8f2;background-color: #49483e">;</span> Request ID: NZT8FG3S4ETHKT83<span style="color: #f8f8f2;background-color: #49483e">;</span> S3 Extended Request ID: AnoFUPCnG4gL1ve8Gly+aaP3tTGQ8tVmSN+TT57AIX/dAvw71KSUsOg2n+eh6NvI7etIoHmZ80M<span style="color: #f92672;font-weight: bold">=</span><span style="color: #f8f8f2;background-color: #49483e">;</span> Proxy: null<span style="color: #f92672;font-weight: bold">)</span>, S3 Extended Request ID: AnoFUPCnG4gL1ve8Gly+aaP3tTGQ8tVmSN+TT57AIX/dAvw71KSUsOg2n+eh6NvI7etIoHmZ80M<span style="color: #f92672;font-weight: bold">=</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Thereâ€™s then a second HTTP request (a <code>POST</code>) for the file itself:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="shell">DEBUG com.amazonaws.request                                        <span style="color: #f92672;font-weight: bold">[]</span> - Sending Request: POST https://warehouse.s3.eu-central-1.amazonaws.com /t_foo_fs/part-12abc4d6-5b99-4627-b27a-d14788c03e36-0-0 Parameters: <span style="color: #f92672;font-weight: bold">({</span><span style="color: #e6db74">&#34;uploads&#34;</span>:[null]<span style="color: #f92672;font-weight: bold">}</span>Headers: <span style="color: #f92672;font-weight: bold">(</span>amz-sdk-invocation-id: f8a0359c-5115-a716-ff73-76482046b4e2, Content-Length: 0, Content-Type: application/octet-stream, User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.319 Mac_OS_X/14.5 OpenJDK_64-Bit_Server_VM/11.0.21+9 java/11.0.21 vendor/Eclipse_Adoptium cfg/retry-mode/legacy, <span style="color: #f92672;font-weight: bold">)</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>This also fails, and fatally so this time:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="shell">DEBUG com.amazonaws.request                                        <span style="color: #f92672;font-weight: bold">[]</span> - Received error response: com.amazonaws.services.s3.model.AmazonS3Exception: The AWS Access Key Id you provided does not exist <span style="color: #66d9ef;font-weight: bold">in </span>our records. <span style="color: #f92672;font-weight: bold">(</span>Service: Amazon S3<span style="color: #f8f8f2;background-color: #49483e">;</span> Status Code: 403<span style="color: #f8f8f2;background-color: #49483e">;</span> Error Code: InvalidAccessKeyId<span style="color: #f8f8f2;background-color: #49483e">;</span> Request ID: NZTDTWG94GJKBSGX<span style="color: #f8f8f2;background-color: #49483e">;</span> S3 Extended Request ID: 7/fnAkRXUg+LiUUzlN9ydkLRuK4Mp/KNjvho4hvQFq9AQYDhwXrGKsEJ8c1yXKmNu+nb8jsfgaQ<span style="color: #f92672;font-weight: bold">=</span><span style="color: #f8f8f2;background-color: #49483e">;</span> Proxy: null<span style="color: #f92672;font-weight: bold">)</span>, S3 Extended Request ID: 7/fnAkRXUg+LiUUzlN9ydkLRuK4Mp/KNjvho4hvQFq9AQYDhwXrGKsEJ8c1yXKmNu+nb8jsfgaQ<span style="color: #f92672;font-weight: bold">=</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>This gets floated up to Flink, which terminates the job with a failure:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="shell">WARN  org.apache.flink.runtime.taskmanager.Task                    <span style="color: #f92672;font-weight: bold">[]</span> - Source: Values[1] -&gt; StreamingFileWriter -&gt; Sink: end <span style="color: #f92672;font-weight: bold">(</span>1/1<span style="color: #f92672;font-weight: bold">)</span><span style="color: #75715e;font-style: italic">#0 (64dd133316241806e123b88524963eb3_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to FAILED with failure cause:</span>
java.nio.file.AccessDeniedException: t_foo_fs/part-12abc4d6-5b99-4627-b27a-d14788c03e36-0-0: initiate MultiPartUpload on t_foo_fs/part-12abc4d6-5b99-4627-b27a-d14788c03e36-0-0:
com.amazonaws.services.s3.model.AmazonS3Exception: The AWS Access Key Id you provided does not exist <span style="color: #66d9ef;font-weight: bold">in </span>our records.
<span style="color: #f92672;font-weight: bold">[</span>â€¦]</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_configuring_an_s3_endpoint_for_minio">Configuring an S3 endpoint for MinIO&nbsp;<a class="headline-hash" href="#_configuring_an_s3_endpoint_for_minio">ðŸ”—</a> </h2>
<div class="sectionbody">
<div class="paragraph">
<p>If youâ€™re using an S3-compatible object store, such as MinIO, you need to tell the Flink S3 client where to find it, since as we saw above it defaults to literally <code>warehouse.s3.amazonaws.com</code>.</p>
</div>
<div class="paragraph">
<p>Configuring the endpoint is covered  <a href="https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/filesystems/s3/#configure-non-s3-endpoint">clearly in the docs</a> â€”add it to your Flink config:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="yaml"><span style="color: #a6e22e">s3.endpoint</span><span style="color: #f8f8f2;background-color: #49483e">:</span> <span style="color: #e6db74">http://localhost:9000</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>After restarting, we see the endpoint reflected in the <code>DEBUG</code> messages as the S3 client starts up and parses its config:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="shell">DEBUG org.apache.hadoop.fs.s3a.DefaultS3ClientFactory              <span style="color: #f92672;font-weight: bold">[]</span> - Creating endpoint configuration <span style="color: #66d9ef;font-weight: bold">for</span> <span style="color: #e6db74">&#34;http://localhost:9000&#34;</span>
DEBUG org.apache.hadoop.fs.s3a.DefaultS3ClientFactory              <span style="color: #f92672;font-weight: bold">[]</span> - Endpoint URI <span style="color: #f92672;font-weight: bold">=</span> http://localhost:9000
DEBUG org.apache.hadoop.fs.s3a.DefaultS3ClientFactory              <span style="color: #f92672;font-weight: bold">[]</span> - Endpoint http://localhost:9000 is not the default<span style="color: #f8f8f2;background-color: #49483e">;</span> parsing
DEBUG org.apache.hadoop.fs.s3a.DefaultS3ClientFactory              <span style="color: #f92672;font-weight: bold">[]</span> - Region <span style="color: #66d9ef;font-weight: bold">for </span>endpoint http://localhost:9000, URI http://localhost:9000 is determined as null</code></pre>
</div>
</div>
<div class="paragraph">
<p>One thing that I will point out here is whatâ€™s shown here in the logs a bit above these endpoint messages:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="shell">DEBUG org.apache.flink.fs.s3hadoop.common.HadoopConfigLoader       <span style="color: #f92672;font-weight: bold">[]</span> - Adding Flink config entry <span style="color: #66d9ef;font-weight: bold">for </span>s3.endpoint as fs.s3a.endpoint to Hadoop config
DEBUG org.apache.flink.fs.s3hadoop.common.HadoopConfigLoader       <span style="color: #f92672;font-weight: bold">[]</span> - Adding Flink config entry <span style="color: #66d9ef;font-weight: bold">for </span>s3.access.key as fs.s3a.access.key to Hadoop config
DEBUG org.apache.flink.fs.s3hadoop.common.HadoopConfigLoader       <span style="color: #f92672;font-weight: bold">[]</span> - Adding Flink config entry <span style="color: #66d9ef;font-weight: bold">for </span>s3.secret.key as fs.s3a.secret.key to Hadoop config</code></pre>
</div>
</div>
<div class="paragraph">
<p>This has been a big source of confusion for me.
Is it <code>s3.endpoint</code> or <code>fs.s3a.endpoint</code>?
The answer is yes!
Itâ€™s both!
For Flink, you configure <code>s3.</code> which then gets mapped internally to the <code>fs.s3a.</code> configuration that the  <a href="https://hadoop.apache.org/docs/stable/hadoop-aws/tools/hadoop-aws/index.html">Hadoop-AWS module</a>  refers to in its documentation.</p>
</div>
<div class="paragraph">
<p>So, with the endpoint set, letâ€™s see what happens.
Weâ€™ll pick up where it went wrong last time; the HTTP calls to the S3 endpoint which should now be correct:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="shell">DEBUG com.amazonaws.request                                        <span style="color: #f92672;font-weight: bold">[]</span> - Sending Request: POST http://warehouse.localhost:9000 /t_foo_fs/part-b933eb6c-5cc4-4a25-bd33-f314268d7f8c-0-0 Parameters: <span style="color: #f92672;font-weight: bold">({</span><span style="color: #e6db74">&#34;uploads&#34;</span>:[null]<span style="color: #f92672;font-weight: bold">}</span>Headers: <span style="color: #f92672;font-weight: bold">(</span>amz-sdk-invocation-id: be591818-8fad-1264-ed5b-9dd97dedb041, Content-Length: 0, Content-Type: application/octet-stream, User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.319 Mac_OS_X/14.5 OpenJDK_64-Bit_Server_VM/11.0.21+9 java/11.0.21 vendor/Eclipse_Adoptium cfg/retry-mode/legacy, <span style="color: #f92672;font-weight: bold">)</span></code></pre>
</div>
</div>
<div class="paragraph">
<p><em>(Interestingly, no HEAD request first this time like there was before.)</em></p>
</div>
<div class="paragraph">
<p>However, this fails, and if you look at the hostname, youâ€™ll see why:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="shell">TRACE com.amazonaws.http.AmazonHttpClient                          <span style="color: #f92672;font-weight: bold">[]</span> - Unable to execute HTTP request: warehouse.localhost: nodename nor servname provided, or not known Request will be retried.</code></pre>
</div>
</div>
<div class="paragraph">
<p>Somehow itâ€™s getting <code>warehouse.localhost</code> from our configuration, which is not a hostname that exists from my machine.
This causes the Flink job to fail (after multiple retries):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="shell">WARN  org.apache.flink.runtime.taskmanager.Task                    <span style="color: #f92672;font-weight: bold">[]</span> - Source: Values[1] -&gt; StreamingFileWriter -&gt; Sink: end <span style="color: #f92672;font-weight: bold">(</span>1/1<span style="color: #f92672;font-weight: bold">)</span><span style="color: #75715e;font-style: italic">#0 (de4000cf76864688506c514ebba58514_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to FAILED with failure cause:</span>
org.apache.hadoop.fs.s3a.AWSClientIOException:
initiate MultiPartUpload on t_foo_fs/part-b933eb6c-5cc4-4a25-bd33-f314268d7f8c-0-0:
com.amazonaws.SdkClientException: Unable to execute HTTP request: warehouse.localhost: nodename nor servname provided, or not known:
<span style="color: #f92672;font-weight: bold">[</span>â€¦]</code></pre>
</div>
</div>
<div class="paragraph">
<p>This problem comes about because the default option in the S3 client is to use  <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/VirtualHosting.html#virtual-hosted-style-access">virtual-hosted-style requests</a>  in which the bucket name (<code>warehouse</code>, in our example) is prefixed to the endpoint hostname (<code>localhost</code>).</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_configuring_path_style_access_for_minio_from_flink_s3">Configuring path-style access for MinIO from Flink S3&nbsp;<a class="headline-hash" href="#_configuring_path_style_access_for_minio_from_flink_s3">ðŸ”—</a> </h2>
<div class="sectionbody">
<div class="paragraph">
<p>Also covered  <a href="https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/filesystems/s3/">very clearly</a>  in the Flink S3 docs is how to configure it to use  <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/VirtualHosting.html#path-style-access">path-style requests</a> .
To the Flink configuration we add:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="yaml"><span style="color: #a6e22e">s3.endpoint</span><span style="color: #f8f8f2;background-color: #49483e">:</span> <span style="color: #e6db74">http://localhost:9000</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>And so, to recap, our <code>flink-conf.yaml</code> for S3 now looks like this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="yaml"><span style="color: #f8f8f2;background-color: #49483e">[</span><span style="color: #f8f8f2">â€¦</span><span style="color: #f8f8f2;background-color: #49483e">]</span>
<span style="color: #a6e22e">s3.access.key</span><span style="color: #f8f8f2;background-color: #49483e">:</span> <span style="color: #e6db74">admin</span>
<span style="color: #a6e22e">s3.secret.key</span><span style="color: #f8f8f2;background-color: #49483e">:</span> <span style="color: #e6db74">password</span>
<span style="color: #a6e22e">s3.endpoint</span><span style="color: #f8f8f2;background-color: #49483e">:</span> <span style="color: #e6db74">http://localhost:9000</span>
<span style="color: #a6e22e">s3.path.style.access</span><span style="color: #f8f8f2;background-color: #49483e">:</span> <span style="color: #66d9ef">true</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>After restarting, things look pretty good.
The config is being read and passed to Hadoop-AWS:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="shell">DEBUG org.apache.flink.fs.s3hadoop.common.HadoopConfigLoader       <span style="color: #f92672;font-weight: bold">[]</span> - Adding Flink config entry <span style="color: #66d9ef;font-weight: bold">for </span>s3.endpoint as fs.s3a.endpoint to Hadoop config
DEBUG org.apache.flink.fs.s3hadoop.common.HadoopConfigLoader       <span style="color: #f92672;font-weight: bold">[]</span> - Adding Flink config entry <span style="color: #66d9ef;font-weight: bold">for </span>s3.access.key as fs.s3a.access.key to Hadoop config
DEBUG org.apache.flink.fs.s3hadoop.common.HadoopConfigLoader       <span style="color: #f92672;font-weight: bold">[]</span> - Adding Flink config entry <span style="color: #66d9ef;font-weight: bold">for </span>s3.secret.key as fs.s3a.secret.key to Hadoop config
DEBUG org.apache.flink.fs.s3hadoop.common.HadoopConfigLoader       <span style="color: #f92672;font-weight: bold">[]</span> - Adding Flink config entry <span style="color: #66d9ef;font-weight: bold">for </span>s3.path.style.access as fs.s3a.path.style.access to Hadoop config</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>POST</code> call is made to the correct MinIO endpoint, which returns an HTTP 200 successful status code:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="shell">DEBUG com.amazonaws.request                                        <span style="color: #f92672;font-weight: bold">[]</span> - Sending Request: POST http://localhost:9000 /warehouse/t_foo_fs/part-5caebe06-17eb-405c-bfc7-3f78f7e109da-0-0 Parameters: <span style="color: #f92672;font-weight: bold">({</span><span style="color: #e6db74">&#34;uploads&#34;</span>:[null]<span style="color: #f92672;font-weight: bold">}</span>Headers: <span style="color: #f92672;font-weight: bold">(</span>amz-sdk-invocation-id: 68d62b6f-997b-ef70-c2ca-3bce040dee2d, Content-Length: 0, Content-Type: application/octet-stream, User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.319 Mac_OS_X/14.5 OpenJDK_64-Bit_Server_VM/11.0.21+9 java/11.0.21 vendor/Eclipse_Adoptium cfg/retry-mode/legacy, <span style="color: #f92672;font-weight: bold">)</span>
<span style="color: #f92672;font-weight: bold">[</span>â€¦]
DEBUG com.amazonaws.request                                        <span style="color: #f92672;font-weight: bold">[]</span> - Received successful response: 200, AWS Request ID: 17E092B83B43303A</code></pre>
</div>
</div>
<div class="paragraph">
<p>The upload completes successfully:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="shell">DEBUG org.apache.hadoop.fs.s3a.Invoker                             <span style="color: #f92672;font-weight: bold">[]</span> - Completing multipart upload: duration 0:00.012s
DEBUG org.apache.hadoop.fs.s3a.S3AFileSystem                       <span style="color: #f92672;font-weight: bold">[]</span> - Finished write to t_foo_fs/part-5caebe06-17eb-405c-bfc7-3f78f7e109da-0-0, len 19. etag e140dda18b4f195055b066f350b52034-1, version null</code></pre>
</div>
</div>
<div class="paragraph">
<p>We have a (very small) file on MinIO (S3):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="shell"><span style="color: #f8f8f2">$ </span>mc <span style="color: #f8f8f2">ls</span> <span style="color: #f92672">--recursive</span> minio
<span style="color: #f92672;font-weight: bold">[</span>2024-07-09 14:46:17 UTC]    19B STANDARD warehouse/t_foo_fs/part-5caebe06-17eb-405c-bfc7-3f78f7e109da-0-0

<span style="color: #f8f8f2">$ </span>mc <span style="color: #f8f8f2">cat </span>minio/warehouse/t_foo_fs/part-5caebe06-17eb-405c-bfc7-3f78f7e109da-0-0
<span style="color: #f92672;font-weight: bold">{</span><span style="color: #e6db74">&#34;c1&#34;</span>:<span style="color: #e6db74">&#34;a&#34;</span>,<span style="color: #e6db74">&#34;c2&#34;</span>:42<span style="color: #f92672;font-weight: bold">}</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>And finally, the Flink job completed successfully:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="shell">Flink SQL&gt; show <span style="color: #f8f8f2">jobs</span><span style="color: #f8f8f2;background-color: #49483e">;</span>
+----------------------------------+-------------------------------------------------------+----------+-------------------------+
|                           job <span style="color: #f8f8f2">id</span> |                                              job name |   status |              start <span style="color: #f8f8f2">time</span> |
+----------------------------------+-------------------------------------------------------+----------+-------------------------+
| 1b54b5d97a3ec6536cf38fdf7e71d22c | insert-into_default_catalog.default_database.t_foo_fs | FINISHED | 2024-07-09T14:46:16.450 |
+----------------------------------+-------------------------------------------------------+----------+-------------------------+
1 row <span style="color: #66d9ef;font-weight: bold">in </span><span style="color: #f8f8f2">set</span></code></pre>
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/2024/08/66aabfa762af1f4adc316c18_AD_4nXe5aPirnsid2aG6h4SYCJaB2hxBD8UmrZ1DRX33A-264Ifq67WN-Y2isETbpUOnU3WgZkgy50CQ2nZQU6MQlOefTvi7uFOBdnrJAjERpzcG7lI11cRWLEbi5S_unA8ZiPqXpVjzWFwG-zhpvxO2fwPKwJNG.gif" alt="giphy"/>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_configuration_stuff">Configuration stuff&nbsp;<a class="headline-hash" href="#_configuration_stuff">ðŸ”—</a> </h2>
<div class="sectionbody">
<div class="paragraph">
<p>The Flink S3 docs say to use <code>s3.</code> for configuring S3, and we saw above that these get mapped to <code>fs.s3a.</code> for the Hadoop-AWS module.
Itâ€™s also valid to specify <code>fs.s3a.</code> directlyâ€”they get read and mapped the same:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="yaml"><span style="color: #a6e22e">fs.s3a.access.key</span><span style="color: #f8f8f2;background-color: #49483e">:</span> <span style="color: #e6db74">admin</span>
<span style="color: #a6e22e">fs.s3a.secret.key</span><span style="color: #f8f8f2;background-color: #49483e">:</span> <span style="color: #e6db74">password</span>
<span style="color: #a6e22e">fs.s3a.endpoint</span><span style="color: #f8f8f2;background-color: #49483e">:</span> <span style="color: #e6db74">http://localhost:9000</span>
<span style="color: #a6e22e">fs.s3a.path.style.access</span><span style="color: #f8f8f2;background-color: #49483e">:</span> <span style="color: #66d9ef">true</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>shows up in the log thus:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="shell">DEBUG org.apache.flink.fs.s3hadoop.common.HadoopConfigLoader       <span style="color: #f92672;font-weight: bold">[]</span> - Adding Flink config entry <span style="color: #66d9ef;font-weight: bold">for </span>fs.s3a.access.key as fs.s3a.access.key to Hadoop config
DEBUG org.apache.flink.fs.s3hadoop.common.HadoopConfigLoader       <span style="color: #f92672;font-weight: bold">[]</span> - Adding Flink config entry <span style="color: #66d9ef;font-weight: bold">for </span>fs.s3a.secret.key as fs.s3a.secret.key to Hadoop config
DEBUG org.apache.flink.fs.s3hadoop.common.HadoopConfigLoader       <span style="color: #f92672;font-weight: bold">[]</span> - Adding Flink config entry <span style="color: #66d9ef;font-weight: bold">for </span>fs.s3a.path.style.access as fs.s3a.path.style.access to Hadoop config
DEBUG org.apache.flink.fs.s3hadoop.common.HadoopConfigLoader       <span style="color: #f92672;font-weight: bold">[]</span> - Adding Flink config entry <span style="color: #66d9ef;font-weight: bold">for </span>fs.s3a.endpoint as fs.s3a.endpoint to Hadoop config</code></pre>
</div>
</div>
<div class="paragraph">
<p>If my educated-guess reading of the code is right,  <a href="https://github.com/apache/flink/blob/4e86d98437480377973f66600c2d5bda907589d6/flink-filesystems/flink-hadoop-fs/src/main/java/org/apache/flink/runtime/util/HadoopUtils.java#L121-L136">here</a>  is where the config values are mapped across.
The code mentions a <code>flink.hadoop.</code> prefix but this seems to be  <a href="https://github.com/apache/flink/blob/master/flink-filesystems/flink-s3-fs-hadoop/src/main/java/org/apache/flink/fs/s3hadoop/S3FileSystemFactory.java#L41-L47">overridden for flink-s3-fs-hadoop</a>  as a set of <code>FLINK_CONFIG_PREFIXES</code> which can be <code>s3., s3a., or fs.s3a.</code>â€”theyâ€™re all the same.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_references">References&nbsp;<a class="headline-hash" href="#_references">ðŸ”—</a> </h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p><a href="https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/filesystems/s3">Flink S3 filesystem</a></p>
</li>
<li>
<p><a href="https://hadoop.apache.org/docs/stable/hadoop-aws/tools/hadoop-aws/index.html">Hadoop-AWS</a></p>
</li>
</ul>
</div>
</div>
</div>
	<hr>
	<div class="giscus-container">
		<script src="https://giscus.app/client.js"
				data-repo="rmoff/rmoff-blog"
				data-repo-id="MDEwOlJlcG9zaXRvcnkxNTE3NDg2MTE="
				data-category="Announcements"
				data-category-id="DIC_kwDOCQuAA84CvP5T"
				data-mapping="pathname"
				data-strict="1"
				data-reactions-enabled="1"
				data-emit-metadata="0"
				data-input-position="bottom"
				data-theme="light"
				data-lang="en"
				crossorigin="anonymous"
				async>
		</script>
	</div>
</article>
      </main>
    
      
      <div class="docs-toc">
        <ul class="nav toc-top">
          <li><a href="#" id="back_to_top" class="docs-toc-title">On this page</a></li>
        </ul>
        <nav id="TableOfContents">
  <ul>
    <li><a href="#_test_rig">Test rig</a></li>
    <li><a href="#_logging">Logging</a></li>
    <li><a href="#_dependency_hadoop_s3_plugin">Dependency: Hadoop S3 plugin</a></li>
    <li><a href="#_log_file_diving">Log File Diving</a></li>
    <li><a href="#_credentials_and_configuration">Credentials and Configuration</a></li>
    <li><a href="#_configuring_an_s3_endpoint_for_minio">Configuring an S3 endpoint for MinIO</a></li>
    <li><a href="#_configuring_path_style_access_for_minio_from_flink_s3">Configuring path-style access for MinIO from Flink S3</a></li>
    <li><a href="#_configuration_stuff">Configuration stuff</a></li>
    <li><a href="#_references">References</a></li>
  </ul>
</nav>
      </div>
      
    
    </div>
  </div>
</div>


		</main>

		

		
		<footer class="site-footer hide-print" role="contentinfo">
			<span>&copy; 2026 </span>
		</footer>
		

		
	</body>
</html>
