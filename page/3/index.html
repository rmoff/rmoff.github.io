<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8" />

  
  <title>rmoff.net</title>

  
  
  <link href="//cdn.jsdelivr.net" rel="dns-prefetch">
  <link href="//cdnjs.cloudflare.com" rel="dns-prefetch">
  <link href="//at.alicdn.com" rel="dns-prefetch">
  <link href="//fonts.googleapis.com" rel="dns-prefetch">
  <link href="//fonts.gstatic.com" rel="dns-prefetch">
  
  
  
  
  

  

  
  
  

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="@gohugoio">
  <meta name="twitter:title" content="rmoff.net">
  
  <meta name="twitter:image" content="/images/avatar.jpg">

  
  <meta property="og:type" content="website">
  <meta property="og:title" content="rmoff.net">
  
  <meta property="og:url" content="https://rmoff.github.io/">
  <meta property="og:image" content="/images/avatar.jpg">




<meta name="generator" content="Hugo 0.52">


<link rel="canonical" href="https://rmoff.github.io/">
<link rel="alternate" type="application/rss+xml" href="https://rmoff.github.io/index.xml" title="rmoff.net">

<meta name="renderer" content="webkit">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="format-detection" content="telephone=no,email=no,adress=no">
<meta http-equiv="Cache-Control" content="no-transform">


<meta name="robots" content="index,follow">
<meta name="referrer" content="origin-when-cross-origin">







<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="apple-mobile-web-app-title" content="rmoff.net">
<meta name="msapplication-tooltip" content="rmoff.net">
<meta name='msapplication-navbutton-color' content="#5fbf5e">
<meta name="msapplication-TileColor" content="#5fbf5e">
<meta name="msapplication-TileImage" content="/images/tile-image-windows.png">
<link rel="icon" href="/images/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
<link rel="icon" sizes="192x192" href="/images/touch-icon-android.png">
<link rel="apple-touch-icon" href="/images/touch-icon-apple.png">


<link rel="preload" href="/styles/main.min.css" as="style">
<link rel="preload" href="https://fonts.googleapis.com/css?family=Lobster" as="style">
<link rel="preload" href="/images/avatar.jpg" as="image">
<link rel="preload" href="/images/grey-prism.svg" as="image">


<style>
  body {
    background: rgb(244, 243, 241) url('/images/grey-prism.svg') repeat fixed;
  }
</style>
<link rel="stylesheet" href="/styles/main.min.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lobster">


<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.2/dist/medium-zoom.min.js"></script>





  
  
<!--[if lte IE 8]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/videojs-ie8@1.1.2/dist/videojs-ie8.min.js"></script>
<![endif]-->

<!--[if lte IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/eligrey-classlist-js-polyfill@1.2.20180112/classList.min.js"></script>
<![endif]-->


<script src="https://cdn.jsdelivr.net/npm/smooth-scroll@14.2.1/dist/smooth-scroll.polyfills.min.js"></script>


</head>
  <body>
    
    <div class="suspension">
      <a title="Go to top" class="to-top is-hide"><span class="icon icon-up"></span></a>
      
    </div>
    
     <header class="site-header">
  <img class="avatar" src="/images/avatar.jpg" alt="Avatar">
  
  <h1 class="title">rmoff.net</h1>
  
  <p class="subtitle"></p>
  <button class="menu-toggle" type="button">
    <span class="icon icon-menu"></span>
  </button>
  <nav class="site-menu collapsed">
    <h2 class="offscreen">Main Menu</h2>
    <ul class="menu-list">
      
      
      
      
    </ul>
  </nav>
  <nav class="social-menu collapsed">
    <h2 class="offscreen">Social Networks</h2>
    <ul class="social-list"></ul>
  </nav>
</header>

<section class="main post-list">
  <header class="list-header offscreen">
    <h2 class="list-label">All Posts</h2>
  </header>
  
  
   <article class="post-entry">
  <header class="post-header">
    <h3 class="post-title"><a href="https://rmoff.github.io/post/stream-table-joins-in-ksql-stream-events-must-be-timestamped-after-the-table-messages/" class="post-link">Stream-Table Joins in KSQL: Stream events must be timestamped after the Table messages</a></h3>
    <p class="post-meta">@Robin Moffatt ¬∑ May 17, 2018 ¬∑ 4 min read</p>
  </header>
  
  <p class="post-summary">(preserving this StackOverflow answer for posterity and future Googlers)
tl;dr When doing a stream-table join, your table messages must already exist (and must be timestamped) before the stream messages. If you re-emit your source stream messages, after the table topic is populated, the join will succeed.
Example data Use kafakcat to populate topics:
kafkacat -b localhost:9092 -P -t sessionDetails &lt;&lt;EOF {&#34;Media&#34;:&#34;Foo&#34;,&#34;SessionIdTime&#34;:&#34;2018-05-17 11:25:33 BST&#34;,&#34;SessionIdSeq&#34;:1} {&#34;Media&#34;:&#34;Foo&#34;,&#34;SessionIdTime&#34;:&#34;2018-05-17 11:26:33 BST&#34;,&#34;SessionIdSeq&#34;:2} EOF kafkacat -b localhost:9092 -P -t voipDetails &lt;&lt;EOF {&#34;SessionIdTime&#34;:&#34;2018-05-17 11:25:33 BST&#34;,&#34;SessionIdSeq&#34;:1,&#34;Details&#34;:&#34;Bar1a&#34;} {&#34;SessionIdTime&#34;:&#34;2018-05-17 11:25:33 BST&#34;,&#34;SessionIdSeq&#34;:1,&#34;Details&#34;:&#34;Bar1b&#34;} {&#34;SessionIdTime&#34;:&#34;2018-05-17 11:26:33 BST&#34;,&#34;SessionIdSeq&#34;:2,&#34;Details&#34;:&#34;Bar2&#34;} EOF  Validate topic contents:</p>
  <footer class="post-footer">
    <a class="read-more" href="https://rmoff.github.io/post/stream-table-joins-in-ksql-stream-events-must-be-timestamped-after-the-table-messages/">Read More ‚Üí</a>
  </footer>
</article>
  <article class="post-entry">
  <header class="post-header">
    <h3 class="post-title"><a href="https://rmoff.github.io/post/quick-n-easy-population-of-realistic-test-data-into-kafka-with-mockaroo-and-kafkacat/" class="post-link">Quick &#39;n Easy Population of Realistic Test Data into Kafka</a></h3>
    <p class="post-meta">@Robin Moffatt ¬∑ May 10, 2018 ¬∑ 3 min read</p>
  </header>
  
  <p class="post-summary">tl;dr Use curl to pull data from the Mockaroo REST endpoint, and pipe it into kafkacat, thus:
curl -s &#34;https://api.mockaroo.com/api/d5a195e0?count=2&amp;key=ff7856d0&#34;| \ kafkacat -b localhost:9092 -t purchases -P  Three things I love‚Ä¶Kafka, kafkacat, and Mockaroo. And in this post I get to show all three üòÅ
Mockaroo is a very cool online service that lets you quickly mock up test data. What sets it apart from SELECT RANDOM(100) FROM DUMMY; is that it has lots of different classes of test data for you to choose from.</p>
  <footer class="post-footer">
    <a class="read-more" href="https://rmoff.github.io/post/quick-n-easy-population-of-realistic-test-data-into-kafka-with-mockaroo-and-kafkacat/">Read More ‚Üí</a>
  </footer>
</article>
  <article class="post-entry">
  <header class="post-header">
    <h3 class="post-title"><a href="https://rmoff.github.io/post/streaming-data-from-mongodb-into-kafka-with-kafka-connect-and-debezium/" class="post-link">Streaming Data from MongoDB into Kafka with Kafka Connect and Debezium</a></h3>
    <p class="post-meta">@Robin Moffatt ¬∑ Mar 27, 2018 ¬∑ 4 min read</p>
  </header>
  
  <p class="post-summary">Disclaimer: I am not a MongoDB person. These steps may or may not be appropriate and proper. But they worked for me :) Feel free to post in comments if I‚Äôm doing something wrong
MongoDB config - enabling replica sets For Debezium to be able to stream changes from MongoDB, Mongo needs to have replication configured:
Docs: Replication / Convert a Standalone to a Replica Set
Stop Mongo:
rmoff@proxmox01 ~&gt; sudo service mongod stop  Add replica set config to /etc/mongod.</p>
  <footer class="post-footer">
    <a class="read-more" href="https://rmoff.github.io/post/streaming-data-from-mongodb-into-kafka-with-kafka-connect-and-debezium/">Read More ‚Üí</a>
  </footer>
</article>
  <article class="post-entry">
  <header class="post-header">
    <h3 class="post-title"><a href="https://rmoff.github.io/post/cloning-ubiquitis-mongodb-instance-to-a-separate-server/" class="post-link">Cloning Ubiquiti&#39;s MongoDB instance to a separate server</a></h3>
    <p class="post-meta">@Robin Moffatt ¬∑ Mar 27, 2018 ¬∑ 3 min read</p>
  </header>
  
  <p class="post-summary">DISCLAIMER: I am not a MongoDB person (even if it is Web Scale X-D) - below instructions may work for you, they may not. Use with care!
For some work I‚Äôve been doing I wanted to access the data in Ubiquiti‚Äôs Unifi controller which it stores in MongoDB. Because I didn‚Äôt want to risk my actual Unifi device by changing local settings to enable remote access, and also because the version of MongoDB on it is older than ideal, I wanted to clone the data elsewhere.</p>
  <footer class="post-footer">
    <a class="read-more" href="https://rmoff.github.io/post/cloning-ubiquitis-mongodb-instance-to-a-separate-server/">Read More ‚Üí</a>
  </footer>
</article>
  <article class="post-entry">
  <header class="post-header">
    <h3 class="post-title"><a href="https://rmoff.github.io/post/streaming-data-from-mysql-into-kafka-with-kafka-connect-and-debezium/" class="post-link">Streaming Data from MySQL into Kafka with Kafka Connect and Debezium</a></h3>
    <p class="post-meta">@Robin Moffatt ¬∑ Mar 24, 2018 ¬∑ 6 min read</p>
  </header>
  
  <p class="post-summary">Debezium is a CDC tool that can stream changes from MySQL, MongoDB, and PostgreSQL into Kafka, using Kafka Connect. In this article we‚Äôll see how to set it up and examine the format of the data. A subsequent article will show using this realtime stream of data from a RDBMS and join it to data originating from other sources, using KSQL.
The software versions used here are:
 Confluent Platform 4.</p>
  <footer class="post-footer">
    <a class="read-more" href="https://rmoff.github.io/post/streaming-data-from-mysql-into-kafka-with-kafka-connect-and-debezium/">Read More ‚Üí</a>
  </footer>
</article>
  <article class="post-entry">
  <header class="post-header">
    <h3 class="post-title"><a href="https://rmoff.github.io/post/ksql-topic-does-not-conform-to-the-requirements/" class="post-link">KSQL: Topic ‚Ä¶ does not conform to the requirements</a></h3>
    <p class="post-meta">@Robin Moffatt ¬∑ Mar 6, 2018 ¬∑ 1 min read</p>
  </header>
  
  <p class="post-summary">io.confluent.ksql.exception.KafkaTopicException: Topic &#39;KSQL_NOTIFY&#39; does not conform to the requirements Partitions:1 v 4. Replication: 1 v 1  Why? Because the topic KSQL creates to underpin a CREATE STREAM AS SELECT or CREATE TABLE AS SELECT already exists, and doesn‚Äôt match what it expects. By default it will create partitions &amp; replicas based on the same values of the input topic.
Options:
 Use a different topic, via the WITH (KAFKA_TOPIC=&#39;FOO&#39;) syntax, e.</p>
  <footer class="post-footer">
    <a class="read-more" href="https://rmoff.github.io/post/ksql-topic-does-not-conform-to-the-requirements/">Read More ‚Üí</a>
  </footer>
</article>
  <article class="post-entry">
  <header class="post-header">
    <h3 class="post-title"><a href="https://rmoff.github.io/post/streaming-data-from-kafka-into-elasticsearch/" class="post-link">Streaming data from Kafka into Elasticsearch</a></h3>
    <p class="post-meta">@Robin Moffatt ¬∑ Mar 6, 2018 ¬∑ 2 min read</p>
  </header>
  
  <p class="post-summary">This article is part of a series exploring Streaming ETL in practice. You can read about setting up the ingest of realtime events from a standard Oracle platform, and building streaming ETL using KSQL.
This post shows how we take data streaming in from an Oracle transactional system into Kafka, and simply stream it onwards into Elasticsearch. This is a common pattern, for enabling rapid search or analytics against data held in systems elsewhere.</p>
  <footer class="post-footer">
    <a class="read-more" href="https://rmoff.github.io/post/streaming-data-from-kafka-into-elasticsearch/">Read More ‚Üí</a>
  </footer>
</article>
  <article class="post-entry">
  <header class="post-header">
    <h3 class="post-title"><a href="https://rmoff.github.io/post/installing-the-python-kafka-library-from-confluent-troubleshooting-some-silly-errors/" class="post-link">Installing the Python Kafka library from Confluent - troubleshooting some silly errors‚Ä¶</a></h3>
    <p class="post-meta">@Robin Moffatt ¬∑ Mar 6, 2018 ¬∑ 3 min read</p>
  </header>
  
  <p class="post-summary">System:
rmoff@proxmox01:~$ uname -a Linux proxmox01 4.4.6-1-pve #1 SMP Thu Apr 21 11:25:40 CEST 2016 x86_64 GNU/Linux rmoff@proxmox01:~$ head -n1 /etc/os-release PRETTY_NAME=&#34;Debian GNU/Linux 8 (jessie)&#34; rmoff@proxmox01:~$ python --version Python 2.7.9  Following:
 https://www.confluent.io/blog/introduction-to-apache-kafka-for-python-programmers/ https://github.com/confluentinc/confluent-kafka-python  Install librdkafka, which is a pre-req for the Python library:
wget -qO - https://packages.confluent.io/deb/4.0/archive.key | sudo apt-key add - sudo add-apt-repository &#34;deb [arch=amd64] https://packages.confluent.io/deb/4.0 stable main&#34; sudo apt-get install librdkafka-dev python-dev  Setup virtualenv:</p>
  <footer class="post-footer">
    <a class="read-more" href="https://rmoff.github.io/post/installing-the-python-kafka-library-from-confluent-troubleshooting-some-silly-errors/">Read More ‚Üí</a>
  </footer>
</article>
  <article class="post-entry">
  <header class="post-header">
    <h3 class="post-title"><a href="https://rmoff.github.io/post/why-do-we-need-streaming-etl/" class="post-link">Why Do We Need Streaming ETL?</a></h3>
    <p class="post-meta">@Robin Moffatt ¬∑ Mar 6, 2018 ¬∑ 6 min read</p>
  </header>
  
  <p class="post-summary">(This is an expanded version of the intro to an article I posted over on the Confluent blog. Here I get to be as verbose as I like ;))
My first job from university was building a datawarehouse for a retailer in the UK. Back then, it was writing COBOL jobs to load tables in DB2. We waited for all the shops to close and do their end of day system processing, and send their data back to the central mainframe.</p>
  <footer class="post-footer">
    <a class="read-more" href="https://rmoff.github.io/post/why-do-we-need-streaming-etl/">Read More ‚Üí</a>
  </footer>
</article>
  <article class="post-entry">
  <header class="post-header">
    <h3 class="post-title"><a href="https://rmoff.github.io/post/howto-oracle-goldengate-apache-kafka-schema-registry-swingbench/" class="post-link">HOWTO: Oracle GoldenGate &#43; Apache Kafka &#43; Schema Registry &#43; Swingbench</a></h3>
    <p class="post-meta">@Robin Moffatt ¬∑ Feb 1, 2018 ¬∑ 4 min read</p>
  </header>
  
  <p class="post-summary">This is the detailed step-by-step if you want to recreate the process I describe in the Confluent blog here
I used Oracle‚Äôs Oracle Developer Days VM, which comes preinstalled with Oracle 12cR2. You can see the notes on how to do this here. These notes take you through installing and configuring:
 Swingbench, to create a sample ‚ÄúOrder Entry‚Äù schema and simulate events on the Oracle database Oracle GoldenGate (OGG, forthwith) and Oracle GoldenGate for Big Data (OGG-BD, forthwith)  I‚Äôm using Oracle GoldenGate 12.</p>
  <footer class="post-footer">
    <a class="read-more" href="https://rmoff.github.io/post/howto-oracle-goldengate-apache-kafka-schema-registry-swingbench/">Read More ‚Üí</a>
  </footer>
</article>
 
   
  <footer class="list-footer">
    <nav class="pagination">
      <h3 class="offscreen">Pagination</h3>
      
      <a class="pagination-previous" href="/page/2/"
        >‚Üê Newer Posts</a
      >
       
      <a class="pagination-next" href="/page/4/"
        >Older Posts ‚Üí</a
      >
      
    </nav>
  </footer>
  
</section>



<footer class="site-footer">
  <p>¬© 2017-2018 rmoff.net</p>
  <p>Powered by <a href="https://gohugo.io/" target="_blank">Hugo</a> with theme <a href="https://github.com/laozhu/hugo-nuo" target="_blank">Nuo</a>.</p>
  
</footer>








<script src="/scripts/index.min.js"></script>






 
  </body>
</html>
