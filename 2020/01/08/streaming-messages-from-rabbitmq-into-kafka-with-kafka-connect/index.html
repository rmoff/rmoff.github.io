<!DOCTYPE html>
<html lang="en">
	<head>
		<meta http-equiv=X-Clacks-Overhead content="GNU Terry Pratchett">
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<title>Streaming messages from RabbitMQ into Kafka with Kafka Connect</title>
		<link rel="alternate" type="application/rss+xml" title="RSS" href="https://rmoff.net/index.xml">
		<link rel="canonical" href="https://rmoff.net/2020/01/08/streaming-messages-from-rabbitmq-into-kafka-with-kafka-connect/">
		
		
		
		

		
		<meta property="og:title" content="Streaming messages from RabbitMQ into Kafka with Kafka Connect" />
		<meta property="og:type" content="article" />
		<meta property="og:image" content="https://rmoff.net/images/2020/01/IMG_2076.jpeg" />
		<meta property="og:description" content="" />
		<meta property="og:url" content="https://rmoff.net/2020/01/08/streaming-messages-from-rabbitmq-into-kafka-with-kafka-connect/" />
		<meta property="og:site_name" content="Streaming messages from RabbitMQ into Kafka with Kafka Connect" />
		<meta name="twitter:card" content="summary_large_image" />
		<meta name="twitter:site" content="@" />


		
		<link rel="stylesheet" href="https://rmoff.net/css/tachyons.min.css" />
		<link rel="stylesheet" href="https://rmoff.net/css/story.css" />
		<link rel="stylesheet" href="https://rmoff.net/css/descartes.css" />
		<link rel="stylesheet" href="https://rmoff.net/css/toc.css" />
		<link rel="stylesheet" href="https://rmoff.net/css/retro-cards.css" />
		<link rel="stylesheet" href="https://rmoff.net/css/custom.css" />
		
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css">
		<link href="https://fonts.googleapis.com/css?family=Quattrocento+Sans:400,400i,700,700i|Quattrocento:400,700|Spectral:400,400i,700,700i&amp;subset=latin-ext" rel="stylesheet">
		
		
		<script>
			!function(t,e){var o,n,p,r;e.__SV||(window.posthog=e,e._i=[],e.init=function(i,s,a){function g(t,e){var o=e.split(".");2==o.length&&(t=t[o[0]],e=o[1]),t[e]=function(){t.push([e].concat(Array.prototype.slice.call(arguments,0)))}}(p=t.createElement("script")).type="text/javascript",p.crossOrigin="anonymous",p.async=!0,p.src=s.api_host.replace(".i.posthog.com","-assets.i.posthog.com")+"/static/array.js",(r=t.getElementsByTagName("script")[0]).parentNode.insertBefore(p,r);var u=e;for(void 0!==a?u=e[a]=[]:a="posthog",u.people=u.people||[],u.toString=function(t){var e="posthog";return"posthog"!==a&&(e+="."+a),t||(e+=" (stub)"),e},u.people.toString=function(){return u.toString(1)+".people (stub)"},o="init capture register register_once register_for_session unregister unregister_for_session getFeatureFlag getFeatureFlagPayload isFeatureEnabled reloadFeatureFlags updateEarlyAccessFeatureEnrollment getEarlyAccessFeatures on onFeatureFlags onSessionId getSurveys getActiveMatchingSurveys renderSurvey canRenderSurvey getNextSurveyStep identify setPersonProperties group resetGroups setPersonPropertiesForFlags resetPersonPropertiesForFlags setGroupPropertiesForFlags resetGroupPropertiesForFlags reset get_distinct_id getGroups get_session_id get_session_replay_url alias set_config startSessionRecording stopSessionRecording sessionRecordingStarted captureException loadToolbar get_property getSessionProperty createPersonProfile opt_in_capturing opt_out_capturing has_opted_in_capturing has_opted_out_capturing clear_opt_in_out_capturing debug".split(" "),n=0;n<o.length;n++)g(u,o[n]);e._i.push([i,s,a])},e.__SV=1)}(document,window.posthog||[]);
            posthog.init('phc_93NEP79Ju4xqXYWXnoLbr4HMW0Iaepj1BGOVoEXYX6P',{api_host:'https://eu.i.posthog.com', person_profiles: 'identified_only' 
                })
		</script>
		
		<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
		
		<script src="https://rmoff.net/js/story.js"></script>
		<script src="https://rmoff.net/js/toc.js"></script>

	</head>
	<body class="ma0 bg-white section-post page-kind-page is-page-true ">
		
		<header class="cover bg-top" style="background-image: url('https://rmoff.net/images/2020/01/IMG_2076.jpeg'); background-position: center;">
			<div class="bg-black-30 bb bt">

				<nav class="hide-print sans-serif  border-box pa3 ph5-l">
					<a href="https://rmoff.net" title="Home">
						<link rel="preload" as="image" href="https://rmoff.net/img/repton.gif">
						<img
							src="https://rmoff.net/img/logo.jpg"
							class="w2 h2 br-100"
							alt="rmoff&#39;s random ramblings"
							onmouseover="this.src='https:\/\/rmoff.net\/img\/repton.gif';"
							onmouseout="this.src='https:\/\/rmoff.net\/img\/logo.jpg';"
						/>
					</a>
					<div class="fr h2 pv2 tr">
						<a class="link f5 ml2 dim near-white" href="https://talks.rmoff.net/bio">about</a>
						<a class="link f5 ml2 dim near-white" href="https://talks.rmoff.net">talks</a>
						<a class="link f5 ml2 dim near-white" href="https://bsky.app/profile/rmoff.net"><i class="fa-brands fa-bluesky"></i></a>
						<a class="link f5 ml2 dim near-white" href="https://github.com/rmoff/"><i class="fab fa-github-square"></i></a>
						<a class="link f5 ml2 dim near-white" href="https://www.youtube.com/c/rmoff"><i class="fab fa-youtube-square"></i></a>
						<a class="link f5 ml2 dim near-white" href="https://www.linkedin.com/in/robinmoffatt/"><i class="fab fa-linkedin"></i></a>
						<a class="link f5 ml2 dim near-white fas fa-rss-square" href="https://rmoff.net/index.xml" title="RSS Feed"></a>
						<a class="link f5 ml2 dim near-white fas fa-search" href="https://rmoff.net/search/" role="search" title="Search"></a>
					</div>
				</nav>

				<div id="hdr" class="tc-l pv4-ns pv5-l pv2 ph3 ph4-ns">
					<h1 class="near-white mt1-ns f2 fw3 mb0 mt0 lh-title">
						<span class="terminal-title">Streaming messages from RabbitMQ into Kafka with Kafka Connect<span class="terminal-cursor"></span></span>
					</h1>
					<h2 class="near-white mt3-l mb4-l fw1 f6 f3-l measure-wide-l center lh-copy mt2 mb3">
						
						
							
								Published
								<time datetime="2020-01-08T13:06:57Z">Jan 8, 2020</time>
								<span class="display-print">by </span>
								 in <a href="https://rmoff.net/categories/rabbitmq" class="no-underline category near-white dim">RabbitMQ</a>, <a href="https://rmoff.net/categories/kafka-connect" class="no-underline category near-white dim">Kafka Connect</a>, <a href="https://rmoff.net/categories/ksqldb" class="no-underline category near-white dim">KsqlDB</a>, <a href="https://rmoff.net/categories/postgres" class="no-underline category near-white dim">Postgres</a>, <a href="https://rmoff.net/categories/schema" class="no-underline category near-white dim">Schema</a>, <a href="https://rmoff.net/categories/bytearrayconverter" class="no-underline category near-white dim">ByteArrayConverter</a>
								<span class="display-print">at https://rmoff.net/2020/01/08/streaming-messages-from-rabbitmq-into-kafka-with-kafka-connect/</span>
							
						
					</h2>
				</div>

				
				
				
				

			</div>
		</header>
		
		<main role="main">
		
<div class="container-fluid docs">
  <div class="row">
    <main class="docs-content" role="main">

<article class="article">
	
<div class="paragraph">
<p>This was prompted by <a href="https://stackoverflow.com/questions/59632068/kafka-connect-is-sending-a-malformed-json">a question</a> on StackOverflow to which I thought the answer would be straightforward, but turned out not to be so. And then I got a bit carried away and ended up with a nice example of how you can handle schema-less data coming from a system such as RabbitMQ and apply a schema to it.</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
This same pattern for ingesting bytes and applying a schema will work with other connectors such as <a href="https://www.confluent.io/hub/confluentinc/kafka-connect-mqtt">MQTT</a>
</td>
</tr>
</tbody></table>
</div>
<div class="sect1">
<h2 id="_what_why">What? Why?&nbsp;<a class="headline-hash" href="#_what_why">ðŸ”—</a> </h2>
<div class="sectionbody">
<div class="paragraph">
<p><a href="https://www.reddit.com/r/java/comments/elv88o/streaming_messages_from_rabbitmq_into_kafka_with/fdkftsw"><code>aeveltstra</code> had this very good question</a>. I mean, RabbitMQ and Kafka, why would you want to integrate them? Seems weird, right? Hereâ€™s my quick take on it:</p>
</div>
<div class="quoteblock">
<blockquote>
<div class="paragraph">
<p>What? Why?</p>
</div>
</blockquote>
</div>
<div class="paragraph">
<p>Often RabbitMQ is in use already and itâ€™s easier to stream the messages from it into Kafka (e.g. to use with ksqlDB, drive other Kafka apps, persist for analysis elsewhere, etc) than it is to re-plumb the existing application(s) that are using RabbitMQ.</p>
</div>
<div class="paragraph">
<p>Another reason (<em>thanks to my colleague <a href="https://twitter.com/miguno">Michael Noll</a> for pointing this one out</em>) is migrations, where you run Kafka alongside RabbitMQ (or others) in parallel so new apps can get built against Kafka right away â€” and still get access to all RabbitMQ data â€” and gradually migrate legacy apps and data sources from RabbitMQ to Kafka. Migrate incrementally, which is safer than big bang.</p>
</div>
<div class="quoteblock">
<blockquote>
<div class="paragraph">
<p>Why would you choose to implement Kafka next to an existing RabbitMQ? Donâ€™t they serve the same purpose?</p>
</div>
</blockquote>
</div>
<div class="paragraph">
<p>There is overlap for sure. Kafka tends to come into its own for things like scale, persistence, stream processing, integration with other technologies, and so on. In a large organisation (or even not-so-large) youâ€™ll often find different teams adopting different technologies, and so whilst it may seem odd to have both, youâ€™ll quite often see these similar (in part) technologies side-by-side.</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
If you want to learn more about this, check out <a href="https://www.confluent.io/whitepaper/comparing-confluent-platform-with-traditional-messaging-middleware/">Comparing Confluent Platform with Traditional Messaging Middleware</a> as well as <a href="https://www.confluent.io/kafka-vs-pulsar/">Kafka compared to RabbitMQ</a>
</td>
</tr>
</tbody></table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_setup_optional">Setup (optional)&nbsp;<a class="headline-hash" href="#_setup_optional">ðŸ”—</a> </h2>
<div class="sectionbody">
<div class="paragraph">
<p>If you want to follow along with this example, you can use Docker Compose to create the environment.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Clone the repo</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">git clone https://github.com/confluentinc/demo-scene.git
cd demo-scene/rabbitmq-into-kafka</code></pre>
</div>
</div>
</li>
<li>
<p>Bring up the test environment</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">docker-compose up -d</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_create_queue_and_test_message_on_rabbitmq">Create queue and test message on RabbitMQ&nbsp;<a class="headline-hash" href="#_create_queue_and_test_message_on_rabbitmq">ðŸ”—</a> </h2>
<div class="sectionbody">
<div class="paragraph">
<p><em>This uses the <a href="https://www.rabbitmq.com/management.html">Management API</a> which has been enabled on the Docker container automagically.</em></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Create the queue</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">curl --user guest:guest \
      -X PUT -H &#39;content-type: application/json&#39; \
      --data-binary &#39;{&#34;vhost&#34;:&#34;/&#34;,&#34;name&#34;:&#34;test-queue-01&#34;,&#34;durable&#34;:&#34;true&#34;,&#34;auto_delete&#34;:&#34;false&#34;,&#34;arguments&#34;:{&#34;x-queue-type&#34;:&#34;classic&#34;}}&#39; \
      &#39;http://localhost:15672/api/queues/%2F/test-queue-01&#39;</code></pre>
</div>
</div>
</li>
<li>
<p>Confirm that the queue has been created</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">curl -s --user guest:guest \
        -X GET -H &#39;content-type: application/json&#39; \
        &#39;http://localhost:15672/api/queues/%2F/&#39; | jq &#39;.[].name&#39;</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">&#34;test-queue-01&#34;</code></pre>
</div>
</div>
</li>
<li>
<p>Send a test message</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">echo &#39;{&#34;vhost&#34;:&#34;/&#34;,&#34;name&#34;:&#34;amq.default&#34;,&#34;properties&#34;:{&#34;delivery_mode&#34;:1,&#34;headers&#34;:{}},&#34;routing_key&#34;:&#34;test-queue-01&#34;,&#34;delivery_mode&#34;:&#34;1&#34;,&#34;payload&#34;:&#34;{\&#34;transaction\&#34;: \&#34;PAYMENT\&#34;, \&#34;amount\&#34;: \&#34;$125.0\&#34;, \&#34;timestamp\&#34;: \&#34;&#39;$(date)&#39;\&#34; }&#34;,&#34;headers&#34;:{},&#34;props&#34;:{},&#34;payload_encoding&#34;:&#34;string&#34;}&#39; |
curl --user guest:guest \
      -X POST -H &#39;content-type: application/json&#39; \
      --data-binary @-  \
      &#39;http://localhost:15672/api/exchanges/%2F/amq.default/publish&#39;</code></pre>
</div>
</div>
</li>
<li>
<p>Test consuming messages from the queue</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">curl --silent --user guest:guest \
        -X POST -H &#39;content-type: application/json&#39; \
        --data-binary &#39;{&#34;ackmode&#34;:&#34;ack_requeue_true&#34;,&#34;encoding&#34;:&#34;auto&#34;,&#34;count&#34;:&#34;10&#34;}&#39; \
        &#39;http://localhost:15672/api/queues/%2F/test-queue-01/get&#39; | jq &#39;.[].payload|fromjson&#39;</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-javascript" data-lang="javascript">{
  &#34;transaction&#34;: &#34;PAYMENT&#34;,
  &#34;amount&#34;: &#34;$125.0&#34;,
  &#34;timestamp&#34;: &#34;Wed 8 Jan 2020 10:41:45 GMT&#34;
}</code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>You can see the RabbitMQ Web UI (login <code>guest</code>/<code>guest</code>) at <a href="http://localhost:15672/#/" class="bare">http://localhost:15672/#/</a></p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_create_the_kafka_connect_connector">Create the Kafka Connect connector&nbsp;<a class="headline-hash" href="#_create_the_kafka_connect_connector">ðŸ”—</a> </h2>
<div class="sectionbody">
<div class="paragraph">
<p><em>This uses the <a href="https://docs.confluent.io/current/connect/kafka-connect-rabbitmq/index.html">RabbitMQ plugin for Kafka Connect</a>, which has been installed in the Docker container already. You can install it yourself from <a href="http://hub.confluent.io/">Confluent Hub</a></em>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">curl -i -X PUT -H  &#34;Content-Type:application/json&#34; \
    http://localhost:8083/connectors/source-rabbitmq-00/config \
    -d &#39;{
        &#34;connector.class&#34; : &#34;io.confluent.connect.rabbitmq.RabbitMQSourceConnector&#34;,
        &#34;kafka.topic&#34; : &#34;rabbit-test-00&#34;,
        &#34;rabbitmq.queue&#34; : &#34;test-queue-01&#34;,
        &#34;rabbitmq.username&#34;: &#34;guest&#34;,
        &#34;rabbitmq.password&#34;: &#34;guest&#34;,
        &#34;rabbitmq.host&#34;: &#34;rabbitmq&#34;,
        &#34;rabbitmq.port&#34;: &#34;5672&#34;,
        &#34;rabbitmq.virtual.host&#34;: &#34;/&#34;,
        &#34;confluent.license&#34;:&#34;&#34;,
        &#34;confluent.topic.bootstrap.servers&#34;:&#34;kafka:29092&#34;,
        &#34;confluent.topic.replication.factor&#34;:1,
        &#34;value.converter&#34;: &#34;org.apache.kafka.connect.converters.ByteArrayConverter&#34;,
        &#34;key.converter&#34;: &#34;org.apache.kafka.connect.storage.StringConverter&#34;
    } &#39;</code></pre>
</div>
</div>
<div class="paragraph">
<p>With the connector created we check that itâ€™s running:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">curl -s &#34;http://localhost:8083/connectors?expand=info&amp;expand=status&#34; | \
           jq &#39;. | to_entries[] | [ .value.info.type, .key, .value.status.connector.state,.value.status.tasks[].state,.value.info.config.&#34;connector.class&#34;]|join(&#34;:|:&#34;)&#39; | \
           column -s : -t| sed &#39;s/\&#34;//g&#39;| sort</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">source  |  source-rabbitmq-00  |  RUNNING  |  RUNNING  |  io.confluent.connect.rabbitmq.RabbitMQSourceConnector</code></pre>
</div>
</div>
<div class="paragraph">
<p>And then we can check the topic thatâ€™s being written to. Here Iâ€™m using kafkacat but you can use any Kafka consumer:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">docker exec kafkacat \
  kafkacat -b kafka:29092 \
           -t rabbit-test-00 \
           -C -u</code></pre>
</div>
</div>
<div class="paragraph">
<p>The message we sent to RabbitMQ shows up in Kafka:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">{&#34;transaction&#34;: &#34;PAYMENT&#34;, &#34;amount&#34;: &#34;$125.0&#34;, &#34;timestamp&#34;: &#34;Wed 8 Jan 2020 10:41:45 GMT&#34;}</code></pre>
</div>
</div>
<div class="paragraph">
<p>If you open another window and use the same <code>curl</code> statement (bottom pane) above to send more messages to RabbitMQ, youâ€™ll see them appear in the Kafka topic (top pane) straight away:</p>
</div>
<script id="asciicast-A0dpWpN7WVs1UVnf0BjLNqqnv" src="https://asciinema.org/a/A0dpWpN7WVs1UVnf0BjLNqqnv.js" async=""></script>
<div class="paragraph">
<p>One of the important things to note in the configuration of the connector is that weâ€™re using the <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-128%3A+Add+ByteArrayConverter+for+Kafka+Connect"><code>ByteArrayConverter</code></a> for the value of the message, which just takes whatever bytes are on the RabbitMQ message and writes them to the Kafka message. Whilst on first look it appears that weâ€™ve got a JSON message on RabbitMQ and so would evidently use the JsonConverter, this is not the case. If we do that, the converter will try to encode the bytes as JSON, and weâ€™ll end up with this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">&#34;eyJ0cmFuc2FjdGlvbiI6ICJQQVlNRU5UIiwgImFtb3VudCI6ICIkNDcuMyIsICJ0aW1lc3RhbXAiOiAiV2VkIDggSmFuIDIwMjAgMTM6MDE6MjEgR01UIiB9&#34;</code></pre>
</div>
</div>
<div class="paragraph">
<p>To understand more about converters and serialisation see this article: <a href="https://www.confluent.io/blog/kafka-connect-deep-dive-converters-serialization-explained/">Kafka Connect Deep Dive â€“ Converters and Serialization Explained</a></p>
</div>
<div class="paragraph">
<p>We can dig into the payload further with kafkacat to examine the headers etc:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">docker exec kafkacat \
  kafkacat -b kafka:29092 -t rabbit-test-00 -C -u -q \
  -f &#39;Topic %t / Partition %p / Offset: %o / Timestamp: %T\nHeaders: %h\nKey (%K bytes): %k\nPayload (%S bytes): %s\n--\n&#39;</code></pre>
</div>
</div>
<div class="paragraph">
<p>The output looks like this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">Topic rabbit-test-00 / Partition 0 / Offset: 48 / Timestamp: 1578480718010
Headers: rabbitmq.consumer.tag=amq.ctag--gWoke550mjIPbeJhquS9g,rabbitmq.content.type=NULL,rabbitmq.content.encoding=NULL,rabbitmq.delivery.mode=1,rabbitmq.priority=0,rabbitmq.correlation.id=NULL,rabbitmq.reply.to=NULL,rabbitmq.expiration=NULL,rabbitmq.message.id=NULL,rabbitmq.timestamp=NULL,rabbitmq.type=NULL,rabbitmq.user.id=NULL,rabbitmq.app.id=NULL,rabbitmq.delivery.tag=45,rabbitmq.redeliver=false,rabbitmq.exchange=,rabbitmq.routing.key=test-queue-01
Key (-1 bytes):
Payload (91 bytes): {&#34;transaction&#34;: &#34;PAYMENT&#34;, &#34;amount&#34;: &#34;$125.0&#34;, &#34;timestamp&#34;: &#34;Wed 8 Jan 2020 10:51:57 GMT&#34; }</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_apply_a_schema_and_manipulate_the_data_in_ksqldb">Apply a schema and manipulate the data in ksqlDB&nbsp;<a class="headline-hash" href="#_apply_a_schema_and_manipulate_the_data_in_ksqldb">ðŸ”—</a> </h2>
<div class="sectionbody">
<div class="paragraph">
<p>So far weâ€™ve got the message (which happens to be JSON) from RabbitMQ into a Kafka topic. Now letâ€™s actually declare the schema so that we can work with the data. For that weâ€™re going to use ksqlDB to do a little bit of stream processing.</p>
</div>
<div class="paragraph">
<p>Fire up the ksqlDB CLI:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">docker exec -it ksqldb-cli ksql http://ksqldb-server:8088</code></pre>
</div>
</div>
<div class="paragraph">
<p>Inspect the raw topic contents:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-sql" data-lang="sql">ksql&gt; PRINT &#39;rabbit-test-00&#39; FROM BEGINNING;
Key format: Â¯\_(ãƒ„)_/Â¯ - no data processed
Value format: JSON or KAFKA_STRING
rowtime: 2021/09/30 09:48:48.854 Z, key: &lt;null&gt;, value: {&#34;transaction&#34;: &#34;PAYMENT&#34;, &#34;amount&#34;: &#34;$125.0&#34;, &#34;timestamp&#34;: &#34;Thu 30 Sep 2021 10:48:30 BST&#34; }, partition: 0</code></pre>
</div>
</div>
<div class="paragraph">
<p>Declare the stream (which is just the existing Kafka topic with an explicit schema):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-sql" data-lang="sql">CREATE STREAM rabbit (transaction VARCHAR,
                      amount VARCHAR,
                      timestamp VARCHAR)
  WITH (KAFKA_TOPIC=&#39;rabbit-test-00&#39;,
        VALUE_FORMAT=&#39;JSON&#39;);</code></pre>
</div>
</div>
<div class="paragraph">
<p>Now we can query the stream of data, starting at the beginning:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-sql" data-lang="sql">ksql&gt; SET &#39;auto.offset.reset&#39; = &#39;earliest&#39;;
Successfully changed local property &#39;auto.offset.reset&#39; to &#39;earliest&#39;. Use the UNSET command to revert your change.

ksql&gt; SELECT transaction, amount, timestamp FROM rabbit EMIT CHANGES;
+-------------+---------+------------------------------+
|TRANSACTION  |AMOUNT   |TIMESTAMP                     |
+-------------+---------+------------------------------+
|PAYMENT      |$125.0   |Thu 30 Sep 2021 10:55:28 BST  |
|PAYMENT      |$25.0    |Thu 30 Sep 2021 10:55:35 BST  |
|PAYMENT      |$42.0    |Thu 30 Sep 2021 10:55:40 BST  |</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>AMOUNT</code> column is clearly a currency, but the source data is a character string (<code>$125.0</code>). Letâ€™s write a stream processor to split these into more appropriate columns, and also drop messages with no timestamp (that weâ€™ll class as invalid data for this example):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-sql" data-lang="sql">CREATE STREAM TRANSACTIONS WITH (VALUE_FORMAT=&#39;AVRO&#39;) AS
  SELECT TRANSACTION AS TX_TYPE,
         SUBSTRING(AMOUNT,1,1) AS CURRENCY,
         CAST(SUBSTRING(AMOUNT,2,LEN(AMOUNT)-1) AS DECIMAL(9,2)) AS TX_AMOUNT,
         TIMESTAMP AS TX_TIMESTAMP
    FROM rabbit
   WHERE TIMESTAMP IS NOT NULL
    EMIT CHANGES;</code></pre>
</div>
</div>
<div class="paragraph">
<p>This creates a new Kafka topic, populated by the transformed data driven by the original Kafka topic populated from RabbitMQ:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-sql" data-lang="sql">ksql&gt; SELECT TX_TYPE, CURRENCY, TX_AMOUNT, TX_TIMESTAMP FROM TRANSACTIONS EMIT CHANGES;
+---------+---------+----------+------------------------------+
|TX_TYPE  |CURRENCY |TX_AMOUNT |TX_TIMESTAMP                  |
+---------+---------+----------+------------------------------+
|PAYMENT  |$        |125.00    |Thu 30 Sep 2021 10:55:28 BST  |
|PAYMENT  |$        |25.00     |Thu 30 Sep 2021 10:55:35 BST  |
|PAYMENT  |$        |42.00     |Thu 30 Sep 2021 10:55:40 BST  |</code></pre>
</div>
</div>
<div class="paragraph">
<p>Note that the messages without a timestamp are not present in the new stream.</p>
</div>
<div class="paragraph">
<p>Compare our source schema:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-sql" data-lang="sql">ksql&gt; DESCRIBE rabbit;

Name                 : RABBIT
 Field       | Type
-----------------------------------------
 ROWTIME     | BIGINT           (system)
 ROWKEY      | VARCHAR(STRING)  (system)
 TRANSACTION | VARCHAR(STRING)
 AMOUNT      | VARCHAR(STRING)
 TIMESTAMP   | VARCHAR(STRING)
-----------------------------------------</code></pre>
</div>
</div>
<div class="paragraph">
<p>with the transformed schema</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-sql" data-lang="sql">ksql&gt; DESCRIBE TRANSACTIONS;

Name                 : TRANSACTIONS
 Field        | Type
------------------------------------------
 ROWTIME      | BIGINT           (system)
 ROWKEY       | VARCHAR(STRING)  (system)
 TX_TYPE      | VARCHAR(STRING)
 CURRENCY     | VARCHAR(STRING)
 TX_AMOUNT    | DECIMAL
 TX_TIMESTAMP | VARCHAR(STRING)
------------------------------------------</code></pre>
</div>
</div>
<div class="paragraph">
<p>Because weâ€™ve applied a schema to the data we can now make better sense of it, as well as do useful things like write it to a database. Since we have a proper schema for the data (stored for us in the Schema Registry because weâ€™re using Avro) Kafka Connect can actually build the target database table that itâ€™s going to write data to:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-sql" data-lang="sql">CREATE SINK CONNECTOR SINK_POSTGRES WITH (
    &#39;connector.class&#39;     = &#39;io.confluent.connect.jdbc.JdbcSinkConnector&#39;,
    &#39;connection.url&#39;      = &#39;jdbc:postgresql://postgres:5432/&#39;,
    &#39;connection.user&#39;     = &#39;postgres&#39;,
    &#39;connection.password&#39; = &#39;postgres&#39;,
    &#39;topics&#39;              = &#39;TRANSACTIONS&#39;,
    &#39;key.converter&#39;       = &#39;org.apache.kafka.connect.storage.StringConverter&#39;,
    &#39;auto.create&#39;         = &#39;true&#39;,
    &#39;transforms&#39;          = &#39;dropSysCols&#39;,
    &#39;transforms.dropSysCols.type&#39; = &#39;org.apache.kafka.connect.transforms.ReplaceField$Value&#39;,
    &#39;transforms.dropSysCols.blacklist&#39; = &#39;ROWKEY,ROWTIME&#39;
  );</code></pre>
</div>
</div>
<div class="paragraph">
<p>Now in Postgres we have the data almost as soon as itâ€™s written to RabbitMQ, with the light transformation applied to it:</p>
</div>
<script id="asciicast-292407" src="https://asciinema.org/a/292407.js" async=""></script>
</div>
</div>

	<hr>
	<div style="background-color: rgba(204, 234, 255, 0.25); margin-bottom:50px;margin-top:50px;padding: 20px; border-width: 2px; border-style: solid; border-color: darkorange;">
	
		<script src="https://giscus.app/client.js"
				data-repo="rmoff/rmoff-blog"
				data-repo-id="MDEwOlJlcG9zaXRvcnkxNTE3NDg2MTE="
				data-category="Announcements"
				data-category-id="DIC_kwDOCQuAA84CvP5T"
				data-mapping="pathname"
				data-strict="1"
				data-reactions-enabled="1"
				data-emit-metadata="0"
				data-input-position="bottom"
				data-theme="light"
				data-lang="en"
				crossorigin="anonymous"
				async>
		</script>
		
	</div>
		
				<div class="hide-print sans-serif f6 f5-l mt5 ph3 pb6 center nested-copy-line-height lh-copy nested-links mw-100 measure-wide">
		<div class="about-the-author">
		
			
			
				
					<hr>
<p><img src="/images/2018/05/ksldn18-01.jpg" alt="Robin Moffatt"></p>
<p><a href="https://bsky.app/profile/rmoff.net"><b class="fa-brands fa-bluesky"></b></a>  <em>Robin Moffatt works on the DevRel team at Confluent. He likes writing about himself in the third person, eating good breakfasts, and drinking good beer.</em></p>

				
			
		
		</div>
		
	</div>

		

</article>
      </main>
    
      
      <div class="docs-toc">
        <ul class="nav toc-top">
          <li><a href="#" id="back_to_top" class="docs-toc-title">Contents</a></li>
        </ul>
        <nav id="TableOfContents">
  <ul>
    <li><a href="#_what_why">What? Why?</a></li>
    <li><a href="#_setup_optional">Setup (optional)</a></li>
    <li><a href="#_create_queue_and_test_message_on_rabbitmq">Create queue and test message on RabbitMQ</a></li>
    <li><a href="#_create_the_kafka_connect_connector">Create the Kafka Connect connector</a></li>
    <li><a href="#_apply_a_schema_and_manipulate_the_data_in_ksqldb">Apply a schema and manipulate the data in ksqlDB</a></li>
  </ul>
</nav>
      </div>
      
      <div class="toc-mobile-label">TABLE OF CONTENTS</div>
      
    
    </div>
  </div>
</div>


		</main>
		
		
		<footer class="hide-print sans-serif f6 fw1 bg-black near-white bottom-0 w-100 pa3" role="contentinfo">
			<p class="w-50 fr tr">
			<a class="no-underline near-white" href="https://github.com/xaprb/story"><img class="dib" title="Made with Hugo and Story" alt="Story logo" src="https://rmoff.net/img/story-logo-white.svg" style="width: 1.5rem; height: 1.5rem" /></a>
			</p>
			<p class="w-50 near-white">
				&copy; 2025 
			</p>
		</footer>
		
	</body>
</html>
