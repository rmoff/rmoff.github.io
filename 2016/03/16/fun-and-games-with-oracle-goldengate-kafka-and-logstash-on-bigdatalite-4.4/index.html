<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8" />

  
  <title>Fun and Games with Oracle GoldenGate, Kafka, and Logstash on BigDataLite 4.4</title>

  
  
  <link href="//cdn.jsdelivr.net" rel="dns-prefetch">
  <link href="//cdnjs.cloudflare.com" rel="dns-prefetch">
  <link href="//at.alicdn.com" rel="dns-prefetch">
  <link href="//fonts.googleapis.com" rel="dns-prefetch">
  <link href="//fonts.gstatic.com" rel="dns-prefetch">
  <link href="///disqus.com" rel="dns-prefetch">
  <link href="//c.disquscdn.com" rel="dns-prefetch">
  
  
  

  

  
  <meta name="author" content="Robin Moffatt">
  <meta name="description" content="The Oracle by Example (ObE) here demonstrating how to use Goldengate to replicate transactions big data targets such as HDFS is written for the BigDataLite 4.2.1, and for me didn&amp;rsquo;t work on the current latest version, 4.4.0.
The OBE (and similar Hands On Lab PDF) assume the presence of pmov.prm and pmov.properties in /u01/ogg/dirprm/. On BDL 4.4 there&amp;rsquo;s only the extract to from Oracle configuration, emov.
Fortunately it&amp;rsquo;s still possible to run this setup out of the box in BDL 4.">

  
  
    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="@gohugoio">
    <meta name="twitter:title" content="Fun and Games with Oracle GoldenGate, Kafka, and Logstash on BigDataLite 4.4">
    <meta name="twitter:description" content="The Oracle by Example (ObE) here demonstrating how to use Goldengate to replicate transactions big data targets such as HDFS is written for the BigDataLite 4.2.1, and for me didn&amp;rsquo;t work on the current latest version, 4.4.0.
The OBE (and similar Hands On Lab PDF) assume the presence of pmov.prm and pmov.properties in /u01/ogg/dirprm/. On BDL 4.4 there&amp;rsquo;s only the extract to from Oracle configuration, emov.
Fortunately it&amp;rsquo;s still possible to run this setup out of the box in BDL 4.">
    <meta name="twitter:image" content="/images/avatar.jpg">
  

  
  <meta property="og:type" content="article">
  <meta property="og:title" content="Fun and Games with Oracle GoldenGate, Kafka, and Logstash on BigDataLite 4.4">
  <meta property="og:description" content="The Oracle by Example (ObE) here demonstrating how to use Goldengate to replicate transactions big data targets such as HDFS is written for the BigDataLite 4.2.1, and for me didn&amp;rsquo;t work on the current latest version, 4.4.0.
The OBE (and similar Hands On Lab PDF) assume the presence of pmov.prm and pmov.properties in /u01/ogg/dirprm/. On BDL 4.4 there&amp;rsquo;s only the extract to from Oracle configuration, emov.
Fortunately it&amp;rsquo;s still possible to run this setup out of the box in BDL 4.">
  <meta property="og:url" content="https://rmoff.github.io/2016/03/16/fun-and-games-with-oracle-goldengate-kafka-and-logstash-on-bigdatalite-4.4/">
  <meta property="og:image" content="/images/avatar.jpg">




<meta name="generator" content="Hugo 0.52">


<link rel="canonical" href="https://rmoff.github.io/2016/03/16/fun-and-games-with-oracle-goldengate-kafka-and-logstash-on-bigdatalite-4.4/">

<meta name="renderer" content="webkit">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="format-detection" content="telephone=no,email=no,adress=no">
<meta http-equiv="Cache-Control" content="no-transform">


<meta name="robots" content="index,follow">
<meta name="referrer" content="origin-when-cross-origin">







<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="apple-mobile-web-app-title" content="rmoff.net">
<meta name="msapplication-tooltip" content="rmoff.net">
<meta name='msapplication-navbutton-color' content="#5fbf5e">
<meta name="msapplication-TileColor" content="#5fbf5e">
<meta name="msapplication-TileImage" content="/images/tile-image-windows.png">
<link rel="icon" href="/images/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
<link rel="icon" sizes="192x192" href="/images/touch-icon-android.png">
<link rel="apple-touch-icon" href="/images/touch-icon-apple.png">


<link rel="preload" href="/styles/main.min.css" as="style">
<link rel="preload" href="https://fonts.googleapis.com/css?family=Lobster" as="style">
<link rel="preload" href="/images/avatar.jpg" as="image">
<link rel="preload" href="/images/grey-prism.svg" as="image">


<style>
  body {
    background: rgb(244, 243, 241) url('/images/grey-prism.svg') repeat fixed;
  }
</style>
<link rel="stylesheet" href="/styles/main.min.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lobster">


<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.2/dist/medium-zoom.min.js"></script>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/video.js@7.3.0/dist/video-js.min.css">



  
  
<!--[if lte IE 8]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/videojs-ie8@1.1.2/dist/videojs-ie8.min.js"></script>
<![endif]-->

<!--[if lte IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/eligrey-classlist-js-polyfill@1.2.20180112/classList.min.js"></script>
<![endif]-->


<script src="https://cdn.jsdelivr.net/npm/smooth-scroll@14.2.1/dist/smooth-scroll.polyfills.min.js"></script>


</head>
  <body>
    
    <div class="suspension">
      <a title="Go to top" class="to-top is-hide"><span class="icon icon-up"></span></a>
      
        
        <a title="Go to comments" class="to-comment" href="#disqus_thread"><span class="icon icon-comment"></span></a>
        
      
    </div>
    
    
  <header class="site-header">
  <img class="avatar" src="/images/avatar.jpg" alt="Avatar">
  
  <h2 class="title">rmoff.net</h2>
  
  <p class="subtitle"></p>
  <button class="menu-toggle" type="button">
    <span class="icon icon-menu"></span>
  </button>
  <nav class="site-menu collapsed">
    <h2 class="offscreen">Main Menu</h2>
    <ul class="menu-list">
      
      
      
      
        <li class="menu-item
            
            
            ">
            <a href="/about-me/">about me</a>
          </li>
      
        <li class="menu-item
            
            
            ">
            <a href="/presentations/">presentations</a>
          </li>
      
    </ul>
  </nav>
  <nav class="social-menu collapsed">
    <h2 class="offscreen">Social Networks</h2>
    <ul class="social-list"></ul>
  </nav>
</header>

  <section class="main post-detail">
    <header class="post-header">
      <h1 class="post-title">Fun and Games with Oracle GoldenGate, Kafka, and Logstash on BigDataLite 4.4</h1>
      <p class="post-meta">@Robin Moffatt · Mar 16, 2016 · 8 min read</p>
    </header>
    <article class="post-content">

<p>The Oracle by Example (ObE) <a href="http://www.oracle.com/webfolder/technetwork/tutorials/obe/fmw/odi/odi_12c/DI_BDL_Guide/BigDataIntegration_Demo.html?cid=10235&amp;ssid=0">here</a> demonstrating how to use <a href="[https://docs.oracle.com/goldengate/bd1221/gg-bd/GBDIN/intro_adapter.htm#GBDIN101](http://)">Goldengate to replicate transactions big data targets</a> such as HDFS is written for the BigDataLite <a href="http://www.oracle.com/technetwork/database/bigdata-appliance/oracle-bigdatalite421-2843803.html">4.2.1</a>, and for me didn&rsquo;t work on the current latest version, <a href="http://www.oracle.com/technetwork/database/bigdata-appliance/oracle-bigdatalite-2104726.html">4.4.0</a>.</p>

<p>The OBE (and similar <a href="http://www.oracle.com/webfolder/technetwork/odi/ODI_BigData_HOL.pdf">Hands On Lab</a> PDF) assume the presence of <code>pmov.prm</code> and <code>pmov.properties</code> in <code>/u01/ogg/dirprm/</code>. On BDL 4.4 there&rsquo;s only the extract to from Oracle configuration, <code>emov</code>.</p>

<p>Fortunately it&rsquo;s still possible to run this setup out of the box in BDL 4.4, with bells on because it includes <a href="http://kafka.apache.org/">Kafka</a> too. And, who doesn&rsquo;t like a bit of Kafka nowadays?</p>

<h2 id="getting-it-running">Getting it running</h2>

<ol>
<li><p>Set the Oracle extract running (as per the OBE/HOL instructions).</p>

<p><em>I&rsquo;m using the ever-awesome <code>rlwrap</code> so that if I mistype stuff in <code>ggsci</code> I can just arrow up/down to cycle through command history.</em></p>

<pre><code>[oracle@bigdatalite ~]$ cd /u01/ogg
[oracle@bigdatalite ogg]$ rlwrap ./ggsci

Oracle GoldenGate Command Interpreter for Oracle
Version 12.2.0.1.0 OGGCORE_12.2.0.1.0_PLATFORMS_151101.1925.2_FBO
Linux, x64, 64bit (optimized), Oracle 12c on Nov 11 2015 03:53:23
Operating system character set identified as UTF-8.

Copyright (C) 1995, 2015, Oracle and/or its affiliates. All rights reserved.



GGSCI (bigdatalite.localdomain) 1&gt; obey dirprm/bigdata.oby
</code></pre>

<p>Note that the output differs from the OBE/HOL screenshot, with only the <code>emov</code> extract listed now:</p>

<pre><code>GGSCI (bigdatalite.localdomain as system@cdb/CDB$ROOT) 9&gt; info all

Program     Status      Group       Lag at Chkpt  Time Since Chkpt

MANAGER     RUNNING
EXTRACT     RUNNING     EMOV        04:00:10      00:00:01
</code></pre>

<p>Press <strong>Ctrl-D</strong> to exit <code>ggsci</code></p></li>

<li><p>Launch <code>ggsci</code> again, but from the <code>/u01/ogg-bd</code> folder this time. Run the same-named bigdata obey file, but note that it&rsquo;s a different set of instructions (because we&rsquo;re now in <code>/u01/ogg-bd</code>, rather than <code>/u01/ogg</code>)</p>

<pre><code>[oracle@bigdatalite ogg]$ cd /u01/ogg-bd
[oracle@bigdatalite ogg-bd]$ rlwrap ./ggsci

Oracle GoldenGate Command Interpreter
Version 12.2.0.1.0 OGGCORE_12.2.0.1.0_PLATFORMS_151101.1925.2
Linux, x64, 64bit (optimized), Generic on Nov 10 2015 16:18:12
Operating system character set identified as UTF-8.

Copyright (C) 1995, 2015, Oracle and/or its affiliates. All rights reserved.

GGSCI (bigdatalite.localdomain) 1&gt; obey dirprm/bigdata.oby
</code></pre>

<p>Looking at what&rsquo;s running we can see two replicats:</p>

<pre><code>GGSCI (bigdatalite.localdomain) 8&gt; INFO ALL

Program     Status      Group       Lag at Chkpt  Time Since Chkpt

MANAGER     RUNNING
REPLICAT    RUNNING     RKAFKA      00:00:00      00:00:01
REPLICAT    RUNNING     RMOV        00:00:00      00:00:02
</code></pre>

<p>Poking around the Kafka parameters we can see the configured topic for the transactions and schema. For full details about the Kafka handler <a href="https://docs.oracle.com/goldengate/bd1221/gg-bd/GADBD/kafka_handler.htm#GADBD449">see the documentation</a>.</p>

<pre><code>[oracle@bigdatalite ogg-bd]$ cat dirprm/kafka.props

gg.handlerlist = kafkahandler
gg.handler.kafkahandler.type = kafka
gg.handler.kafkahandler.KafkaProducerConfigFile=custom_kafka_producer.properties
gg.handler.kafkahandler.TopicName =oggtopic
gg.handler.kafkahandler.format =avro_op
gg.handler.kafkahandler.SchemaTopicName=mySchemaTopic
gg.handler.kafkahandler.BlockingSend =false
gg.handler.kafkahandler.includeTokens=false

gg.handler.kafkahandler.mode =tx
#gg.handler.kafkahandler.maxGroupSize =100, 1Mb
#gg.handler.kafkahandler.minGroupSize =50, 500Kb
</code></pre></li>
</ol>

<h2 id="testing-it-out">Testing it out</h2>

<p>Using the Kafka console shell we can observe what Oracle GoldenGate sends to Kafka:</p>

<pre><code>[oracle@bigdatalite dirprm]$ kafka-console-consumer --zookeeper localhost:2181 --topic oggtopic
</code></pre>

<p>In a separate session (or even better, in the same session but using <code>screen</code> as in the demo below) modify data in the <code>MOVIEDEMO.MOVIE</code> table on Oracle. You should see the change come through to Kafka after a few moments.</p>

<p><img src="/content/images/2016/03/ogg-kafka.gif" alt="" /></p>

<h3 id="always-rtfm">Always RTFM…</h3>

<blockquote>
<p>The manual? That thing that explains how things work, and what problems to watch out for? Yeah… about that…</p>
</blockquote>

<p>So I got the Kafka bit working above and was happy, it worked, it was neat. But, for the life of me I couldn&rsquo;t get the transactions to appear in Hive. They appeared in the HDFS file when I <code>hadoop fs -cat</code>&rsquo;d it, they showed up in the Hue data browser &hellip; but not in Hive. Was this some <a href="http://marcelkrcah.net/blog/how-newline-can-ruin-your-hive/">weird bug/issue</a> involving new lines? What was going on?</p>

<p>Here&rsquo;s what I saw in HDFS. Note the last line, 22:32:21:</p>

<pre><code>[oracle@bigdatalite ogg]$ sudo su - hdfs -c &quot;hadoop fs -cat /user/odi/hive/orcl.moviedemo.movie/*&quot;
D2016-03-16 22:14:47.0000001Foo201450000020000000give you up
D2016-03-16 22:14:47.0000002never gonna201450000020000000give you up
D2016-03-16 22:14:47.0000003never gonna201450000020000000give you up
D2016-03-16 22:14:47.0000004never gonna201450000020000000give you up
I2016-03-16 22:27:18.0000002Sharknadozz201450000020000000Flying sharks attack city
I2016-03-16 22:32:21.0000004242never gonna201450000020000000give you up
[oracle@bigdatalite ogg]$
</code></pre>

<p>And this is what I saw in Hive - only five of the six rows of data:</p>

<pre><code>hive&gt; select * from movie_updates;
OK
D       2016-03-16 22:14:47             1       Foo     2014    500000  20000000        give you up
D       2016-03-16 22:14:47             2       never gonna     2014    500000  20000000        give you up
D       2016-03-16 22:14:47             3       never gonna     2014    500000  20000000        give you up
D       2016-03-16 22:14:47             4       never gonna     2014    500000  20000000        give you up
I       2016-03-16 22:27:18             2       Sharknadozz     2014    500000  20000000        Flying sharks attack city
Time taken: 0.087 seconds, Fetched: 5 row(s)
</code></pre>

<p>​
Turns out <a href="https://docs.oracle.com/goldengate/bd1221/gg-bd/GADBD/hdfs_handler.htm#GADBD395">the manual</a> spells this out pretty darn clearly in a section cunningly named <strong>Common Pitfalls</strong> it notes that</p>

<blockquote>
<p>HDFS blocks under construction are not always visible to analytic tools.</p>
</blockquote>

<p>And since I&rsquo;m noodling around with a few rows of data here and there (nowhere near the 128MB HDFS block size), this was the very cause of my issue. A workaround to prove that I wasn&rsquo;t going mad? Restart the GoldenGate replicat with the <code>rmov.properties</code> file changed to close the HDFS file periodically:</p>

<pre><code>gg.handler.hdfs.fileRollInterval=30s
</code></pre>

<p>Obviously this has performance implications in a real-life implementation, but for proving out functionality, it saved me from complete insanity :-)</p>

<h2 id="sidenote-error-in-reset-bigdata-oby">Sidenote - error in reset_bigdata.oby?</h2>

<p>I might be missing something here, but it looks like there&rsquo;s a minor fubar in <code>/u01/ogg-bd/dirprm/reset_bigdata.oby</code>:</p>

<pre><code>start mgr
stop rmov
stop rkafka
shell sleep 5
delete rmov
stop rkafka
[...]
</code></pre>

<p>That second <code>stop rkafka</code> I&rsquo;m guessing should be <code>delete rkafka</code>?</p>

<h2 id="logstash">Logstash</h2>

<p>I&rsquo;m a long-time fan of the <a href="http://elastic.co">Elastic stack</a>, and Logstash has an input plugin for Kafka, so let&rsquo;s see if that can fit the jigsaw here too.</p>

<p>The data from GoldenGate is serialised using <a href="https://avro.apache.org/">Avro</a>. The schema is put by Goldengate onto a separate Kafka topic, <code>mySchemaTopic</code>. There&rsquo;s probably a more proper way to get it but I dumped it to file thus:</p>

<pre><code>kafka-console-consumer --zookeeper localhost:2181 --topic mySchemaTopic --from-beginning &gt; ~/schema.avsc
</code></pre>

<p>Here&rsquo;s a snippet of what it looks like:</p>

<pre><code>{
  &quot;type&quot; : &quot;record&quot;,
  &quot;name&quot; : &quot;MOVIE&quot;,
  &quot;namespace&quot; : &quot;ORCL.MOVIEDEMO&quot;,
  &quot;fields&quot; : [ {
    &quot;name&quot; : &quot;table&quot;,
    &quot;type&quot; : &quot;string&quot;
  }, {
    &quot;name&quot; : &quot;op_type&quot;,
    &quot;type&quot; : &quot;string&quot;
  }, {
[...]
</code></pre>

<p>Logstash can use the Avro <strong>codec</strong> to deserialise the data it&rsquo;s going to be pulling from Kafka. It isn&rsquo;t part of the standard distribution, so needs installing thus:</p>

<pre><code>/opt/logstash-2.2.0/bin/plugin install logstash-codec-avro
</code></pre>

<p>Now we can build our Logstash config file:</p>

<pre><code class="language-ruby"> input {
     kafka {
         zk_connect =&gt; 'bigdatalite:2181'
         topic_id =&gt; 'oggtopic'
         codec =&gt;
             avro {
                 schema_uri =&gt; &quot;/home/oracle/schema.avsc&quot;
             }
         # These next two options will force logstash to pull
         # the entire contents of the topic.
         reset_beginning =&gt; 'true'
         auto_offset_reset =&gt; 'smallest'
     }
 }

 output {
     stdout {
         codec =&gt; rubydebug
     }
 }
</code></pre>

<p>Note the syntax for referencing the Avro codec - if you follow the syntax in the docs it will fail with the error <code>undefined method `decode' for [&quot;avro&quot;</code>. Thanks to <a href="http://stackoverflow.com/a/33211940/350613">this Stackoverflow post</a> for help on fixing that problem.</p>

<p>Because we&rsquo;ve told Logstash to use the <strong>stdout</strong> output plugin we can see everything that it&rsquo;s reading from Kafka, and the <strong>rubydebug</strong> codec ensures that field names etc are nicely formatted. You can see from this the point of the Avro schema - it supports the idea of records deletions, as in this one:</p>

<pre><code>[oracle@bigdatalite logstash-2.2.0]$ /opt/logstash-2.2.0/bin/logstash -f ~/logstash-kafka-stdout.conf
Settings: Default pipeline workers: 4
Logstash startup completed
{
           &quot;table&quot; =&gt; &quot;ORCL.MOVIEDEMO.MOVIE&quot;,
         &quot;op_type&quot; =&gt; &quot;D&quot;,
           &quot;op_ts&quot; =&gt; &quot;2016-03-16 22:14:47.000000&quot;,
      &quot;current_ts&quot; =&gt; &quot;2016-03-16T22:26:29.515000&quot;,
             &quot;pos&quot; =&gt; &quot;00000000010000002172&quot;,
    &quot;primary_keys&quot; =&gt; [
        [0] &quot;MOVIE_ID&quot;
    ],
          &quot;tokens&quot; =&gt; {},
          &quot;before&quot; =&gt; {
                      &quot;MOVIE_ID&quot; =&gt; &quot;1&quot;,
            &quot;MOVIE_ID_isMissing&quot; =&gt; false,
                         &quot;TITLE&quot; =&gt; &quot;Foo&quot;,
               &quot;TITLE_isMissing&quot; =&gt; false,
                          &quot;YEAR&quot; =&gt; &quot;2014&quot;,
                &quot;YEAR_isMissing&quot; =&gt; false,
                        &quot;BUDGET&quot; =&gt; &quot;500000&quot;,
              &quot;BUDGET_isMissing&quot; =&gt; false,
                         &quot;GROSS&quot; =&gt; &quot;20000000&quot;,
               &quot;GROSS_isMissing&quot; =&gt; false,
                  &quot;PLOT_SUMMARY&quot; =&gt; &quot;give you up&quot;,
        &quot;PLOT_SUMMARY_isMissing&quot; =&gt; false
    },
           &quot;after&quot; =&gt; nil,
        &quot;@version&quot; =&gt; &quot;1&quot;,
      &quot;@timestamp&quot; =&gt; &quot;2016-03-16T22:53:48.675Z&quot;
}
</code></pre>

<p>as well as inserts and updates:</p>

<pre><code>{
           &quot;table&quot; =&gt; &quot;ORCL.MOVIEDEMO.MOVIE&quot;,
         &quot;op_type&quot; =&gt; &quot;I&quot;,
           &quot;op_ts&quot; =&gt; &quot;2016-03-16 22:32:21.000000&quot;,
      &quot;current_ts&quot; =&gt; &quot;2016-03-16T22:32:22.941000&quot;,
             &quot;pos&quot; =&gt; &quot;00000000010000003090&quot;,
    &quot;primary_keys&quot; =&gt; [
        [0] &quot;MOVIE_ID&quot;
    ],
          &quot;tokens&quot; =&gt; {},
          &quot;before&quot; =&gt; nil,
           &quot;after&quot; =&gt; {
                      &quot;MOVIE_ID&quot; =&gt; &quot;4242&quot;,
            &quot;MOVIE_ID_isMissing&quot; =&gt; false,
                         &quot;TITLE&quot; =&gt; &quot;never gonna&quot;,
               &quot;TITLE_isMissing&quot; =&gt; false,
                          &quot;YEAR&quot; =&gt; &quot;2014&quot;,
                &quot;YEAR_isMissing&quot; =&gt; false,
                        &quot;BUDGET&quot; =&gt; &quot;500000&quot;,
              &quot;BUDGET_isMissing&quot; =&gt; false,
                         &quot;GROSS&quot; =&gt; &quot;20000000&quot;,
               &quot;GROSS_isMissing&quot; =&gt; false,
                  &quot;PLOT_SUMMARY&quot; =&gt; &quot;give you up&quot;,
        &quot;PLOT_SUMMARY_isMissing&quot; =&gt; false
    },
        &quot;@version&quot; =&gt; &quot;1&quot;,
      &quot;@timestamp&quot; =&gt; &quot;2016-03-16T23:08:58.804Z&quot;
}
{
           &quot;table&quot; =&gt; &quot;ORCL.MOVIEDEMO.MOVIE&quot;,
         &quot;op_type&quot; =&gt; &quot;U&quot;,
           &quot;op_ts&quot; =&gt; &quot;2016-03-16 23:09:58.000000&quot;,
      &quot;current_ts&quot; =&gt; &quot;2016-03-16T23:10:01.023000&quot;,
             &quot;pos&quot; =&gt; &quot;00000000010000003700&quot;,
    &quot;primary_keys&quot; =&gt; [
        [0] &quot;MOVIE_ID&quot;
    ],
          &quot;tokens&quot; =&gt; {},
          &quot;before&quot; =&gt; {
                      &quot;MOVIE_ID&quot; =&gt; &quot;4242&quot;,
            &quot;MOVIE_ID_isMissing&quot; =&gt; false,
                         &quot;TITLE&quot; =&gt; &quot;never gonna&quot;,
               &quot;TITLE_isMissing&quot; =&gt; false,
                          &quot;YEAR&quot; =&gt; &quot;2014&quot;,
                &quot;YEAR_isMissing&quot; =&gt; false,
                        &quot;BUDGET&quot; =&gt; &quot;500000&quot;,
              &quot;BUDGET_isMissing&quot; =&gt; false,
                         &quot;GROSS&quot; =&gt; &quot;20000000&quot;,
               &quot;GROSS_isMissing&quot; =&gt; false,
                  &quot;PLOT_SUMMARY&quot; =&gt; &quot;give you up&quot;,
        &quot;PLOT_SUMMARY_isMissing&quot; =&gt; false
    },
           &quot;after&quot; =&gt; {
                      &quot;MOVIE_ID&quot; =&gt; &quot;4242&quot;,
            &quot;MOVIE_ID_isMissing&quot; =&gt; false,
                         &quot;TITLE&quot; =&gt; &quot;Foobar&quot;,
               &quot;TITLE_isMissing&quot; =&gt; false,
                          &quot;YEAR&quot; =&gt; &quot;2014&quot;,
                &quot;YEAR_isMissing&quot; =&gt; false,
                        &quot;BUDGET&quot; =&gt; &quot;500000&quot;,
              &quot;BUDGET_isMissing&quot; =&gt; false,
                         &quot;GROSS&quot; =&gt; &quot;20000000&quot;,
               &quot;GROSS_isMissing&quot; =&gt; false,
                  &quot;PLOT_SUMMARY&quot; =&gt; &quot;give you up&quot;,
        &quot;PLOT_SUMMARY_isMissing&quot; =&gt; false
    },
        &quot;@version&quot; =&gt; &quot;1&quot;,
      &quot;@timestamp&quot; =&gt; &quot;2016-03-16T23:10:11.043Z&quot;
}

</code></pre>

<p>If you want to get this into Elasticsearch you can send it there from Logstash, just by adding</p>

<pre><code> elasticsearch { hosts =&gt; &quot;localhost&quot;}
</code></pre>

<p>to the <code>output</code> stanza of the logstash configuration file. I hit the error</p>

<pre><code>SSLConnectionSocketFactory not found [...]
</code></pre>

<p>when I ran Logstash with Elasticsearch output option, to which a quick Google produced the answer; run <code>unset CLASSPATH</code> first.</p>

<p>With the data in Elasticsearch it&rsquo;s a matter of moments to get set up in Kibana and to start poking around it:</p>

<p><img src="/content/images/2016/03/2016-03-17_21-49-15.png" alt="" /></p>

<hr />

<p>So what&rsquo;s the point of all this? Well, I mentioned it partly above - jigsaws. It&rsquo;s fun seeing what fits together with what 8-) But more usefully, Kafka has a vital role to play in <a href="http://www.rittmanmead.com/2015/10/forays-into-kafka-enabling-flexible-data-pipelines/">flexible data pipelines</a>, and Logstash is just an easy example of one of the many consumers that can take advantage of data persisted in the buffer that Kafka provides. Logstash itself gives a bunch of integration permutations, if the desired target itself doesn&rsquo;t have a direct Kafka consumer (which something like Elasticsearch may have, with the advent of <a href="http://docs.confluent.io/2.0.0/connect/">Kafka Connect</a>).</p>

<p>Pulling the GoldenGate data into Elasticsearch as seen above is cool (c.f. jigsaws, or maybe Lego is a better analogy), and for poking around the Kafka messages and deserialising the Avro messages it&rsquo;s perfect, but given the CDC nature of it having update and delete transactions too it could be that <a href="https://www.elastic.co/products/hadoop">Elasticsearch-Hadoop</a> is a better route if you want a consistent point-in-time view of your data. Done that way you&rsquo;d have <a href="https://www.elastic.co/guide/en/elasticsearch/hadoop/current/hive.html#_writing_data_to_elasticsearch_2">Hive pushing a copy of the data to Elasticsearch</a> thus:</p>

<pre><code>OGG -- [Kafka] --&gt; HDFS/Hive --&gt; Elasticsearch
</code></pre>
</article>
    <footer class="post-footer">
      
      <ul class="post-tags">
        
          <li><a href="/tags/logstash"><span class="tag">Logstash</span></a></li>
        
          <li><a href="/tags/kafka"><span class="tag">Kafka</span></a></li>
        
          <li><a href="/tags/goldengate"><span class="tag">Goldengate</span></a></li>
        
          <li><a href="/tags/avro"><span class="tag">Avro</span></a></li>
        
          <li><a href="/tags/elasticsearch"><span class="tag">Elasticsearch</span></a></li>
        
      </ul>
      
      <p class="post-copyright">
        This post was published <strong>1004</strong> days ago, content in the post may be inaccurate, even wrong now, please take risk yourself.
      </p>
    </footer>
    
      <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "rmoff" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
      
    
  </section>
  


<footer class="site-footer">
  <p>© 2017-2018 rmoff.net</p>
  <p>Powered by <a href="https://gohugo.io/" target="_blank">Hugo</a> with theme <a href="https://github.com/laozhu/hugo-nuo" target="_blank">Nuo</a>.</p>
  
</footer>



<script async src="https://cdn.jsdelivr.net/npm/video.js@7.3.0/dist/video.min.js"></script>




<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      displayMath: [['$$','$$'], ['\\[','\\]']],
      processEscapes: true,
      processEnvironments: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      TeX: { equationNumbers: { autoNumber: "AMS" },
      extensions: ["AMSmath.js", "AMSsymbols.js"] }
    },
  });
</script>
<script type="text/x-mathjax-config">
  // Fix <code> tags after MathJax finishes running. This is a
  // hack to overcome a shortcoming of Markdown. Discussion at
  // https://github.com/mojombo/jekyll/issues/199
  MathJax.Hub.Queue(() => {
    MathJax.Hub.getAllJax().map(v => v.SourceElement().parentNode.className += ' has-jax');
  });
</script>



<script src="/scripts/index.min.js"></script>








  </body>
</html>
