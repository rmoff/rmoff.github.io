<!DOCTYPE html>
<html lang="en">
	<head>
		<meta http-equiv=X-Clacks-Overhead content="GNU Terry Pratchett">
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		
		<link rel="preconnect" href="https://fonts.googleapis.com">
		<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
		<link rel="preload" as="image" href="https://rmoff.net/images/2016/04/kd05a-1.png" >
		
		<title>Decoupling the Data Pipeline with Kafka - A (Very) Simple Real Life Example</title>
		<link rel="alternate" type="application/rss+xml" title="RSS" href="https://rmoff.net/index.xml">
		<link rel="canonical" href="https://rmoff.net/2016/04/12/decoupling-the-data-pipeline-with-kafka-a-very-simple-real-life-example/">
		
		

		
		<meta property="og:title" content="Decoupling the Data Pipeline with Kafka - A (Very) Simple Real Life Example" />
		<meta property="og:type" content="article" />
		<meta property="og:image" content="https://rmoff.net/images/2016/04/kd05a-1.png" />
		<meta property="og:description" content="" />
		<meta property="og:url" content="https://rmoff.net/2016/04/12/decoupling-the-data-pipeline-with-kafka-a-very-simple-real-life-example/" />
		<meta property="og:site_name" content="Decoupling the Data Pipeline with Kafka - A (Very) Simple Real Life Example" />
		<meta name="twitter:card" content="summary_large_image" />
		<meta name="twitter:site" content="@" />


		
		<style>
			html { background-color: #FAF8F5; color: #2D2926; }
			body { opacity: 0; transition: opacity 0.1s ease; }
			body.loaded { opacity: 1; }
			.site-header { height: 60px; background-color: #FAF8F5; border-bottom: 1px solid #E8421E; }
		</style>

		
		
		<link rel="stylesheet" href="https://rmoff.net/css/redesign.css" />
		
		<link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Bricolage+Grotesque:opsz,wght@12..96,400;12..96,600;12..96,700;12..96,800&family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&family=JetBrains+Mono:wght@400;500&family=Outfit:wght@400;500;600&display=swap">
		<link href="https://fonts.googleapis.com/css2?family=Bricolage+Grotesque:opsz,wght@12..96,400;12..96,600;12..96,700;12..96,800&family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&family=JetBrains+Mono:wght@400;500&family=Outfit:wght@400;500;600&display=swap" rel="stylesheet" media="print" onload="this.media='all'">
		<noscript><link href="https://fonts.googleapis.com/css2?family=Bricolage+Grotesque:opsz,wght@12..96,400;12..96,600;12..96,700;12..96,800&family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&family=JetBrains+Mono:wght@400;500&family=Outfit:wght@400;500;600&display=swap" rel="stylesheet"></noscript>
		

		

		
		<script>
			!function(t,e){var o,n,p,r;e.__SV||(window.posthog=e,e._i=[],e.init=function(i,s,a){function g(t,e){var o=e.split(".");2==o.length&&(t=t[o[0]],e=o[1]),t[e]=function(){t.push([e].concat(Array.prototype.slice.call(arguments,0)))}}(p=t.createElement("script")).type="text/javascript",p.crossOrigin="anonymous",p.async=!0,p.src=s.api_host.replace(".i.posthog.com","-assets.i.posthog.com")+"/static/array.js",(r=t.getElementsByTagName("script")[0]).parentNode.insertBefore(p,r);var u=e;for(void 0!==a?u=e[a]=[]:a="posthog",u.people=u.people||[],u.toString=function(t){var e="posthog";return"posthog"!==a&&(e+="."+a),t||(e+=" (stub)"),e},u.people.toString=function(){return u.toString(1)+".people (stub)"},o="init capture register register_once register_for_session unregister unregister_for_session getFeatureFlag getFeatureFlagPayload isFeatureEnabled reloadFeatureFlags updateEarlyAccessFeatureEnrollment getEarlyAccessFeatures on onFeatureFlags onSessionId getSurveys getActiveMatchingSurveys renderSurvey canRenderSurvey getNextSurveyStep identify setPersonProperties group resetGroups setPersonPropertiesForFlags resetPersonPropertiesForFlags setGroupPropertiesForFlags resetGroupPropertiesForFlags reset get_distinct_id getGroups get_session_id get_session_replay_url alias set_config startSessionRecording stopSessionRecording sessionRecordingStarted captureException loadToolbar get_property getSessionProperty createPersonProfile opt_in_capturing opt_out_capturing has_opted_in_capturing has_opted_out_capturing clear_opt_in_out_capturing debug".split(" "),n=0;n<o.length;n++)g(u,o[n]);e._i.push([i,s,a])},e.__SV=1)}(document,window.posthog||[]);
            posthog.init('phc_93NEP79Ju4xqXYWXnoLbr4HMW0Iaepj1BGOVoEXYX6P',{api_host:'https://eu.i.posthog.com', person_profiles: 'identified_only'})
		</script>

		
		<script src="https://rmoff.net/js/story.js"></script>
		<script src="https://rmoff.net/js/toc.js"></script>
		<script src="https://rmoff.net/js/medium-mirror.js"></script>
	</head>
	<body class="ma0 section-post page-kind-page is-page-true ">
		<script>document.body.classList.add('loaded');</script>

		<header class="site-header hide-print">
	<div class="site-header-inner">
		<a href="https://rmoff.net/" class="site-title">rmoff's random ramblings</a>
		<nav class="site-nav">
			<a href="/categories/interesting-links/" class="nav-il"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"/><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"/></svg> Interesting Links</a>
			<span class="nav-sep"></span>
			<a href="/categories/"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"/><line x1="7" y1="7" x2="7.01" y2="7"/></svg> Categories</a>
			<a href="https://rmoff.net/search/"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="11" cy="11" r="8"/><line x1="21" y1="21" x2="16.65" y2="16.65"/></svg> Search</a>
			<a href="https://rmoff.net/index.xml"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 11a9 9 0 0 1 9 9"/><path d="M4 4a16 16 0 0 1 16 16"/><circle cx="5" cy="19" r="1"/></svg> RSS</a>
			<div class="nav-social">
				<a href="https://www.linkedin.com/in/robinmoffatt/" title="linkedin"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433a2.062 2.062 0 0 1-2.063-2.065 2.064 2.064 0 1 1 2.063 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg></a>
				<a href="https://twitter.com/rmoff/" title="twitter"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"/></svg></a>
				<a href="https://bsky.app/profile/rmoff.net" title="bluesky"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 568 501" fill="currentColor"><path d="M123.121 33.664C188.241 82.553 258.281 181.68 284 234.873c25.719-53.192 95.759-152.32 160.879-201.21C491.866-1.611 568-28.906 568 57.947c0 17.346-9.945 145.713-15.778 166.555-20.275 72.453-94.155 90.933-159.875 79.748C507.222 323.8 536.444 388.56 473.333 453.32c-119.86 122.992-172.272-30.859-185.702-70.281-2.462-7.227-3.614-10.608-3.631-7.733-.017-2.875-1.169.506-3.631 7.733-13.43 39.422-65.842 193.273-185.702 70.281-63.111-64.76-33.89-129.52 80.986-149.071-65.72 11.185-139.6-7.295-159.875-79.748C10.945 203.659 1 75.291 1 57.946 1-28.906 76.135-1.612 123.121 33.664z"/></svg></a>
				<a href="https://www.youtube.com/c/rmoff" title="youtube"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M23.498 6.186a3.016 3.016 0 0 0-2.122-2.136C19.505 3.545 12 3.545 12 3.545s-7.505 0-9.377.505A3.017 3.017 0 0 0 .502 6.186C0 8.07 0 12 0 12s0 3.93.502 5.814a3.016 3.016 0 0 0 2.122 2.136c1.871.505 9.376.505 9.376.505s7.505 0 9.377-.505a3.015 3.015 0 0 0 2.122-2.136C24 15.93 24 12 24 12s0-3.93-.502-5.814zM9.545 15.568V8.432L15.818 12l-6.273 3.568z"/></svg></a>
				<a href="https://talks.rmoff.net" title="talks"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><rect x="2" y="3" width="20" height="14" rx="0"/><line x1="12" y1="17" x2="12" y2="22"/><line x1="8" y1="22" x2="16" y2="22"/><polyline points="7 8 12 12 17 8"/></svg></a>
				<a href="https://github.com/rmoff/" title="github"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a>
			</div>
		</nav>
		<button class="nav-toggle" onclick="document.querySelector('.mobile-nav').classList.toggle('open')" aria-label="Menu">
			<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="18" x2="21" y2="18"/></svg>
		</button>
	</div>
	<nav class="mobile-nav">
		<a href="https://rmoff.net/">Home</a>
		<a href="/categories/">Categories</a>
		<a href="/categories/interesting-links/">Interesting Links</a>
		<a href="https://rmoff.net/search/">Search</a>
		<a href="https://rmoff.net/index.xml">RSS</a>
		<a href="https://www.linkedin.com/in/robinmoffatt/">linkedin</a>
		<a href="https://twitter.com/rmoff/">twitter</a>
		<a href="https://bsky.app/profile/rmoff.net">bluesky</a>
		<a href="https://www.youtube.com/c/rmoff">youtube</a>
		<a href="https://talks.rmoff.net">talks</a>
		<a href="https://github.com/rmoff/">github</a>
	</nav>
</header>


		<main role="main">
		

<div class="article-hero" style="background-image: url('https://rmoff.net/images/2016/04/kd05a-1.png');">
	<div class="article-hero-overlay">
		<div class="article-hero-content">
			<h1>Decoupling the Data Pipeline with Kafka - A (Very) Simple Real Life Example</h1>
			<p class="article-hero-meta">
				
					<time datetime="2016-04-12T21:50:46Z">12 Apr 2016</time>
					<span class="display-print">by </span>
					 &middot; <a href="https://rmoff.net/categories/apache-kafka">apache kafka</a>, <a href="https://rmoff.net/categories/apache-kafka">Apache Kafka</a>, <a href="https://rmoff.net/categories/logstash">logstash</a>, <a href="https://rmoff.net/categories/elastic">elastic</a>, <a href="https://rmoff.net/categories/elasticsearch">elasticsearch</a>, <a href="https://rmoff.net/categories/kibana">kibana</a>, <a href="https://rmoff.net/categories/elastic-v5">elastic v5</a>, <a href="https://rmoff.net/categories/zookeeper">zookeeper</a>
					<span class="display-print">at https://rmoff.net/2016/04/12/decoupling-the-data-pipeline-with-kafka-a-very-simple-real-life-example/</span>
				
			</p>
		</div>
	</div>
</div>


<details class="toc-mobile">
	<summary>Table of Contents</summary>
	<nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#consumer-groups-and-offsets">Consumer Groups and Offsets</a></li>
        <li><a href="#summary">Summary</a></li>
      </ul>
    </li>
  </ul>
</nav>
</details>

<div class="container-fluid docs">
	<div class="row">
		<main class="docs-content" role="main">

<article class="article" data-pagefind-body>
	<span data-pagefind-filter="category" style="display:none">apache kafka</span><span data-pagefind-filter="category" style="display:none">Apache Kafka</span><span data-pagefind-filter="category" style="display:none">logstash</span><span data-pagefind-filter="category" style="display:none">elastic</span><span data-pagefind-filter="category" style="display:none">elasticsearch</span><span data-pagefind-filter="category" style="display:none">kibana</span><span data-pagefind-filter="category" style="display:none">elastic v5</span><span data-pagefind-filter="category" style="display:none">zookeeper</span>
	<img data-pagefind-meta="image[src]" src="https://rmoff.net/images/2016/04/kd05a-1.png" style="display:none" alt="">
	<p>I&rsquo;ve recently been playing around with the ELK stack (<a href="https://www.elastic.co/blog/heya-elastic-stack-and-x-pack">now officially known as the Elastic stack</a>) collecting data from <a href="/2016/03/03/obihackers-irc-channel/">an IRC channel</a> with Elastic&rsquo;s Logstash, storing it in Elasticsearch and <a href="/2016/03/24/my-latest-irc-client-kibana/">analysing it with Kibana</a>. But, this isn&rsquo;t an &ldquo;ELK&rdquo; post - this is a Kafka post! ELK is just some example data manipulation tooling that helps demonstrate the principles.</p>
<p>As I <a href="http://www.rittmanmead.com/2015/10/forays-into-kafka-enabling-flexible-data-pipelines/">wrote about last year</a>, Apache Kafka provides a handy way to build flexible &ldquo;pipelines&rdquo;. Today I&rsquo;m writing up a short real-world example of this in practice. There are three elements to the flexibility that I really want to highlight:</p>
<ol>
<li>Decoupling the consumption of data from its production at the previous stage</li>
<li>Because the consumer is decoupled, being able to stop and start it and have it continue ingesting data from the point at which it previously stopped</li>
<li>The ability to replay the ingest phase of a pipeline repeatedly into multiple consumers, with no change required to the configuration from source</li>
</ol>
<p>The simplest form of the pipeline I was using looks like this:</p>
<p><img src="/images/2016/04/kd01.png" alt=""></p>
<p>A logstash configuration (<a href="https://gist.github.com/rmoff/862d0ceea223aa7283244b1b27594941#file-01-logstash-irc-conf"><code>logstash-irc.conf</code></a>) gets Logstash to connect to the IRC server and send messages received to Elasticsearch. From here they can be displayed and analysed within Kibana. <a href="/2016/03/24/my-latest-irc-client-kibana/">Read more about the details here</a> if you&rsquo;re interested.</p>
<p>From a &ldquo;pipeline&rdquo; point of view this is a pretty typical pattern. A tool (Logstash here, but could be ODI, Informatica, etc) runs with a set of &ldquo;code&rdquo; (a very simple <code>.conf</code> here, elsewhere it could be mappings and load plans), reading data from a source. Obviously in full-blown system there&rsquo;s a dozen more moving parts than this simple example, but the point stands.</p>
<p>Let&rsquo;s think a bit more about what a pipeline does, as this will give us the basis for understanding why and how Kafka fits in so nicely. Overlaying some labels onto the above diagram shows all the processing that we&rsquo;re doing:</p>
<p><img src="/images/2016/04/kd01a-1.png" alt=""></p>
<p>If any of this needs reconfiguring, restarting, or rerunning, it&rsquo;s an all-or-nothing job. Given that we&rsquo;re streaming data in near-real-time (or conceptually, designing something that <em>could</em> if needed with minimal-to-no rework), shutting down the pipeline just to change one of these bits is a problem because we&rsquo;ll lose the data that the source system is spitting out whether we&rsquo;re there to gather it or not.</p>
<p>Why would we need to change the pipeline configuration? Consider:</p>
<ul>
<li>Reconfiguring - Adding in additional enrichment functionality (eg GeoIP lookup), or filtering out duff records, or fixing a bug in the logic, or a dozen other easy examples - in all these cases it&rsquo;s great if we can reprocess the existing backlog of processed data and then continue processing data as it&rsquo;s available from the source system.</li>
<li>Restarting - if the load fails, ideally we don&rsquo;t want to be hitting the source system again for our data if we&rsquo;ve extracted it once already. Similarly if the load process needs to be stopped, maybe for maintenance of the target load system, it&rsquo;s useful to be able to restart the processing exactly from where it left off.</li>
</ul>
<p>So I decoupled the source extract from any subsequent processing with a very simple Logstash configuration (<a href="https://gist.github.com/rmoff/862d0ceea223aa7283244b1b27594941#file-02-logstash-irc-kafka-conf"><code>logstash-irc-kafka.conf</code></a>) that pulls the data from IRC as before and <strong>just</strong> sends it straight to Kafka:</p>
<p><img src="/images/2016/04/kd02a.png" alt=""></p>
<p>The data lands in Kafka, which becomes our &lsquo;staging&rsquo; area in effect, taking advantage of Kafka&rsquo;s &ldquo;durable buffer&rdquo; concept. The data extracted is ideally as raw as possible - because we don&rsquo;t know what subsequent processing we want to do with it, maybe now, or at some future date. Kafka can be configured to retain data based on age or volume - since the data I was working with was low volume I set the topic to retain it for 90 days:</p>
<pre><code>./kafka-topics.sh --zookeeper localhost:2181 --topic irc --alter --config retention.ms=7776000000
</code></pre>
<p>With the data streaming into Kafka and building up there we can then set up one or more consumers of that data. <em>Note that I&rsquo;m using consumers in the logical sense, not the Kafka &ldquo;Consumer&rdquo; specific terminology</em>. My consumer here is Logstash using <a href="https://gist.github.com/rmoff/862d0ceea223aa7283244b1b27594941#file-03-logstash-kafka-es-conf"><code>logstash-kafka-es.conf</code></a>, which is a variant of the original configuration, this time pulling from Kafka instead of the live IRC feed. And since Kafka is so low-latency, a side-benefit of this setup is that I can both catch up on and replay past records, as well as stream live ones in near-real-time. Result!</p>
<p><img src="/images/2016/04/kd03a.png" alt=""></p>
<p>At this point I&rsquo;m <a href="/2016/03/24/my-latest-irc-client-kibana/">where I was before</a>; streaming IRC content in near-real-time to Elasticsearch and analysing it with Kibana. The only difference is that I&rsquo;ve added in Kafka as a buffer, decoupling the reading messages from IRC with the processing and subsequent storage of them.</p>
<p>Now here&rsquo;s the money shot &ndash; I can add new consumers of this data that&rsquo;s in Kafka, whenever I want, without needing to know about them at the time that I extracted the source data. I can pick up from the end of the feed, or I can reprocess the whole lot, <em>per consumer</em>. I&rsquo;ve used this in a couple of instances recently:</p>
<ul>
<li>Add and refine a GeoIP lookup step to the Logstash processing (see <a href="https://gist.github.com/rmoff/862d0ceea223aa7283244b1b27594941#file-04-logstash-kafka-es-02-conf">example config</a>), <em>without affecting the existing Logstash-&gt;Elasticsearch-&gt;Kibana flow</em></li>
<li>Testing the <a href="https://www.elastic.co/blog/elasticsearch-5-0-0-alpha1-released">Elastic stack v5 alpha release</a> by processing the <strong>same source data again</strong> but with a different version of the downstream tools, enabling a proper like-for-like comparison of the pipeline. This is similar in concept to an idea that <a href="https://twitter.com/gwenshap">Gwen Shapira</a> wrote about <a href="http://radar.oreilly.com/2015/05/validating-data-models-with-kafka-based-pipelines.html">in an article in 2015</a>.</li>
</ul>
<p>In both of these cases <strong>the existing original consumer remains running and untouched</strong>. This kind of concurrent running is a great way to work with a single feed from the source system, keep the data pipeline running for subsequent analytics, whilst also developing and validating new functionality.</p>
<p><img src="/images/2016/04/kd05a.png" alt="kd05a"></p>
<h3 id="consumer-groups-and-offsets">Consumer Groups and Offsets&nbsp;<a class="headline-hash" href="#consumer-groups-and-offsets">ðŸ”—</a> </h3>
<p>One of the key concepts in all of this is that of the Kafka <strong>consumer group</strong>, which is a unique identifier for a given consumer (or group of consumers for the same logical entity if you want to parallelise the consumption). In Kafka 0.8 Zookeeper is used by default to keep track off the <strong>offset</strong> of the last record that a given consumer group received. So in my development environment I can look on my Kafka server at Zookeeper and see for each consumer group the latest offset: (<a href="https://cwiki.apache.org/confluence/display/KAFKA/System+Tools#SystemTools-ExportZookeeperOffsets">reference</a>)</p>
<pre tabindex="0"><code>$ bin/kafka-run-class.sh kafka.tools.ExportZkOffsets --zkconnect localhost:2181 --output-file &gt;(cat)

/consumers/console-consumer-32467/offsets/irc/0:4145
/consumers/kafka-ubuntu03/offsets/irc/0:1035
/consumers/logstash/offsets/irc/0:4145
/consumers/logstash-5-testing/offsets/irc/0:4143
</code></pre><p><em>A brief note on the command above - I&rsquo;m using <a href="http://tldp.org/LDP/abs/html/process-sub.html">bash process substitution</a> to send the output to stdout (via <code>cat</code>) instead of the asked-for output file.</em></p>
<p>From the above output you can see that there are four consumer groups. Two are at the same offset (4145) which happens to be the latest, and therefore have consumed all the available messages. A third (<code>logstash-5-testing</code>) is almost caught up (4143, vs 4145), and the final one (<code>kafka-ubuntu03</code>) is way behind at 1035. By running the command periodically you can see if a consumer is actually reading records, or just offline (or maybe stuck).</p>
<p>To see more information about a given consumer, including the lag (current vs maximum offset) use <code>ConsumerOffsetChecker</code> and specify the consumer group:</p>
<pre tabindex="0"><code>$ bin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --zookeeper localhost:2181 --group logstash-5-testing
Group           Topic                          Pid Offset          logSize         Lag             Owner
logstash-5-testing irc                            0   4143            4148            5               none
</code></pre><h3 id="summary">Summary&nbsp;<a class="headline-hash" href="#summary">ðŸ”—</a> </h3>
<p>Building a successful data pipeline requires that it is flexible to changing requirements, as well as unknown future ones. This is as true for little local PoCs such as this one as it is for large-scale implementations. The pipeline needs to be able to have minimal impact on source systems whilst being able to satisfy multiple destinations, some or all of which may want to batch process instead of stream the data. In addition, being able to re-stream the raw data repeatedly and on-demand into adhoc applications without affecting the primary &lsquo;productionised&rsquo; consumers is a powerful enabler of the &lsquo;data discovery lab&rsquo; concept, which I write about <a href="http://www.rittmanmead.com/2015/10/forays-into-kafka-enabling-flexible-data-pipelines/">in more detail here</a>.</p>
<p>Kafka enables the above, summarised in the following benefits:</p>
<ol start="0">
<li>
<p>Stream or batch the data from source <strong>once</strong>, consume by multiple hetrogenous applications <strong>many</strong> times.</p>
</li>
<li>
<p>Offset tracking distinct for each consuming application</p>
</li>
<li>
<p>Processing can be re-run, which is useful for:</p>
<ul>
<li>Development process - iterative improvements / bug fixing against the same streamed data set</li>
<li>Production data - data discovery/advanced analytics</li>
</ul>
</li>
</ol>
<p>You can read more about this in detail <a href="http://www.rittmanmead.com/2015/10/forays-into-kafka-enabling-flexible-data-pipelines/">over here</a>.</p>

	<hr>
	<div class="giscus-container">
		<script src="https://giscus.app/client.js"
				data-repo="rmoff/rmoff-blog"
				data-repo-id="MDEwOlJlcG9zaXRvcnkxNTE3NDg2MTE="
				data-category="Announcements"
				data-category-id="DIC_kwDOCQuAA84CvP5T"
				data-mapping="pathname"
				data-strict="1"
				data-reactions-enabled="1"
				data-emit-metadata="0"
				data-input-position="bottom"
				data-theme="light"
				data-lang="en"
				crossorigin="anonymous"
				async>
		</script>
	</div>
</article>
      </main>
    
      
      <div class="docs-toc">
        <ul class="nav toc-top">
          <li><a href="#" id="back_to_top" class="docs-toc-title">On this page</a></li>
        </ul>
        <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#consumer-groups-and-offsets">Consumer Groups and Offsets</a></li>
        <li><a href="#summary">Summary</a></li>
      </ul>
    </li>
  </ul>
</nav>
      </div>
      
    
    </div>
  </div>
</div>


		</main>

		

		
		<footer class="site-footer hide-print" role="contentinfo">
			<span>&copy; 2026 </span>
		</footer>
		

		
	</body>
</html>
