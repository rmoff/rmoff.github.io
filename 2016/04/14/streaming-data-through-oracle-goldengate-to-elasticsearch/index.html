<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8" />

  
  <title>Streaming Data through Oracle GoldenGate to Elasticsearch</title>

  
  
  <link href="//cdn.jsdelivr.net" rel="dns-prefetch">
  <link href="//cdnjs.cloudflare.com" rel="dns-prefetch">
  <link href="//at.alicdn.com" rel="dns-prefetch">
  <link href="//fonts.googleapis.com" rel="dns-prefetch">
  <link href="//fonts.gstatic.com" rel="dns-prefetch">
  <link href="///disqus.com" rel="dns-prefetch">
  <link href="//c.disquscdn.com" rel="dns-prefetch">
  
  
  

  

  
  <meta name="author" content="Robin Moffatt">
  <meta name="description" content="Recently added to the oracledi project over at java.net is an adaptor enabling Oracle GoldenGate (OGG) to send data to Elasticsearch. This adds a powerful alternative to [micro-]batch extract via JDBC from Oracle to Elasticsearch, which I wrote about recently over at the Elastic blog.
Elasticsearch is a &amp;lsquo;document store&amp;rsquo; widely used for both search and analytics. It&amp;rsquo;s something I&amp;rsquo;ve written a lot about (here and here for archives), as well as spoken about - preaching the good word, as it were, since the Elastic stack as a whole is very very good at what it does and a pleasure to work with.">

  
  
    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="@gohugoio">
    <meta name="twitter:title" content="Streaming Data through Oracle GoldenGate to Elasticsearch">
    <meta name="twitter:description" content="Recently added to the oracledi project over at java.net is an adaptor enabling Oracle GoldenGate (OGG) to send data to Elasticsearch. This adds a powerful alternative to [micro-]batch extract via JDBC from Oracle to Elasticsearch, which I wrote about recently over at the Elastic blog.
Elasticsearch is a &amp;lsquo;document store&amp;rsquo; widely used for both search and analytics. It&amp;rsquo;s something I&amp;rsquo;ve written a lot about (here and here for archives), as well as spoken about - preaching the good word, as it were, since the Elastic stack as a whole is very very good at what it does and a pleasure to work with.">
    <meta name="twitter:image" content="/images/avatar.jpg">
  

  
  <meta property="og:type" content="article">
  <meta property="og:title" content="Streaming Data through Oracle GoldenGate to Elasticsearch">
  <meta property="og:description" content="Recently added to the oracledi project over at java.net is an adaptor enabling Oracle GoldenGate (OGG) to send data to Elasticsearch. This adds a powerful alternative to [micro-]batch extract via JDBC from Oracle to Elasticsearch, which I wrote about recently over at the Elastic blog.
Elasticsearch is a &amp;lsquo;document store&amp;rsquo; widely used for both search and analytics. It&amp;rsquo;s something I&amp;rsquo;ve written a lot about (here and here for archives), as well as spoken about - preaching the good word, as it were, since the Elastic stack as a whole is very very good at what it does and a pleasure to work with.">
  <meta property="og:url" content="https://rmoff.github.io/2016/04/14/streaming-data-through-oracle-goldengate-to-elasticsearch/">
  <meta property="og:image" content="/images/avatar.jpg">




<meta name="generator" content="Hugo 0.52">


<link rel="canonical" href="https://rmoff.github.io/2016/04/14/streaming-data-through-oracle-goldengate-to-elasticsearch/">

<meta name="renderer" content="webkit">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="format-detection" content="telephone=no,email=no,adress=no">
<meta http-equiv="Cache-Control" content="no-transform">


<meta name="robots" content="index,follow">
<meta name="referrer" content="origin-when-cross-origin">







<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="apple-mobile-web-app-title" content="rmoff.net">
<meta name="msapplication-tooltip" content="rmoff.net">
<meta name='msapplication-navbutton-color' content="#5fbf5e">
<meta name="msapplication-TileColor" content="#5fbf5e">
<meta name="msapplication-TileImage" content="/images/tile-image-windows.png">
<link rel="icon" href="/images/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
<link rel="icon" sizes="192x192" href="/images/touch-icon-android.png">
<link rel="apple-touch-icon" href="/images/touch-icon-apple.png">


<link rel="preload" href="/styles/main.min.css" as="style">
<link rel="preload" href="https://fonts.googleapis.com/css?family=Lobster" as="style">
<link rel="preload" href="/images/avatar.jpg" as="image">
<link rel="preload" href="/images/grey-prism.svg" as="image">


<style>
  body {
    background: rgb(244, 243, 241) url('/images/grey-prism.svg') repeat fixed;
  }
</style>
<link rel="stylesheet" href="/styles/main.min.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lobster">


<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.2/dist/medium-zoom.min.js"></script>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/video.js@7.3.0/dist/video-js.min.css">



  
  
<!--[if lte IE 8]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/videojs-ie8@1.1.2/dist/videojs-ie8.min.js"></script>
<![endif]-->

<!--[if lte IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/eligrey-classlist-js-polyfill@1.2.20180112/classList.min.js"></script>
<![endif]-->


<script src="https://cdn.jsdelivr.net/npm/smooth-scroll@14.2.1/dist/smooth-scroll.polyfills.min.js"></script>


</head>
  <body>
    
    <div class="suspension">
      <a title="Go to top" class="to-top is-hide"><span class="icon icon-up"></span></a>
      
        
        <a title="Go to comments" class="to-comment" href="#disqus_thread"><span class="icon icon-comment"></span></a>
        
      
    </div>
    
    
  <header class="site-header">
  <img class="avatar" src="/images/avatar.jpg" alt="Avatar">
  
  <h2 class="title">rmoff.net</h2>
  
  <p class="subtitle"></p>
  <button class="menu-toggle" type="button">
    <span class="icon icon-menu"></span>
  </button>
  <nav class="site-menu collapsed">
    <h2 class="offscreen">Main Menu</h2>
    <ul class="menu-list">
      
      
      
      
        <li class="menu-item
            
            
            ">
            <a href="/about-me/">about me</a>
          </li>
      
        <li class="menu-item
            
            
            ">
            <a href="/presentations/">presentations</a>
          </li>
      
    </ul>
  </nav>
  <nav class="social-menu collapsed">
    <h2 class="offscreen">Social Networks</h2>
    <ul class="social-list"></ul>
  </nav>
</header>

  <section class="main post-detail">
    <header class="post-header">
      <h1 class="post-title">Streaming Data through Oracle GoldenGate to Elasticsearch</h1>
      <p class="post-meta">@Robin Moffatt · Apr 14, 2016 · 12 min read</p>
    </header>
    <article class="post-content">

<p>Recently added to the <a href="https://java.net/projects/oracledi/">oracledi project over at java.net</a> is <a href="https://java.net/projects/oracledi/">an adaptor</a> enabling Oracle GoldenGate (OGG) to send data to Elasticsearch. This adds a powerful alternative to [micro-]batch extract via JDBC from Oracle to Elasticsearch, which I wrote about recently <a href="https://www.elastic.co/blog/visualising-oracle-performance-data-with-the-elastic-stack">over at the Elastic blog</a>.</p>

<p>Elasticsearch is a &lsquo;document store&rsquo; widely used for both search and analytics. It&rsquo;s something I&rsquo;ve written a lot about (<a href="http://rmoff.net/tag/elasticsearch/">here</a> and <a href="www.rittmanmead.com/tag/elasticsearch">here</a> for archives), as well as <a href="https://speakerdeck.com/rmoff/data-discovery-and-systems-diagnostics-with-the-elk-stack">spoken about</a> - preaching the good word, as it were, since the Elastic stack as a whole is very very good at what it does and a pleasure to work with. So, being able to combine that with my &ldquo;day job&rdquo; focus of Oracle is fun. Let&rsquo;s get started!</p>

<p>From the <a href="https://java.net/projects/oracledi/downloads/directory/GoldenGate/Oracle%20GoldenGate%20Adapter%20for%20ElasticSearch">adaptor page</a>, download the zip to your machine. I&rsquo;m using Oracle&rsquo;s <a href="http://www.oracle.com/technetwork/database/bigdata-appliance/oracle-bigdatalite-2104726.html">BigDataLite VM</a> which already has GoldenGate installed and configured, and which I&rsquo;ve also got Elasticsearch already on following on from <a href="http://rmoff.net/2016/03/16/oracle-goldengate-kafka-hive-on-bigdatalite-4-4/">this earlier post</a>. If you&rsquo;ve not got Elasticsearch already, head over to <a href="https://www.elastic.co/downloads/elasticsearch">elastic.co</a> to download it. I&rsquo;m using version 2.3.1, installed in <code>/opt/elasticsearch-2.3.1</code>.</p>

<h2 id="ready">Ready &hellip;</h2>

<p>Once you&rsquo;ve got the OGG adaptor zip, you&rsquo;ll want to unzip it &ndash; a word of advice here, specify the destination folder as there&rsquo;s no containing root within the archive so you&rsquo;ll end up with a mess of folder and files in amongst your download folder otherwise:</p>

<pre><code>unzip OGG_elasticsearch_v1.0.zip -d /u01/OGG_elasticsearch_v1.0
</code></pre>

<p>Copy the provided <code>.prm</code> and <code>.props</code> files to your OGG <code>dirprm</code> folder:</p>

<pre><code>cp /u01/OGG_elasticsearch_v1.0/dirprm/elasticsearch.props /u01/ogg-bd/dirprm/
cp /u01/OGG_elasticsearch_v1.0/dirprm/res.prm /u01/ogg-bd/dirprm/
</code></pre>

<p>Edit the <code>elasticsearch.props</code> (e.g. <code>/u01/ogg/dirprm/elasticsearch.props</code>) file to set:</p>

<ol>
<li><p><strong>gg.classpath</strong>, to pick up both the Elasticsearch jars and the OGG adaptor jar. On my installation this is :</p>

<pre><code>gg.classpath=/opt/elasticsearch-2.3.1/lib/*:/u01/OGG_elasticsearch_v1.0/bin/ogg-elasticsearch-adapter-1.0.jar:
</code></pre></li>

<li><p><strong>gg.handler.elasticsearch.clusterName</strong>, which is the name of your elasticsearch cluster - if you don&rsquo;t know it you can check with</p>

<pre><code>[oracle@bigdatalite ~]$ curl -s localhost:9200|grep cluster_name
&quot;cluster_name&quot; : &quot;elasticsearch&quot;,
</code></pre>

<p>So mine is the default - <strong>elasticsearch</strong>:</p>

<pre><code>gg.handler.elasticsearch.clusterName=elasticsearch
</code></pre></li>

<li><p>For <strong>gg.handler.elasticsearch.host</strong> and <strong>gg.handler.elasticsearch.port</strong> I left the defaults (localhost / 9300) unchanged - update these for your Elasticsearch instance as required. Note that <a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/_talking_to_elasticsearch.html">Elasticsearch listens</a> on two ports, with 9200 by default for HTTP traffic, and 9300 for Java clients which is what we&rsquo;re using here.</p></li>
</ol>

<h2 id="steady">Steady &hellip;</h2>

<p>Run <code>ggsci</code> to add and start the replicat using the provided <code>res</code> configuration (<strong>res</strong> = <strong>R</strong>eplicat, <strong>E</strong>lastic<strong>S</strong>earch, I&rsquo;m guessing) and sample trail file (i.e. we don&rsquo;t need a live extract running to try this thing out):</p>

<pre><code class="language-bash">$ cd /u01/ogg-bd
$ rlwrap ./ggsci

Oracle GoldenGate Command Interpreter
Version 12.2.0.1.0 OGGCORE_12.2.0.1.0_PLATFORMS_151101.1925.2
Linux, x64, 64bit (optimized), Generic on Nov 10 2015 16:18:12
Operating system character set identified as UTF-8.

Copyright (C) 1995, 2015, Oracle and/or its affiliates. All rights reserved.



GGSCI (bigdatalite.localdomain) 1&gt; start mgr
Manager started.


GGSCI (bigdatalite.localdomain) 2&gt; add replicat res, exttrail AdapterExamples/trail/tr
REPLICAT added.
</code></pre>

<h2 id="go">Go!</h2>

<pre><code class="language-bash">GGSCI (bigdatalite.localdomain) 3&gt; start res

Sending START request to MANAGER ...
REPLICAT RES starting
</code></pre>

<p>Yay!</p>

<pre><code class="language-bash">GGSCI (bigdatalite.localdomain) 5&gt; info res

REPLICAT   RES       Initialized   2016-04-14 22:03   Status STOPPED
</code></pre>

<p><code>STOPPED</code>? Oh &hellip;</p>

<p>Time for debug. Open up <code>/u01/ogg-bd/ggserr.log</code>, and the error (<em>`Error loading shared library ggjava.dll</em>) is nice and clear to see:</p>

<pre><code>2016-04-14 22:04:25  INFO    OGG-00987  Oracle GoldenGate Command Interpreter:  GGSCI command (oracle): start res.
2016-04-14 22:04:25  INFO    OGG-00963  Oracle GoldenGate Manager, mgr.prm:  Command received from GGSCI on host [127.0.0.1]:13379 (START REPLICAT RES ).
2016-04-14 22:04:25  INFO    OGG-00960  Oracle GoldenGate Manager, mgr.prm:  Access granted (rule #6).
2016-04-14 22:04:25  INFO    OGG-00975  Oracle GoldenGate Manager, mgr.prm:  REPLICAT RES starting.
2016-04-14 22:04:25  INFO    OGG-00995  Oracle GoldenGate Delivery, res.prm:  REPLICAT RES starting.
2016-04-14 22:04:25  INFO    OGG-03059  Oracle GoldenGate Delivery, res.prm:  Operating system character set identified as UTF-8.
2016-04-14 22:04:25  INFO    OGG-02695  Oracle GoldenGate Delivery, res.prm:  ANSI SQL parameter syntax is used for parameter parsing.
2016-04-14 22:04:25  ERROR   OGG-02554  Oracle GoldenGate Delivery, res.prm:  Error loading shared library ggjava.dll: 2 No such file or directory.
2016-04-14 22:04:25  ERROR   OGG-01668  Oracle GoldenGate Delivery, res.prm:  PROCESS ABENDING.
</code></pre>

<p>But hang on &hellip; <strong><code>ggjava.dll</code></strong> ? <em><strong><code>dll</code></strong></em>? This is Linux, not Windows.</p>

<p>So, a quick change to the <code>prm</code> is in order, switching <code>.dll</code> for <code>.so</code>:</p>

<pre><code>[oracle@bigdatalite ogg-bd]$ diff dirprm/res.prm dirprm/res.prm.bak
5c5
&lt; TARGETDB LIBFILE libggjava.so SET property=dirprm/elasticsearch.props
---
&gt; TARGETDB LIBFILE ggjava.dll SET property=dirprm/elasticsearch.props
</code></pre>

<h2 id="second-time-lucky">Second time lucky?</h2>

<p>Redefine the replicat:</p>

<pre><code>GGSCI (bigdatalite.localdomain) 7&gt; delete res
Deleted REPLICAT RES.


GGSCI (bigdatalite.localdomain) 8&gt; add replicat res, exttrail AdapterExamples/trail/tr
REPLICAT added.
</code></pre>

<p>And start it again:</p>

<pre><code>GGSCI (bigdatalite.localdomain) 9&gt; start res

Sending START request to MANAGER ...
REPLICAT RES starting
</code></pre>

<p>Now it looks better:</p>

<pre><code>GGSCI (bigdatalite.localdomain) 14&gt; info res

REPLICAT   RES       Last Started 2016-04-14 22:10   Status RUNNING
Checkpoint Lag       00:00:00 (updated 00:00:02 ago)
Process ID           15101
Log Read Checkpoint  File AdapterExamples/trail/tr000000000
                     2015-11-05 18:45:39.000000  RBA 5660
</code></pre>

<h2 id="result">Result!</h2>

<p>Let&rsquo;s check out what&rsquo;s happened in Elasticsearch. The console log looks promising, showing that an index with two mappings has been created:</p>

<pre><code>[2016-04-14 22:10:08,709][INFO ][cluster.metadata         ] [Abner Jenkins] [qasource] creating index, cause [auto(bulk api)], templates [], shards [5]/[1], mappings [tcustmer, tcustord]
[2016-04-14 22:10:09,458][INFO ][cluster.routing.allocation] [Abner Jenkins] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[qasource][4]] ...]).
[2016-04-14 22:10:09,488][INFO ][cluster.metadata         ] [Abner Jenkins] [qasource] update_mapping [tcustmer]
[2016-04-14 22:10:09,658][INFO ][cluster.metadata         ] [Abner Jenkins] [qasource] update_mapping [tcustord]
</code></pre>

<p>We can confirm that with the Elasticsearch REST API:</p>

<pre><code>$ curl --silent -XGET http://localhost:9200/_cat/indices?pretty=true
yellow open qasource 5 1 8 6 19.6kb 19.6kb
</code></pre>

<p>And see how many documents (&ldquo;rows&rdquo;) have been loaded (8):</p>

<pre><code>$ curl -s -XGET 'http://localhost:9200/qasource/_search?search_type=count&amp;pretty=true'
{
  &quot;took&quot; : 1,
  &quot;timed_out&quot; : false,
  &quot;_shards&quot; : {
    &quot;total&quot; : 5,
    &quot;successful&quot; : 5,
    &quot;failed&quot; : 0
  },
  &quot;hits&quot; : {
    &quot;total&quot; : 8,
    &quot;max_score&quot; : 0.0,
    &quot;hits&quot; : [ ]
  }
}
</code></pre>

<p>You can even see the mappings (&ldquo;schema&rdquo;) defined within each index:</p>

<pre><code>$ curl -XGET 'http://localhost:9200/_mapping?pretty=true'
{
  &quot;.kibana&quot; : {
    &quot;mappings&quot; : {
      &quot;config&quot; : {
        &quot;properties&quot; : {
          &quot;buildNum&quot; : {
            &quot;type&quot; : &quot;string&quot;,
            &quot;index&quot; : &quot;not_analyzed&quot;
          }
        }
      }
    }
  },
  &quot;qasource&quot; : {
    &quot;mappings&quot; : {
      &quot;tcustord&quot; : {
        &quot;properties&quot; : {
          &quot;CUST_CODE&quot; : {
            &quot;type&quot; : &quot;string&quot;
          },
          &quot;ORDER_DATE&quot; : {
            &quot;type&quot; : &quot;string&quot;
          },
          &quot;ORDER_ID&quot; : {
            &quot;type&quot; : &quot;string&quot;
[...]
</code></pre>

<p>All this faffing about with <code>curl</code> is fine, but if you&rsquo;re doing proper poking with Elasticsearch you may well find <a href="https://github.com/lmenezes/elasticsearch-kopf">kopf</a> handy:</p>

<p><img src="/content/images/2016/04/ogges01.png" alt="ogges01" /></p>

<p>It&rsquo;s easy to install:  (modify the path if your Elasticsearch binary is in a different location):</p>

<pre><code>/opt/elasticsearch-2.3.1/bin/plugin install lmenezes/elasticsearch-kopf
</code></pre>

<p>After installation, restart Elasticsearch and then go to <a href="http://localhost:9200/_plugin/kopf">http://localhost:9200/_plugin/kopf</a></p>

<p>If you&rsquo;re using Elasticsearch, you may well be doing so for the whole Elastic experience, using Kibana to view the data:</p>

<p><img src="/content/images/2016/04/ogges02.png" alt="ogges02" /></p>

<p>and even start doing quick profiling:</p>

<p><img src="/content/images/2016/04/ogges03.png" alt="ogges03" /></p>

<p>One issue with the data that&rsquo;s come through in this example is that it is <em>all</em> string - even the dates and numerics (AMOUNT, PRICE), which makes instant-analysis in Kibana less possible.</p>

<h1 id="streaming-data-from-oracle-to-elasticsearch">Streaming data from Oracle to Elasticsearch</h1>

<p>Now that we&rsquo;ve tested and proven the replicat load into Elasticsearch, let&rsquo;s do the full end-to-end. I&rsquo;m going to use the same Extract as the BigDataLite <a href="http://www.oracle.com/webfolder/technetwork/tutorials/obe/fmw/odi/odi_12c/DI_BDL_Guide/BigDataIntegration_Demo.html?cid=10235&amp;ssid=0">Oracle by Example</a> (you can see my notes on it <a href="http://rmoff.net/2016/03/16/oracle-goldengate-kafka-hive-on-bigdatalite-4-4/">here</a> if you&rsquo;re interested).</p>

<p>Reset &amp; recreate the Extract, in the first OGG instance (<code>/u01/ogg</code>)</p>

<pre><code>$ cd /u01/ogg/
$ rlwrap ./ggsci

GGSCI (bigdatalite.localdomain as system@cdb/CDB$ROOT) 1&gt; obey dirprm/reset_bigdata.oby

[...]

GGSCI (bigdatalite.localdomain as system@cdb/CDB$ROOT) 2&gt; info all

Program     Status      Group       Lag at Chkpt  Time Since Chkpt

MANAGER     RUNNING

GGSCI (bigdatalite.localdomain) 3&gt; obey dirprm/bigdata.oby

[...]

GGSCI (bigdatalite.localdomain as system@cdb/CDB$ROOT) 9&gt; info all

Program     Status      Group       Lag at Chkpt  Time Since Chkpt

MANAGER     RUNNING
EXTRACT     RUNNING     EMOV        00:00:03      00:00:00
</code></pre>

<p>Now define a new replicat parameter file, over in the second OGG instance (that we used above for the <code>res</code> test):</p>

<pre><code>cat &gt; /u01/ogg-bd/dirprm/relastic.prm &lt;&lt;EOF

REPLICAT relastic
TARGETDB LIBFILE libggjava.so SET property=dirprm/elasticsearch.props
REPORTCOUNT EVERY 1 MINUTES, RATE
GROUPTRANSOPS 10000
MAP orcl.moviedemo.movie TARGET orcl.moviedemo.movie;

EOF
</code></pre>

<p>Remove the previous replicat (<code>res</code>) just to keep things clear:</p>

<pre><code>$ cd /u01/ogg-bd
$ rlwrap ./ggsci

Oracle GoldenGate Command Interpreter
Version 12.2.0.1.0 OGGCORE_12.2.0.1.0_PLATFORMS_151101.1925.2
Linux, x64, 64bit (optimized), Generic on Nov 10 2015 16:18:12
Operating system character set identified as UTF-8.

Copyright (C) 1995, 2015, Oracle and/or its affiliates. All rights reserved.


GGSCI (bigdatalite.localdomain) 2&gt; stop res

Sending STOP request to REPLICAT RES ...
Request processed.


GGSCI (bigdatalite.localdomain) 3&gt; delete res
Deleted REPLICAT RES.


GGSCI (bigdatalite.localdomain) 4&gt; info all

Program     Status      Group       Lag at Chkpt  Time Since Chkpt

MANAGER     RUNNING
</code></pre>

<p>Add the new one (<code>relastic</code>):</p>

<pre><code>GGSCI (bigdatalite.localdomain) 1&gt; add replicat relastic, exttrail /u01/ogg/dirdat/tm
REPLICAT added.
</code></pre>

<p>And start it:</p>

<pre><code>GGSCI (bigdatalite.localdomain) 2&gt; start relastic

Sending START request to MANAGER ...
REPLICAT RELASTIC starting

GGSCI (bigdatalite.localdomain) 4&gt; info relastic

REPLICAT   RELASTIC  Last Started 2016-04-14 22:55   Status RUNNING
Checkpoint Lag       00:00:00 (updated 00:00:04 ago)
Process ID           17564
Log Read Checkpoint  File /u01/ogg/dirdat/tm000000000
                     First Record  RBA 1406
</code></pre>

<p>If we head over to the Elasticsearch, we&rsquo;ll see that &hellip;</p>

<pre><code>$  curl --silent -XGET http://localhost:9200/_cat/indices?pretty=true
yellow open qasource  5 1 8 6 19.6kb 19.6kb
</code></pre>

<p>&hellip; nothing&rsquo;s changed! Because, of course, nothing&rsquo;s changed on the source Oracle table that the Extract is set up against.</p>

<p>Let&rsquo;s rectify that:</p>

<pre><code>$ rlwrap sqlplus system/welcome1@orcl

SQL*Plus: Release 12.1.0.2.0 Production on Thu Apr 14 23:01:57 2016

Copyright (c) 1982, 2014, Oracle.  All rights reserved.

Last Successful login time: Thu Apr 14 2016 22:48:35 +01:00

Connected to:
Oracle Database 12c Enterprise Edition Release 12.1.0.2.0 - 64bit Production
With the Partitioning, OLAP, Advanced Analytics and Real Application Testing options

SQL&gt; INSERT INTO &quot;MOVIEDEMO&quot;.&quot;MOVIE&quot; (MOVIE_ID, TITLE, YEAR, BUDGET, GROSS, PLOT_SUMMARY) VALUES ('42444', 'never gonna', '2014', '500000', '20000000', 'give you up');

1 row created.

SQL&gt; COMMIT;

Commit complete.
</code></pre>

<p>Check Elasticsearch again:</p>

<pre><code>$  curl --silent -XGET http://localhost:9200/_cat/indices?pretty=true
yellow open qasource  5 1 8 6 19.6kb 19.6kb
yellow open moviedemo 5 1 1 0  4.5kb  4.5kb
</code></pre>

<p>Much better - a new index! We&rsquo;ve got a new index because the replicat is handling a different schema this time - moviedemo, not qasource.</p>

<p>We can look at the data in the index directly:</p>

<pre><code>$ curl -XGET 'http://localhost:9200/moviedemo/_search?q=*&amp;pretty=true'
{
  &quot;took&quot; : 6,
  &quot;timed_out&quot; : false,
  &quot;_shards&quot; : {
    &quot;total&quot; : 5,
    &quot;successful&quot; : 5,
    &quot;failed&quot; : 0
  },
  &quot;hits&quot; : {
    &quot;total&quot; : 1,
    &quot;max_score&quot; : 1.0,
    &quot;hits&quot; : [ {
      &quot;_index&quot; : &quot;moviedemo&quot;,
      &quot;_type&quot; : &quot;movie&quot;,
      &quot;_id&quot; : &quot;42444&quot;,
      &quot;_score&quot; : 1.0,
      &quot;_source&quot; : {
        &quot;PLOT_SUMMARY&quot; : &quot;give you up&quot;,
        &quot;YEAR&quot; : &quot;2014&quot;,
        &quot;MOVIE_ID&quot; : &quot;42444&quot;,
        &quot;BUDGET&quot; : &quot;500000&quot;,
        &quot;TITLE&quot; : &quot;never gonna&quot;,
        &quot;GROSS&quot; : &quot;20000000&quot;
      }
    } ]
  }
}
</code></pre>

<p>You&rsquo;ll note that the primary key (<code>MOVIE_ID</code>) has been correctly identied as the unique document <code>_id</code> field. The <code>_id</code> is now where things begin to get interesting, because this field enables the new OGG-Elasticsearch adaptor to apparently perform &ldquo;UPSERT&rdquo; on documents that already exist.</p>

<p>To doublecheck this apparent method of handling of the data, I first wanted to validate what was coming through from OGG in terms of the data flowing through from the extract. To do this I hooked up a second replicat, to Kafka and on to Logstash into Elasticseach (<a href="http://rmoff.net/2016/03/16/oracle-goldengate-kafka-hive-on-bigdatalite-4-4/">using this method</a>), and then compared the doc count in the two relevant indices (or strictly speaking, the mapping types, corresponding to each index).</p>

<p>To start with, I deleted all my Elasticsearch data, as this shows:</p>

<pre><code>$ curl &quot;localhost:9200/*/_search?search_type=count&amp;pretty=true&quot; -d '{
    &quot;aggs&quot;: {
        &quot;count_by_type&quot;: {
            &quot;terms&quot;: {
                &quot;field&quot;: &quot;_type&quot;
            }
        }
    }
}'
{
  &quot;took&quot; : 2,
  &quot;timed_out&quot; : false,
  &quot;_shards&quot; : {
    &quot;total&quot; : 1,
    &quot;successful&quot; : 1,
    &quot;failed&quot; : 0
  },
  &quot;hits&quot; : {
    &quot;total&quot; : 0,
    &quot;max_score&quot; : 0.0,
    &quot;hits&quot; : [ ]
  },
  &quot;aggregations&quot; : {
    &quot;count_by_type&quot; : {
      &quot;doc_count_error_upper_bound&quot; : 0,
      &quot;sum_other_doc_count&quot; : 0,
      &quot;buckets&quot; : [ ]
    }
  }
}
</code></pre>

<p>Then I insert a row on <code>&quot;MOVIEDEMO&quot;.&quot;MOVIE&quot;</code> in Oracle (having previously truncated it):</p>

<pre><code>SQL&gt; INSERT INTO &quot;MOVIEDEMO&quot;.&quot;MOVIE&quot; (MOVIE_ID, TITLE, YEAR, BUDGET, GROSS, PLOT_SUMMARY) VALUES ('1', 'never gonna', '2014', '500000', '20000000', 'give you up');

1 row created.

SQL&gt; commit;

Commit complete.
</code></pre>

<p>and see it shows up in both Elasticsearch indices:</p>

<pre><code>$ curl &quot;localhost:9200/*/_search?search_type=count&amp;pretty=true&quot; -d '{
    &quot;aggs&quot;: {
        &quot;count_by_type&quot;: {
            &quot;terms&quot;: {
                &quot;field&quot;: &quot;_type&quot;
            }
        }
    }
}'
[...]
  }, {
    &quot;key&quot; : &quot;logs&quot;,
    &quot;doc_count&quot; : 1
  }, {
    &quot;key&quot; : &quot;movie&quot;,
    &quot;doc_count&quot; : 1
</code></pre>

<ul>
<li><strong><code>logs</code></strong> is the index mapping loaded through OGG &ndash;&gt; Kafka &ndash;&gt; Logstash &ndash;&gt; Elasticsearch</li>
<li><strong><code>movie</code></strong> is the index mapping loaded through the new adaptor, OGG &ndash;&gt; Elasticsearch</li>
</ul>

<p>So far, so good. Now, let&rsquo;s add a second row in Oracle:</p>

<pre><code>SQL&gt; INSERT INTO &quot;MOVIEDEMO&quot;.&quot;MOVIE&quot; (MOVIE_ID, TITLE, YEAR, BUDGET, GROSS, PLOT_SUMMARY) VALUES ('2', 'foo', '2014', '500000', '20000000', 'bar');

1 row created.

SQL&gt; commit;

Commit complete.
</code></pre>

<p>Both indices match count:</p>

<pre><code> &quot;buckets&quot; : [ {
    &quot;key&quot; : &quot;logs&quot;,
    &quot;doc_count&quot; : 2
  }, {
    &quot;key&quot; : &quot;movie&quot;,
    &quot;doc_count&quot; : 2
  }, {
</code></pre>

<p>What about an update?</p>

<pre><code>SQL&gt; UPDATE &quot;MOVIEDEMO&quot;.&quot;MOVIE&quot; SET TITLE ='Foobar' where movie_id = 1;

1 row updated.

SQL&gt; commit;

Commit complete.
</code></pre>

<p>Hmmmm&hellip;</p>

<pre><code>  &quot;buckets&quot; : [ {
    &quot;key&quot; : &quot;logs&quot;,
    &quot;doc_count&quot; : 3
  }, {
    &quot;key&quot; : &quot;movie&quot;,
    &quot;doc_count&quot; : 2
  }, {
</code></pre>

<p>The index loaded from the OGG-Elasticsearch Adaptor has only two documents still, whilst the other route has three. If we look at what&rsquo;s in the first of these (movie, loaded by OGG-Elasticsearch) for <code>movie_id=1</code>:</p>

<pre><code>[oracle@bigdatalite ogg-bd]$ curl -XGET 'http://localhost:9200/moviedemo/_search?q=_id=1&amp;pretty=true'
{
  &quot;took&quot; : 2,
  &quot;timed_out&quot; : false,
  &quot;_shards&quot; : {
    &quot;total&quot; : 5,
    &quot;successful&quot; : 5,
    &quot;failed&quot; : 0
  },
  &quot;hits&quot; : {
    &quot;total&quot; : 1,
    &quot;max_score&quot; : 0.014065012,
    &quot;hits&quot; : [ {
      &quot;_index&quot; : &quot;moviedemo&quot;,
      &quot;_type&quot; : &quot;movie&quot;,
      &quot;_id&quot; : &quot;1&quot;,
      &quot;_score&quot; : 0.014065012,
      &quot;_source&quot; : {
        &quot;PLOT_SUMMARY&quot; : &quot;give you up&quot;,
        &quot;YEAR&quot; : &quot;2014&quot;,
        &quot;MOVIE_ID&quot; : &quot;1&quot;,
        &quot;BUDGET&quot; : &quot;500000&quot;,
        &quot;TITLE&quot; : &quot;Foobar&quot;,
        &quot;GROSS&quot; : &quot;20000000&quot;
      }
    } ]
  }
}
</code></pre>

<p>You can see it&rsquo;s the latest version of the row (<code>TITLE=Foobar</code>). In the second index, loaded from the change record sent to Kafka and then on through Logstash, there are <em>both</em> the before and after record for this key:</p>

<pre><code>}
[oracle@bigdatalite ogg-bd]$ curl -XGET 'http://localhost:9200/logstash*/_search?q=*&amp;pretty=true'
[...]
      &quot;_source&quot; : {
        &quot;table&quot; : &quot;ORCL.MOVIEDEMO.MOVIE&quot;,
        &quot;op_type&quot; : &quot;I&quot;,
        &quot;op_ts&quot; : &quot;2016-04-14 22:34:43.000000&quot;,
        &quot;current_ts&quot; : &quot;2016-04-14T23:34:45.131000&quot;,
        &quot;pos&quot; : &quot;00000000000000003514&quot;,
        &quot;primary_keys&quot; : [ &quot;MOVIE_ID&quot; ],
        &quot;tokens&quot; : { },
        &quot;before&quot; : null,
        &quot;after&quot; : {
          &quot;MOVIE_ID&quot; : &quot;1&quot;,
          &quot;MOVIE_ID_isMissing&quot; : false,
          &quot;TITLE&quot; : &quot;never gonna&quot;,
          &quot;TITLE_isMissing&quot; : false,

[...]

        &quot;_source&quot; : {
        &quot;table&quot; : &quot;ORCL.MOVIEDEMO.MOVIE&quot;,
        &quot;op_type&quot; : &quot;U&quot;,
        &quot;op_ts&quot; : &quot;2016-04-14 22:39:37.000000&quot;,
        &quot;current_ts&quot; : &quot;2016-04-14T23:39:39.583000&quot;,
        &quot;pos&quot; : &quot;00000000000000004097&quot;,
        &quot;primary_keys&quot; : [ &quot;MOVIE_ID&quot; ],
        &quot;tokens&quot; : { },
        &quot;before&quot; : {
          [...]
          &quot;TITLE&quot; : &quot;never gonna&quot;,
          [...]
        },
        &quot;after&quot; : {
          [...]
          &quot;TITLE&quot; : &quot;Foobar&quot;,
          [...]
</code></pre>

<p>Finally, if I delete a record in Oracle:</p>

<pre><code>SQL&gt; delete from &quot;MOVIEDEMO&quot;.&quot;MOVIE&quot; where MOVIE_ID = 1;

1 row deleted.

SQL&gt; commit;

Commit complete.
</code></pre>

<p>My document counts reflect what I&rsquo;d expect &ndash; the OGG-Elasticsearch adaptor deleted the record from Elasticsearch, whilst the Kafka route just recorded another change record, of <code>op_type='D'</code> this time.</p>

<pre><code>   &quot;key&quot; : &quot;logs&quot;,
    &quot;doc_count&quot; : 4
  }, {
    &quot;key&quot; : &quot;movie&quot;,
    &quot;doc_count&quot; : 1
</code></pre>

<h1 id="summary">Summary</h1>

<p>This adaptor is a pretty smart way of mirroring a table&rsquo;s contents from one of <a href="http://www.oracle.com/technetwork/middleware/goldengate/certify-100402.html">the many RDBMS that GoldenGate supports</a> as an extract source, into Elasticsearch.</p>

<p>If you want to retain history of changed records, then using <a href="http://rmoff.net/2016/03/16/oracle-goldengate-kafka-hive-on-bigdatalite-4-4/">OGG-&gt;Kafka-&gt;Logstash-&gt;Elasticsearch</a> is an option.</p>

<p>And, if you don&rsquo;t have the spare cash for OGG, you can use <a href="https://www.elastic.co/blog/visualising-oracle-performance-data-with-the-elastic-stack">Logstash&rsquo;s JDBC input</a> mechanism to pull data periodically from your RDBMS. This has the additional benefit of being able to specify custom SQL queries with joins etc - useful when pulling in denormalised datasets into Elasticsearch for analytics.</p>
</article>
    <footer class="post-footer">
      
      <ul class="post-tags">
        
          <li><a href="/tags/elasticsearch"><span class="tag">Elasticsearch</span></a></li>
        
          <li><a href="/tags/goldengate"><span class="tag">Goldengate</span></a></li>
        
          <li><a href="/tags/kafka"><span class="tag">Kafka</span></a></li>
        
          <li><a href="/tags/logstash"><span class="tag">Logstash</span></a></li>
        
          <li><a href="/tags/oracle"><span class="tag">Oracle</span></a></li>
        
      </ul>
      
      <p class="post-copyright">
        This post was published <strong>974</strong> days ago, content in the post may be inaccurate, even wrong now, please take risk yourself.
      </p>
    </footer>
    
      <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "rmoff" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
      
    
  </section>
  


<footer class="site-footer">
  <p>© 2017-2018 rmoff.net</p>
  <p>Powered by <a href="https://gohugo.io/" target="_blank">Hugo</a> with theme <a href="https://github.com/laozhu/hugo-nuo" target="_blank">Nuo</a>.</p>
  
</footer>



<script async src="https://cdn.jsdelivr.net/npm/video.js@7.3.0/dist/video.min.js"></script>




<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      displayMath: [['$$','$$'], ['\\[','\\]']],
      processEscapes: true,
      processEnvironments: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      TeX: { equationNumbers: { autoNumber: "AMS" },
      extensions: ["AMSmath.js", "AMSsymbols.js"] }
    },
  });
</script>
<script type="text/x-mathjax-config">
  // Fix <code> tags after MathJax finishes running. This is a
  // hack to overcome a shortcoming of Markdown. Discussion at
  // https://github.com/mojombo/jekyll/issues/199
  MathJax.Hub.Queue(() => {
    MathJax.Hub.getAllJax().map(v => v.SourceElement().parentNode.className += ' has-jax');
  });
</script>



<script src="/scripts/index.min.js"></script>








  </body>
</html>
