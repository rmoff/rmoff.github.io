<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<title>Streaming Data through Oracle GoldenGate to Elasticsearch</title>
		<link rel="alternate" type="application/rss+xml" title="RSS" href="https://rmoff.github.io/index.xml">
		<link rel="canonical" href="https://rmoff.github.io/2016/04/14/streaming-data-through-oracle-goldengate-to-elasticsearch/">
		
		<link rel="shortcut icon" type="image/png" href="https://rmoff.github.io/apple-touch-icon-precomposed.png">
		
		
		<meta name="generator" content="Hugo 0.52" />

		
		<meta name="og:title" content="Streaming Data through Oracle GoldenGate to Elasticsearch" />
		<meta name="og:type" content="article" />
		<meta name="og:image" content="https://rmoff.github.io/images/2016/04/ogges02-1.png" />
		<meta name="og:description" content="" />
		<meta name="og:url" content="https://rmoff.github.io/2016/04/14/streaming-data-through-oracle-goldengate-to-elasticsearch/" />
		<meta name="og:site_name" content="Streaming Data through Oracle GoldenGate to Elasticsearch" />
		<meta name="twitter:card" content="summary_large_image" />
		<meta name="twitter:site" content="@" />


		
		<link rel="stylesheet" href="https://rmoff.github.io/css/tachyons.min.css" />
		<link rel="stylesheet" href="https://rmoff.github.io/css/story.css" />
		<link rel="stylesheet" href="https://rmoff.github.io/css/descartes.css" />
		
		<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">
		<link href="https://fonts.googleapis.com/css?family=Quattrocento+Sans:400,400i,700,700i|Quattrocento:400,700|Spectral:400,400i,700,700i&amp;subset=latin-ext" rel="stylesheet">
		

		<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
		
		<script src="https://rmoff.github.io/js/story.js"></script>

	</head>
	<body class="ma0 bg-white section-post page-kind-page is-page-true ">
		
		<header class="cover bg-top" style="background-image: url('https://rmoff.github.io/images/2016/04/ogges02-1.png'); background-position: center;">
			<div class="bg-black-30 bb bt">

				<nav class="hide-print sans-serif  border-box pa3 ph5-l">
					<a href="https://rmoff.github.io" title="Home">
						<img src="https://rmoff.github.io/img/logo.jpg" class="w2 h2 br-100" alt="rmoff&#39;s random ramblings" />
					</a>
					<div class="fr h2 pv2 tr">
						<a class="link f5 ml2 dim near-white" href="/about-me/">about</a>
						<a class="link f5 ml2 dim near-white" href="/talks/">talks</a>
						<a class="link f5 ml2 dim near-white" href="https://github.com/rmoff/"><i class="fab fa-github-square"></i></a>
						<a class="link f5 ml2 dim near-white" href="https://www.linkedin.com/in/robinmoffatt/"><i class="fab fa-linkedin"></i></a>
						<a class="link f5 ml2 dim near-white" href="https://twitter.com/rmoff/"><i class="fab fa-twitter-square"></i></a>
						<a class="link f5 ml2 dim near-white fas fa-rss-square" href="https://rmoff.github.io/index.xml" title="RSS Feed"></a>
						<a class="link f5 ml2 dim near-white fas fa-search" href="https://rmoff.github.io/search/" role="search" title="Search"></a>
					</div>
				</nav>

				<div id="hdr" class="tc-l pv4-ns pv5-l pv2 ph3 ph4-ns">
					<h1 class="near-white mt1-ns f2 fw3 mb0 mt0 lh-title">Streaming Data through Oracle GoldenGate to Elasticsearch</h1>
					<h2 class="near-white mt3-l mb4-l fw1 f6 f3-l measure-wide-l center lh-copy mt2 mb3">
						
						
							
								Published
								<time datetime="2016-04-14T22:51:43Z">Apr 14, 2016</time>
								<span class="display-print">by Robin Moffatt</span>
								 in <a href="https://rmoff.github.io/categories//elasticsearch" class="no-underline category near-white dim">Elasticsearch</a>, <a href="https://rmoff.github.io/categories//goldengate" class="no-underline category near-white dim">Goldengate</a>, <a href="https://rmoff.github.io/categories//kafka" class="no-underline category near-white dim">Kafka</a>, <a href="https://rmoff.github.io/categories//logstash" class="no-underline category near-white dim">Logstash</a>, <a href="https://rmoff.github.io/categories//oracle" class="no-underline category near-white dim">Oracle</a>
								<span class="display-print">at https://rmoff.github.io/2016/04/14/streaming-data-through-oracle-goldengate-to-elasticsearch/</span>
							
						
					</h2>
				</div>

				
				
				
				

			</div>
		</header>
		
		<main role="main">
		
<article class="center bg-white br-3 pv1 ph4 nested-copy-line-height lh-copy f4 nested-links mw-100 measure-wide">
	

<p>Recently added to the <a href="https://java.net/projects/oracledi/">oracledi project over at java.net</a> is <a href="https://java.net/projects/oracledi/">an adaptor</a> enabling Oracle GoldenGate (OGG) to send data to Elasticsearch. This adds a powerful alternative to [micro-]batch extract via JDBC from Oracle to Elasticsearch, which I wrote about recently <a href="https://www.elastic.co/blog/visualising-oracle-performance-data-with-the-elastic-stack">over at the Elastic blog</a>.</p>

<p>Elasticsearch is a &lsquo;document store&rsquo; widely used for both search and analytics. It&rsquo;s something I&rsquo;ve written a lot about (<a href="http://rmoff.net/tag/elasticsearch/">here</a> and <a href="www.rittmanmead.com/tag/elasticsearch">here</a> for archives), as well as <a href="https://speakerdeck.com/rmoff/data-discovery-and-systems-diagnostics-with-the-elk-stack">spoken about</a> - preaching the good word, as it were, since the Elastic stack as a whole is very very good at what it does and a pleasure to work with. So, being able to combine that with my &ldquo;day job&rdquo; focus of Oracle is fun. Let&rsquo;s get started!</p>

<p>From the <a href="https://java.net/projects/oracledi/downloads/directory/GoldenGate/Oracle%20GoldenGate%20Adapter%20for%20ElasticSearch">adaptor page</a>, download the zip to your machine. I&rsquo;m using Oracle&rsquo;s <a href="http://www.oracle.com/technetwork/database/bigdata-appliance/oracle-bigdatalite-2104726.html">BigDataLite VM</a> which already has GoldenGate installed and configured, and which I&rsquo;ve also got Elasticsearch already on following on from <a href="http://rmoff.net/2016/03/16/oracle-goldengate-kafka-hive-on-bigdatalite-4-4/">this earlier post</a>. If you&rsquo;ve not got Elasticsearch already, head over to <a href="https://www.elastic.co/downloads/elasticsearch">elastic.co</a> to download it. I&rsquo;m using version 2.3.1, installed in <code>/opt/elasticsearch-2.3.1</code>.</p>

<h3 id="ready">Ready &hellip;</h3>

<p>Once you&rsquo;ve got the OGG adaptor zip, you&rsquo;ll want to unzip it &ndash; a word of advice here, specify the destination folder as there&rsquo;s no containing root within the archive so you&rsquo;ll end up with a mess of folder and files in amongst your download folder otherwise:</p>

<pre><code>unzip OGG_elasticsearch_v1.0.zip -d /u01/OGG_elasticsearch_v1.0
</code></pre>

<p>Copy the provided <code>.prm</code> and <code>.props</code> files to your OGG <code>dirprm</code> folder:</p>

<pre><code>cp /u01/OGG_elasticsearch_v1.0/dirprm/elasticsearch.props /u01/ogg-bd/dirprm/
cp /u01/OGG_elasticsearch_v1.0/dirprm/res.prm /u01/ogg-bd/dirprm/
</code></pre>

<p>Edit the <code>elasticsearch.props</code> (e.g. <code>/u01/ogg/dirprm/elasticsearch.props</code>) file to set:</p>

<ol>
<li><p><strong>gg.classpath</strong>, to pick up both the Elasticsearch jars and the OGG adaptor jar. On my installation this is :</p>

<pre><code>gg.classpath=/opt/elasticsearch-2.3.1/lib/*:/u01/OGG_elasticsearch_v1.0/bin/ogg-elasticsearch-adapter-1.0.jar:
</code></pre></li>

<li><p><strong>gg.handler.elasticsearch.clusterName</strong>, which is the name of your elasticsearch cluster - if you don&rsquo;t know it you can check with</p>

<pre><code>[oracle@bigdatalite ~]$ curl -s localhost:9200|grep cluster_name
&quot;cluster_name&quot; : &quot;elasticsearch&quot;,
</code></pre>

<p>So mine is the default - <strong>elasticsearch</strong>:</p>

<pre><code>gg.handler.elasticsearch.clusterName=elasticsearch
</code></pre></li>

<li><p>For <strong>gg.handler.elasticsearch.host</strong> and <strong>gg.handler.elasticsearch.port</strong> I left the defaults (localhost / 9300) unchanged - update these for your Elasticsearch instance as required. Note that <a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/_talking_to_elasticsearch.html">Elasticsearch listens</a> on two ports, with 9200 by default for HTTP traffic, and 9300 for Java clients which is what we&rsquo;re using here.</p></li>
</ol>

<h3 id="steady">Steady &hellip;</h3>

<p>Run <code>ggsci</code> to add and start the replicat using the provided <code>res</code> configuration (<strong>res</strong> = <strong>R</strong>eplicat, <strong>E</strong>lastic<strong>S</strong>earch, I&rsquo;m guessing) and sample trail file (i.e. we don&rsquo;t need a live extract running to try this thing out):</p>

<pre><code class="language-bash">$ cd /u01/ogg-bd
$ rlwrap ./ggsci

Oracle GoldenGate Command Interpreter
Version 12.2.0.1.0 OGGCORE_12.2.0.1.0_PLATFORMS_151101.1925.2
Linux, x64, 64bit (optimized), Generic on Nov 10 2015 16:18:12
Operating system character set identified as UTF-8.

Copyright (C) 1995, 2015, Oracle and/or its affiliates. All rights reserved.



GGSCI (bigdatalite.localdomain) 1&gt; start mgr
Manager started.


GGSCI (bigdatalite.localdomain) 2&gt; add replicat res, exttrail AdapterExamples/trail/tr
REPLICAT added.
</code></pre>

<h3 id="go">Go!</h3>

<pre><code class="language-bash">GGSCI (bigdatalite.localdomain) 3&gt; start res

Sending START request to MANAGER ...
REPLICAT RES starting
</code></pre>

<p>Yay!</p>

<pre><code class="language-bash">GGSCI (bigdatalite.localdomain) 5&gt; info res

REPLICAT   RES       Initialized   2016-04-14 22:03   Status STOPPED
</code></pre>

<p><code>STOPPED</code>? Oh &hellip;</p>

<p>Time for debug. Open up <code>/u01/ogg-bd/ggserr.log</code>, and the error (<em>`Error loading shared library ggjava.dll</em>) is nice and clear to see:</p>

<pre><code>2016-04-14 22:04:25  INFO    OGG-00987  Oracle GoldenGate Command Interpreter:  GGSCI command (oracle): start res.
2016-04-14 22:04:25  INFO    OGG-00963  Oracle GoldenGate Manager, mgr.prm:  Command received from GGSCI on host [127.0.0.1]:13379 (START REPLICAT RES ).
2016-04-14 22:04:25  INFO    OGG-00960  Oracle GoldenGate Manager, mgr.prm:  Access granted (rule #6).
2016-04-14 22:04:25  INFO    OGG-00975  Oracle GoldenGate Manager, mgr.prm:  REPLICAT RES starting.
2016-04-14 22:04:25  INFO    OGG-00995  Oracle GoldenGate Delivery, res.prm:  REPLICAT RES starting.
2016-04-14 22:04:25  INFO    OGG-03059  Oracle GoldenGate Delivery, res.prm:  Operating system character set identified as UTF-8.
2016-04-14 22:04:25  INFO    OGG-02695  Oracle GoldenGate Delivery, res.prm:  ANSI SQL parameter syntax is used for parameter parsing.
2016-04-14 22:04:25  ERROR   OGG-02554  Oracle GoldenGate Delivery, res.prm:  Error loading shared library ggjava.dll: 2 No such file or directory.
2016-04-14 22:04:25  ERROR   OGG-01668  Oracle GoldenGate Delivery, res.prm:  PROCESS ABENDING.
</code></pre>

<p>But hang on &hellip; <strong><code>ggjava.dll</code></strong> ? <em><strong><code>dll</code></strong></em>? This is Linux, not Windows.</p>

<p>So, a quick change to the <code>prm</code> is in order, switching <code>.dll</code> for <code>.so</code>:</p>

<pre><code>[oracle@bigdatalite ogg-bd]$ diff dirprm/res.prm dirprm/res.prm.bak
5c5
&lt; TARGETDB LIBFILE libggjava.so SET property=dirprm/elasticsearch.props
---
&gt; TARGETDB LIBFILE ggjava.dll SET property=dirprm/elasticsearch.props
</code></pre>

<h3 id="second-time-lucky">Second time lucky?</h3>

<p>Redefine the replicat:</p>

<pre><code>GGSCI (bigdatalite.localdomain) 7&gt; delete res
Deleted REPLICAT RES.


GGSCI (bigdatalite.localdomain) 8&gt; add replicat res, exttrail AdapterExamples/trail/tr
REPLICAT added.
</code></pre>

<p>And start it again:</p>

<pre><code>GGSCI (bigdatalite.localdomain) 9&gt; start res

Sending START request to MANAGER ...
REPLICAT RES starting
</code></pre>

<p>Now it looks better:</p>

<pre><code>GGSCI (bigdatalite.localdomain) 14&gt; info res

REPLICAT   RES       Last Started 2016-04-14 22:10   Status RUNNING
Checkpoint Lag       00:00:00 (updated 00:00:02 ago)
Process ID           15101
Log Read Checkpoint  File AdapterExamples/trail/tr000000000
                     2015-11-05 18:45:39.000000  RBA 5660
</code></pre>

<h3 id="result">Result!</h3>

<p>Let&rsquo;s check out what&rsquo;s happened in Elasticsearch. The console log looks promising, showing that an index with two mappings has been created:</p>

<pre><code>[2016-04-14 22:10:08,709][INFO ][cluster.metadata         ] [Abner Jenkins] [qasource] creating index, cause [auto(bulk api)], templates [], shards [5]/[1], mappings [tcustmer, tcustord]
[2016-04-14 22:10:09,458][INFO ][cluster.routing.allocation] [Abner Jenkins] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[qasource][4]] ...]).
[2016-04-14 22:10:09,488][INFO ][cluster.metadata         ] [Abner Jenkins] [qasource] update_mapping [tcustmer]
[2016-04-14 22:10:09,658][INFO ][cluster.metadata         ] [Abner Jenkins] [qasource] update_mapping [tcustord]
</code></pre>

<p>We can confirm that with the Elasticsearch REST API:</p>

<pre><code>$ curl --silent -XGET http://localhost:9200/_cat/indices?pretty=true
yellow open qasource 5 1 8 6 19.6kb 19.6kb
</code></pre>

<p>And see how many documents (&ldquo;rows&rdquo;) have been loaded (8):</p>

<pre><code>$ curl -s -XGET 'http://localhost:9200/qasource/_search?search_type=count&amp;pretty=true'
{
  &quot;took&quot; : 1,
  &quot;timed_out&quot; : false,
  &quot;_shards&quot; : {
    &quot;total&quot; : 5,
    &quot;successful&quot; : 5,
    &quot;failed&quot; : 0
  },
  &quot;hits&quot; : {
    &quot;total&quot; : 8,
    &quot;max_score&quot; : 0.0,
    &quot;hits&quot; : [ ]
  }
}
</code></pre>

<p>You can even see the mappings (&ldquo;schema&rdquo;) defined within each index:</p>

<pre><code>$ curl -XGET 'http://localhost:9200/_mapping?pretty=true'
{
  &quot;.kibana&quot; : {
    &quot;mappings&quot; : {
      &quot;config&quot; : {
        &quot;properties&quot; : {
          &quot;buildNum&quot; : {
            &quot;type&quot; : &quot;string&quot;,
            &quot;index&quot; : &quot;not_analyzed&quot;
          }
        }
      }
    }
  },
  &quot;qasource&quot; : {
    &quot;mappings&quot; : {
      &quot;tcustord&quot; : {
        &quot;properties&quot; : {
          &quot;CUST_CODE&quot; : {
            &quot;type&quot; : &quot;string&quot;
          },
          &quot;ORDER_DATE&quot; : {
            &quot;type&quot; : &quot;string&quot;
          },
          &quot;ORDER_ID&quot; : {
            &quot;type&quot; : &quot;string&quot;
[...]
</code></pre>

<p>All this faffing about with <code>curl</code> is fine, but if you&rsquo;re doing proper poking with Elasticsearch you may well find <a href="https://github.com/lmenezes/elasticsearch-kopf">kopf</a> handy:</p>

<p><img src="/content/images/2016/04/ogges01.png" alt="ogges01" /></p>

<p>It&rsquo;s easy to install:  (modify the path if your Elasticsearch binary is in a different location):</p>

<pre><code>/opt/elasticsearch-2.3.1/bin/plugin install lmenezes/elasticsearch-kopf
</code></pre>

<p>After installation, restart Elasticsearch and then go to <a href="http://localhost:9200/_plugin/kopf">http://localhost:9200/_plugin/kopf</a></p>

<p>If you&rsquo;re using Elasticsearch, you may well be doing so for the whole Elastic experience, using Kibana to view the data:</p>

<p><img src="/content/images/2016/04/ogges02.png" alt="ogges02" /></p>

<p>and even start doing quick profiling:</p>

<p><img src="/content/images/2016/04/ogges03.png" alt="ogges03" /></p>

<p>One issue with the data that&rsquo;s come through in this example is that it is <em>all</em> string - even the dates and numerics (AMOUNT, PRICE), which makes instant-analysis in Kibana less possible.</p>

<h1 id="streaming-data-from-oracle-to-elasticsearch">Streaming data from Oracle to Elasticsearch</h1>

<p>Now that we&rsquo;ve tested and proven the replicat load into Elasticsearch, let&rsquo;s do the full end-to-end. I&rsquo;m going to use the same Extract as the BigDataLite <a href="http://www.oracle.com/webfolder/technetwork/tutorials/obe/fmw/odi/odi_12c/DI_BDL_Guide/BigDataIntegration_Demo.html?cid=10235&amp;ssid=0">Oracle by Example</a> (you can see my notes on it <a href="http://rmoff.net/2016/03/16/oracle-goldengate-kafka-hive-on-bigdatalite-4-4/">here</a> if you&rsquo;re interested).</p>

<p>Reset &amp; recreate the Extract, in the first OGG instance (<code>/u01/ogg</code>)</p>

<pre><code>$ cd /u01/ogg/
$ rlwrap ./ggsci

GGSCI (bigdatalite.localdomain as system@cdb/CDB$ROOT) 1&gt; obey dirprm/reset_bigdata.oby

[...]

GGSCI (bigdatalite.localdomain as system@cdb/CDB$ROOT) 2&gt; info all

Program     Status      Group       Lag at Chkpt  Time Since Chkpt

MANAGER     RUNNING

GGSCI (bigdatalite.localdomain) 3&gt; obey dirprm/bigdata.oby

[...]

GGSCI (bigdatalite.localdomain as system@cdb/CDB$ROOT) 9&gt; info all

Program     Status      Group       Lag at Chkpt  Time Since Chkpt

MANAGER     RUNNING
EXTRACT     RUNNING     EMOV        00:00:03      00:00:00
</code></pre>

<p>Now define a new replicat parameter file, over in the second OGG instance (that we used above for the <code>res</code> test):</p>

<pre><code>cat &gt; /u01/ogg-bd/dirprm/relastic.prm &lt;&lt;EOF

REPLICAT relastic
TARGETDB LIBFILE libggjava.so SET property=dirprm/elasticsearch.props
REPORTCOUNT EVERY 1 MINUTES, RATE
GROUPTRANSOPS 10000
MAP orcl.moviedemo.movie TARGET orcl.moviedemo.movie;

EOF
</code></pre>

<p>Remove the previous replicat (<code>res</code>) just to keep things clear:</p>

<pre><code>$ cd /u01/ogg-bd
$ rlwrap ./ggsci

Oracle GoldenGate Command Interpreter
Version 12.2.0.1.0 OGGCORE_12.2.0.1.0_PLATFORMS_151101.1925.2
Linux, x64, 64bit (optimized), Generic on Nov 10 2015 16:18:12
Operating system character set identified as UTF-8.

Copyright (C) 1995, 2015, Oracle and/or its affiliates. All rights reserved.


GGSCI (bigdatalite.localdomain) 2&gt; stop res

Sending STOP request to REPLICAT RES ...
Request processed.


GGSCI (bigdatalite.localdomain) 3&gt; delete res
Deleted REPLICAT RES.


GGSCI (bigdatalite.localdomain) 4&gt; info all

Program     Status      Group       Lag at Chkpt  Time Since Chkpt

MANAGER     RUNNING
</code></pre>

<p>Add the new one (<code>relastic</code>):</p>

<pre><code>GGSCI (bigdatalite.localdomain) 1&gt; add replicat relastic, exttrail /u01/ogg/dirdat/tm
REPLICAT added.
</code></pre>

<p>And start it:</p>

<pre><code>GGSCI (bigdatalite.localdomain) 2&gt; start relastic

Sending START request to MANAGER ...
REPLICAT RELASTIC starting

GGSCI (bigdatalite.localdomain) 4&gt; info relastic

REPLICAT   RELASTIC  Last Started 2016-04-14 22:55   Status RUNNING
Checkpoint Lag       00:00:00 (updated 00:00:04 ago)
Process ID           17564
Log Read Checkpoint  File /u01/ogg/dirdat/tm000000000
                     First Record  RBA 1406
</code></pre>

<p>If we head over to the Elasticsearch, we&rsquo;ll see that &hellip;</p>

<pre><code>$  curl --silent -XGET http://localhost:9200/_cat/indices?pretty=true
yellow open qasource  5 1 8 6 19.6kb 19.6kb
</code></pre>

<p>&hellip; nothing&rsquo;s changed! Because, of course, nothing&rsquo;s changed on the source Oracle table that the Extract is set up against.</p>

<p>Let&rsquo;s rectify that:</p>

<pre><code>$ rlwrap sqlplus system/welcome1@orcl

SQL*Plus: Release 12.1.0.2.0 Production on Thu Apr 14 23:01:57 2016

Copyright (c) 1982, 2014, Oracle.  All rights reserved.

Last Successful login time: Thu Apr 14 2016 22:48:35 +01:00

Connected to:
Oracle Database 12c Enterprise Edition Release 12.1.0.2.0 - 64bit Production
With the Partitioning, OLAP, Advanced Analytics and Real Application Testing options

SQL&gt; INSERT INTO &quot;MOVIEDEMO&quot;.&quot;MOVIE&quot; (MOVIE_ID, TITLE, YEAR, BUDGET, GROSS, PLOT_SUMMARY) VALUES ('42444', 'never gonna', '2014', '500000', '20000000', 'give you up');

1 row created.

SQL&gt; COMMIT;

Commit complete.
</code></pre>

<p>Check Elasticsearch again:</p>

<pre><code>$  curl --silent -XGET http://localhost:9200/_cat/indices?pretty=true
yellow open qasource  5 1 8 6 19.6kb 19.6kb
yellow open moviedemo 5 1 1 0  4.5kb  4.5kb
</code></pre>

<p>Much better - a new index! We&rsquo;ve got a new index because the replicat is handling a different schema this time - moviedemo, not qasource.</p>

<p>We can look at the data in the index directly:</p>

<pre><code>$ curl -XGET 'http://localhost:9200/moviedemo/_search?q=*&amp;pretty=true'
{
  &quot;took&quot; : 6,
  &quot;timed_out&quot; : false,
  &quot;_shards&quot; : {
    &quot;total&quot; : 5,
    &quot;successful&quot; : 5,
    &quot;failed&quot; : 0
  },
  &quot;hits&quot; : {
    &quot;total&quot; : 1,
    &quot;max_score&quot; : 1.0,
    &quot;hits&quot; : [ {
      &quot;_index&quot; : &quot;moviedemo&quot;,
      &quot;_type&quot; : &quot;movie&quot;,
      &quot;_id&quot; : &quot;42444&quot;,
      &quot;_score&quot; : 1.0,
      &quot;_source&quot; : {
        &quot;PLOT_SUMMARY&quot; : &quot;give you up&quot;,
        &quot;YEAR&quot; : &quot;2014&quot;,
        &quot;MOVIE_ID&quot; : &quot;42444&quot;,
        &quot;BUDGET&quot; : &quot;500000&quot;,
        &quot;TITLE&quot; : &quot;never gonna&quot;,
        &quot;GROSS&quot; : &quot;20000000&quot;
      }
    } ]
  }
}
</code></pre>

<p>You&rsquo;ll note that the primary key (<code>MOVIE_ID</code>) has been correctly identied as the unique document <code>_id</code> field. The <code>_id</code> is now where things begin to get interesting, because this field enables the new OGG-Elasticsearch adaptor to apparently perform &ldquo;UPSERT&rdquo; on documents that already exist.</p>

<p>To doublecheck this apparent method of handling of the data, I first wanted to validate what was coming through from OGG in terms of the data flowing through from the extract. To do this I hooked up a second replicat, to Kafka and on to Logstash into Elasticseach (<a href="http://rmoff.net/2016/03/16/oracle-goldengate-kafka-hive-on-bigdatalite-4-4/">using this method</a>), and then compared the doc count in the two relevant indices (or strictly speaking, the mapping types, corresponding to each index).</p>

<p>To start with, I deleted all my Elasticsearch data, as this shows:</p>

<pre><code>$ curl &quot;localhost:9200/*/_search?search_type=count&amp;pretty=true&quot; -d '{
    &quot;aggs&quot;: {
        &quot;count_by_type&quot;: {
            &quot;terms&quot;: {
                &quot;field&quot;: &quot;_type&quot;
            }
        }
    }
}'
{
  &quot;took&quot; : 2,
  &quot;timed_out&quot; : false,
  &quot;_shards&quot; : {
    &quot;total&quot; : 1,
    &quot;successful&quot; : 1,
    &quot;failed&quot; : 0
  },
  &quot;hits&quot; : {
    &quot;total&quot; : 0,
    &quot;max_score&quot; : 0.0,
    &quot;hits&quot; : [ ]
  },
  &quot;aggregations&quot; : {
    &quot;count_by_type&quot; : {
      &quot;doc_count_error_upper_bound&quot; : 0,
      &quot;sum_other_doc_count&quot; : 0,
      &quot;buckets&quot; : [ ]
    }
  }
}
</code></pre>

<p>Then I insert a row on <code>&quot;MOVIEDEMO&quot;.&quot;MOVIE&quot;</code> in Oracle (having previously truncated it):</p>

<pre><code>SQL&gt; INSERT INTO &quot;MOVIEDEMO&quot;.&quot;MOVIE&quot; (MOVIE_ID, TITLE, YEAR, BUDGET, GROSS, PLOT_SUMMARY) VALUES ('1', 'never gonna', '2014', '500000', '20000000', 'give you up');

1 row created.

SQL&gt; commit;

Commit complete.
</code></pre>

<p>and see it shows up in both Elasticsearch indices:</p>

<pre><code>$ curl &quot;localhost:9200/*/_search?search_type=count&amp;pretty=true&quot; -d '{
    &quot;aggs&quot;: {
        &quot;count_by_type&quot;: {
            &quot;terms&quot;: {
                &quot;field&quot;: &quot;_type&quot;
            }
        }
    }
}'
[...]
  }, {
    &quot;key&quot; : &quot;logs&quot;,
    &quot;doc_count&quot; : 1
  }, {
    &quot;key&quot; : &quot;movie&quot;,
    &quot;doc_count&quot; : 1
</code></pre>

<ul>
<li><strong><code>logs</code></strong> is the index mapping loaded through OGG &ndash;&gt; Kafka &ndash;&gt; Logstash &ndash;&gt; Elasticsearch</li>
<li><strong><code>movie</code></strong> is the index mapping loaded through the new adaptor, OGG &ndash;&gt; Elasticsearch</li>
</ul>

<p>So far, so good. Now, let&rsquo;s add a second row in Oracle:</p>

<pre><code>SQL&gt; INSERT INTO &quot;MOVIEDEMO&quot;.&quot;MOVIE&quot; (MOVIE_ID, TITLE, YEAR, BUDGET, GROSS, PLOT_SUMMARY) VALUES ('2', 'foo', '2014', '500000', '20000000', 'bar');

1 row created.

SQL&gt; commit;

Commit complete.
</code></pre>

<p>Both indices match count:</p>

<pre><code> &quot;buckets&quot; : [ {
    &quot;key&quot; : &quot;logs&quot;,
    &quot;doc_count&quot; : 2
  }, {
    &quot;key&quot; : &quot;movie&quot;,
    &quot;doc_count&quot; : 2
  }, {
</code></pre>

<p>What about an update?</p>

<pre><code>SQL&gt; UPDATE &quot;MOVIEDEMO&quot;.&quot;MOVIE&quot; SET TITLE ='Foobar' where movie_id = 1;

1 row updated.

SQL&gt; commit;

Commit complete.
</code></pre>

<p>Hmmmm&hellip;</p>

<pre><code>  &quot;buckets&quot; : [ {
    &quot;key&quot; : &quot;logs&quot;,
    &quot;doc_count&quot; : 3
  }, {
    &quot;key&quot; : &quot;movie&quot;,
    &quot;doc_count&quot; : 2
  }, {
</code></pre>

<p>The index loaded from the OGG-Elasticsearch Adaptor has only two documents still, whilst the other route has three. If we look at what&rsquo;s in the first of these (movie, loaded by OGG-Elasticsearch) for <code>movie_id=1</code>:</p>

<pre><code>[oracle@bigdatalite ogg-bd]$ curl -XGET 'http://localhost:9200/moviedemo/_search?q=_id=1&amp;pretty=true'
{
  &quot;took&quot; : 2,
  &quot;timed_out&quot; : false,
  &quot;_shards&quot; : {
    &quot;total&quot; : 5,
    &quot;successful&quot; : 5,
    &quot;failed&quot; : 0
  },
  &quot;hits&quot; : {
    &quot;total&quot; : 1,
    &quot;max_score&quot; : 0.014065012,
    &quot;hits&quot; : [ {
      &quot;_index&quot; : &quot;moviedemo&quot;,
      &quot;_type&quot; : &quot;movie&quot;,
      &quot;_id&quot; : &quot;1&quot;,
      &quot;_score&quot; : 0.014065012,
      &quot;_source&quot; : {
        &quot;PLOT_SUMMARY&quot; : &quot;give you up&quot;,
        &quot;YEAR&quot; : &quot;2014&quot;,
        &quot;MOVIE_ID&quot; : &quot;1&quot;,
        &quot;BUDGET&quot; : &quot;500000&quot;,
        &quot;TITLE&quot; : &quot;Foobar&quot;,
        &quot;GROSS&quot; : &quot;20000000&quot;
      }
    } ]
  }
}
</code></pre>

<p>You can see it&rsquo;s the latest version of the row (<code>TITLE=Foobar</code>). In the second index, loaded from the change record sent to Kafka and then on through Logstash, there are <em>both</em> the before and after record for this key:</p>

<pre><code>}
[oracle@bigdatalite ogg-bd]$ curl -XGET 'http://localhost:9200/logstash*/_search?q=*&amp;pretty=true'
[...]
      &quot;_source&quot; : {
        &quot;table&quot; : &quot;ORCL.MOVIEDEMO.MOVIE&quot;,
        &quot;op_type&quot; : &quot;I&quot;,
        &quot;op_ts&quot; : &quot;2016-04-14 22:34:43.000000&quot;,
        &quot;current_ts&quot; : &quot;2016-04-14T23:34:45.131000&quot;,
        &quot;pos&quot; : &quot;00000000000000003514&quot;,
        &quot;primary_keys&quot; : [ &quot;MOVIE_ID&quot; ],
        &quot;tokens&quot; : { },
        &quot;before&quot; : null,
        &quot;after&quot; : {
          &quot;MOVIE_ID&quot; : &quot;1&quot;,
          &quot;MOVIE_ID_isMissing&quot; : false,
          &quot;TITLE&quot; : &quot;never gonna&quot;,
          &quot;TITLE_isMissing&quot; : false,

[...]

        &quot;_source&quot; : {
        &quot;table&quot; : &quot;ORCL.MOVIEDEMO.MOVIE&quot;,
        &quot;op_type&quot; : &quot;U&quot;,
        &quot;op_ts&quot; : &quot;2016-04-14 22:39:37.000000&quot;,
        &quot;current_ts&quot; : &quot;2016-04-14T23:39:39.583000&quot;,
        &quot;pos&quot; : &quot;00000000000000004097&quot;,
        &quot;primary_keys&quot; : [ &quot;MOVIE_ID&quot; ],
        &quot;tokens&quot; : { },
        &quot;before&quot; : {
          [...]
          &quot;TITLE&quot; : &quot;never gonna&quot;,
          [...]
        },
        &quot;after&quot; : {
          [...]
          &quot;TITLE&quot; : &quot;Foobar&quot;,
          [...]
</code></pre>

<p>Finally, if I delete a record in Oracle:</p>

<pre><code>SQL&gt; delete from &quot;MOVIEDEMO&quot;.&quot;MOVIE&quot; where MOVIE_ID = 1;

1 row deleted.

SQL&gt; commit;

Commit complete.
</code></pre>

<p>My document counts reflect what I&rsquo;d expect &ndash; the OGG-Elasticsearch adaptor deleted the record from Elasticsearch, whilst the Kafka route just recorded another change record, of <code>op_type='D'</code> this time.</p>

<pre><code>   &quot;key&quot; : &quot;logs&quot;,
    &quot;doc_count&quot; : 4
  }, {
    &quot;key&quot; : &quot;movie&quot;,
    &quot;doc_count&quot; : 1
</code></pre>

<h1 id="summary">Summary</h1>

<p>This adaptor is a pretty smart way of mirroring a table&rsquo;s contents from one of <a href="http://www.oracle.com/technetwork/middleware/goldengate/certify-100402.html">the many RDBMS that GoldenGate supports</a> as an extract source, into Elasticsearch.</p>

<p>If you want to retain history of changed records, then using <a href="http://rmoff.net/2016/03/16/oracle-goldengate-kafka-hive-on-bigdatalite-4-4/">OGG-&gt;Kafka-&gt;Logstash-&gt;Elasticsearch</a> is an option.</p>

<p>And, if you don&rsquo;t have the spare cash for OGG, you can use <a href="https://www.elastic.co/blog/visualising-oracle-performance-data-with-the-elastic-stack">Logstash&rsquo;s JDBC input</a> mechanism to pull data periodically from your RDBMS. This has the additional benefit of being able to specify custom SQL queries with joins etc - useful when pulling in denormalised datasets into Elasticsearch for analytics.</p>

</article>

		</main>
		
				<div class="hide-print sans-serif f6 f5-l mt5 ph3 pb6 center nested-copy-line-height lh-copy nested-links mw-100 measure-wide">
		<div class="about-the-author">
		
			
			
				
					<hr />

<p><img src="/images/2018/05/ksldn18-01.jpg" alt="Robin Moffatt" /></p>

<p>Robin Moffatt is a Developer Advocate at Confluent, and Oracle Groundbreaker Ambassador. He also likes writing about himself in the third person, eating good breakfasts, and drinking good beer.</p>

				
			
		
		</div>
		
	</div>

		
		
		
		<footer class="hide-print sans-serif f6 fw1 bg-black near-white bottom-0 w-100 pa3" role="contentinfo">
			<p class="w-50 fr tr">
			<a class="no-underline near-white" href="https://github.com/xaprb/story"><img class="dib" title="Made with Hugo and Story" alt="Story logo" src="https://rmoff.github.io/img/story-logo-white.svg" style="width: 1.5rem; height: 1.5rem" /></a>
			</p>
			<p class="w-50 near-white">
				&copy; 2019 Robin Moffatt
			</p>
		</footer>
		
	
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-75492960-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

	
	</body>
</html>
