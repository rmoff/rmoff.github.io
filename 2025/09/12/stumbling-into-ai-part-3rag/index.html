<!DOCTYPE html>
<html lang="en">
	<head>
		<meta http-equiv=X-Clacks-Overhead content="GNU Terry Pratchett">
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		
		<link rel="preconnect" href="https://fonts.googleapis.com">
		<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
		<link rel="preload" as="image" href="https://rmoff.net/images/2025/09/h_IMG_2454.webp" >
		
		<title>Stumbling into AI: Part 3â€”RAG</title>
		<link rel="alternate" type="application/rss+xml" title="RSS" href="https://rmoff.net/index.xml">
		<link rel="canonical" href="https://rmoff.net/2025/09/12/stumbling-into-ai-part-3rag/">
		
		

		
		<meta property="og:title" content="Stumbling into AI: Part 3â€”RAG" />
		<meta property="og:type" content="article" />
		<meta property="og:image" content="https://rmoff.net/images/2025/09/h_IMG_2454.webp" />
		<meta property="og:description" content="" />
		<meta property="og:url" content="https://rmoff.net/2025/09/12/stumbling-into-ai-part-3rag/" />
		<meta property="og:site_name" content="Stumbling into AI: Part 3â€”RAG" />
		<meta name="twitter:card" content="summary_large_image" />
		<meta name="twitter:site" content="@" />


		
		<style>
			html { background-color: #FAF8F5; color: #2D2926; }
			body { opacity: 0; transition: opacity 0.1s ease; }
			body.loaded { opacity: 1; }
			.site-header { height: 60px; background-color: #FAF8F5; border-bottom: 1px solid #E8421E; }
		</style>

		
		
		<link rel="stylesheet" href="https://rmoff.net/css/redesign.css" />
		
		<link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Bricolage+Grotesque:opsz,wght@12..96,400;12..96,600;12..96,700;12..96,800&family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&family=JetBrains+Mono:wght@400;500&family=Outfit:wght@400;500;600&display=swap">
		<link href="https://fonts.googleapis.com/css2?family=Bricolage+Grotesque:opsz,wght@12..96,400;12..96,600;12..96,700;12..96,800&family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&family=JetBrains+Mono:wght@400;500&family=Outfit:wght@400;500;600&display=swap" rel="stylesheet" media="print" onload="this.media='all'">
		<noscript><link href="https://fonts.googleapis.com/css2?family=Bricolage+Grotesque:opsz,wght@12..96,400;12..96,600;12..96,700;12..96,800&family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&family=JetBrains+Mono:wght@400;500&family=Outfit:wght@400;500;600&display=swap" rel="stylesheet"></noscript>
		

		
		<script src="/js/copy-code.js"></script>
		

		
		<script>
			!function(t,e){var o,n,p,r;e.__SV||(window.posthog=e,e._i=[],e.init=function(i,s,a){function g(t,e){var o=e.split(".");2==o.length&&(t=t[o[0]],e=o[1]),t[e]=function(){t.push([e].concat(Array.prototype.slice.call(arguments,0)))}}(p=t.createElement("script")).type="text/javascript",p.crossOrigin="anonymous",p.async=!0,p.src=s.api_host.replace(".i.posthog.com","-assets.i.posthog.com")+"/static/array.js",(r=t.getElementsByTagName("script")[0]).parentNode.insertBefore(p,r);var u=e;for(void 0!==a?u=e[a]=[]:a="posthog",u.people=u.people||[],u.toString=function(t){var e="posthog";return"posthog"!==a&&(e+="."+a),t||(e+=" (stub)"),e},u.people.toString=function(){return u.toString(1)+".people (stub)"},o="init capture register register_once register_for_session unregister unregister_for_session getFeatureFlag getFeatureFlagPayload isFeatureEnabled reloadFeatureFlags updateEarlyAccessFeatureEnrollment getEarlyAccessFeatures on onFeatureFlags onSessionId getSurveys getActiveMatchingSurveys renderSurvey canRenderSurvey getNextSurveyStep identify setPersonProperties group resetGroups setPersonPropertiesForFlags resetPersonPropertiesForFlags setGroupPropertiesForFlags resetGroupPropertiesForFlags reset get_distinct_id getGroups get_session_id get_session_replay_url alias set_config startSessionRecording stopSessionRecording sessionRecordingStarted captureException loadToolbar get_property getSessionProperty createPersonProfile opt_in_capturing opt_out_capturing has_opted_in_capturing has_opted_out_capturing clear_opt_in_out_capturing debug".split(" "),n=0;n<o.length;n++)g(u,o[n]);e._i.push([i,s,a])},e.__SV=1)}(document,window.posthog||[]);
            posthog.init('phc_93NEP79Ju4xqXYWXnoLbr4HMW0Iaepj1BGOVoEXYX6P',{api_host:'https://eu.i.posthog.com', person_profiles: 'identified_only'})
		</script>

		
		<script src="https://rmoff.net/js/story.js"></script>
		<script src="https://rmoff.net/js/toc.js"></script>
		<script src="https://rmoff.net/js/medium-mirror.js"></script>
	</head>
	<body class="ma0 section-post page-kind-page is-page-true ">
		<script>document.body.classList.add('loaded');</script>

		<header class="site-header hide-print">
	<div class="site-header-inner">
		<a href="https://rmoff.net/" class="site-title">rmoff's random ramblings</a>
		<nav class="site-nav">
			<a href="/categories/interesting-links/" class="nav-il"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"/><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"/></svg> Interesting Links</a>
			<span class="nav-sep"></span>
			<a href="/categories/"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"/><line x1="7" y1="7" x2="7.01" y2="7"/></svg> Categories</a>
			<a href="https://rmoff.net/search/"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="11" cy="11" r="8"/><line x1="21" y1="21" x2="16.65" y2="16.65"/></svg> Search</a>
			<a href="https://rmoff.net/index.xml"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 11a9 9 0 0 1 9 9"/><path d="M4 4a16 16 0 0 1 16 16"/><circle cx="5" cy="19" r="1"/></svg> RSS</a>
			<div class="nav-social">
				<a href="https://www.linkedin.com/in/robinmoffatt/" title="linkedin"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433a2.062 2.062 0 0 1-2.063-2.065 2.064 2.064 0 1 1 2.063 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg></a>
				<a href="https://twitter.com/rmoff/" title="twitter"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"/></svg></a>
				<a href="https://bsky.app/profile/rmoff.net" title="bluesky"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 568 501" fill="currentColor"><path d="M123.121 33.664C188.241 82.553 258.281 181.68 284 234.873c25.719-53.192 95.759-152.32 160.879-201.21C491.866-1.611 568-28.906 568 57.947c0 17.346-9.945 145.713-15.778 166.555-20.275 72.453-94.155 90.933-159.875 79.748C507.222 323.8 536.444 388.56 473.333 453.32c-119.86 122.992-172.272-30.859-185.702-70.281-2.462-7.227-3.614-10.608-3.631-7.733-.017-2.875-1.169.506-3.631 7.733-13.43 39.422-65.842 193.273-185.702 70.281-63.111-64.76-33.89-129.52 80.986-149.071-65.72 11.185-139.6-7.295-159.875-79.748C10.945 203.659 1 75.291 1 57.946 1-28.906 76.135-1.612 123.121 33.664z"/></svg></a>
				<a href="https://www.youtube.com/c/rmoff" title="youtube"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M23.498 6.186a3.016 3.016 0 0 0-2.122-2.136C19.505 3.545 12 3.545 12 3.545s-7.505 0-9.377.505A3.017 3.017 0 0 0 .502 6.186C0 8.07 0 12 0 12s0 3.93.502 5.814a3.016 3.016 0 0 0 2.122 2.136c1.871.505 9.376.505 9.376.505s7.505 0 9.377-.505a3.015 3.015 0 0 0 2.122-2.136C24 15.93 24 12 24 12s0-3.93-.502-5.814zM9.545 15.568V8.432L15.818 12l-6.273 3.568z"/></svg></a>
				<a href="https://talks.rmoff.net" title="talks"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><rect x="2" y="3" width="20" height="14" rx="0"/><line x1="12" y1="17" x2="12" y2="22"/><line x1="8" y1="22" x2="16" y2="22"/><polyline points="7 8 12 12 17 8"/></svg></a>
				<a href="https://github.com/rmoff/" title="github"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a>
			</div>
		</nav>
		<button class="nav-toggle" onclick="document.querySelector('.mobile-nav').classList.toggle('open')" aria-label="Menu">
			<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="18" x2="21" y2="18"/></svg>
		</button>
	</div>
	<nav class="mobile-nav">
		<a href="https://rmoff.net/">Home</a>
		<a href="/categories/">Categories</a>
		<a href="/categories/interesting-links/">Interesting Links</a>
		<a href="https://rmoff.net/search/">Search</a>
		<a href="https://rmoff.net/index.xml">RSS</a>
		<a href="https://www.linkedin.com/in/robinmoffatt/">linkedin</a>
		<a href="https://twitter.com/rmoff/">twitter</a>
		<a href="https://bsky.app/profile/rmoff.net">bluesky</a>
		<a href="https://www.youtube.com/c/rmoff">youtube</a>
		<a href="https://talks.rmoff.net">talks</a>
		<a href="https://github.com/rmoff/">github</a>
	</nav>
</header>


		<main role="main">
		

<div class="article-hero" style="background-image: url('https://rmoff.net/images/2025/09/h_IMG_2454.webp');">
	<div class="article-hero-overlay">
		<div class="article-hero-content">
			<h1>Stumbling into AI: Part 3â€”RAG</h1>
			<p class="article-hero-meta">
				
					<time datetime="2025-09-12T13:10:34Z">12 Sep 2025</time>
					<span class="display-print">by </span>
					 &middot; <a href="https://rmoff.net/categories/ai">AI</a>, <a href="https://rmoff.net/categories/rag">RAG</a>, <a href="https://rmoff.net/categories/stumbling-into-ai">Stumbling into AI</a>
					<span class="display-print">at https://rmoff.net/2025/09/12/stumbling-into-ai-part-3rag/</span>
				
			</p>
		</div>
	</div>
</div>


<details class="toc-mobile">
	<summary>Table of Contents</summary>
	<nav id="TableOfContents">
  <ul>
    <li><a href="#_rag_basics">RAG basics</a></li>
    <li><a href="#_embeddings_and_vectors">Embeddings and Vectors</a>
      <ul>
        <li><a href="#_rag_ingestion_populating_a_vector_database_with_embeddings">RAG Ingestion: Populating a vector database with embeddings</a></li>
        <li><a href="#_rag_retrieval_using_embeddings_to_provide_context_to_an_llm">RAG Retrieval: Using embeddings to provide context to an LLM</a></li>
      </ul>
    </li>
    <li><a href="#_and_then_the_snake_ate_its_own_tail">And then the snake ate its own tail</a></li>
    <li><a href="#_further_reading">Further reading</a></li>
  </ul>
</nav>
</details>

<div class="container-fluid docs">
	<div class="row">
		<main class="docs-content" role="main">

<article class="article" data-pagefind-body>
	<span data-pagefind-filter="category" style="display:none">AI</span><span data-pagefind-filter="category" style="display:none">RAG</span><span data-pagefind-filter="category" style="display:none">Stumbling into AI</span>
	<img data-pagefind-meta="image[src]" src="https://rmoff.net/images/2025/09/h_IMG_2454.webp" style="display:none" alt="">
	<div class="paragraph">
<p><em>A <a href="/categories/stumbling-into-ai">short series</a> of notes for myself as I learn more about the AI ecosystem as of September 2025.</em>
<em>The driver for all this is understanding more about Apache Flinkâ€™s <a href="https://github.com/apache/flink-agents"><strong>Flink Agents</strong></a> project, and Confluentâ€™s <a href="https://www.confluent.io/product/streaming-agents/"><strong>Streaming Agents</strong></a>.</em></p>
</div>
<div class="paragraph">
<p>Having <a href="/2025/09/04/stumbling-into-ai-part-1mcp/">poked around MCP</a> and <a href="/2025/09/08/stumbling-into-ai-part-2models/">Models</a>, next up is RAG.</p>
</div>
<div class="paragraph">
<p>RAG has been one of the buzzwords of the last couple of years, with any vendor worth its salt finding a way to crowbar it into their product.
Iâ€™d been sufficiently put off it by the hype to steer away from actually understanding what it is.
In this blog post, letâ€™s fix thatâ€”because if Iâ€™ve understood it correctly, itâ€™s a pattern thatâ€™s not scary at all.</p>
</div>
<div class="sect1">
<h2 id="_rag_basics">RAG basics&nbsp;<a class="headline-hash" href="#_rag_basics">ðŸ”—</a> </h2>
<div class="sectionbody">
<div class="paragraph">
<p>First up: RAG stands for <strong>Retrieval-Augmented Generation</strong>.</p>
</div>
<div class="paragraph">
<p>Put another way, itâ€™s about <strong>Generation</strong> (using LLMs, like we saw <a href="/2025/09/08/stumbling-into-ai-part-2models/">before</a> and like you use every day), in which the prompt given to the LLM is <strong>Augmented</strong> by the <strong>Retrieval</strong> of additional context.</p>
</div>
<div class="paragraph">
<p>It is literally the difference between this prompt &amp; response from an LLM:</p>
</div>
<div class="quoteblock">
<blockquote>
<div class="paragraph">
<p>Respond to this prompt: whatâ€™s the latest version of kafka?</p>
</div>
</blockquote>
</div>
<div class="quoteblock">
<blockquote>
<div class="quoteblock">
<blockquote>
<div class="paragraph">
<p>Apache Kafka 3.7 (released on May 12, 2023)</p>
</div>
</blockquote>
</div>
</blockquote>
</div>
<div class="paragraph">
<p>and this one:</p>
</div>
<div class="quoteblock">
<blockquote>
<div class="paragraph">
<p><strong>Using this data: The latest version of Apache Kafka is 4.1</strong>. Respond to this prompt: whatâ€™s the latest version of kafka?</p>
</div>
</blockquote>
</div>
<div class="quoteblock">
<blockquote>
<div class="quoteblock">
<blockquote>
<div class="paragraph">
<p>The latest version of Apache Kafka is 4.1.</p>
</div>
</blockquote>
</div>
</blockquote>
</div>
<div class="paragraph">
<p>The second exampleâ€™s <strong>generation</strong> has been <strong>augmented</strong> by the <strong>retrieval</strong> of additional information thatâ€™s then added to the prompt prior to submission to the LLM.</p>
</div>
<div class="paragraph">
<p>This may seem stupidâ€”why would I tell the LLM the latest version, and then ask it the latest version?
But itâ€™s not me asking!
In a typical interaction youâ€™ll have the end-user entering a prompt, and the prompt given to the LLM will be the userâ€™s question, plus context (information) added by some kind of lookup.</p>
</div>
<div class="paragraph">
<p><span class="image"><img src="/images/2025/09/rag1.webp" alt="rag1"/></span></p>
</div>
<div class="paragraph">
<p>The LLM uses the additional context in order to provide an answer that is much more likely to be accurate, avoiding the issue of hallucinations (when LLMs make shit up) or simply out of date information (on which the LLM was trained; itâ€™s not their fault really).</p>
</div>
<div class="paragraph">
<p><span class="image"><img src="/images/2025/09/rag4.webp" alt="rag4"/></span></p>
</div>
<div class="admonitionblock tip">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>If you like videos, I really liked this video from IBMâ€™s Marina Danilevsky that explains the concept.</p>
</div>
<div class="paragraph">
<p>She uses the analogy of her kid asking her which planet has the most moons, and the fact that her &#34;training dataset&#34; was from several decades ago, and discoveries have been made since then that could render her answer, given in good faith, incorrect.
The RAG bit of the analogy is that she would go and check the latest datasource from somewhere like NASA before giving the answer to her child.</p>
</div>
<div class="paragraph">
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/T-D1OfcDW1M?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>

</div>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>So far, so simple, really.
RAG==a fancy way for giving LLMs more context with which to hopefully give you a better answer.</p>
</div>
<div class="paragraph">
<p>The Kafka version number example is somewhat trite and could be picked apart in multiple ways.
Why do I need an LLM to tell me that? Why canâ€™t I just go to the datasource that gave the additional context to the prompt myself?</p>
</div>
<div class="paragraph">
<p>The point with RAG is that youâ€™re still wanting an LLM to do its thingâ€”but to do so either with much greater accuracy (e.g. Kafka version), or in a way that it simply couldnâ€™t do without the additional context.</p>
</div>
<div class="paragraph">
<p>RAGs really come into their own for <strong>enriching</strong> the behaviour of LLMs with data, often thatâ€™s held within our business.
As a customer, we all expect companies to know &#34;everything&#34; about us, right?
After all, we completely the forms, we checked the boxesâ€”why are you asking me to type in a bunch of data that you already know?</p>
</div>
<div class="paragraph">
<p>Hereâ€™s a simple example of this concept.
Imagine we want to know where <em>our</em> nearest airport is?</p>
</div>
<div class="paragraph">
<p><em>Yes yes, we could just open Google Maps, but hear me out.</em></p>
</div>
<div class="paragraph">
<p>If we ask an LLM this, itâ€™s not got a clueâ€”it has no <em>context</em>:</p>
</div>
<div class="quoteblock">
<blockquote>
<div class="paragraph">
<p>Where is Rickâ€™s nearest airport? Single answer only.</p>
</div>
</blockquote>
</div>
<div class="quoteblock">
<blockquote>
<div class="quoteblock">
<blockquote>
<div class="paragraph">
<p>Iâ€™m not aware of any information about Rick, so Iâ€™ll need more context or details about who or what &#34;Rick&#34; refers to.</p>
</div>
</blockquote>
</div>
</blockquote>
</div>
<div class="paragraph">
<p>Whereas if we already hold information about our customer &#39;Rick&#39;, we can look that information up and pass it to the LLM:</p>
</div>
<div class="quoteblock">
<blockquote>
<div class="paragraph">
<p>Using this data: <strong>Rick lives in Dulwich.</strong> Respond to this prompt: Where is Rickâ€™s nearest airport? Single answer only.</p>
</div>
</blockquote>
</div>
<div class="quoteblock">
<blockquote>
<div class="quoteblock">
<blockquote>
<div class="paragraph">
<p>London Gatwick Airport (LGW)</p>
</div>
</blockquote>
</div>
</blockquote>
</div>
<div class="paragraph">
<p><span class="image"><img src="/images/2025/09/rag3.webp" alt="rag3"/></span></p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_embeddings_and_vectors">Embeddings and Vectors&nbsp;<a class="headline-hash" href="#_embeddings_and_vectors">ðŸ”—</a> </h2>
<div class="sectionbody">
<div class="paragraph">
<p>So how do we get this additional context?
Or rather, how do we do the <strong>Retrieval</strong> of data with which we can <strong>Augment</strong> our <strong>Generation</strong>?</p>
</div>
<div class="paragraph">
<p>Well, you could literally run a SQL query, as illustrated above.
You could have your client make API calls to get data, you could even use an <a href="/2025/09/04/stumbling-into-ai-part-1mcp/">MCP server</a>â€”the end result is the same: the LLM is getting additional context to help it do what you want it to do.</p>
</div>
<div class="paragraph">
<p>One common pattern for the implementation of RAG is the use of vector databases.
In fact, so common I would say itâ€™s become synonymous.
The reason that itâ€™s so widely used is that whilst a SQL lookup is excellent for working with <em>structured</em> data (e.g. &#34;where does my customer live&#34;), thatâ€™s often not the kind of additional context that we want to provide to the LLM.</p>
</div>
<div class="paragraph">
<p>What if weâ€™re working with <em>text</em>?
Whilst LLMs are trained on a metric crap-ton of publicly available text, thereâ€™s material out there that they donâ€™t know about.
That could be content that was created after the LLM was trained (for example, the release notes for the latest version of Apache Kafka).
Often, in the context of RAG, itâ€™s material internal to a company such as documentation, wikis, emails, Slack conversationsâ€¦any manner of content.</p>
</div>
<div class="paragraph">
<p>To use this text data in RAG, a representation (&#34;<em>embedding</em>&#34;) of the <em>semantic meaning</em> of the text is created, and stored as a <em>vector</em>.
This is the <em>RAG Ingestion</em> part.
Once the data is stored, it can be used in <em>RAG Retrieval</em>.
What this does is take the userâ€™s query and convert that to an embedding too.
It then compares the queryâ€™s vector with those held in the vector store (populated by the ingest process) and finds the piece of textual data (&#34;embedding&#34;) thatâ€™s most closely related to it.
This piece of additional information is then included in the LLM request, in exactly the same manner we saw aboveâ€”adding context to the existing prompt.</p>
</div>
<div class="paragraph">
<p>The <a href="https://ollama.com/blog/embedding-models">Ollama blog</a> has a nice example which Iâ€™m going to use here, demonstrating the Kafka version example I showed above.</p>
</div>
<div class="sect2">
<h3 id="_rag_ingestion_populating_a_vector_database_with_embeddings">RAG Ingestion: Populating a vector database with embeddings&nbsp;<a class="headline-hash" href="#_rag_ingestion_populating_a_vector_database_with_embeddings">ðŸ”—</a> </h3>
<div class="paragraph">
<p>First, set up the environment.
Weâ€™re using <a href="https://docs.trychroma.com/">ChromaDB</a> as an in-memory vector store.
<a href="https://ollama.com/">Ollama</a> is a tool for running models locally.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="python"><span style="color: #f92672;font-weight: bold">import</span> <span style="color: #f8f8f2">ollama</span>
<span style="color: #f92672;font-weight: bold">import</span> <span style="color: #f8f8f2">chromadb</span>
<span style="color: #f8f8f2;background-color: #49483e">client</span> <span style="color: #f92672;font-weight: bold">=</span> <span style="color: #f8f8f2;background-color: #49483e">chromadb</span><span style="color: #f8f8f2;background-color: #49483e">.</span><span style="color: #f8f8f2;background-color: #49483e">Client</span><span style="color: #f8f8f2;background-color: #49483e">()</span>
<span style="color: #f8f8f2;background-color: #49483e">collection</span> <span style="color: #f92672;font-weight: bold">=</span> <span style="color: #f8f8f2;background-color: #49483e">client</span><span style="color: #f8f8f2;background-color: #49483e">.</span><span style="color: #f8f8f2;background-color: #49483e">create_collection</span><span style="color: #f8f8f2;background-color: #49483e">(</span><span style="color: #f8f8f2;background-color: #49483e">name</span><span style="color: #f92672;font-weight: bold">=</span><span style="color: #e6db74">&#34;docs&#34;</span><span style="color: #f8f8f2;background-color: #49483e">)</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Now we define our &#39;documents&#39;.
This is a very simplified example.
In practice we could be ingesting entire wikis or codebases of information.
The vital bit is how we carve it up, which is known as <em>chunking</em>.
A <em>chunk</em> is what will get passed to the LLM for enriching the context, so it needs to be big enough to be useful, but not so big that it is unhelpful (e.g. blows the token limit on the LLM, provides context that is not specific enough, etc).</p>
</div>
<div class="paragraph">
<p>Here Iâ€™ve manually pasted excerpts of the <a href="https://kafka.apache.org/blog">Apache Kafka 4.1.0 release blog post</a> (Iâ€™ve cropped the text in the code sample here, just for clarity of layout):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="python"><span style="color: #f8f8f2;background-color: #49483e">documents</span> <span style="color: #f92672;font-weight: bold">=</span> <span style="color: #f8f8f2;background-color: #49483e">[</span>
  <span style="color: #e6db74">&#34;4 September 2025 - We are proud to announce the release of Apache KafkaÂ® 4.1.0. This release contai[â€¦]&#34;</span><span style="color: #f8f8f2;background-color: #49483e">,</span>
  <span style="color: #e6db74">&#34;KIP-877: Mechanism for plugins and connectors to register metrics Many client-side plugins can now [â€¦]&#34;</span><span style="color: #f8f8f2;background-color: #49483e">,</span>
  <span style="color: #e6db74">&#34;KIP-932: Queues for Kafka (Early Access) This KIP introduces the concept of a share group as a way [â€¦]&#34;</span><span style="color: #f8f8f2;background-color: #49483e">,</span>
  <span style="color: #e6db74">&#34;KIP-996: Pre-Vote KIP-996 introduces a &#39;Pre-Vote&#39; mechanism to reduce unnecessary KRaft leader elec[â€¦]&#34;</span>
<span style="color: #f8f8f2;background-color: #49483e">]</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>For each of these documents we call an <em>embedding model</em> (which is <strong>not</strong> an LLM!) which captures the semantic meaning of the text and encodes it in a series of vectors which are added to the ChromaDB <code>collection</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="python"><span style="color: #66d9ef;font-weight: bold">for</span> <span style="color: #f8f8f2;background-color: #49483e">i</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">d</span> <span style="color: #f92672;font-weight: bold">in</span> <span style="color: #f8f8f2">enumerate</span><span style="color: #f8f8f2;background-color: #49483e">(</span><span style="color: #f8f8f2;background-color: #49483e">documents</span><span style="color: #f8f8f2;background-color: #49483e">):</span>
  <span style="color: #f8f8f2;background-color: #49483e">response</span> <span style="color: #f92672;font-weight: bold">=</span> <span style="color: #f8f8f2;background-color: #49483e">ollama</span><span style="color: #f8f8f2;background-color: #49483e">.</span><span style="color: #f8f8f2;background-color: #49483e">embed</span><span style="color: #f8f8f2;background-color: #49483e">(</span><span style="color: #f8f8f2;background-color: #49483e">model</span><span style="color: #f92672;font-weight: bold">=</span><span style="color: #e6db74">&#34;mxbai-embed-large&#34;</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2">input</span><span style="color: #f92672;font-weight: bold">=</span><span style="color: #f8f8f2;background-color: #49483e">d</span><span style="color: #f8f8f2;background-color: #49483e">)</span>
  <span style="color: #f8f8f2;background-color: #49483e">embeddings</span> <span style="color: #f92672;font-weight: bold">=</span> <span style="color: #f8f8f2;background-color: #49483e">response</span><span style="color: #f8f8f2;background-color: #49483e">[</span><span style="color: #e6db74">&#34;embeddings&#34;</span><span style="color: #f8f8f2;background-color: #49483e">]</span>

  <span style="color: #75715e;font-style: italic"># Store the embeddings in ChromaDB
</span>  <span style="color: #f8f8f2;background-color: #49483e">collection</span><span style="color: #f8f8f2;background-color: #49483e">.</span><span style="color: #f8f8f2;background-color: #49483e">add</span><span style="color: #f8f8f2;background-color: #49483e">(</span>
    <span style="color: #f8f8f2;background-color: #49483e">ids</span><span style="color: #f92672;font-weight: bold">=</span><span style="color: #f8f8f2;background-color: #49483e">[</span><span style="color: #f8f8f2">str</span><span style="color: #f8f8f2;background-color: #49483e">(</span><span style="color: #f8f8f2;background-color: #49483e">i</span><span style="color: #f8f8f2;background-color: #49483e">)],</span>
    <span style="color: #f8f8f2;background-color: #49483e">embeddings</span><span style="color: #f92672;font-weight: bold">=</span><span style="color: #f8f8f2;background-color: #49483e">embeddings</span><span style="color: #f8f8f2;background-color: #49483e">,</span>
    <span style="color: #f8f8f2;background-color: #49483e">documents</span><span style="color: #f92672;font-weight: bold">=</span><span style="color: #f8f8f2;background-color: #49483e">[</span><span style="color: #f8f8f2;background-color: #49483e">d</span><span style="color: #f8f8f2;background-color: #49483e">]</span>
  <span style="color: #f8f8f2;background-color: #49483e">)</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>The model used here is <a href="https://www.mixedbread.com/blog/mxbai-embed-large-v1"><code>mxbai-embed-large</code></a>.</p>
</div>
<div class="paragraph">
<p>For interest, hereâ€™s what the data weâ€™re storing in the vector database looks like:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code>ID: 0
Document: 4 September 2025 - We are proud to announce the release of Apache KafkaÂ® 4.1.0. This relea[â€¦]
Embedding: [ 0.05642379 -0.02119605 -0.04147635  0.05452667 -0.01146116]...

ID: 1
Document: KIP-877: Mechanism for plugins and connectors to register metrics Many client-side plugins[â€¦]
Embedding: [-0.01764962 -0.00686921 -0.03395142  0.00759143 -0.02553692]...

ID: 2
Document: KIP-932: Queues for Kafka (Early Access) This KIP introduces the concept of a share group [â€¦]
Embedding: [0.05048409 0.00816069 0.00764809 0.03790297 0.00651639]...

ID: 3
Document: KIP-996: Pre-Vote KIP-996 introduces a &#39;Pre-Vote&#39; mechanism to reduce unnecessary KRaft le[â€¦]
Embedding: [ 0.04927347 -0.02349585  0.01001445  0.01915772 -0.010186  ]...</code></pre>
</div>
</div>
<div class="paragraph">
<p>So the vector database holds the <em>actual document (chunk) data</em>, along with the embedding representation.</p>
</div>
<div class="paragraph">
<p>Thatâ€™s all, so far.
A static set of text data, stored in a way that represents the <em>semantic meaning</em> of the data.</p>
</div>
<div class="paragraph">
<p>You do this process once, or add to the vector database as new documents are needed (for example, when Apache Kafka 4.2.0 is released).</p>
</div>
</div>
<div class="sect2">
<h3 id="_rag_retrieval_using_embeddings_to_provide_context_to_an_llm">RAG Retrieval: Using embeddings to provide context to an LLM&nbsp;<a class="headline-hash" href="#_rag_retrieval_using_embeddings_to_provide_context_to_an_llm">ðŸ”—</a> </h3>
<div class="paragraph">
<p>Now our merry user arrives with their LLM client, and wants to know the latest version of Kafka.</p>
</div>
<div class="paragraph">
<p>Left to its own devices, the LLM only knows what it was trained with, which will have a cutoff date.
Sometimes the LLM will tell you that, sometimes it wonâ€™t.</p>
</div>
<div class="paragraph">
<p>Instead of <code>ollama.embed</code>, letâ€™s use <code>ollama.generate</code> with the <code>llama3.2</code> LLM to generate the answer to the question with no additional context:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="python"><span style="color: #f8f8f2;background-color: #49483e">user_input</span> <span style="color: #f92672;font-weight: bold">=</span> <span style="color: #e6db74">&#34;what&#39;s the latest version of kafka?&#34;</span>

<span style="color: #f8f8f2;background-color: #49483e">prompt</span><span style="color: #f92672;font-weight: bold">=</span><span style="color: #66d9ef;font-weight: bold">f</span><span style="color: #e6db74">&#34;Respond to this prompt: </span><span style="color: #e6db74">{</span><span style="color: #f8f8f2;background-color: #49483e">user_input</span><span style="color: #e6db74">}</span><span style="color: #e6db74">&#34;</span>

<span style="color: #f8f8f2;background-color: #49483e">output</span> <span style="color: #f92672;font-weight: bold">=</span> <span style="color: #f8f8f2;background-color: #49483e">ollama</span><span style="color: #f8f8f2;background-color: #49483e">.</span><span style="color: #f8f8f2;background-color: #49483e">generate</span><span style="color: #f8f8f2;background-color: #49483e">(</span>
  <span style="color: #f8f8f2;background-color: #49483e">model</span><span style="color: #f92672;font-weight: bold">=</span><span style="color: #e6db74">&#34;llama3.2&#34;</span><span style="color: #f8f8f2;background-color: #49483e">,</span>
  <span style="color: #f8f8f2;background-color: #49483e">prompt</span><span style="color: #f92672;font-weight: bold">=</span><span style="color: #f8f8f2;background-color: #49483e">prompt</span>
<span style="color: #f8f8f2;background-color: #49483e">)</span>
<span style="color: #66d9ef;font-weight: bold">print</span><span style="color: #f8f8f2;background-color: #49483e">(</span><span style="color: #66d9ef;font-weight: bold">f</span><span style="color: #e6db74">&#34;</span><span style="color: #e6db74">{</span><span style="color: #f8f8f2;background-color: #49483e">prompt</span><span style="color: #e6db74">}</span><span style="color: #ae81ff">\n</span><span style="color: #e6db74">-----</span><span style="color: #ae81ff">\n</span><span style="color: #e6db74">{</span><span style="color: #f8f8f2;background-color: #49483e">output</span><span style="color: #f8f8f2;background-color: #49483e">[</span><span style="color: #e6db74">&#39;response&#39;</span><span style="color: #f8f8f2;background-color: #49483e">]</span><span style="color: #e6db74">}</span><span style="color: #ae81ff">\n\n</span><span style="color: #e6db74">=-=-=-=-&#34;</span><span style="color: #f8f8f2;background-color: #49483e">)</span></code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code>Respond to this prompt: what&#39;s the latest version of kafka?
____
As of my knowledge cutoff in December 2023, the latest version of Apache Kafka is 3.4.</code></pre>
</div>
</div>
<div class="paragraph">
<p>OKâ€”so as expected, not up-to-date, at all.
What weâ€™d like to do is help out the LLM by giving it some more context.</p>
</div>
<div class="paragraph">
<p>We canâ€™t throw our entire library of knowledge at itâ€”that wouldnâ€™t work (too many tokens, not specific enough).
Instead, weâ€™re going to work out within our library, which document <em>is most relevant <strong>to the query</strong></em>.</p>
</div>
<div class="paragraph">
<p>The first step is to generate an embedding for our query, using the same model with which we created the embeddings for the documents in the vector database (the &#34;library&#34; to which Iâ€™m figuratively referring).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="python"><span style="color: #f8f8f2;background-color: #49483e">user_input</span> <span style="color: #f92672;font-weight: bold">=</span> <span style="color: #e6db74">&#34;what&#39;s the latest version of kafka?&#34;</span>

<span style="color: #f8f8f2;background-color: #49483e">response</span> <span style="color: #f92672;font-weight: bold">=</span> <span style="color: #f8f8f2;background-color: #49483e">ollama</span><span style="color: #f8f8f2;background-color: #49483e">.</span><span style="color: #f8f8f2;background-color: #49483e">embed</span><span style="color: #f8f8f2;background-color: #49483e">(</span>
  <span style="color: #f8f8f2;background-color: #49483e">model</span><span style="color: #f92672;font-weight: bold">=</span><span style="color: #e6db74">&#34;mxbai-embed-large&#34;</span><span style="color: #f8f8f2;background-color: #49483e">,</span>
  <span style="color: #f8f8f2">input</span><span style="color: #f92672;font-weight: bold">=</span><span style="color: #f8f8f2;background-color: #49483e">user_input</span>
<span style="color: #f8f8f2;background-color: #49483e">)</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>The vector looks like this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code>[[0.017346583, -0.021703502, -0.0436593, 0.045320738, -0.0005510414, -0.038553298, 0.016 [â€¦]</code></pre>
</div>
</div>
<div class="paragraph">
<p>which to you or I might not mean much, but when passed to the vector database as a <code>.query</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="python"><span style="color: #f8f8f2;background-color: #49483e">results</span> <span style="color: #f92672;font-weight: bold">=</span> <span style="color: #f8f8f2;background-color: #49483e">collection</span><span style="color: #f8f8f2;background-color: #49483e">.</span><span style="color: #f8f8f2;background-color: #49483e">query</span><span style="color: #f8f8f2;background-color: #49483e">(</span>
  <span style="color: #f8f8f2;background-color: #49483e">query_embeddings</span><span style="color: #f92672;font-weight: bold">=</span><span style="color: #f8f8f2;background-color: #49483e">response</span><span style="color: #f8f8f2;background-color: #49483e">[</span><span style="color: #e6db74">&#34;embeddings&#34;</span><span style="color: #f8f8f2;background-color: #49483e">],</span>
  <span style="color: #f8f8f2;background-color: #49483e">n_results</span><span style="color: #f92672;font-weight: bold">=</span><span style="color: #ae81ff">1</span>
<span style="color: #f8f8f2;background-color: #49483e">)</span>
<span style="color: #f8f8f2;background-color: #49483e">data</span> <span style="color: #f92672;font-weight: bold">=</span> <span style="color: #f8f8f2;background-color: #49483e">results</span><span style="color: #f8f8f2;background-color: #49483e">[</span><span style="color: #e6db74">&#39;documents&#39;</span><span style="color: #f8f8f2;background-color: #49483e">][</span><span style="color: #ae81ff">0</span><span style="color: #f8f8f2;background-color: #49483e">][</span><span style="color: #ae81ff">0</span><span style="color: #f8f8f2;background-color: #49483e">]</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>returns the document that is the most closely related, semantically:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code>4 September 2025 - We are proud to announce the release of Apache KafkaÂ® 4.1.0. This release contains many new features and improvements. [â€¦]</code></pre>
</div>
</div>
<div class="paragraph">
<p>Weâ€™ve now <strong>retrieved</strong> the <strong>additional</strong> context with which we can now do the generation.
The prompt is the same as before, except we include the document that we retrieved from the vector database in it too:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="python"><span style="color: #f8f8f2;background-color: #49483e">prompt</span><span style="color: #f92672;font-weight: bold">=</span><span style="color: #66d9ef;font-weight: bold">f</span><span style="color: #e6db74">&#34;Using this data: </span><span style="color: #e6db74">{</span><span style="color: #f8f8f2;background-color: #49483e">data</span><span style="color: #e6db74">}</span><span style="color: #e6db74">. Respond to this prompt: </span><span style="color: #e6db74">{</span><span style="color: #f8f8f2;background-color: #49483e">user_input</span><span style="color: #e6db74">}</span><span style="color: #e6db74">&#34;</span>
<span style="color: #f8f8f2;background-color: #49483e">output</span> <span style="color: #f92672;font-weight: bold">=</span> <span style="color: #f8f8f2;background-color: #49483e">ollama</span><span style="color: #f8f8f2;background-color: #49483e">.</span><span style="color: #f8f8f2;background-color: #49483e">generate</span><span style="color: #f8f8f2;background-color: #49483e">(</span>
  <span style="color: #f8f8f2;background-color: #49483e">model</span><span style="color: #f92672;font-weight: bold">=</span><span style="color: #e6db74">&#34;llama3.2&#34;</span><span style="color: #f8f8f2;background-color: #49483e">,</span>
  <span style="color: #f8f8f2;background-color: #49483e">prompt</span><span style="color: #f92672;font-weight: bold">=</span><span style="color: #f8f8f2;background-color: #49483e">prompt</span>
<span style="color: #f8f8f2;background-color: #49483e">)</span></code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code>Using this data: 4 September 2025 - We are proud to announce the release of Apache KafkaÂ® 4.1.0. This release contains many new features and improvements. This blog post will highlight some of the more prominent ones. For a full list of changes, be sure to check the release notes. Queues for Kafka (KIP-932) is now in preview. It&#39;s still not ready for production but you can start evaluating and testing it. See the preview release notes for more details. This release also introduces a new Streams Rebalance Protocol (KIP-1071) in early access. It is based on the new consumer group protocol (KIP-848). See the Upgrading to 4.1 section in the documentation for the list of notable changes and detailed upgrade steps..
Respond to this prompt: what&#39;s the latest version of kafka?
____
The latest version of Kafka mentioned in the data is Apache Kafka 4.1.0, which was released on September 4, 2025.</code></pre>
</div>
</div>
<div class="paragraph">
<p>There we goâ€“our LLM used the context from the release notes to not only tell us the latest version, but also its release date.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_and_then_the_snake_ate_its_own_tail">And then the snake ate its own tail&nbsp;<a class="headline-hash" href="#_and_then_the_snake_ate_its_own_tail">ðŸ”—</a> </h2>
<div class="sectionbody">
<div class="paragraph">
<p>In writing this article I made a rookie mistake.
No surprise there; but one worth illustrating here.</p>
</div>
<div class="paragraph">
<p>I use LLMs a lot to help my writingâ€”never to <em>write</em> but to help generate code, for example.
The embeddings example on the <a href="https://ollama.com/blog/embedding-models">Ollama blog</a> had these documents:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="python"><span style="color: #f8f8f2;background-color: #49483e">documents</span> <span style="color: #f92672;font-weight: bold">=</span> <span style="color: #f8f8f2;background-color: #49483e">[</span>
  <span style="color: #e6db74">&#34;Llamas are members of the camelid family meaning they&#39;re pretty closely related to vicuÃ±as and camels&#34;</span><span style="color: #f8f8f2;background-color: #49483e">,</span>
  <span style="color: #e6db74">&#34;Llamas were first domesticated and used as pack animals 4,000 to 5,000 years ago in the Peruvian highlands&#34;</span><span style="color: #f8f8f2;background-color: #49483e">,</span>
  <span style="color: #e6db74">&#34;Llamas can grow as much as 6 feet tall though the average llama between 5 feet 6 inches and 5 feet 9 inches tall&#34;</span><span style="color: #f8f8f2;background-color: #49483e">,</span>
  <span style="color: #e6db74">&#34;Llamas weigh between 280 and 450 pounds and can carry 25 to 30 percent of their body weight&#34;</span><span style="color: #f8f8f2;background-color: #49483e">,</span>
  <span style="color: #e6db74">&#34;Llamas are vegetarians and have very efficient digestive systems&#34;</span><span style="color: #f8f8f2;background-color: #49483e">,</span>
  <span style="color: #e6db74">&#34;Llamas live to be about 20 years old, though some only live for 15 years and others live to be 30 years old&#34;</span><span style="color: #f8f8f2;background-color: #49483e">,</span>
<span style="color: #f8f8f2;background-color: #49483e">]</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Cute, but nothing to do with my domain.
So I did as I often doâ€”chuck it over to an LLM.</p>
</div>
<div class="paragraph">
<p><span class="image"><img src="/images/2025/09/8310d728162d567b92f79e2be71aebb3f6b7e66fee68d6d0d7fcee0f3a62c8c5.webp" alt="8310d728162d567b92f79e2be71aebb3f6b7e66fee68d6d0d7fcee0f3a62c8c5"/></span></p>
</div>
<div class="paragraph">
<p>Feeling smug, I copied this into my Python code and added a couple more documents (chunks) to illustrate the point about release version freshness:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="python"><span style="color: #f8f8f2;background-color: #49483e">documents</span> <span style="color: #f92672;font-weight: bold">=</span> <span style="color: #f8f8f2;background-color: #49483e">[</span>
    <span style="color: #e6db74">&#34;The latest version of Apache Kafka is 4.1&#34;</span><span style="color: #f8f8f2;background-color: #49483e">,</span>
    <span style="color: #e6db74">&#34;KIP-932 adds support for traditional message queue semantics to Kafka&#34;</span><span style="color: #f8f8f2;background-color: #49483e">,</span>
    <span style="color: #e6db74">&#34;Apache Kafka is a distributed event streaming platform originally developed by LinkedIn and later open-sourced to the Apache Software Foundation&#34;</span><span style="color: #f8f8f2;background-color: #49483e">,</span>
    <span style="color: #e6db74">&#34;Kafka was first released in 2011 and is written primarily in Scala and Java, designed to handle high-throughput, low-latency data streaming&#34;</span><span style="color: #f8f8f2;background-color: #49483e">,</span>
    <span style="color: #e6db74">&#34;Kafka clusters can scale horizontally across multiple servers and can handle millions of messages per second with sub-millisecond latency&#34;</span><span style="color: #f8f8f2;background-color: #49483e">,</span>
    <span style="color: #e6db74">&#34;Kafka uses a publish-subscribe messaging model where producers write data to topics and consumers read from those topics in real-time&#34;</span><span style="color: #f8f8f2;background-color: #49483e">,</span>
    <span style="color: #e6db74">&#34;Kafka provides durability through configurable data replication and can retain messages for days, weeks, or even indefinitely depending on configuration&#34;</span><span style="color: #f8f8f2;background-color: #49483e">,</span>
    <span style="color: #e6db74">&#34;Kafka is widely used by companies like Netflix, Uber, Airbnb, and thousands of other organizations for real-time analytics, log aggregation, and event-driven architectures&#34;</span>
<span style="color: #f8f8f2;background-color: #49483e">]</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>But when it came to comparing LLM responses using RAG and this data, it didnâ€™t really make much difference in some cases:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code>Respond to this prompt: what is Apache Kafka? Give me one sentence. <i class="conum" data-value="1"></i><b>(1)</b>
____
Apache Kafka is a distributed streaming platform that enables real-time data processing and event-driven architecture, providing fault-tolerant and scalable messaging capabilities for large-scale data ingestion, storage, and analysis.

=-=-=-=-
Using this data: Apache Kafka is a distributed event streaming platform originally developed by LinkedIn and later open-sourced to the Apache Software Foundation. Respond to this prompt: what is Apache Kafka? Give me one sentence. <i class="conum" data-value="2"></i><b>(2)</b>
____
Apache Kafka is a distributed event streaming platform that enables scalable, fault-tolerant, and secure data processing and consumption for real-time applications.

=-=-=-=-</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tbody><tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>No RAG</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>With RAG</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>Whyâ€™s the output basically the same?
Because the LLM <em>already knows</em> what Apache Kafka is!
If it didnâ€™t, how would it have generated the <code>documents</code> array above?</p>
</div>
<div class="paragraph">
<p><em>(technically I used Claude 4 Sonnet to generate the array and Llama 3.2 in my Python scriptâ€”but basically the same principle)</em>.</p>
</div>
<div class="paragraph">
<p>One lesson, but to express in two different ways from this:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>RAG content only makes sense if itâ€™s not already in the LLM</p>
</li>
<li>
<p>Donâ€™t use LLMs to generate RAG content</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>There are probably a bunch of nuances to this.
For example, could you use a more powerful LLM to distill down content for use in RAG by a smaller LLM (cheaper/faster to run)?
Tell me in the comments belowâ€”Iâ€™m here to learn :)</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_further_reading">Further reading&nbsp;<a class="headline-hash" href="#_further_reading">ðŸ”—</a> </h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>ðŸŽ¥ <a href="https://www.youtube.com/watch?v=T-D1OfcDW1M">Marina Danilevsky - What is RAG</a>.</p>
</li>
<li>
<p>Tons of great content in <a href="https://www.infoq.com/presentations/llm-data-code-model-prompt/">this talk from Paul Iusztin at QCon London 2025</a>, including lots about RAG (at around 24 minutes in).</p>
</li>
</ul>
</div>
</div>
</div>
	<hr>
	<div class="giscus-container">
		<script src="https://giscus.app/client.js"
				data-repo="rmoff/rmoff-blog"
				data-repo-id="MDEwOlJlcG9zaXRvcnkxNTE3NDg2MTE="
				data-category="Announcements"
				data-category-id="DIC_kwDOCQuAA84CvP5T"
				data-mapping="pathname"
				data-strict="1"
				data-reactions-enabled="1"
				data-emit-metadata="0"
				data-input-position="bottom"
				data-theme="light"
				data-lang="en"
				crossorigin="anonymous"
				async>
		</script>
	</div>
</article>
      </main>
    
      
      <div class="docs-toc">
        <ul class="nav toc-top">
          <li><a href="#" id="back_to_top" class="docs-toc-title">On this page</a></li>
        </ul>
        <nav id="TableOfContents">
  <ul>
    <li><a href="#_rag_basics">RAG basics</a></li>
    <li><a href="#_embeddings_and_vectors">Embeddings and Vectors</a>
      <ul>
        <li><a href="#_rag_ingestion_populating_a_vector_database_with_embeddings">RAG Ingestion: Populating a vector database with embeddings</a></li>
        <li><a href="#_rag_retrieval_using_embeddings_to_provide_context_to_an_llm">RAG Retrieval: Using embeddings to provide context to an LLM</a></li>
      </ul>
    </li>
    <li><a href="#_and_then_the_snake_ate_its_own_tail">And then the snake ate its own tail</a></li>
    <li><a href="#_further_reading">Further reading</a></li>
  </ul>
</nav>
      </div>
      
    
    </div>
  </div>
</div>


		</main>

		

		
		<footer class="site-footer hide-print" role="contentinfo">
			<span>&copy; 2026 </span>
		</footer>
		

		
	</body>
</html>
