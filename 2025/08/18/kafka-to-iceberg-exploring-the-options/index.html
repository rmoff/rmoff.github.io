<!DOCTYPE html>
<html lang="en">
	<head>
		<meta http-equiv=X-Clacks-Overhead content="GNU Terry Pratchett">
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<title>Kafka to Iceberg - Exploring the Options</title>
		<link rel="alternate" type="application/rss+xml" title="RSS" href="https://rmoff.net/index.xml">
		<link rel="canonical" href="https://rmoff.net/2025/08/18/kafka-to-iceberg-exploring-the-options/">
		
		<script src="/js/copy-code.js"></script>
		
		
		
		

		
		<meta property="og:title" content="Kafka to Iceberg - Exploring the Options" />
		<meta property="og:type" content="article" />
		<meta property="og:image" content="https://rmoff.net/images/2025/08/h_IMG_2136.webp" />
		<meta property="og:description" content="" />
		<meta property="og:url" content="https://rmoff.net/2025/08/18/kafka-to-iceberg-exploring-the-options/" />
		<meta property="og:site_name" content="Kafka to Iceberg - Exploring the Options" />
		<meta name="twitter:card" content="summary_large_image" />
		<meta name="twitter:site" content="@" />


		
		<link rel="stylesheet" href="https://rmoff.net/css/tachyons.min.css" />
		<link rel="stylesheet" href="https://rmoff.net/css/story.css" />
		<link rel="stylesheet" href="https://rmoff.net/css/descartes.css" />
		<link rel="stylesheet" href="https://rmoff.net/css/toc.css" />
		<link rel="stylesheet" href="https://rmoff.net/css/retro-cards.css" />
		<link rel="stylesheet" href="https://rmoff.net/css/custom.css" />
		
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css">
		<link href="https://fonts.googleapis.com/css?family=Quattrocento+Sans:400,400i,700,700i|Quattrocento:400,700|Spectral:400,400i,700,700i&amp;subset=latin-ext" rel="stylesheet">
		
		
		<script>
			!function(t,e){var o,n,p,r;e.__SV||(window.posthog=e,e._i=[],e.init=function(i,s,a){function g(t,e){var o=e.split(".");2==o.length&&(t=t[o[0]],e=o[1]),t[e]=function(){t.push([e].concat(Array.prototype.slice.call(arguments,0)))}}(p=t.createElement("script")).type="text/javascript",p.crossOrigin="anonymous",p.async=!0,p.src=s.api_host.replace(".i.posthog.com","-assets.i.posthog.com")+"/static/array.js",(r=t.getElementsByTagName("script")[0]).parentNode.insertBefore(p,r);var u=e;for(void 0!==a?u=e[a]=[]:a="posthog",u.people=u.people||[],u.toString=function(t){var e="posthog";return"posthog"!==a&&(e+="."+a),t||(e+=" (stub)"),e},u.people.toString=function(){return u.toString(1)+".people (stub)"},o="init capture register register_once register_for_session unregister unregister_for_session getFeatureFlag getFeatureFlagPayload isFeatureEnabled reloadFeatureFlags updateEarlyAccessFeatureEnrollment getEarlyAccessFeatures on onFeatureFlags onSessionId getSurveys getActiveMatchingSurveys renderSurvey canRenderSurvey getNextSurveyStep identify setPersonProperties group resetGroups setPersonPropertiesForFlags resetPersonPropertiesForFlags setGroupPropertiesForFlags resetGroupPropertiesForFlags reset get_distinct_id getGroups get_session_id get_session_replay_url alias set_config startSessionRecording stopSessionRecording sessionRecordingStarted captureException loadToolbar get_property getSessionProperty createPersonProfile opt_in_capturing opt_out_capturing has_opted_in_capturing has_opted_out_capturing clear_opt_in_out_capturing debug".split(" "),n=0;n<o.length;n++)g(u,o[n]);e._i.push([i,s,a])},e.__SV=1)}(document,window.posthog||[]);
            posthog.init('phc_93NEP79Ju4xqXYWXnoLbr4HMW0Iaepj1BGOVoEXYX6P',{api_host:'https://eu.i.posthog.com', person_profiles: 'identified_only' 
                })
		</script>
		
		<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
		
		<script src="https://rmoff.net/js/story.js"></script>
		<script src="https://rmoff.net/js/toc.js"></script>

	</head>
	<body class="ma0 bg-white section-post page-kind-page is-page-true ">
		
		<header class="cover bg-top" style="background-image: url('https://rmoff.net/images/2025/08/h_IMG_2136.webp'); background-position: center;">
			<div class="bg-black-30 bb bt">

				<nav class="hide-print sans-serif  border-box pa3 ph5-l">
					<a href="https://rmoff.net" title="Home">
						<link rel="preload" as="image" href="https://rmoff.net/img/repton.gif">
						<img
							src="https://rmoff.net/img/logo.jpg"
							class="w2 h2 br-100"
							alt="rmoff&#39;s random ramblings"
							onmouseover="this.src='https:\/\/rmoff.net\/img\/repton.gif';"
							onmouseout="this.src='https:\/\/rmoff.net\/img\/logo.jpg';"
						/>
					</a>
					<div class="fr h2 pv2 tr">
						<a class="link f5 ml2 dim near-white" href="https://talks.rmoff.net/bio">about</a>
						<a class="link f5 ml2 dim near-white" href="https://talks.rmoff.net">talks</a>
						<a class="link f5 ml2 dim near-white" href="https://bsky.app/profile/rmoff.net"><i class="fa-brands fa-bluesky"></i></a>
						<a class="link f5 ml2 dim near-white" href="https://github.com/rmoff/"><i class="fab fa-github-square"></i></a>
						<a class="link f5 ml2 dim near-white" href="https://www.youtube.com/c/rmoff"><i class="fab fa-youtube-square"></i></a>
						<a class="link f5 ml2 dim near-white" href="https://www.linkedin.com/in/robinmoffatt/"><i class="fab fa-linkedin"></i></a>
						<a class="link f5 ml2 dim near-white fas fa-rss-square" href="https://rmoff.net/index.xml" title="RSS Feed"></a>
						<a class="link f5 ml2 dim near-white fas fa-search" href="https://rmoff.net/search/" role="search" title="Search"></a>
					</div>
				</nav>

				<div id="hdr" class="tc-l pv4-ns pv5-l pv2 ph3 ph4-ns">
					<h1 class="near-white mt1-ns f2 fw3 mb0 mt0 lh-title">
						<span class="terminal-title">Kafka to Iceberg - Exploring the Options<span class="terminal-cursor"></span></span>
					</h1>
					<h2 class="near-white mt3-l mb4-l fw1 f6 f3-l measure-wide-l center lh-copy mt2 mb3">
						
						
							
								Published
								<time datetime="2025-08-18T13:43:31Z">Aug 18, 2025</time>
								<span class="display-print">by </span>
								 in <a href="https://rmoff.net/categories/apache-iceberg" class="no-underline category near-white dim">Apache Iceberg</a>, <a href="https://rmoff.net/categories/apache-kafka" class="no-underline category near-white dim">Apache Kafka</a>, <a href="https://rmoff.net/categories/apache-flink" class="no-underline category near-white dim">Apache Flink</a>, <a href="https://rmoff.net/categories/kafka-connect" class="no-underline category near-white dim">Kafka Connect</a>, <a href="https://rmoff.net/categories/tableflow" class="no-underline category near-white dim">Tableflow</a>
								<span class="display-print">at https://rmoff.net/2025/08/18/kafka-to-iceberg-exploring-the-options/</span>
							
						
					</h2>
				</div>

				
				
				
				<div class="w-100 cf hide-print">
					<a class="fr f6 ma0 pa2 link white-50 dim fas fa-camera" href="https://bsky.app/profile/rmoff.net" title="Photo Credit"></a>
				</div>
				
				

			</div>
		</header>
		
		<main role="main">
		
<div class="container-fluid docs">
  <div class="row">
    <main class="docs-content" role="main">

<article class="article">
	<div class="paragraph">
<p>Youâ€™ve got data in <a href="https://www.youtube.com/watch?v=9CrlA0Wasvk">Apache Kafka</a>.</p>
</div>
<div class="paragraph">
<p>You want to get that data into <a href="https://www.youtube.com/watch?v=TsmhRZElPvM">Apache Iceberg</a>.</p>
</div>
<div class="paragraph">
<p>Whatâ€™s the best way to do it?</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/2025/08/kafka-to-iceberg.png" alt="kafka to iceberg"/>
</div>
</div>
<div class="paragraph">
<p>Perhaps invariably, the answer is: <strong>IT DEPENDS</strong>.
But fear not: here is a guide to help you navigate your way to choosing the best solution <em>for you</em> ðŸ«µ.</p>
</div>
<div class="sect1">
<h2 id="_the_candidates">The Candidates&nbsp;<a class="headline-hash" href="#_the_candidates">ðŸ”—</a> </h2>
<div class="sectionbody">
<div class="paragraph">
<p>Iâ€™m considering three technologies in this blog post:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://nightlies.apache.org/flink/flink-docs-master/docs/dev/table/sql/gettingstarted/#hello-world">Apache Flink SQL</a> (open source)</p>
</li>
<li>
<p><a href="https://kafka.apache.org/documentation.html#connect">Kafka Connect</a> (open source)</p>
</li>
<li>
<p><a href="https://www.confluent.io/product/tableflow/">Confluent Tableflow</a> ($)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>There are others, and Iâ€™ll mention those <a href="#_but_what_about_this_other_tool">at the end</a>.
The one that Iâ€™ve really not looked at, and is perhaps conspicuous by its absence, is Apache Spark.
If youâ€™re interested in Spark, check out <a href="https://www.youtube.com/watch?v=5pXfznKniGg">this video from Danica Fine</a> in which she covers it.</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<em>Disclaimer: I work for Confluent, but will do my best to remain impartial in this article.</em> ðŸ˜€
</td>
</tr>
</tbody></table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_the_approach">The Approach&nbsp;<a class="headline-hash" href="#_the_approach">ðŸ”—</a> </h2>
<div class="sectionbody">
<div class="paragraph">
<p>Iâ€™ve framed this blog post around the key areas that you can use as the basis for making your decision.
Some of these will be show-stoppers and rule a particular option out, whilst others are simply gentle nudges that one tool might be preferred over another.</p>
</div>
<div class="paragraph">
<p>Iâ€™m going to break the areas of consideration down into two (and a bit) areas:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Your data</strong>: including where itâ€™s from, what youâ€™re doing with it, how itâ€™s structured, and how many topics</p>
</li>
<li>
<p><strong>Living with it</strong>: important factors such as whatâ€™s your existing deployment (if any), preference for self-managed vs SaaS, and table maintenance</p>
</li>
<li>
<p><strong>Other</strong>: licensing, support for other formats, other bits and pieces</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_tool_overview">Tool overview&nbsp;<a class="headline-hash" href="#_tool_overview">ðŸ”—</a> </h2>
<div class="sectionbody">
<div class="paragraph">
<p>Before we get into it, letâ€™s take a quick look at what the three tools are and how they integrate with Iceberg.</p>
</div>
<div class="sect2">
<h3 id="_apache_flink_sql">Apache Flink SQL&nbsp;<a class="headline-hash" href="#_apache_flink_sql">ðŸ”—</a> </h3>
<div class="admonitionblock tip">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
Read more: <a href="/2025/06/24/writing-to-apache-iceberg-on-s3-using-flink-sql-with-glue-catalog/">Writing to Apache Iceberg using Flink SQL</a>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>Flink SQL jobs run on a Flink cluster.
They do not require Kafka (unless you are specifically reading or writing to itâ€”such as in this article).</p>
</div>
<div class="paragraph">
<p>Source and targets are defined as tables using DDL, with the integration (such as Kafka or Iceberg) specified as a connector type.
Target tables are loaded as a stream using either <code>CREATE TABLE â€¦ AS SELECT</code> or a standalone <code>INSERT INTO</code> after defining the target table first.</p>
</div>
<div class="paragraph">
<p>There are some <a href="https://nightlies.apache.org/flink/flink-docs-master/docs/connectors/table/overview/#supported-connectors">connectors available within Flink</a>, along with notable standalone connectors including <a href="https://nightlies.apache.org/flink/flink-cdc-docs-master/docs/connectors/flink-sources/overview/">Flink CDC</a>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_kafka_connect">Kafka Connect&nbsp;<a class="headline-hash" href="#_kafka_connect">ðŸ”—</a> </h3>
<div class="admonitionblock tip">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
Read more: <a href="/2025/07/04/writing-to-apache-iceberg-on-s3-using-kafka-connect-with-glue-catalog/">Writing to Apache Iceberg using Kafka Connect</a>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>Kafka Connect runs on a Kafka Connect worker cluster.
It is a pluggable ecosystem, providing an integration runtime that handles common tasks whilst individual connectors handle the technology-specific requirements.
It uses a Kafka broker to track configuration and processing status.</p>
</div>
<div class="paragraph">
<p>You define <em>connector</em> jobs using JSON configuration, submitted using a REST API.
There are <a href="https://hub.confluent.io">hundreds of connectors</a> available for Kafka Connect.</p>
</div>
</div>
<div class="sect2">
<h3 id="_tableflow">Tableflow&nbsp;<a class="headline-hash" href="#_tableflow">ðŸ”—</a> </h3>
<div class="admonitionblock tip">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
Read more: <a href="https://www.confluent.io/blog/building-streaming-data-pipelines-part-1/#exposing-apache-kafka-topics-as-apache-icebergtm%EF%B8%8F-tables-with-tableflow">Exposing Kafka Topics as Iceberg Tables With Tableflow</a>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>Tableflow is a managed service as part of Confluent Cloud for streaming data from Apache Kafka topics into Apache Iceberg tables.
You can use it with any topic in Confluent Cloud that has a schema.</p>
</div>
<div class="paragraph">
<p>Confluent Cloud also provides <a href="https://docs.confluent.io/cloud/current/connectors/overview.html">managed connectors</a> (giving you access to a <a href="https://hub.confluent.io">huge ecosystem of source connectors</a>) and <a href="https://docs.confluent.io/cloud/current/flink/overview.html">managed Flink SQL</a> (for doing any processing on the data before sending it to Iceberg).</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_your_data">Your Data&nbsp;<a class="headline-hash" href="#_your_data">ðŸ”—</a> </h2>
<div class="sectionbody">
<div class="paragraph">
<p><em>Letâ€™s start off the comparison by thinking about the data that weâ€™ve got in Kafka and want to get into Iceberg.</em></p>
</div>
<div class="sect2">
<h3 id="_where_is_the_data_coming_from">Where is the data coming from?&nbsp;<a class="headline-hash" href="#_where_is_the_data_coming_from">ðŸ”—</a> </h3>
<div class="paragraph">
<p>This article is focussed on data <strong>in</strong> Kafka, but that data came from somewhere.
Perhaps itâ€™s applications writing directly to it, in which case it has no bearing on your technology of choice.
However, if your data is coming into Kafka from other systems, youâ€™ll find that <strong>Kafka Connect</strong> and Confluent Cloud (for <strong>Tableflow</strong>) have a richer set of connectors than <strong>Flink</strong>.
Flink does have several, including Flink CDC (which is built on Debezium).</p>
</div>
<div class="paragraph">
<p>Under this consideration also think about whether you want the data in Kafka for other purposes.
Flink can take data directly from a source (e.g. RDBMS) directly into Iceberg and not write it in Kafka.
This might simplify your pipeline, but it also means the same source data isnâ€™t then available for use by other integrations or applications.</p>
</div>
</div>
<div class="sect2">
<h3 id="_how_many_topics_do_you_have">How many topics do you have?&nbsp;<a class="headline-hash" href="#_how_many_topics_do_you_have">ðŸ”—</a> </h3>
<div class="paragraph">
<p>There are two variants of this.
The first is where you have multiple topics for <em>different entities</em>.
For example, youâ€™ve got <code>orders</code>, <code>customers</code>, <code>products</code>, <code>inventory</code>â€¦theyâ€™re all different, and theyâ€™re all going to their own respective Iceberg table.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/2025/08/different-topics.excalidraw.png" alt="different topics.excalidraw"/>
</div>
</div>
<div class="paragraph">
<p>The second is where itâ€™s multiple instances of <em>the same entity</em>.
This is very common in multi-tenant architectures.
Maybe each customer has their own <code>transactions</code> topic, and youâ€™re wanting to populate a single consolidated Iceberg table from them.
Another example of this would be where topics are geographically isolated (perhaps across Kafka different clusters, and then replicated into a central one), from where theyâ€™re all to be written to a single Iceberg table.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/2025/08/same-topics.excalidraw.png" alt="same topics.excalidraw"/>
</div>
</div>
<div class="paragraph">
<p>So, if either of these scenarios apply to your data, how does it impact your tool choice?</p>
</div>
<div class="paragraph">
<p>In <strong>Flink SQL</strong> every unique source schema must be explicitly defined.
Thereâ€™s no automagic population from a schema registry.
This means that if you have four different topics you need to declare eight Flink SQL tables.
Bear in mind with Flink SQL itâ€™s not only the table name but its schema too that needs specifying.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="sql"><span style="color: #66d9ef;font-weight: bold">CREATE</span> <span style="color: #66d9ef;font-weight: bold">TABLE</span> <span style="color: #f8f8f2;background-color: #49483e">src</span><span style="color: #f8f8f2;background-color: #49483e">.</span><span style="color: #f8f8f2;background-color: #49483e">orders</span> <span style="color: #f8f8f2;background-color: #49483e">(</span> <span style="color: #f8f8f2;background-color: #49483e">orderID</span> <span style="color: #f8f8f2">INT</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">customerID</span> <span style="color: #f8f8f2">INT</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">product</span> <span style="color: #f8f8f2;background-color: #49483e">STRING</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">quantity</span> <span style="color: #f8f8f2">INT</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">orderTS</span> <span style="color: #f8f8f2">TIMESTAMP</span><span style="color: #f8f8f2;background-color: #49483e">(</span><span style="color: #ae81ff">3</span><span style="color: #f8f8f2;background-color: #49483e">)</span> <span style="color: #f8f8f2;background-color: #49483e">)</span>
    <span style="color: #66d9ef;font-weight: bold">WITH</span> <span style="color: #f8f8f2;background-color: #49483e">(</span><span style="color: #e6db74">&#39;connector&#39;</span><span style="color: #f92672;font-weight: bold">=</span><span style="color: #e6db74">&#39;kafka&#39;</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #e6db74">&#39;topic&#39;</span><span style="color: #f92672;font-weight: bold">=</span><span style="color: #e6db74">&#39;orders&#39;</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">[</span><span style="color: #960050;background-color: #1e0010">â€¦</span><span style="color: #f8f8f2;background-color: #49483e">]);</span>

<span style="color: #66d9ef;font-weight: bold">CREATE</span> <span style="color: #66d9ef;font-weight: bold">TABLE</span> <span style="color: #f8f8f2;background-color: #49483e">src</span><span style="color: #f8f8f2;background-color: #49483e">.</span><span style="color: #f8f8f2;background-color: #49483e">customers</span> <span style="color: #f8f8f2;background-color: #49483e">(</span> <span style="color: #f8f8f2;background-color: #49483e">customerID</span> <span style="color: #f8f8f2">INT</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">firstName</span> <span style="color: #f8f8f2;background-color: #49483e">STRING</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">lastName</span> <span style="color: #f8f8f2;background-color: #49483e">STRING</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">email</span> <span style="color: #f8f8f2;background-color: #49483e">STRING</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">createdTS</span> <span style="color: #f8f8f2">TIMESTAMP</span><span style="color: #f8f8f2;background-color: #49483e">(</span><span style="color: #ae81ff">3</span><span style="color: #f8f8f2;background-color: #49483e">)</span> <span style="color: #f8f8f2;background-color: #49483e">)</span>
    <span style="color: #66d9ef;font-weight: bold">WITH</span> <span style="color: #f8f8f2;background-color: #49483e">(</span><span style="color: #e6db74">&#39;connector&#39;</span><span style="color: #f92672;font-weight: bold">=</span><span style="color: #e6db74">&#39;kafka&#39;</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #e6db74">&#39;topic&#39;</span><span style="color: #f92672;font-weight: bold">=</span><span style="color: #e6db74">&#39;customers&#39;</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">[</span><span style="color: #960050;background-color: #1e0010">â€¦</span><span style="color: #f8f8f2;background-color: #49483e">]);</span>

<span style="color: #66d9ef;font-weight: bold">CREATE</span> <span style="color: #66d9ef;font-weight: bold">TABLE</span> <span style="color: #f8f8f2;background-color: #49483e">src</span><span style="color: #f8f8f2;background-color: #49483e">.</span><span style="color: #f8f8f2;background-color: #49483e">products</span> <span style="color: #f8f8f2;background-color: #49483e">(</span> <span style="color: #f8f8f2;background-color: #49483e">productID</span> <span style="color: #f8f8f2">INT</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">sku</span> <span style="color: #f8f8f2;background-color: #49483e">STRING</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">name</span> <span style="color: #f8f8f2;background-color: #49483e">STRING</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">unitPrice</span> <span style="color: #f8f8f2">DECIMAL</span><span style="color: #f8f8f2;background-color: #49483e">(</span><span style="color: #ae81ff">10</span><span style="color: #f8f8f2;background-color: #49483e">,</span><span style="color: #ae81ff">2</span><span style="color: #f8f8f2;background-color: #49483e">),</span> <span style="color: #f8f8f2;background-color: #49483e">updatedTS</span> <span style="color: #f8f8f2">TIMESTAMP</span><span style="color: #f8f8f2;background-color: #49483e">(</span><span style="color: #ae81ff">3</span><span style="color: #f8f8f2;background-color: #49483e">)</span> <span style="color: #f8f8f2;background-color: #49483e">)</span>
    <span style="color: #66d9ef;font-weight: bold">WITH</span> <span style="color: #f8f8f2;background-color: #49483e">(</span><span style="color: #e6db74">&#39;connector&#39;</span><span style="color: #f92672;font-weight: bold">=</span><span style="color: #e6db74">&#39;kafka&#39;</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #e6db74">&#39;topic&#39;</span><span style="color: #f92672;font-weight: bold">=</span><span style="color: #e6db74">&#39;products&#39;</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">[</span><span style="color: #960050;background-color: #1e0010">â€¦</span><span style="color: #f8f8f2;background-color: #49483e">]);</span>

<span style="color: #66d9ef;font-weight: bold">CREATE</span> <span style="color: #66d9ef;font-weight: bold">TABLE</span> <span style="color: #f8f8f2;background-color: #49483e">src</span><span style="color: #f8f8f2;background-color: #49483e">.</span><span style="color: #f8f8f2;background-color: #49483e">inventory</span> <span style="color: #f8f8f2;background-color: #49483e">(</span> <span style="color: #f8f8f2;background-color: #49483e">productID</span> <span style="color: #f8f8f2">INT</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">locationID</span> <span style="color: #f8f8f2;background-color: #49483e">STRING</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">onHand</span> <span style="color: #f8f8f2">INT</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">reserved</span> <span style="color: #f8f8f2">INT</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">invTS</span> <span style="color: #f8f8f2">TIMESTAMP</span><span style="color: #f8f8f2;background-color: #49483e">(</span><span style="color: #ae81ff">3</span><span style="color: #f8f8f2;background-color: #49483e">)</span> <span style="color: #f8f8f2;background-color: #49483e">)</span>
    <span style="color: #66d9ef;font-weight: bold">WITH</span> <span style="color: #f8f8f2;background-color: #49483e">(</span><span style="color: #e6db74">&#39;connector&#39;</span><span style="color: #f92672;font-weight: bold">=</span><span style="color: #e6db74">&#39;kafka&#39;</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #e6db74">&#39;topic&#39;</span><span style="color: #f92672;font-weight: bold">=</span><span style="color: #e6db74">&#39;inventory&#39;</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">[</span><span style="color: #960050;background-color: #1e0010">â€¦</span><span style="color: #f8f8f2;background-color: #49483e">]);</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Now if you want to write these to Iceberg tables, you need to declare an Iceberg table for each:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="sql"><span style="color: #66d9ef;font-weight: bold">CREATE</span> <span style="color: #f8f8f2;background-color: #49483e">dest</span><span style="color: #f8f8f2;background-color: #49483e">.</span><span style="color: #f8f8f2;background-color: #49483e">orders</span> <span style="color: #66d9ef;font-weight: bold">WITH</span> <span style="color: #f8f8f2;background-color: #49483e">(</span><span style="color: #e6db74">&#39;connector&#39;</span><span style="color: #f92672;font-weight: bold">=</span><span style="color: #e6db74">&#39;iceberg&#39;</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">[</span><span style="color: #960050;background-color: #1e0010">â€¦</span><span style="color: #f8f8f2;background-color: #49483e">])</span> <span style="color: #66d9ef;font-weight: bold">AS</span> <span style="color: #66d9ef;font-weight: bold">SELECT</span> <span style="color: #f92672;font-weight: bold">*</span> <span style="color: #66d9ef;font-weight: bold">FROM</span> <span style="color: #f8f8f2;background-color: #49483e">src</span><span style="color: #f8f8f2;background-color: #49483e">.</span><span style="color: #f8f8f2;background-color: #49483e">orders</span><span style="color: #f8f8f2;background-color: #49483e">;</span>
<span style="color: #66d9ef;font-weight: bold">CREATE</span> <span style="color: #f8f8f2;background-color: #49483e">dest</span><span style="color: #f8f8f2;background-color: #49483e">.</span><span style="color: #f8f8f2;background-color: #49483e">customers</span> <span style="color: #66d9ef;font-weight: bold">WITH</span> <span style="color: #f8f8f2;background-color: #49483e">(</span><span style="color: #e6db74">&#39;connector&#39;</span><span style="color: #f92672;font-weight: bold">=</span><span style="color: #e6db74">&#39;iceberg&#39;</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">[</span><span style="color: #960050;background-color: #1e0010">â€¦</span><span style="color: #f8f8f2;background-color: #49483e">])</span> <span style="color: #66d9ef;font-weight: bold">AS</span> <span style="color: #66d9ef;font-weight: bold">SELECT</span> <span style="color: #f92672;font-weight: bold">*</span> <span style="color: #66d9ef;font-weight: bold">FROM</span> <span style="color: #f8f8f2;background-color: #49483e">src</span><span style="color: #f8f8f2;background-color: #49483e">.</span><span style="color: #f8f8f2;background-color: #49483e">customers</span><span style="color: #f8f8f2;background-color: #49483e">;</span>
<span style="color: #66d9ef;font-weight: bold">CREATE</span> <span style="color: #f8f8f2;background-color: #49483e">dest</span><span style="color: #f8f8f2;background-color: #49483e">.</span><span style="color: #f8f8f2;background-color: #49483e">products</span> <span style="color: #66d9ef;font-weight: bold">WITH</span> <span style="color: #f8f8f2;background-color: #49483e">(</span><span style="color: #e6db74">&#39;connector&#39;</span><span style="color: #f92672;font-weight: bold">=</span><span style="color: #e6db74">&#39;iceberg&#39;</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">[</span><span style="color: #960050;background-color: #1e0010">â€¦</span><span style="color: #f8f8f2;background-color: #49483e">])</span> <span style="color: #66d9ef;font-weight: bold">AS</span> <span style="color: #66d9ef;font-weight: bold">SELECT</span> <span style="color: #f92672;font-weight: bold">*</span> <span style="color: #66d9ef;font-weight: bold">FROM</span> <span style="color: #f8f8f2;background-color: #49483e">src</span><span style="color: #f8f8f2;background-color: #49483e">.</span><span style="color: #f8f8f2;background-color: #49483e">products</span><span style="color: #f8f8f2;background-color: #49483e">;</span>
<span style="color: #66d9ef;font-weight: bold">CREATE</span> <span style="color: #f8f8f2;background-color: #49483e">dest</span><span style="color: #f8f8f2;background-color: #49483e">.</span><span style="color: #f8f8f2;background-color: #49483e">inventory</span> <span style="color: #66d9ef;font-weight: bold">WITH</span> <span style="color: #f8f8f2;background-color: #49483e">(</span><span style="color: #e6db74">&#39;connector&#39;</span><span style="color: #f92672;font-weight: bold">=</span><span style="color: #e6db74">&#39;iceberg&#39;</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">[</span><span style="color: #960050;background-color: #1e0010">â€¦</span><span style="color: #f8f8f2;background-color: #49483e">])</span> <span style="color: #66d9ef;font-weight: bold">AS</span> <span style="color: #66d9ef;font-weight: bold">SELECT</span> <span style="color: #f92672;font-weight: bold">*</span> <span style="color: #66d9ef;font-weight: bold">FROM</span> <span style="color: #f8f8f2;background-color: #49483e">src</span><span style="color: #f8f8f2;background-color: #49483e">.</span><span style="color: #f8f8f2;background-color: #49483e">inventory</span><span style="color: #f8f8f2;background-color: #49483e">;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>However, if youâ€™ve got multiple topics <em>with the same schema</em> then things are a bit easier since <a href="https://nightlies.apache.org/flink/flink-docs-master/docs/connectors/table/kafka/#connector-options">the Kafka connector in Flink SQL</a> does support wildcards (<code>topic-pattern</code>) or a list of topics (<code>topic</code> with semi-colon separated topics).
You can also add <code>topic</code> as a <em>metadata</em> column to your source table so that it is exposed for writing to Icebergâ€”important if you want to retain the lineage information of your data.
Hereâ€™s an example of fan-in (N:1) in Flink SQL.
First, create the source table reading from multiple topics:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="sql"><span style="color: #66d9ef;font-weight: bold">CREATE</span> <span style="color: #66d9ef;font-weight: bold">TABLE</span> <span style="color: #f8f8f2;background-color: #49483e">src</span><span style="color: #f8f8f2;background-color: #49483e">.</span><span style="color: #f8f8f2;background-color: #49483e">kafka_transactions_all</span> <span style="color: #f8f8f2;background-color: #49483e">(</span>
    <span style="color: #f8f8f2;background-color: #49483e">transaction_id</span> <span style="color: #f8f8f2;background-color: #49483e">STRING</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">user_id</span> <span style="color: #f8f8f2;background-color: #49483e">STRING</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">amount</span> <span style="color: #f8f8f2">DECIMAL</span><span style="color: #f8f8f2;background-color: #49483e">(</span><span style="color: #ae81ff">10</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #ae81ff">2</span><span style="color: #f8f8f2;background-color: #49483e">),</span> <span style="color: #f8f8f2;background-color: #49483e">currency</span> <span style="color: #f8f8f2;background-color: #49483e">STRING</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">merchant</span> <span style="color: #f8f8f2;background-color: #49483e">STRING</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">transaction_time</span> <span style="color: #f8f8f2">TIMESTAMP</span><span style="color: #f8f8f2;background-color: #49483e">(</span><span style="color: #ae81ff">3</span><span style="color: #f8f8f2;background-color: #49483e">),</span>
    <span style="color: #f8f8f2;background-color: #49483e">src_topic</span> <span style="color: #f8f8f2;background-color: #49483e">STRING</span> <span style="color: #f8f8f2;background-color: #49483e">METADATA</span> <span style="color: #66d9ef;font-weight: bold">FROM</span> <span style="color: #e6db74">&#39;topic&#39;</span> <i class="conum" data-value="1"></i><b>(1)</b>
<span style="color: #f8f8f2;background-color: #49483e">)</span> <span style="color: #66d9ef;font-weight: bold">WITH</span> <span style="color: #f8f8f2;background-color: #49483e">(</span>
    <span style="color: #e6db74">&#39;connector&#39;</span> <span style="color: #f92672;font-weight: bold">=</span> <span style="color: #e6db74">&#39;kafka&#39;</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #e6db74">&#39;properties.bootstrap.servers&#39;</span> <span style="color: #f92672;font-weight: bold">=</span> <span style="color: #e6db74">&#39;broker:9092&#39;</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #e6db74">&#39;format&#39;</span> <span style="color: #f92672;font-weight: bold">=</span> <span style="color: #e6db74">&#39;json&#39;</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #e6db74">&#39;scan.startup.mode&#39;</span> <span style="color: #f92672;font-weight: bold">=</span> <span style="color: #e6db74">&#39;earliest-offset&#39;</span><span style="color: #f8f8f2;background-color: #49483e">,</span>
    <span style="color: #e6db74">&#39;topic-pattern&#39;</span> <span style="color: #f92672;font-weight: bold">=</span> <span style="color: #e6db74">&#39;transactions</span><span style="color: #ae81ff">\.</span><span style="color: #e6db74">.*&#39;</span> <i class="conum" data-value="2"></i><b>(2)</b>
<span style="color: #f8f8f2;background-color: #49483e">);</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tbody><tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Topic metadata column included in the table definition</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Wildcard pattern for source Kafka topics</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>Now letâ€™s write that to a single Iceberg table:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="sql"><span style="color: #66d9ef;font-weight: bold">CREATE</span> <span style="color: #66d9ef;font-weight: bold">TABLE</span> <span style="color: #f8f8f2;background-color: #49483e">my_iceberg_catalog</span><span style="color: #f8f8f2;background-color: #49483e">.</span><span style="color: #f8f8f2;background-color: #49483e">my_glue_db</span><span style="color: #f8f8f2;background-color: #49483e">.</span><span style="color: #f8f8f2;background-color: #49483e">transactions_all</span> <span style="color: #66d9ef;font-weight: bold">AS</span>
    <span style="color: #66d9ef;font-weight: bold">SELECT</span> <span style="color: #f92672;font-weight: bold">*</span> <span style="color: #66d9ef;font-weight: bold">FROM</span> <span style="color: #f8f8f2;background-color: #49483e">src</span><span style="color: #f8f8f2;background-color: #49483e">.</span><span style="color: #f8f8f2;background-color: #49483e">kafka_transactions_all</span><span style="color: #f8f8f2;background-color: #49483e">;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>You can also do fan-in (N:1) in Flink SQL using the <code>UNION ALL</code> operator.
For example, if the above Kafka topics were defined as individual Flink SQL tables (perhaps with slightly different schemas that need unifying), you could do something like this to write them all to a single Iceberg table:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="sql"><span style="color: #66d9ef;font-weight: bold">CREATE</span> <span style="color: #66d9ef;font-weight: bold">TABLE</span> <span style="color: #f8f8f2;background-color: #49483e">my_iceberg_catalog</span><span style="color: #f8f8f2;background-color: #49483e">.</span><span style="color: #f8f8f2;background-color: #49483e">my_glue_db</span><span style="color: #f8f8f2;background-color: #49483e">.</span><span style="color: #f8f8f2;background-color: #49483e">transactions_all</span> <span style="color: #66d9ef;font-weight: bold">AS</span>
    <span style="color: #66d9ef;font-weight: bold">SELECT</span>  <span style="color: #e6db74">&#39;uk&#39;</span> <span style="color: #66d9ef;font-weight: bold">as</span> <span style="color: #f8f8f2;background-color: #49483e">src_topic</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">transaction_id</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">user_id</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">amount</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">currency</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">merchant</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">transaction_time</span> <span style="color: #66d9ef;font-weight: bold">FROM</span> <span style="color: #f8f8f2;background-color: #49483e">src</span><span style="color: #f8f8f2;background-color: #49483e">.</span><span style="color: #f8f8f2;background-color: #49483e">kafka_transactions_uk</span>
    <span style="color: #66d9ef;font-weight: bold">UNION</span> <span style="color: #66d9ef;font-weight: bold">ALL</span>
    <span style="color: #66d9ef;font-weight: bold">SELECT</span>  <span style="color: #e6db74">&#39;eu&#39;</span> <span style="color: #66d9ef;font-weight: bold">as</span> <span style="color: #f8f8f2;background-color: #49483e">src_topic</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">transaction_id</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">user_id</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">amount</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">currency</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">merchant</span><span style="color: #f8f8f2;background-color: #49483e">,</span> <span style="color: #f8f8f2;background-color: #49483e">transaction_time</span> <span style="color: #66d9ef;font-weight: bold">FROM</span> <span style="color: #f8f8f2;background-color: #49483e">src</span><span style="color: #f8f8f2;background-color: #49483e">.</span><span style="color: #f8f8f2;background-color: #49483e">kafka_transactions_eu</span>
    <span style="color: #f8f8f2;background-color: #49483e">[</span><span style="color: #960050;background-color: #1e0010">â€¦</span><span style="color: #f8f8f2;background-color: #49483e">]</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Further more to Flink SQLâ€™s flexibility is the <a href="https://nightlies.apache.org/flink/flink-docs-master/docs/dev/table/sql/insert/#insert-into-multiple-tables"><em>statement sets</em></a> feature, which you can use for fan-out (1:N)â€”routing data from the same source table to different target tables.</p>
</div>
<div class="paragraph">
<p>Moving onto <strong>Kafka Connect</strong>, it supports wildcards and can do <a href="/2025/07/04/writing-to-apache-iceberg-on-s3-using-kafka-connect-with-glue-catalog/#_n1_fan_in_writing_many_topics_to_one_table">fan-in (N:1)</a> using the <code>topics.regex</code> parameter:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="javascript"><span style="color: #e6db74">&#34;</span><span style="color: #e6db74">topics.regex</span><span style="color: #e6db74">&#34;</span><span style="color: #f8f8f2;background-color: #49483e">:</span> <span style="color: #e6db74">&#34;</span><span style="color: #e6db74">src.*</span><span style="color: #e6db74">&#34;</span><span style="color: #f8f8f2;background-color: #49483e">,</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>It can also do fan-out (1:N) using the <code>iceberg.tables.route-field</code> parameter for the Iceberg sink connector, described <a href="/2025/07/04/writing-to-apache-iceberg-on-s3-using-kafka-connect-with-glue-catalog/#_1n_fan_out_writing_one_topic_to_many_tables">here</a>.</p>
</div>
<div class="paragraph">
<p><strong>Tableflow</strong> has a 1:1 relationship between Kafka topics and Iceberg tables.
It can be enabled for multiple topics easily either through the UI, or from the CLI:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="bash"><span style="color: #75715e;font-style: italic"># Write topics `my_topic[1-5]` to an Iceberg table</span>
<span style="color: #f8f8f2">$ </span>confluent tableflow topic create my_topic1
<span style="color: #f8f8f2">$ </span>confluent tableflow topic create my_topic2
<span style="color: #f8f8f2">$ </span>confluent tableflow topic create my_topic3
<span style="color: #f8f8f2">$ </span>confluent tableflow topic create my_topic4
<span style="color: #f8f8f2">$ </span>confluent tableflow topic create my_topic5</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can achieve fan-in either by using Kafka Connect on Confluent Cloud to ingest to a single topic from multiple sources</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/2025/08/kc-tf-flink-fan-in.excalidraw.png" alt="kc tf flink fan in.excalidraw"/>
</div>
</div>
<div class="paragraph">
<p>or using Confluent Cloud for Apache Flink to <code>UNION</code> multiple topics into one.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/2025/08/tf-flink-fan-in.excalidraw.png" alt="tf flink fan in.excalidraw"/>
</div>
</div>
<div class="paragraph">
<p>Similarly, fan-out can be done using Flink to route the source topics into multiple destination ones, each of which is then enabled for Tableflow.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/2025/08/tf-flink-fan-out.excalidraw.png" alt="tf flink fan out.excalidraw"/>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_whither_schema">Whither Schema?&nbsp;<a class="headline-hash" href="#_whither_schema">ðŸ”—</a> </h3>
<div class="paragraph">
<p>Sure, your data has a schema.
But does it have a <em>schema</em>?</p>
</div>
<div class="paragraph">
<p>If your data is just a lump of JSON like this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="javascript"><span style="color: #f8f8f2;background-color: #49483e">{</span>
    <span style="color: #e6db74">&#34;</span><span style="color: #e6db74">click_ts</span><span style="color: #e6db74">&#34;</span><span style="color: #f8f8f2;background-color: #49483e">:</span> <span style="color: #e6db74">&#34;</span><span style="color: #e6db74">2023-02-01T14:30:25Z</span><span style="color: #e6db74">&#34;</span><span style="color: #f8f8f2;background-color: #49483e">,</span>
    <span style="color: #e6db74">&#34;</span><span style="color: #e6db74">ad_cost</span><span style="color: #e6db74">&#34;</span><span style="color: #f8f8f2;background-color: #49483e">:</span> <span style="color: #e6db74">&#34;</span><span style="color: #e6db74">1.50</span><span style="color: #e6db74">&#34;</span><span style="color: #f8f8f2;background-color: #49483e">,</span>
    <span style="color: #e6db74">&#34;</span><span style="color: #e6db74">is_conversion</span><span style="color: #e6db74">&#34;</span><span style="color: #f8f8f2;background-color: #49483e">:</span> <span style="color: #e6db74">&#34;</span><span style="color: #e6db74">true</span><span style="color: #e6db74">&#34;</span><span style="color: #f8f8f2;background-color: #49483e">,</span>
    <span style="color: #e6db74">&#34;</span><span style="color: #e6db74">user_id</span><span style="color: #e6db74">&#34;</span><span style="color: #f8f8f2;background-color: #49483e">:</span> <span style="color: #e6db74">&#34;</span><span style="color: #e6db74">001234567890</span><span style="color: #e6db74">&#34;</span>
<span style="color: #f8f8f2;background-color: #49483e">}</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>What should the target Iceberg table look like?</p>
</div>
<div class="paragraph">
<p>One option is that you manually created it first.
Doing this you can at least make sure that the data types are set correctly.</p>
</div>
<div class="paragraph">
<p>If youâ€™re <a href="/2025/06/24/writing-to-apache-iceberg-on-s3-using-flink-sql-with-glue-catalog/#_define_the_kafka_source">using <strong>Flink SQL</strong> to write to Iceberg</a> you have to declare the datatypes as part of the source Flink table DDL.
For <strong>every. single. table</strong>.
But at least theyâ€™ll be correct (so long as you didnâ€™t make a mistake in typing out all that DDL!).</p>
</div>
<div class="paragraph">
<p><a href="/2025/07/04/writing-to-apache-iceberg-on-s3-using-kafka-connect-with-glue-catalog/#_schemas"><strong>Kafka Connect</strong></a> will give you the option to play fast-and-loose with your schema if you want, and YOLO it by guessing.
It might work, but you might also get this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code>+----------------+----------+
|      Name      |  Type    |
+----------------+----------+
|  click_ts      |  string  | <i class="conum" data-value="3"></i><b>(3)</b>
|  ad_cost       |  string  | <i class="conum" data-value="2"></i><b>(2)</b>
|  user_id       |  string  |
|  is_conversion |  string  | <i class="conum" data-value="1"></i><b>(1)</b>
+----------------+----------+</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tbody><tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Storing a boolean as a string? not ideal.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Storing a currency as a string? not good.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Storing a timestamp as a string? gross.</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>A better way all round to do this if youâ€™re using <strong>Kafka Connect</strong> or <strong>Tableflow</strong> is to have your topics&#39; schemas in the <a href="https://docs.confluent.io/platform/current/schema-registry/index.html">Schema Registry</a>.
This way the target Iceberg table can be defined correctly based on the actual schema of the dataâ€”not a guess at it:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code>+----------------+-----------------+
|      Name      |  Type           |
+----------------+-----------------+
|  click_ts      |  timestamp      |
|  ad_cost       |  decimal(38,2)  |
|  user_id       |  string         |
|  is_conversion |  boolean        |
+----------------+-----------------+</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_schema_evolution">Schema Evolution&nbsp;<a class="headline-hash" href="#_schema_evolution">ðŸ”—</a> </h3>
<div class="quoteblock">
<blockquote>
<div class="paragraph">
<p>Nothing is stable, even what is close to us in time</p>
</div>
</blockquote>
</div>
<div class="paragraph">
<p>Another consideration to bear in mind is what happens when your schema changes.
And at some point, your schema <strong>will</strong> change.
So how do you make sure that the target Iceberg reflects those changes?</p>
</div>
<div class="paragraph">
<p>In <strong>Flink SQL</strong> there is no way to do this without duplicating records.
Youâ€™d need to make sure that youâ€™re using <code>scan.startup.mode=group-offsets</code> and have set <code>properties.group.id</code> in your original DDL, then cancel the job, amend the table DDL to reflect the new schema, and then restart the job (with an <code>INSERT INTO</code> if you were using a <code>CREATE TABLEâ€¦AS SELECT</code> originally).
Even then, youâ€™re going to duplicate the records that were written before Flink checkpointed and saved the Kafka topic offset that it had got to.</p>
</div>
<div class="paragraph">
<p>The <strong>Kafka Connect</strong> Iceberg sink supports <a href="/2025/07/04/writing-to-apache-iceberg-on-s3-using-kafka-connect-with-glue-catalog/#_schema_evolution">schema evolution</a>, just make sure youâ€™ve set <code>iceberg.tables.evolve-schema-enabled=true</code>.</p>
</div>
<div class="paragraph">
<p><a href="https://docs.confluent.io/cloud/current/topics/tableflow/overview.html#schematization-and-schema-evolution"><strong>Tableflow</strong> supports schema evolution</a> out of the box.</p>
</div>
</div>
<div class="sect2">
<h3 id="_do_you_want_some_processing_to_go_with_that">Do you want some processing to go with that?&nbsp;<a class="headline-hash" href="#_do_you_want_some_processing_to_go_with_that">ðŸ”—</a> </h3>
<div class="paragraph">
<p>Perhaps youâ€™re just wanting a big &#39;ole dumb pipe through which to dump your data into Iceberg.
Perhaps, however, youâ€™ve decided that it would be useful to mask a few columns or filter some rows.
Maybe, even, youâ€™ve decided to <a href="https://www.youtube.com/watch?v=FiZmyl1Npg0">shift left</a> and move a bunch of your batch workload out of the datalake and closer to the point at which the dataâ€™s created (per <a href="https://ssbipolar.com/2021/05/31/roches-maxim/">Rocheâ€™s maxim</a>)</p>
</div>
<div class="paragraph">
<p>This can contribute a significant amount of weighting to your tool choice.</p>
</div>
<div class="admonitionblock tip">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>An added dimension to consider is <em>what kind of processing</em> youâ€™re doing (or plausibly would want to do in the future without needing to change your architecture).</p>
</div>
<div class="paragraph">
<p><em>Stateless</em> means literally what it says; there is no state.
If you can process each record as it arrives without needing to build up state (like a counter, for example, or a lookup table), itâ€™s stateless.</p>
</div>
<div class="paragraph">
<p><em>Stateful</em>, on the other hand, is where you <em>do</em> use state.
Common examples would be an aggregation (<code>COUNT</code>, <code>SUM</code>, etc), a join to enrich the data, and so on.</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>If integration is Kafka Connectâ€™s <em>raison dâ€™Ãªtre</em>, processing is Flinkâ€™s.
Itâ€™s where <strong>Flink SQL</strong> really comes into its own, particularly for state<em>ful</em> transformations.</p>
</div>
<div class="paragraph">
<p>If you can express it in SQL, you can probably do it in Flink.
Joining to other data (whether in Kafka, or other systems), time-based aggregations (orders per hour, for example), sessionising and pattern matchingâ€”all of this is Flinkâ€™s bread and butter.
Flink SQL can also do stateless processing (filtering, schema projection, etc) too, and compared to Kafka Connectâ€™s Single Message Transforms (see below) definitely easier to configure (itâ€™s just SQL) and also richer in functionality.
Youâ€™ll sometimes find with Single Message Transforms that thereâ€™s a particular transformation that you need and it just doesnâ€™t exist yet.</p>
</div>
<div class="paragraph">
<p><strong>Kafka Connect</strong> can do <em>stateless</em> processing using Single Message Transforms.
These are configured through bits of JSON configuration, and whilst not the most intuitive way to express a transformation, they are remarkably powerful.
For example, to drop named fields from the source table so that they arenâ€™t included in the Iceberg table schema, youâ€™d add this to your connector configuration:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="javascript"><span style="color: #f8f8f2;background-color: #49483e">{</span>
    <span style="color: #e6db74">&#34;</span><span style="color: #e6db74">connector.class</span><span style="color: #e6db74">&#34;</span><span style="color: #f8f8f2;background-color: #49483e">:</span> <span style="color: #e6db74">&#34;</span><span style="color: #e6db74">org.apache.iceberg.connect.IcebergSinkConnector</span><span style="color: #e6db74">&#34;</span><span style="color: #f8f8f2;background-color: #49483e">,</span>
    <span style="color: #f8f8f2;background-color: #49483e">[</span><span style="color: #960050;background-color: #1e0010">â€¦</span><span style="color: #f8f8f2;background-color: #49483e">]</span>
    <span style="color: #e6db74">&#34;</span><span style="color: #e6db74">transforms</span><span style="color: #e6db74">&#34;</span>                 <span style="color: #f8f8f2;background-color: #49483e">:</span> <span style="color: #e6db74">&#34;</span><span style="color: #e6db74">dropCC</span><span style="color: #e6db74">&#34;</span><span style="color: #f8f8f2;background-color: #49483e">,</span>
    <span style="color: #e6db74">&#34;</span><span style="color: #e6db74">transforms.dropCC.type</span><span style="color: #e6db74">&#34;</span>     <span style="color: #f8f8f2;background-color: #49483e">:</span> <span style="color: #e6db74">&#34;</span><span style="color: #e6db74">org.apache.kafka.connect.transforms.ReplaceField$Value</span><span style="color: #e6db74">&#34;</span><span style="color: #f8f8f2;background-color: #49483e">,</span>
    <span style="color: #e6db74">&#34;</span><span style="color: #e6db74">transforms.dropCC.exclude</span><span style="color: #e6db74">&#34;</span>  <span style="color: #f8f8f2;background-color: #49483e">:</span> <span style="color: #e6db74">&#34;</span><span style="color: #e6db74">col1, col4</span><span style="color: #e6db74">&#34;</span>
<span style="color: #f8f8f2;background-color: #49483e">}</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>There are lots of other transformations available, many part of Apache Kafka itself, others provided by the community.
I wrote a blog series about these previously: <a href="/categories/twelvedaysofsmt/">Twelve Days of SMT</a></p>
</div>
<div class="paragraph">
<p><strong>Tableflow</strong> is part of Confluent Cloud which means you already have access to Confluent Cloud for Apache Flink for your processingâ€”the best of both worlds!</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/2025/08/tf-flink.excalidraw.png" alt="tf flink.excalidraw"/>
</div>
</div>
<div class="paragraph">
<p>If your Kafka data is coming from Kafka Connect upstream using a managed connector in Confluent Cloud you can also use Single Message Transforms at ingest.</p>
</div>
</div>
<div class="sect2">
<h3 id="_insert_overwrite_and_upsert"><code>INSERT OVERWRITE</code> and <code>UPSERT</code>&nbsp;<a class="headline-hash" href="#_insert_overwrite_and_upsert">ðŸ”—</a> </h3>
<div class="paragraph">
<p>Just as schemas may change, so may the data itself.
This could be an aggregate (such as a <code>COUNT</code>) for which more records have been received and so needs updating, or late-arriving data or data thatâ€™s been restated and needs to replace whatâ€™s there.
For whatever reason, youâ€™ll need to plan how youâ€™re going to handle this in your Iceberg table.</p>
</div>
<div class="paragraph">
<p>One option is using <code>UPSERT</code> or <code>INSERT OVERWRITE</code> semantics:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>UPSERT</code> is a portmanteau of the operation that it describes: attempt to <strong><code>UP</code></strong><code>DATE</code> a keyâ€™s value, and if the key doesnâ€™t exist then <code>IN</code><strong><code>SERT</code></strong> it instead.
This is a common pattern used in data engineering when loading data.</p>
</li>
<li>
<p><code>INSERT OVERWRITE</code> takes a more extreme approach, and does what it says on the tin: insert values, and overwrite whatâ€™s there currently.
This would more likely be used for data housekeeping (e.g. replacing the contents of a dayâ€™s partition with a restatement of the data once late data has arrived), or dimension table repopulation (replace the entire contents of the table with the latest version of the dimension).</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Flink SQL</strong> supports both <a href="/2025/06/24/writing-to-apache-iceberg-on-s3-using-flink-sql-with-glue-catalog/#_upsert"><code>UPSERT</code></a> and <a href="/2025/06/24/writing-to-apache-iceberg-on-s3-using-flink-sql-with-glue-catalog/#_insert_overwrite"><code>INSERT OVERWRITE</code></a> (the latter in batch mode only, understandably).</p>
</div>
<div class="paragraph">
<p><strong>Kafka Connect</strong> does not support either of these operations.</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The current (v1.10) version of the Apache Iceberg connector for Kafka Connect does not support <code>UPSERT</code>.
However, an earlier incarnation of the connectorâ€”authored by Tabular, before being donated to the Apache Iceberg projectâ€”<em>did</em> support it including for CDC-sourced data.</p>
</div>
<div class="paragraph">
<p>This means that you may see mention of the functionality, including configuration options such as <code>iceberg.tables.iceberg.tables.upsert-mode-enabled</code> and <code>iceberg.tables.cdc-field</code>.</p>
</div>
<div class="paragraph">
<p>For more information and latest status, see <a href="https://github.com/apache/iceberg/pull/12070">the PR to add the functionality</a>, <a href="https://github.com/apache/iceberg/issues/10842">the GitHub issue</a>, and a <a href="https://lists.apache.org/thread/96dhf3sj5pc4ql0l8yk8sxgtr78bchrd">mailing list discussion</a>.</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p><strong>Tableflow</strong> will support <code>UPSERT</code> soon.</p>
</div>
</div>
<div class="sect2">
<h3 id="_delivery_semantics">Delivery Semantics&nbsp;<a class="headline-hash" href="#_delivery_semantics">ðŸ”—</a> </h3>
<div class="paragraph">
<p><strong>Flink SQL</strong> reading from Kafka and writing to Iceberg will have exactly-once semantics so long as you enable checkpointing:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="sql"><span style="color: #66d9ef;font-weight: bold">SET</span> <span style="color: #e6db74">&#39;execution.checkpointing.interval&#39;</span> <span style="color: #f92672;font-weight: bold">=</span> <span style="color: #e6db74">&#39;30s&#39;</span><span style="color: #f8f8f2;background-color: #49483e">;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p><a href="https://iceberg.apache.org/docs/nightly/kafka-connect/#requirements"><strong>Kafka Connect</strong></a> and <strong>Tableflow</strong> both have out-of-the-box support for exactly-once semantics for writing to Iceberg.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_living_with_it">Living with it&nbsp;<a class="headline-hash" href="#_living_with_it">ðŸ”—</a> </h2>
<div class="sectionbody">
<div class="paragraph">
<p>So far Iâ€™ve looked at the areas to think about with regards to the data that youâ€™re sending to Iceberg.
Thatâ€™s only part of the puzzle though.
It might be a fun science experiment to put together random technologies based on their feature-support alone, but in the real world we have to live with the design choices we make too.
Letâ€™s look at some more factors to include in our weighing up of options.</p>
</div>
<div class="sect2">
<h3 id="_existing_ecosystem">Existing Ecosystem&nbsp;<a class="headline-hash" href="#_existing_ecosystem">ðŸ”—</a> </h3>
<div class="paragraph">
<p>If you already run <strong>Apache Flink</strong> or <strong>Kafka Connect</strong> (or are already a <strong>Confluent Cloud</strong> user) then that should be your assumed default.
From that default position you can then weigh in the other factors described in this article and decide if any warrant deploying new technology.</p>
</div>
</div>
<div class="sect2">
<h3 id="_iceberg_housekeeping">Iceberg Housekeeping&nbsp;<a class="headline-hash" href="#_iceberg_housekeeping">ðŸ”—</a> </h3>
<div class="paragraph">
<p>Iceberg does some thingsâ€”but not all.
One of the things that it doesnâ€™t do out of the box is its own housekeeping.
Particularly with streaming ingest into Iceberg, you can very quickly end up with lots of small data and metadata files, which will become a problem over time for performance.
I wrote more about this <a href="/2025/07/14/keeping-your-data-lakehouse-in-order-table-maintenance-in-apache-iceberg/#_combining_data_files_into_fewer_data_files">here</a>.</p>
</div>
<div class="paragraph">
<p>If youâ€™re using <strong>Apache Flink</strong> or <strong>Kafka Connect</strong> to get your data into Iceberg, youâ€™ll need to do the housekeeping yourself.
This could be a custom job using something like Trino or Apache Spark, or a tool such as <a href="https://amoro.apache.org/quick-start/#check-self-optimizing">Apache Amoro</a> or <a href="https://github.com/nimtable/nimtable">Nimtable</a>.</p>
</div>
<div class="paragraph">
<p><strong>Tableflow</strong> includes <a href="https://docs.confluent.io/cloud/current/topics/tableflow/overview.html#table-maintenance-and-optimizations">built-in table maintenance</a>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_ease_of_use">Ease of Use&nbsp;<a class="headline-hash" href="#_ease_of_use">ðŸ”—</a> </h3>
<div class="paragraph">
<p>Thereâ€™s a reason I gave a conference talk called <a href="https://talks.rmoff.net/9GpIYA/the-joy-of-jars-and-other-flink-sql-troubleshooting-tales"><em>The Joy of JARs</em></a>.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/2025/08/my-god-it-is-full-of-java.webp" alt="My God" width="It&#39;s full of Java"/>
</div>
</div>
<div class="paragraph">
<p><strong>Flink SQL</strong> is SQL on the surface, but <a href="/2025/06/24/writing-to-apache-iceberg-on-s3-using-flink-sql-with-glue-catalog/#_random_jiggling_hadoop_jars">a morass of Java underneath</a>, which matters for users and operators alike.
If youâ€™re already using Flink SQL then youâ€™ll know what Iâ€™m talking about.
If youâ€™re not and youâ€™re looking for a warm fuzzy SQL-embrace, forget it.</p>
</div>
<div class="paragraph">
<p><strong>Kafka Connect</strong> is built on Java too, but generally isolates the user from it.
You can use <a href="https://hub.confluent.io">Confluent Hub</a> to install the Iceberg connector (or build it yourself, if thatâ€™s what you like doing).
Configuration isnâ€™t <em>pretty</em>, but it is &#34;just&#34; JSON.
Use <a href="https://github.com/kcctl/kcctl">kcctl</a> to make your life easier.</p>
</div>
<div class="paragraph">
<p><strong>Tableflow</strong> is ridiculously simple to use.
Click &#34;Enable Tableflow&#34;, and thatâ€™s it.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/2025/08/tableflow.webp" alt="tableflow"/>
</div>
</div>
<div class="paragraph">
<p>You can use the Confluent CLI instead if youâ€™d rather:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight" style="color: #f8f8f2;background-color: #49483e"><code data-lang="bash"><span style="color: #f8f8f2">$ </span>confluent tableflow topic create my_topic1</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_self_managed_vs_fully_managed">Self-Managed vs Fully-Managed&nbsp;<a class="headline-hash" href="#_self_managed_vs_fully_managed">ðŸ”—</a> </h3>
<div class="paragraph">
<p><strong>Tableflow</strong> is available on Confluent Cloud, which is a fully-managed option and includes Kafka brokers and Flink SQL (plus Kafka Connect if you want it for ingest).</p>
</div>
<div class="paragraph">
<p>If you want to self-manage then both <strong>Flink SQL</strong> and <strong>Kafka Connect</strong> (plus the necessary Apache Kafka) can be hosted yourself either on-premises or on a cloud provider.
Plenty of people do this so youâ€™ll not have a shortage of content online to help you set this up and keep it running.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_cost">Cost&nbsp;<a class="headline-hash" href="#_cost">ðŸ”—</a> </h2>
<div class="sectionbody">
<div class="paragraph">
<p><strong>Apache Flink</strong>, Apache Kafka (of which <strong>Kafka Connect</strong> is part), and the Apache Iceberg connector for Kafka Connect are all Apache 2.0 open source, owned by the Apache Software Foundation.
Youâ€™re free to run them and modify them as you want (and youâ€™re also then reliant on the community for any support requirements).</p>
</div>
<div class="paragraph">
<p><strong>Tableflow</strong> is a proprietary component of Confluent Cloud and usage of it is <a href="https://docs.confluent.io/cloud/current/topics/tableflow/concepts/tableflow-billing.html">billed</a>.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_i_used_to_be_indecisivenow_im_not_so_sure">I used to be indecisiveâ€¦now Iâ€™m not so sureâ€¦&nbsp;<a class="headline-hash" href="#_i_used_to_be_indecisivenow_im_not_so_sure">ðŸ”—</a> </h2>
<div class="sectionbody">
<div class="paragraph">
<p>Canâ€™t decide between Apache Iceberg and <a href="https://delta.io/">Delta Lake</a> as your open table format of choice?
Want to leave options open for the future, or other teams in your organisation?</p>
</div>
<div class="paragraph">
<p><strong>Flink SQL</strong> has a <a href="https://github.com/delta-io/delta/tree/master/connectors/flink/">Delta Lake connector</a> (open source).</p>
</div>
<div class="paragraph">
<p>There is a <a href="https://docs.confluent.io/kafka-connectors/databricks-delta-lake-sink/current/overview.html">Delta Lake connector for <strong>Kafka Connect</strong></a> but it is not open source and requires a paid Confluent subscription.
The <a href="https://github.com/delta-io/kafka-delta-ingest"><code>kafka-delta-ingest</code></a> project is part of the Delta project and open source, but does not use the Kafka Connect framework.</p>
</div>
<div class="paragraph">
<p><strong>Tableflow</strong> <a href="https://docs.confluent.io/cloud/current/topics/tableflow/overview.html#tableflow-and-delta-lake-tables">has support</a> for both Apache Iceberg and Delta Lake.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_but_what_about_this_other_tool">bUt wHaT aBoUt tHiS oThEr tOoL?&nbsp;<a class="headline-hash" href="#_but_what_about_this_other_tool">ðŸ”—</a> </h2>
<div class="sectionbody">
<div class="paragraph">
<p>The aim of this blog post is not to give a comprehensive listing of all the ways of getting data into Iceberg from Kafka, but to look in more detail at the most common options that I see in use.</p>
</div>
<div class="paragraph">
<p>As well as Flink SQL, Kafka Connect, and Tableflow, other options include:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://iceberg.apache.org/docs/nightly/spark-getting-started/">Apache Spark</a> (Danica Fine covers this in her video <a href="https://www.youtube.com/watch?v=5pXfznKniGg">here</a>)</p>
</li>
<li>
<p>Flink CDC added a <a href="https://nightlies.apache.org/flink/flink-cdc-docs-master/docs/connectors/pipeline-connectors/iceberg/">pipeline connector for Iceberg</a> in the 3.5 release.
Thereâ€™s no source connector for Kafka, but if your data is coming from <a href="https://nightlies.apache.org/flink/flink-cdc-docs-master/docs/connectors/pipeline-connectors/postgres/">Postgres</a> or <a href="https://nightlies.apache.org/flink/flink-cdc-docs-master/docs/connectors/pipeline-connectors/mysql/">MySQL</a> this might be an interesting option to look into.</p>
</li>
<li>
<p>The <a href="https://memiiso.github.io/debezium-server-iceberg/">Debezium Iceberg Consumer</a> is a community project that integrates with Debezium Server as a sink to Iceberg.
Similar to Flink CDC Pipelines, youâ€™d not use it for reading from Kafka but if youâ€™ve got a Debezium-supported RDBMS as source and youâ€™re not already running Kafka, this could be worth a look.</p>
</li>
<li>
<p>Aiven recently published <a href="https://github.com/Aiven-Open/tiered-storage-for-apache-kafka/blob/main/iceberg_whitepaper.md#upcoming-work">a whitepaper</a> describing <code>Iceberg Topics for Apache Kafka</code>.
Itâ€™s very early days and it has yet to be proven in production, and has significant gaps including lack of schema evolution.
Itâ€™ll be interesting to see how the project develops and the traction that itâ€™ll get.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_tldr">tl;dr&nbsp;<a class="headline-hash" href="#_tldr">ðŸ”—</a> </h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p><strong>Flink SQL</strong> is fantastic if you want to process data before sending it to Iceberg, typically as part of an analytics pipeline.
If you just need a &#34;dumb pipe&#34; itâ€™s less easy to justify.</p>
</li>
<li>
<p><strong>Kafka Connect</strong> excels as a &#34;dumb pipe&#34;, and also has support for stateless transformations.
If you want to do stateful processing youâ€™ll want to pair it with a stream processor (hey, such as Flink SQL!).</p>
</li>
<li>
<p><strong>Tableflow</strong> is a fully-managed tool for getting data from Kafka into Iceberg.
Itâ€™s part of Confluent Cloud so you also have access to Flink SQL through Confluent Cloud for Apache Flink if you want to pre-process any of the data before sending it to Iceberg.
Tableflow includes table maintenance, which youâ€™d have to do yourself if using Flink SQL or Kafka Connect to send the data to Iceberg.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_references">References&nbsp;<a class="headline-hash" href="#_references">ðŸ”—</a> </h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p><a href="/2025/07/14/keeping-your-data-lakehouse-in-order-table-maintenance-in-apache-iceberg/">Keeping your Data Lakehouse in Order: Table Maintenance in Apache Iceberg</a></p>
</li>
<li>
<p><a href="/2025/06/24/writing-to-apache-iceberg-on-s3-using-flink-sql-with-glue-catalog/">Writing to Apache Iceberg on S3 using Flink SQL with Glue catalog</a></p>
</li>
<li>
<p><a href="/2025/07/04/writing-to-apache-iceberg-on-s3-using-kafka-connect-with-glue-catalog/">Writing to Apache Iceberg on S3 using Kafka Connect with Glue catalog</a></p>
</li>
<li>
<p>ðŸŽ¥ <a href="https://current.confluent.io/post-conference-videos-2025/tableflow-not-just-another-kafka-to-iceberg-connector-lnd25">Tableflow: Not Just Another Kafka-to-Iceberg Connector!</a> (Alex Sorokoumov)</p>
</li>
<li>
<p>ðŸ“‘ <a href="https://microsites.databricks.com/sites/default/files/dais/2025/D25B3065_v2-Adi_Polak_DAIS_2025_kafka2iceberg.pdf">No More Fragile Pipelines: Kafka and Iceberg the Declarative Way - Adi Polak</a> (<a href="https://www.youtube.com/watch?v=zDVaYolMoJg">ðŸŽ¥ Video</a>)</p>
</li>
<li>
<p>ðŸŽ¥ <a href="https://www.youtube.com/watch?v=5pXfznKniGg">Iced Kaf-fee: Chilling Kafka Data into Iceberg Tables by Danica Fine</a></p>
</li>
</ul>
</div>
</div>
</div>
	<hr>
	<div style="background-color: rgba(204, 234, 255, 0.25); margin-bottom:50px;margin-top:50px;padding: 20px; border-width: 2px; border-style: solid; border-color: darkorange;">
	
		<script src="https://giscus.app/client.js"
				data-repo="rmoff/rmoff-blog"
				data-repo-id="MDEwOlJlcG9zaXRvcnkxNTE3NDg2MTE="
				data-category="Announcements"
				data-category-id="DIC_kwDOCQuAA84CvP5T"
				data-mapping="pathname"
				data-strict="1"
				data-reactions-enabled="1"
				data-emit-metadata="0"
				data-input-position="bottom"
				data-theme="light"
				data-lang="en"
				crossorigin="anonymous"
				async>
		</script>
		
	</div>
		
				<div class="hide-print sans-serif f6 f5-l mt5 ph3 pb6 center nested-copy-line-height lh-copy nested-links mw-100 measure-wide">
		<div class="about-the-author">
		
			
			
				
					<hr>
<p><img src="/images/2018/05/ksldn18-01.jpg" alt="Robin Moffatt"></p>
<p><a href="https://bsky.app/profile/rmoff.net"><b class="fa-brands fa-bluesky"></b></a>  <em>Robin Moffatt works on the DevRel team at Confluent. He likes writing about himself in the third person, eating good breakfasts, and drinking good beer.</em></p>

				
			
		
		</div>
		
	</div>

		

</article>
      </main>
    
      
      <div class="docs-toc">
        <ul class="nav toc-top">
          <li><a href="#" id="back_to_top" class="docs-toc-title">Contents</a></li>
        </ul>
        <nav id="TableOfContents">
  <ul>
    <li><a href="#_the_candidates">The Candidates</a></li>
    <li><a href="#_the_approach">The Approach</a></li>
    <li><a href="#_tool_overview">Tool overview</a>
      <ul>
        <li><a href="#_apache_flink_sql">Apache Flink SQL</a></li>
        <li><a href="#_kafka_connect">Kafka Connect</a></li>
        <li><a href="#_tableflow">Tableflow</a></li>
      </ul>
    </li>
    <li><a href="#_your_data">Your Data</a>
      <ul>
        <li><a href="#_where_is_the_data_coming_from">Where is the data coming from?</a></li>
        <li><a href="#_how_many_topics_do_you_have">How many topics do you have?</a></li>
        <li><a href="#_whither_schema">Whither Schema?</a></li>
        <li><a href="#_schema_evolution">Schema Evolution</a></li>
        <li><a href="#_do_you_want_some_processing_to_go_with_that">Do you want some processing to go with that?</a></li>
        <li><a href="#_insert_overwrite_and_upsert"><code>INSERT OVERWRITE</code> and <code>UPSERT</code></a></li>
        <li><a href="#_delivery_semantics">Delivery Semantics</a></li>
      </ul>
    </li>
    <li><a href="#_living_with_it">Living with it</a>
      <ul>
        <li><a href="#_existing_ecosystem">Existing Ecosystem</a></li>
        <li><a href="#_iceberg_housekeeping">Iceberg Housekeeping</a></li>
        <li><a href="#_ease_of_use">Ease of Use</a></li>
        <li><a href="#_self_managed_vs_fully_managed">Self-Managed vs Fully-Managed</a></li>
      </ul>
    </li>
    <li><a href="#_cost">Cost</a></li>
    <li><a href="#_i_used_to_be_indecisivenow_im_not_so_sure">I used to be indecisiveâ€¦now Iâ€™m not so sureâ€¦</a></li>
    <li><a href="#_but_what_about_this_other_tool">bUt wHaT aBoUt tHiS oThEr tOoL?</a></li>
    <li><a href="#_tldr">tl;dr</a></li>
    <li><a href="#_references">References</a></li>
  </ul>
</nav>
      </div>
      
      <div class="toc-mobile-label">TABLE OF CONTENTS</div>
      
    
    </div>
  </div>
</div>


		</main>
		
		
		<footer class="hide-print sans-serif f6 fw1 bg-black near-white bottom-0 w-100 pa3" role="contentinfo">
			<p class="w-50 fr tr">
			<a class="no-underline near-white" href="https://github.com/xaprb/story"><img class="dib" title="Made with Hugo and Story" alt="Story logo" src="https://rmoff.net/img/story-logo-white.svg" style="width: 1.5rem; height: 1.5rem" /></a>
			</p>
			<p class="w-50 near-white">
				&copy; 2025 
			</p>
		</footer>
		
	</body>
</html>
