<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<title>Streaming data from SQL Server to Kafka to Snowflake ❄️ with Kafka Connect</title>
		<link rel="alternate" type="application/rss+xml" title="RSS" href="https://rmoff.net/index.xml">
		<link rel="canonical" href="https://rmoff.net/2019/11/20/streaming-data-from-sql-server-to-kafka-to-snowflake-with-kafka-connect/">
		
		
		
		<meta name="generator" content="Hugo 0.75.1" />

		
		<meta property="og:title" content="Streaming data from SQL Server to Kafka to Snowflake ❄️ with Kafka Connect" />
		<meta property="og:type" content="article" />
		<meta property="og:image" content="https://rmoff.net/images/2019/11/IMG_1303.jpeg" />
		<meta property="og:description" content="" />
		<meta property="og:url" content="https://rmoff.net/2019/11/20/streaming-data-from-sql-server-to-kafka-to-snowflake-with-kafka-connect/" />
		<meta property="og:site_name" content="Streaming data from SQL Server to Kafka to Snowflake ❄️ with Kafka Connect" />
		<meta name="twitter:card" content="summary_large_image" />
		<meta name="twitter:site" content="@" />


		
		<link rel="stylesheet" href="https://rmoff.net/css/tachyons.min.css" />
		<link rel="stylesheet" href="https://rmoff.net/css/story.css" />
		<link rel="stylesheet" href="https://rmoff.net/css/descartes.css" />
		
		<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">
		<link href="https://fonts.googleapis.com/css?family=Quattrocento+Sans:400,400i,700,700i|Quattrocento:400,700|Spectral:400,400i,700,700i&amp;subset=latin-ext" rel="stylesheet">
		

		<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
		
		<script src="https://rmoff.net/js/story.js"></script>

	</head>
	<body class="ma0 bg-white section-post page-kind-page is-page-true ">
		
		<header class="cover bg-top" style="background-image: url('https://rmoff.net/images/2019/11/IMG_1303.jpeg'); background-position: center;">
			<div class="bg-black-30 bb bt">

				<nav class="hide-print sans-serif  border-box pa3 ph5-l">
					<a href="https://rmoff.net" title="Home">
						<img src="https://rmoff.net/img/logo.jpg" class="w2 h2 br-100" alt="rmoff&#39;s random ramblings" />
					</a>
					<div class="fr h2 pv2 tr">
						<a class="link f5 ml2 dim near-white" href="https://talks.rmoff.net/bio">about</a>
						<a class="link f5 ml2 dim near-white" href="https://talks.rmoff.net">talks</a>
						<a class="link f5 ml2 dim near-white" href="https://www.youtube.com/c/rmoff"><i class="fab fa-youtube-square"></i></a>
						<a class="link f5 ml2 dim near-white" href="https://twitter.com/rmoff/"><i class="fab fa-twitter-square"></i></a>
						<a class="link f5 ml2 dim near-white" href="https://github.com/rmoff/"><i class="fab fa-github-square"></i></a>
						<a class="link f5 ml2 dim near-white" href="https://www.linkedin.com/in/robinmoffatt/"><i class="fab fa-linkedin"></i></a>
						<a class="link f5 ml2 dim near-white fas fa-rss-square" href="https://rmoff.net/index.xml" title="RSS Feed"></a>
						<a class="link f5 ml2 dim near-white fas fa-search" href="https://rmoff.net/search/" role="search" title="Search"></a>
					</div>
				</nav>

				<div id="hdr" class="tc-l pv4-ns pv5-l pv2 ph3 ph4-ns">
					<h1 class="near-white mt1-ns f2 fw3 mb0 mt0 lh-title">Streaming data from SQL Server to Kafka to Snowflake ❄️ with Kafka Connect</h1>
					<h2 class="near-white mt3-l mb4-l fw1 f6 f3-l measure-wide-l center lh-copy mt2 mb3">
						
						
							
								Published
								<time datetime="2019-11-20T17:59:50Z">Nov 20, 2019</time>
								<span class="display-print">by </span>
								 in <a href="https://rmoff.net/categories/kafka-connect" class="no-underline category near-white dim">Kafka Connect</a>, <a href="https://rmoff.net/categories/snowflake" class="no-underline category near-white dim">Snowflake</a>, <a href="https://rmoff.net/categories/sql-server" class="no-underline category near-white dim">SQL Server</a>, <a href="https://rmoff.net/categories/confluent-cloud" class="no-underline category near-white dim">Confluent Cloud</a>, <a href="https://rmoff.net/categories/debezium" class="no-underline category near-white dim">Debezium</a>
								<span class="display-print">at https://rmoff.net/2019/11/20/streaming-data-from-sql-server-to-kafka-to-snowflake-with-kafka-connect/</span>
							
						
					</h2>
				</div>

				
				
				
				

			</div>
		</header>
		
		<main role="main">
		
<article class="center bg-white br-3 pv1 ph4 lh-copy f5 nested-links mw7">
	<div class="paragraph">
<p><a href="https://www.snowflake.com/">Snowflake</a> is <em>the data warehouse built for the cloud</em>, so let’s get all ☁️ cloudy and stream some data from Kafka running in <a href="https://confluent.cloud">Confluent Cloud</a> to Snowflake!</p>
</div>
<div class="paragraph">
<p>What I’m showing also works just as well for an on-premises Kafka cluster. I’m using SQL Server as an example data source, with Debezium to capture and stream and changes from it into Kafka.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/2019/11/sf01.png" alt="sf01"/>
</div>
</div>
<div class="paragraph">
<p>I’m assuming that you’ve signed up for <a href="https://confluent.cloud/">Confluent Cloud</a> and <a href="https://www.snowflake.com/try-the-data-warehouse-built-for-the-cloud/">Snowflake</a> and are the proud owner of credentials for both. I’m going to use a demo rig based on Docker to provision SQL Server and a Kafka Connect worker, but you can use your own setup if you want.</p>
</div>
<div class="paragraph">
<p>All the code shown here is based on <a href="https://github.com/confluentinc/demo-scene/tree/master/pipeline-to-the-cloud">this github repo</a>. If you’re following along then make sure you set up <code>.env</code> (copy the template from <code>.env.example</code>) with all of your cloud details. This <code>.env</code> file gets mounted in the Docker container to <code>/data/credentials.properties</code>, which is what’s referenced in the connector configurations below.</p>
</div>
<div class="sect1">
<h2 id="_sql_server_️_kafka_with_debezium">SQL Server ➡️ Kafka with Debezium</h2>
<div class="sectionbody">
<div class="paragraph">
<p>SQL Server needs to be configured for CDC at a database level:</p>
</div>
<div class="paragraph">
<div class="highlight"><pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sql" data-lang="sql">USE [demo]
<span style="color:#008000;font-weight:bold">GO</span>
<span style="color:#008000;font-weight:bold">EXEC</span> sys.sp_cdc_enable_db
<span style="color:#008000;font-weight:bold">GO</span> </code></pre></div>
</div>
<div class="paragraph">
<p>and then per table:</p>
</div>
<div class="paragraph">
<div class="highlight"><pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sql" data-lang="sql">USE [demo]

<span style="color:#008000;font-weight:bold">EXEC</span> sys.sp_cdc_enable_table
<span style="color:#666">@</span>source_schema <span style="color:#666">=</span> N<span style="color:#ba2121">&#39;dbo&#39;</span>,
<span style="color:#666">@</span>source_name   <span style="color:#666">=</span> N<span style="color:#ba2121">&#39;ORDERS&#39;</span>,
<span style="color:#666">@</span>role_name     <span style="color:#666">=</span> <span style="color:#008000;font-weight:bold">NULL</span>,
<span style="color:#666">@</span>supports_net_changes <span style="color:#666">=</span> <span style="color:#666">0</span>
<span style="color:#008000;font-weight:bold">GO</span> </code></pre></div>
</div>
<div class="paragraph">
<p>Once that’s done you can setup the connector. If you’ve not installed it already then make sure you’ve installed the Debezium SQL Server connector in your Kafka Connect worker and restarted it:</p>
</div>
<div class="paragraph">
<div class="highlight"><pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">confluent-hub install --no-prompt debezium/debezium-connector-sqlserver:0.10.0</code></pre></div>
</div>
<div class="paragraph">
<p>Check that the plugin has been loaded successfully:</p>
</div>
<div class="paragraph">
<div class="highlight"><pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ curl -s localhost:8083/connector-plugins|jq <span style="color:#ba2121">&#39;.[].class&#39;</span>|grep debezium
<span style="color:#ba2121">&#34;io.debezium.connector.sqlserver.SqlServerConnector&#34;</span></code></pre></div>
</div>
<div class="paragraph">
<p>Debezium will write to a topic with all of the data from SQL Server. Debezium also needs its own topic for tracking the DDL—and we need to pre-create both these topics (see <a href="https://rmoff.net/2019/10/16/using-kafka-connect-and-debezium-with-confluent-cloud/">this article</a> for more details):</p>
</div>
<div class="paragraph">
<div class="highlight"><pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ ccloud kafka topic create --partitions <span style="color:#666">1</span> dbz_dbhistory.mssql.asgard-01
$ ccloud kafka topic create mssql-01-mssql.dbo.ORDERS
$ ccloud kafka topic list
                 Name
+-------------------------------------+
  dbz_dbhistory.mssql.asgard-01
  mssql-01-mssql.dbo.ORDERS</code></pre></div>
</div>
<div class="paragraph">
<p>Now create the connector. It’s a bit more verbose because we’re using a secure Kafka cluster and Debezium needs the details passed directly to it:</p>
</div>
<div class="paragraph">
<div class="highlight"><pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">curl -i -X PUT -H  <span style="color:#ba2121">&#34;Content-Type:application/json&#34;</span> <span style="color:#b62;font-weight:bold">\
</span><span style="color:#b62;font-weight:bold"></span>    http://localhost:8083/connectors/source-debezium-mssql-01/config <span style="color:#b62;font-weight:bold">\
</span><span style="color:#b62;font-weight:bold"></span>    -d <span style="color:#ba2121">&#39;{
</span><span style="color:#ba2121">    &#34;connector.class&#34;: &#34;io.debezium.connector.sqlserver.SqlServerConnector&#34;, 
</span><span style="color:#ba2121">    &#34;database.hostname&#34;: &#34;mssql&#34;,
</span><span style="color:#ba2121">    &#34;database.port&#34;: &#34;1433&#34;,
</span><span style="color:#ba2121">    &#34;database.user&#34;: &#34;sa&#34;,
</span><span style="color:#ba2121">    &#34;database.password&#34;: &#34;Admin123&#34;,
</span><span style="color:#ba2121">    &#34;database.dbname&#34;: &#34;demo&#34;,
</span><span style="color:#ba2121">    &#34;database.server.name&#34;: &#34;mssql&#34;,
</span><span style="color:#ba2121">    &#34;table.whitelist&#34;:&#34;dbo.orders&#34;,
</span><span style="color:#ba2121">    &#34;database.history.kafka.bootstrap.servers&#34;: &#34;${file:/data/credentials.properties:CCLOUD_BROKER_HOST}:9092&#34;,
</span><span style="color:#ba2121">    &#34;database.history.kafka.topic&#34;: &#34;dbz_dbhistory.mssql.asgard-01&#34;,
</span><span style="color:#ba2121">    &#34;database.history.consumer.security.protocol&#34;: &#34;SASL_SSL&#34;,
</span><span style="color:#ba2121">    &#34;database.history.consumer.ssl.endpoint.identification.algorithm&#34;: &#34;https&#34;,
</span><span style="color:#ba2121">    &#34;database.history.consumer.sasl.mechanism&#34;: &#34;PLAIN&#34;,
</span><span style="color:#ba2121">    &#34;database.history.consumer.sasl.jaas.config&#34;: &#34;org.apache.kafka.common.security.plain.PlainLoginModule required username=\&#34;${file:/data/credentials.properties:CCLOUD_API_KEY}\&#34; password=\&#34;${file:/data/credentials.properties:CCLOUD_API_SECRET}\&#34;;&#34;,
</span><span style="color:#ba2121">    &#34;database.history.producer.security.protocol&#34;: &#34;SASL_SSL&#34;,
</span><span style="color:#ba2121">    &#34;database.history.producer.ssl.endpoint.identification.algorithm&#34;: &#34;https&#34;,
</span><span style="color:#ba2121">    &#34;database.history.producer.sasl.mechanism&#34;: &#34;PLAIN&#34;,
</span><span style="color:#ba2121">    &#34;database.history.producer.sasl.jaas.config&#34;: &#34;org.apache.kafka.common.security.plain.PlainLoginModule required username=\&#34;${file:/data/credentials.properties:CCLOUD_API_KEY}\&#34; password=\&#34;${file:/data/credentials.properties:CCLOUD_API_SECRET}\&#34;;&#34;,
</span><span style="color:#ba2121">    &#34;decimal.handling.mode&#34;:&#34;double&#34;,
</span><span style="color:#ba2121">    &#34;transforms&#34;: &#34;unwrap,addTopicPrefix&#34;,
</span><span style="color:#ba2121">    &#34;transforms.unwrap.type&#34;: &#34;io.debezium.transforms.ExtractNewRecordState&#34;,
</span><span style="color:#ba2121">    &#34;transforms.addTopicPrefix.type&#34;:&#34;org.apache.kafka.connect.transforms.RegexRouter&#34;,
</span><span style="color:#ba2121">    &#34;transforms.addTopicPrefix.regex&#34;:&#34;(.*)&#34;,
</span><span style="color:#ba2121">    &#34;transforms.addTopicPrefix.replacement&#34;:&#34;mssql-01-$1&#34;
</span><span style="color:#ba2121">    }&#39;</span></code></pre></div>
</div>
<div class="paragraph">
<p>With that running we can then check the data from Kafka. Note that we’re using Avro to serialise the data, with the Schema Registry running as part of Confluent Cloud.</p>
</div>
<div class="paragraph">
<div class="highlight"><pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ ccloud kafka topic consume --from-beginning mssql-04-mssql.dbo.ORDERS
Starting Kafka Consumer. ^C to <span style="color:#008000">exit</span>
����������@Proper Job
���q<span style="color:#666">=</span>
ףp�?Wainwright
��Ҝ333333@Proper Job
�ޜ��Q��@Galena</code></pre></div>
</div>
<div class="paragraph">
<p>Because it’s Avro, it renders here as a bunch of <em>odd</em> characters. We can use a tool such as <code>kafkacat</code> if we want to deserialise it:</p>
</div>
<div class="paragraph">
<div class="highlight"><pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#008000">source</span> .env
docker run --rm edenhill/kafkacat:1.5.0 <span style="color:#b62;font-weight:bold">\
</span><span style="color:#b62;font-weight:bold"></span>    -X security.protocol<span style="color:#666">=</span>SASL_SSL -X sasl.mechanisms<span style="color:#666">=</span>PLAIN <span style="color:#b62;font-weight:bold">\
</span><span style="color:#b62;font-weight:bold"></span>    -X ssl.ca.location<span style="color:#666">=</span>./etc/ssl/cert.pem -X api.version.request<span style="color:#666">=</span><span style="color:#008000">true</span> <span style="color:#b62;font-weight:bold">\
</span><span style="color:#b62;font-weight:bold"></span>    -b <span style="color:#b68;font-weight:bold">${</span><span style="color:#19177c">CCLOUD_BROKER_HOST</span><span style="color:#b68;font-weight:bold">}</span>:9092 <span style="color:#b62;font-weight:bold">\
</span><span style="color:#b62;font-weight:bold"></span>    -X sasl.username<span style="color:#666">=</span><span style="color:#ba2121">&#34;</span><span style="color:#b68;font-weight:bold">${</span><span style="color:#19177c">CCLOUD_API_KEY</span><span style="color:#b68;font-weight:bold">}</span><span style="color:#ba2121">&#34;</span> <span style="color:#b62;font-weight:bold">\
</span><span style="color:#b62;font-weight:bold"></span>    -X sasl.password<span style="color:#666">=</span><span style="color:#ba2121">&#34;</span><span style="color:#b68;font-weight:bold">${</span><span style="color:#19177c">CCLOUD_API_SECRET</span><span style="color:#b68;font-weight:bold">}</span><span style="color:#ba2121">&#34;</span> <span style="color:#b62;font-weight:bold">\
</span><span style="color:#b62;font-weight:bold"></span>    -r https://<span style="color:#ba2121">&#34;</span><span style="color:#b68;font-weight:bold">${</span><span style="color:#19177c">CCLOUD_SCHEMA_REGISTRY_API_KEY</span><span style="color:#b68;font-weight:bold">}</span><span style="color:#ba2121">&#34;</span>:<span style="color:#ba2121">&#34;</span><span style="color:#b68;font-weight:bold">${</span><span style="color:#19177c">CCLOUD_SCHEMA_REGISTRY_API_SECRET</span><span style="color:#b68;font-weight:bold">}</span><span style="color:#ba2121">&#34;</span>@<span style="color:#b68;font-weight:bold">${</span><span style="color:#19177c">CCLOUD_SCHEMA_REGISTRY_HOST</span><span style="color:#b68;font-weight:bold">}</span> <span style="color:#b62;font-weight:bold">\
</span><span style="color:#b62;font-weight:bold"></span>    -s avro <span style="color:#b62;font-weight:bold">\
</span><span style="color:#b62;font-weight:bold"></span>    -t mssql-04-mssql.dbo.ORDERS <span style="color:#b62;font-weight:bold">\
</span><span style="color:#b62;font-weight:bold"></span>    -f <span style="color:#ba2121">&#39;Topic %t[%p], offset: %o, Headers: %h, key: %k, payload: %S bytes: %s\n&#39;</span> <span style="color:#b62;font-weight:bold">\
</span><span style="color:#b62;font-weight:bold"></span>    -C -o beginning -c5</code></pre></div>
</div>
<div class="paragraph">
<div class="highlight"><pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">Topic mssql-04-mssql.dbo.ORDERS<span style="color:#666">[</span>5<span style="color:#666">]</span>, offset: 0, Headers: , key: , payload: <span style="color:#666">34</span> bytes: <span style="color:#666">{</span><span style="color:#ba2121">&#34;order_id&#34;</span>: <span style="color:#666">{</span><span style="color:#ba2121">&#34;int&#34;</span>: 5<span style="color:#666">}</span>, <span style="color:#ba2121">&#34;customer_id&#34;</span>: <span style="color:#666">{</span><span style="color:#ba2121">&#34;int&#34;</span>: 14<span style="color:#666">}</span>, <span style="color:#ba2121">&#34;order_ts&#34;</span>: <span style="color:#666">{</span><span style="color:#ba2121">&#34;int&#34;</span>: 18233<span style="color:#666">}</span>, <span style="color:#ba2121">&#34;order_total_usd&#34;</span>: <span style="color:#666">{</span><span style="color:#ba2121">&#34;double&#34;</span>: 3.8900000000000001<span style="color:#666">}</span>, <span style="color:#ba2121">&#34;item&#34;</span>: <span style="color:#666">{</span><span style="color:#ba2121">&#34;string&#34;</span>: <span style="color:#ba2121">&#34;Wainwright&#34;</span><span style="color:#666">}}</span>
Topic mssql-04-mssql.dbo.ORDERS<span style="color:#666">[</span>5<span style="color:#666">]</span>, offset: 1, Headers: , key: , payload: <span style="color:#666">30</span> bytes: <span style="color:#666">{</span><span style="color:#ba2121">&#34;order_id&#34;</span>: <span style="color:#666">{</span><span style="color:#ba2121">&#34;int&#34;</span>: 6<span style="color:#666">}</span>, <span style="color:#ba2121">&#34;customer_id&#34;</span>: <span style="color:#666">{</span><span style="color:#ba2121">&#34;int&#34;</span>: 16<span style="color:#666">}</span>, <span style="color:#ba2121">&#34;order_ts&#34;</span>: <span style="color:#666">{</span><span style="color:#ba2121">&#34;int&#34;</span>: 18225<span style="color:#666">}</span>, <span style="color:#ba2121">&#34;order_total_usd&#34;</span>: <span style="color:#666">{</span><span style="color:#ba2121">&#34;double&#34;</span>: 3.9100000000000001<span style="color:#666">}</span>, <span style="color:#ba2121">&#34;item&#34;</span>: <span style="color:#666">{</span><span style="color:#ba2121">&#34;string&#34;</span>: <span style="color:#ba2121">&#34;Galena&#34;</span><span style="color:#666">}}</span>
Topic mssql-04-mssql.dbo.ORDERS<span style="color:#666">[</span>5<span style="color:#666">]</span>, offset: 2, Headers: , key: , payload: <span style="color:#666">32</span> bytes: <span style="color:#666">{</span><span style="color:#ba2121">&#34;order_id&#34;</span>: <span style="color:#666">{</span><span style="color:#ba2121">&#34;int&#34;</span>: 7<span style="color:#666">}</span>, <span style="color:#ba2121">&#34;customer_id&#34;</span>: <span style="color:#666">{</span><span style="color:#ba2121">&#34;int&#34;</span>: 19<span style="color:#666">}</span>, <span style="color:#ba2121">&#34;order_ts&#34;</span>: <span style="color:#666">{</span><span style="color:#ba2121">&#34;int&#34;</span>: 18227<span style="color:#666">}</span>, <span style="color:#ba2121">&#34;order_total_usd&#34;</span>: <span style="color:#666">{</span><span style="color:#ba2121">&#34;double&#34;</span>: 4.6900000000000004<span style="color:#666">}</span>, <span style="color:#ba2121">&#34;item&#34;</span>: <span style="color:#666">{</span><span style="color:#ba2121">&#34;string&#34;</span>: <span style="color:#ba2121">&#34;Landlord&#34;</span><span style="color:#666">}}</span>
Topic mssql-04-mssql.dbo.ORDERS<span style="color:#666">[</span>5<span style="color:#666">]</span>, offset: 3, Headers: , key: , payload: <span style="color:#666">34</span> bytes: <span style="color:#666">{</span><span style="color:#ba2121">&#34;order_id&#34;</span>: <span style="color:#666">{</span><span style="color:#ba2121">&#34;int&#34;</span>: 8<span style="color:#666">}</span>, <span style="color:#ba2121">&#34;customer_id&#34;</span>: <span style="color:#666">{</span><span style="color:#ba2121">&#34;int&#34;</span>: 2<span style="color:#666">}</span>, <span style="color:#ba2121">&#34;order_ts&#34;</span>: <span style="color:#666">{</span><span style="color:#ba2121">&#34;int&#34;</span>: 18228<span style="color:#666">}</span>, <span style="color:#ba2121">&#34;order_total_usd&#34;</span>: <span style="color:#666">{</span><span style="color:#ba2121">&#34;double&#34;</span>: 3.6699999999999999<span style="color:#666">}</span>, <span style="color:#ba2121">&#34;item&#34;</span>: <span style="color:#666">{</span><span style="color:#ba2121">&#34;string&#34;</span>: <span style="color:#ba2121">&#34;Proper Job&#34;</span><span style="color:#666">}}</span>
Topic mssql-04-mssql.dbo.ORDERS<span style="color:#666">[</span>5<span style="color:#666">]</span>, offset: 4, Headers: , key: , payload: <span style="color:#666">39</span> bytes: <span style="color:#666">{</span><span style="color:#ba2121">&#34;order_id&#34;</span>: <span style="color:#666">{</span><span style="color:#ba2121">&#34;int&#34;</span>: 9<span style="color:#666">}</span>, <span style="color:#ba2121">&#34;customer_id&#34;</span>: <span style="color:#666">{</span><span style="color:#ba2121">&#34;int&#34;</span>: 5<span style="color:#666">}</span>, <span style="color:#ba2121">&#34;order_ts&#34;</span>: <span style="color:#666">{</span><span style="color:#ba2121">&#34;int&#34;</span>: 18229<span style="color:#666">}</span>, <span style="color:#ba2121">&#34;order_total_usd&#34;</span>: <span style="color:#666">{</span><span style="color:#ba2121">&#34;double&#34;</span>: 2.2400000000000002<span style="color:#666">}</span>, <span style="color:#ba2121">&#34;item&#34;</span>: <span style="color:#666">{</span><span style="color:#ba2121">&#34;string&#34;</span>: <span style="color:#ba2121">&#34;Black Sheep Ale&#34;</span><span style="color:#666">}}</span></code></pre></div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_kafka_️_snowflake_️">Kafka ➡️ Snowflake ❄️</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_setting_up_snowflake_account_and_key_pair">Setting up Snowflake account and key pair</h3>
<div class="paragraph">
<p>To send data to Snowflake you first need to generate a private/public key pair that will be used for authentication. Generate the keys:</p>
</div>
<div class="paragraph">
<div class="highlight"><pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#408080;font-style:italic"># Create Private key - keep this safe, do not share!</span>
openssl genrsa -out snowflake_key.pem <span style="color:#666">2048</span>
<span style="color:#408080;font-style:italic"># Generate public key from private key. You can share your public key. </span>
openssl rsa -in snowflake_key.pem  -pubout -out snowflake_key.pub</code></pre></div>
</div>
<div class="paragraph">
<p>You should now have two files:</p>
</div>
<div class="paragraph">
<div class="highlight"><pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ ls -l snowflake_key*
-rw-r--r--  <span style="color:#666">1</span> rmoff  staff  <span style="color:#666">1679</span> <span style="color:#666">21</span> Nov 09:28 snowflake_key.pem
-rw-r--r--  <span style="color:#666">1</span> rmoff  staff   <span style="color:#666">451</span> <span style="color:#666">21</span> Nov 09:28 snowflake_key.pub</code></pre></div>
</div>
<div class="paragraph">
<p>Now you need to get your <strong>public</strong> key:</p>
</div>
<div class="paragraph">
<div class="highlight"><pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ cat snowflake_key.pub
-----BEGIN PUBLIC KEY-----
MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAya/BRlyhsfdlJQnPqoRn
lJfxKxujoyionNBPIDFpVpGZ9C1ZE7Q1kGIrEoZfq1t2p6lT8cX6gIZkMDF10I/8
yqHGiCdSEQBuMYXwWpnl3C1sttFHNfxbsjiKSZDlMTbEmzwU5s5LpMt8YvFWp8Iu
3ilHK9Vwy0wbsMDCjDcrC6xCS6qp1n4oso+V24aaxKd/mUtpPy9toAx2NC5GMoDb
tehlbTyPkk/9qFl7GUsf46HbQMEGoGkRrY9VFm+3Z8wCwsFNpURIvLEBcrTFdnmn
IgDBa96+dKgaN8qV6RW3ZMheQOJH1tP3M0qXsLNbR00E7yAlCYjNQD3hXjGKL3Oc
5wIDAQAB
-----END PUBLIC KEY-----</code></pre></div>
</div>
<div class="paragraph">
<p>But minus the header and footer and joined over a single line. You can do this manually, or automagically:</p>
</div>
<div class="paragraph">
<div class="highlight"><pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ grep -v <span style="color:#ba2121">&#34;BEGIN PUBLIC&#34;</span> snowflake_key.pub | grep -v <span style="color:#ba2121">&#34;END PUBLIC&#34;</span>|tr -d <span style="color:#b62;font-weight:bold">\n</span>
MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAya/BRlyhsfdlJQnPqoRnlJfxKxujoyionNBPIDFpVpGZ9C1ZE7Q1kGIrEoZfq1t2p6lT8cX6gIZkMDF10I/8yqHGiCdSEQBuMYXwWpnl3C1sttFHNfxbsjiKSZDlMTbEmzwU5s5LpMt8YvFWp8Iu3ilHK9Vwy0wbsMDCjDcrC6xCS6qp1n4oso+V24aaxKd/mUtpPy9toAx2NC5GMoDbtehlbTyPkk/9qFl7GUsf46HbQMEGoGkRrY9VFm+3Z8wCwsFNpURIvLEBcrTFdnmnIgDBa96+dKgaN8qV6RW3ZMheQOJH1tP3M0qXsLNbR00E7yAlCYjNQD3hXjGKL3Oc5wIDAQAB</code></pre></div>
</div>
<div class="paragraph">
<p>Now head to Snowflake, where we need to create a user for loading the data. First up, switch to the <code>SECURITYADMIN</code> role.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/2019/11/sf02.png" alt="sf02"/>
</div>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
Make sure you do this in the <code>Context</code> section of the worksheet, not the top-right dropdown (otherwise you’ll get <code>SQL access control error: Insufficient privileges to operate on account &#39;xyz&#39;</code>).
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>Now create the user, here called <code>kafka</code>. Because we’re in demo-land we’re also granting Kafka the keys to the kingdom (<code>SYSADMIN</code>), just to make everything nice &#39;n easy.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-sql" data-lang="sql">CREATE USER kafka RSA_PUBLIC_KEY=&#39;MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAya/BRlyhsfdlJQnPqoRnlJfxKxujoyionNBPIDFpVpGZ9C1ZE7Q1kGIrEoZfq1t2p6lT8cX6gIZkMDF10I/8yqHGiCdSEQBuMYXwWpnl3C1sttFHNfxbsjiKSZDlMTbEmzwU5s5LpMt8YvFWp8Iu3ilHK9Vwy0wbsMDCjDcrC6xCS6qp1n4oso+V24aaxKd/mUtpPy9toAx2NC5GMoDbtehlbTyPkk/9qFl7GUsf46HbQMEGoGkRrY9VFm+3Z8wCwsFNpURIvLEBcrTFdnmnIgDBa96+dKgaN8qV6RW3ZMheQOJH1tP3M0qXsLNbR00E7yAlCYjNQD3hXjGKL3Oc5wIDAQAB&#39;;
GRANT ROLE SYSADMIN TO USER kafka;</code></pre>
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/2019/11/sf03.png" alt="sf03"/>
</div>
</div>
<div class="paragraph">
<p>Now we need to extract the private key for the key pair, which is in the <code>.pem</code> file that we created, minus the header and footer and on a single line:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/2019/11/sf04.png" alt="sf04"/>
</div>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
Your private key is <strong>private</strong> - don’t share it with anyone who shouldn’t have access to the account, and definitely don’t post it on the internet on a blog post!
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>As before you can extract the key automagically with:</p>
</div>
<div class="paragraph">
<div class="highlight"><pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">grep -v <span style="color:#ba2121">&#34;BEGIN RSA PRIVATE&#34;</span> snowflake_key.pem | grep -v <span style="color:#ba2121">&#34;END RSA PRIVATE&#34;</span>|tr -d <span style="color:#b62;font-weight:bold">\n</span></code></pre></div>
</div>
<div class="paragraph">
<p>Put this value, along with the URL of your Snowflake environment and the user that we created (<code>kafka</code>) in the <code>.env</code> file</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/2019/11/sf05.png" alt="sf05"/>
</div>
</div>
<div class="paragraph">
<p>This <code>.env</code> file gets mounted in the Docker container to <code>/data/credentials.properties</code> which is what’s referenced in the connector configuration below.</p>
</div>
</div>
<div class="sect2">
<h3 id="_setting_up_the_snowflake_connector">Setting up the Snowflake connector</h3>
<div class="paragraph">
<p>Install the connector:</p>
</div>
<div class="paragraph">
<div class="highlight"><pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">confluent-hub install --no-prompt snowflakeinc/snowflake-kafka-connector:0.5.5</code></pre></div>
</div>
<div class="paragraph">
<p>Restart the Kafka Connect connector and check that it’s been loaded:</p>
</div>
<div class="paragraph">
<div class="highlight"><pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ curl -s localhost:8083/connector-plugins|jq <span style="color:#ba2121">&#39;.[].class&#39;</span>|grep snowflake
<span style="color:#ba2121">&#34;com.snowflake.kafka.connector.SnowflakeSinkConnector&#34;</span></code></pre></div>
</div>
<div class="paragraph">
<p>Now set up your connector configuration. A few important settings of note:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>topics</code> - A comma separated list of one or more topics that are to be streamed to Snowflake. You can optionally map topics to table names with <code>snowflake.topic2table.map</code> but this is not mandatory.</p>
</li>
<li>
<p><code>value.converter</code> - Snowflake provide their own converters. Use either:</p>
<div class="ulist">
<ul>
<li>
<p><code>com.snowflake.kafka.connector.records.SnowflakeAvroConverter</code></p>
</li>
<li>
<p><code>com.snowflake.kafka.connector.records.SnowflakeJsonConverter</code></p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Authentication / sensitive information</strong> I’ve <a href="https://rmoff.net/2019/05/24/putting-kafka-connect-passwords-in-a-separate-file-/-externalising-secrets/">embedded these in a separate file</a> (<code>.env</code>) that’s loaded by the connector directly:</p>
<div class="ulist">
<ul>
<li>
<p><code>snowflake.url.name</code></p>
</li>
<li>
<p><code>snowflake.user.name</code> - we created the user <code>kafka</code> for this above</p>
</li>
<li>
<p><code>snowflake.private.key</code> - this is the key that we extracted in the step above</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>You can see all of the configuration options in <a href="https://docs.snowflake.net/manuals/user-guide/kafka-connector-install.html#kafka-configuration-properties">the documentation</a>.</p>
</div>
<div class="paragraph">
<p>Create the connector:</p>
</div>
<div class="paragraph">
<div class="highlight"><pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">curl -i -X PUT -H  <span style="color:#ba2121">&#34;Content-Type:application/json&#34;</span> <span style="color:#b62;font-weight:bold">\
</span><span style="color:#b62;font-weight:bold"></span>    http://localhost:8083/connectors/sink_snowflake_01/config <span style="color:#b62;font-weight:bold">\
</span><span style="color:#b62;font-weight:bold"></span>    -d <span style="color:#ba2121">&#39;{
</span><span style="color:#ba2121">        &#34;connector.class&#34;:&#34;com.snowflake.kafka.connector.SnowflakeSinkConnector&#34;,
</span><span style="color:#ba2121">        &#34;tasks.max&#34;:1,
</span><span style="color:#ba2121">        &#34;topics&#34;:&#34;mssql-01-mssql.dbo.ORDERS&#34;,
</span><span style="color:#ba2121">        &#34;snowflake.url.name&#34;:&#34;${file:/data/credentials.properties:SNOWFLAKE_HOST}&#34;,
</span><span style="color:#ba2121">        &#34;snowflake.user.name&#34;:&#34;${file:/data/credentials.properties:SNOWFLAKE_USER}&#34;,
</span><span style="color:#ba2121">        &#34;snowflake.user.role&#34;:&#34;SYSADMIN&#34;,
</span><span style="color:#ba2121">        &#34;snowflake.private.key&#34;:&#34;${file:/data/credentials.properties:SNOWFLAKE_PRIVATE_KEY}&#34;,
</span><span style="color:#ba2121">        &#34;snowflake.database.name&#34;:&#34;DEMO_DB&#34;,
</span><span style="color:#ba2121">        &#34;snowflake.schema.name&#34;:&#34;PUBLIC&#34;,
</span><span style="color:#ba2121">        &#34;key.converter&#34;:&#34;org.apache.kafka.connect.storage.StringConverter&#34;,
</span><span style="color:#ba2121">        &#34;value.converter&#34;:&#34;com.snowflake.kafka.connector.records.SnowflakeAvroConverter&#34;,
</span><span style="color:#ba2121">        &#34;value.converter.schema.registry.url&#34;:&#34;https://${file:/data/credentials.properties:CCLOUD_SCHEMA_REGISTRY_HOST}&#34;,
</span><span style="color:#ba2121">        &#34;value.converter.basic.auth.credentials.source&#34;:&#34;USER_INFO&#34;,
</span><span style="color:#ba2121">        &#34;value.converter.basic.auth.user.info&#34;:&#34;${file:/data/credentials.properties:CCLOUD_SCHEMA_REGISTRY_API_KEY}:${file:/data/credentials.properties:CCLOUD_SCHEMA_REGISTRY_API_SECRET}&#34;
</span><span style="color:#ba2121">    }&#39;</span></code></pre></div>
</div>
<div class="paragraph">
<p>Check that it’s running:</p>
</div>
<div class="paragraph">
<div class="highlight"><pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ curl -s <span style="color:#ba2121">&#34;http://localhost:8083/connectors?expand=info&amp;expand=status&#34;</span> | <span style="color:#b62;font-weight:bold">\
</span><span style="color:#b62;font-weight:bold"></span>           jq <span style="color:#ba2121">&#39;. | to_entries[] | [ .value.info.type, .key, .value.status.connector.state,.value.status.tasks[].state,.value.info.config.&#34;connector.class&#34;]|join(&#34;:|:&#34;)&#39;</span> | <span style="color:#b62;font-weight:bold">\
</span><span style="color:#b62;font-weight:bold"></span>           column -s : -t| sed <span style="color:#ba2121">&#39;s/\&#34;//g&#39;</span>| sort
sink    |  sink_snowflake_01         |  RUNNING  |  RUNNING  |  com.snowflake.kafka.connector.SnowflakeSinkConnector</code></pre></div>
</div>
<div class="paragraph">
<p>Now head over to Snowflake and you’ll see your table created and data loaded:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/2019/11/sf06.png" alt="sf06"/>
</div>
</div>
<div class="paragraph">
<p>The connector writes the Kafka message payload to the <code>RECORD_CONTENT</code> field and its metadata (partition, offset, etc) to <code>RECORD_METADATA</code>. You can access the nested values using the colon as a seperator, e.g.:</p>
</div>
<div class="paragraph">
<div class="highlight"><pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sql" data-lang="sql"><span style="color:#008000;font-weight:bold">SELECT</span> RECORD_CONTENT:customer_id <span style="color:#008000;font-weight:bold">AS</span> CUSTOMER_ID,
       RECORD_CONTENT:item <span style="color:#008000;font-weight:bold">AS</span> ITEM, 
       RECORD_CONTENT:order_total_usd <span style="color:#008000;font-weight:bold">AS</span> ORDER_TOTAL_USD
  <span style="color:#008000;font-weight:bold">FROM</span> <span style="color:#ba2121">&#34;DEMO_DB&#34;</span>.<span style="color:#ba2121">&#34;PUBLIC&#34;</span>.<span style="color:#ba2121">&#34;MSSQL_01_MSSQL_DBO_ORDERS_97237615&#34;</span>;</code></pre></div>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/2019/11/sf07.png" alt="sf07"/>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_footnote_a_few_gotchas">Footnote : a few gotchas</h3>
<div class="ulist">
<ul>
<li>
<p>Gotcha 01 : The <strong>connector name</strong> must be a valid Snowflake identifier. If it’s not you’ll get this error:</p>
<div class="paragraph">
<div class="highlight"><pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#666">[</span>SF_KAFKA_CONNECTOR<span style="color:#666">]</span> name is empty or invalid. It should match Snowflake object identifier syntax. Please see the documentation. <span style="color:#666">(</span>com.snowflake.kafka.connector.Utils:246<span style="color:#666">)</span></code></pre></div>
</div>
<div class="paragraph">
<p>In the example above, the connector name is <code>sink_snowflake_01</code>. If I tried to name it <code>sink-snowflake-01</code> (i.e. using <code>-</code> instead of <code>_</code>) then it would fail 🤷‍♂️</p>
</div>
<div class="paragraph">
<p>See <a href="https://github.com/snowflakedb/snowflake-kafka-connector/issues/62">this issue</a> on the Snowflake connector repo.</p>
</div>
<div class="paragraph">
<p><strong>Solution</strong>: don’t name your connector with characters that aren’t <a href="https://docs.snowflake.net/manuals/sql-reference/identifiers-syntax.html">valid in a Snowflake object name</a>.</p>
</div>
</li>
<li>
<p>You have to use Snowflake’s own converters, or else you get:</p>
<div class="paragraph">
<div class="highlight"><pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#666">[</span>SF_KAFKA_CONNECTOR<span style="color:#666">]</span> Exception: Invalid record data
<span style="color:#666">[</span>SF_KAFKA_CONNECTOR<span style="color:#666">]</span> Error Code: <span style="color:#666">0019</span>
<span style="color:#666">[</span>SF_KAFKA_CONNECTOR<span style="color:#666">]</span> Detail: Unrecognizable record content, please use Snowflake Converters</code></pre></div>
</div>
<div class="paragraph">
<p><strong>Solution</strong>: Depending on how your data is serialised, use <code>com.snowflake.kafka.connector.records.SnowflakeJsonConverter</code> or <code>com.snowflake.kafka.connector.records.SnowflakeAvroConverter</code>.</p>
</div>
</li>
<li>
<p>Sometimes the connector will fail with an error and need restarting:</p>
<div class="paragraph">
<div class="highlight"><pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#666">[</span>SF_KAFKA_CONNECTOR<span style="color:#666">]</span> Exception: Failed to put records
<span style="color:#666">[</span>SF_KAFKA_CONNECTOR<span style="color:#666">]</span> Error Code: <span style="color:#666">5014</span>
<span style="color:#666">[</span>SF_KAFKA_CONNECTOR<span style="color:#666">]</span> Detail: SinkTask hasn<span style="">&#39;</span>t been initialized before calling PUT <span style="color:#008000;font-weight:bold">function</span>
  at com.snowflake.kafka.connector.internal.SnowflakeErrors.getException<span style="color:#666">(</span>SnowflakeErrors.java:362<span style="color:#666">)</span>
  at com.snowflake.kafka.connector.internal.SnowflakeErrors.getException<span style="color:#666">(</span>SnowflakeErrors.java:321<span style="color:#666">)</span>
  at com.snowflake.kafka.connector.SnowflakeSinkTask.getSink<span style="color:#666">(</span>SnowflakeSinkTask.java:94<span style="color:#666">)</span>
  at com.snowflake.kafka.connector.SnowflakeSinkTask.put<span style="color:#666">(</span>SnowflakeSinkTask.java:195<span style="color:#666">)</span>
  at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages<span style="color:#666">(</span>WorkerSinkTask.java:538<span style="color:#666">)</span>
  at org.apache.kafka.connect.runtime.WorkerSinkTask.poll<span style="color:#666">(</span>WorkerSinkTask.java:321<span style="color:#666">)</span>
  at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration<span style="color:#666">(</span>WorkerSinkTask.java:224<span style="color:#666">)</span>
  at org.apache.kafka.connect.runtime.WorkerSinkTask.execute<span style="color:#666">(</span>WorkerSinkTask.java:192<span style="color:#666">)</span>
  at org.apache.kafka.connect.runtime.WorkerTask.doRun<span style="color:#666">(</span>WorkerTask.java:177<span style="color:#666">)</span>
  at org.apache.kafka.connect.runtime.WorkerTask.run<span style="color:#666">(</span>WorkerTask.java:227<span style="color:#666">)</span>
  at java.util.concurrent.Executors<span style="color:#19177c">$RunnableAdapter</span>.call<span style="color:#666">(</span>Executors.java:511<span style="color:#666">)</span>
  at java.util.concurrent.FutureTask.run<span style="color:#666">(</span>FutureTask.java:266<span style="color:#666">)</span>
  at java.util.concurrent.ThreadPoolExecutor.runWorker<span style="color:#666">(</span>ThreadPoolExecutor.java:1149<span style="color:#666">)</span>
  at java.util.concurrent.ThreadPoolExecutor<span style="color:#19177c">$Worker</span>.run<span style="color:#666">(</span>ThreadPoolExecutor.java:624<span style="color:#666">)</span>
  at java.lang.Thread.run<span style="color:#666">(</span>Thread.java:748<span style="color:#666">)</span></code></pre></div>
</div>
<div class="paragraph">
<p><strong>Solution</strong>: Restart the Connect task via the REST API. If your connector is called <code>sink_snowflake_01</code> then you can run this to restart task <code>0</code>:</p>
</div>
<div class="paragraph">
<div class="highlight"><pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">curl -X POST http://localhost:8083/connectors/sink_snowflake_01/tasks/0/restart</code></pre></div>
</div>
</li>
</ul>
</div>
</div>
</div>
</div>

</article>

		</main>
		
				<div class="hide-print sans-serif f6 f5-l mt5 ph3 pb6 center nested-copy-line-height lh-copy nested-links mw-100 measure-wide">
		<div class="about-the-author">
		
			
			
				
					<hr>
<p><img src="/images/2018/05/ksldn18-01.jpg" alt="Robin Moffatt"></p>
<p><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --> <!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --> <em>Robin Moffatt is a Senior Developer Advocate at Confluent, and an Oracle ACE Director (Alumnus). He likes writing about himself in the third person, eating good breakfasts, and drinking good beer.</em></p>

				
			
		
		</div>
		
	</div>

		
		
		
		<footer class="hide-print sans-serif f6 fw1 bg-black near-white bottom-0 w-100 pa3" role="contentinfo">
			<p class="w-50 fr tr">
			<a class="no-underline near-white" href="https://github.com/xaprb/story"><img class="dib" title="Made with Hugo and Story" alt="Story logo" src="https://rmoff.net/img/story-logo-white.svg" style="width: 1.5rem; height: 1.5rem" /></a>
			</p>
			<p class="w-50 near-white">
				&copy; 2020 
			</p>
		</footer>
		
	
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-75492960-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

	
	</body>
</html>
