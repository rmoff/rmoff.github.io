<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<title>Pivoting Aggregates in Ksql</title>
		<link rel="alternate" type="application/rss+xml" title="RSS" href="https://rmoff.net/index.xml">
		<link rel="canonical" href="https://rmoff.net/2019/04/17/pivoting-aggregates-in-ksql/">
		
		
		
		<meta name="generator" content="Hugo 0.75.1" />

		
		<meta property="og:title" content="Pivoting Aggregates in Ksql" />
		<meta property="og:type" content="article" />
		<meta property="og:image" content="https://rmoff.net/images/2019/04/DSCF2886.jpg" />
		<meta property="og:description" content="" />
		<meta property="og:url" content="https://rmoff.net/2019/04/17/pivoting-aggregates-in-ksql/" />
		<meta property="og:site_name" content="Pivoting Aggregates in Ksql" />
		<meta name="twitter:card" content="summary_large_image" />
		<meta name="twitter:site" content="@" />


		
		<link rel="stylesheet" href="https://rmoff.net/css/tachyons.min.css" />
		<link rel="stylesheet" href="https://rmoff.net/css/story.css" />
		<link rel="stylesheet" href="https://rmoff.net/css/descartes.css" />
		
		<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">
		<link href="https://fonts.googleapis.com/css?family=Quattrocento+Sans:400,400i,700,700i|Quattrocento:400,700|Spectral:400,400i,700,700i&amp;subset=latin-ext" rel="stylesheet">
		

		<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
		
		<script src="https://rmoff.net/js/story.js"></script>

	</head>
	<body class="ma0 bg-white section-post page-kind-page is-page-true ">
		
		<header class="cover bg-top" style="background-image: url('https://rmoff.net/images/2019/04/DSCF2886.jpg'); background-position: center;">
			<div class="bg-black-30 bb bt">

				<nav class="hide-print sans-serif  border-box pa3 ph5-l">
					<a href="https://rmoff.net" title="Home">
						<img src="https://rmoff.net/img/logo.jpg" class="w2 h2 br-100" alt="rmoff&#39;s random ramblings" />
					</a>
					<div class="fr h2 pv2 tr">
						<a class="link f5 ml2 dim near-white" href="https://talks.rmoff.net/bio">about</a>
						<a class="link f5 ml2 dim near-white" href="https://talks.rmoff.net">talks</a>
						<a class="link f5 ml2 dim near-white" href="https://www.youtube.com/c/rmoff"><i class="fab fa-youtube-square"></i></a>
						<a class="link f5 ml2 dim near-white" href="https://twitter.com/rmoff/"><i class="fab fa-twitter-square"></i></a>
						<a class="link f5 ml2 dim near-white" href="https://github.com/rmoff/"><i class="fab fa-github-square"></i></a>
						<a class="link f5 ml2 dim near-white" href="https://www.linkedin.com/in/robinmoffatt/"><i class="fab fa-linkedin"></i></a>
						<a class="link f5 ml2 dim near-white fas fa-rss-square" href="https://rmoff.net/index.xml" title="RSS Feed"></a>
						<a class="link f5 ml2 dim near-white fas fa-search" href="https://rmoff.net/search/" role="search" title="Search"></a>
					</div>
				</nav>

				<div id="hdr" class="tc-l pv4-ns pv5-l pv2 ph3 ph4-ns">
					<h1 class="near-white mt1-ns f2 fw3 mb0 mt0 lh-title">Pivoting Aggregates in Ksql</h1>
					<h2 class="near-white mt3-l mb4-l fw1 f6 f3-l measure-wide-l center lh-copy mt2 mb3">
						
						
							
								Published
								<time datetime="2019-04-17T15:42:56&#43;01:00">Apr 17, 2019</time>
								<span class="display-print">by </span>
								 in <a href="https://rmoff.net/categories/ksql" class="no-underline category near-white dim">KSQL</a>, <a href="https://rmoff.net/categories/data-wrangling" class="no-underline category near-white dim">Data Wrangling</a>
								<span class="display-print">at https://rmoff.net/2019/04/17/pivoting-aggregates-in-ksql/</span>
							
						
					</h2>
				</div>

				
				
				
				

			</div>
		</header>
		
		<main role="main">
		
<article class="center bg-white br-3 pv1 ph4 lh-copy f5 nested-links mw7">
	<p>Prompted by <a href="https://stackoverflow.com/questions/55680719/aggregating-by-multiple-fields-and-map-to-one-result">a question on StackOverflow</a>, the requirement is to take a series of events related to a common key and for each key output a series of aggregates derived from a changing value in the events. I&rsquo;ll use the data from the question, based on ticket statuses. Each ticket can go through various stages, and the requirement was to show, per customer, how many tickets are currently at each stage.</p>
<p>Here&rsquo;s the source data:</p>
<table>
<thead>
<tr>
<th>Customer</th>
<th>Ticket ID</th>
<th>Ticket Status</th>
</tr>
</thead>
<tbody>
<tr>
<td>2216</td>
<td>1472</td>
<td>closed</td>
</tr>
<tr>
<td>8945</td>
<td>1472</td>
<td>waiting</td>
</tr>
<tr>
<td>8945</td>
<td>1472</td>
<td>processing</td>
</tr>
<tr>
<td>8945</td>
<td>1472</td>
<td>waiting</td>
</tr>
<tr>
<td>8952</td>
<td>1472</td>
<td>new</td>
</tr>
<tr>
<td>8952</td>
<td>1472</td>
<td>close-request</td>
</tr>
</tbody>
</table>
<p>By eyeballing the data we can see that for this one customer there are three tickets, in state <strong>closed, waiting, close-request</strong> and so the desired output is:</p>
<table>
<thead>
<tr>
<th>Customer</th>
<th>Tickets closed</th>
<th>Tickets waiting</th>
<th>Tickets processing</th>
<th>Tickets waiting</th>
<th>Tickets new</th>
<th>Tickets close request</th>
</tr>
</thead>
<tbody>
<tr>
<td>1472</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>In RDBMS SQL this would be a fairly trivial PIVOT operation. In KSQL we can achieve the same using the <code>CASE</code> statement which was added in 5.2. Along the way we also need to reason about state vs event stream.</p>
<hr>
<p>It&rsquo;s possible to do this by building a table (for state) and then an aggregate on that table.</p>
<ol>
<li>
<p>Set up the test data</p>
<pre><code> kafkacat -b localhost -t tickets -P &lt;&lt;EOF
 {&quot;ID&quot;:2216,&quot;CONTACT_ID&quot;:1472,&quot;SUBJECT&quot;:&quot;Test Bodenbach&quot;,&quot;STATUS&quot;:&quot;closed&quot;,&quot;TIMESTRING&quot;:&quot;2012-11-08 10:34:30.000&quot;}
 {&quot;ID&quot;:8945,&quot;CONTACT_ID&quot;:1472,&quot;SUBJECT&quot;:&quot;sync-test&quot;,&quot;STATUS&quot;:&quot;waiting&quot;,&quot;TIMESTRING&quot;:&quot;2019-04-16 23:07:01.000&quot;}
 {&quot;ID&quot;:8945,&quot;CONTACT_ID&quot;:1472,&quot;SUBJECT&quot;:&quot;sync-test&quot;,&quot;STATUS&quot;:&quot;processing&quot;,&quot;TIMESTRING&quot;:&quot;2019-04-16 23:52:08.000&quot;}
 {&quot;ID&quot;:8945,&quot;CONTACT_ID&quot;:1472,&quot;SUBJECT&quot;:&quot;sync-test&quot;,&quot;STATUS&quot;:&quot;waiting&quot;,&quot;TIMESTRING&quot;:&quot;2019-04-17 00:10:38.000&quot;}
 {&quot;ID&quot;:8952,&quot;CONTACT_ID&quot;:1472,&quot;SUBJECT&quot;:&quot;another sync ticket&quot;,&quot;STATUS&quot;:&quot;new&quot;,&quot;TIMESTRING&quot;:&quot;2019-04-17 00:11:23.000&quot;}
 {&quot;ID&quot;:8952,&quot;CONTACT_ID&quot;:1472,&quot;SUBJECT&quot;:&quot;another sync ticket&quot;,&quot;STATUS&quot;:&quot;close-request&quot;,&quot;TIMESTRING&quot;:&quot;2019-04-17 00:12:04.000&quot;}
 EOF
</code></pre>
</li>
<li>
<p>Preview the topic data</p>
<pre><code> ksql&gt; PRINT 'tickets' FROM BEGINNING;
 Format:JSON
 {&quot;ROWTIME&quot;:1555511270573,&quot;ROWKEY&quot;:&quot;null&quot;,&quot;ID&quot;:2216,&quot;CONTACT_ID&quot;:1472,&quot;SUBJECT&quot;:&quot;Test Bodenbach&quot;,&quot;STATUS&quot;:&quot;closed&quot;,&quot;TIMESTRING&quot;:&quot;2012-11-08 10:34:30.000&quot;}
 {&quot;ROWTIME&quot;:1555511270573,&quot;ROWKEY&quot;:&quot;null&quot;,&quot;ID&quot;:8945,&quot;CONTACT_ID&quot;:1472,&quot;SUBJECT&quot;:&quot;sync-test&quot;,&quot;STATUS&quot;:&quot;waiting&quot;,&quot;TIMESTRING&quot;:&quot;2019-04-16 23:07:01.000&quot;}
 {&quot;ROWTIME&quot;:1555511270573,&quot;ROWKEY&quot;:&quot;null&quot;,&quot;ID&quot;:8945,&quot;CONTACT_ID&quot;:1472,&quot;SUBJECT&quot;:&quot;sync-test&quot;,&quot;STATUS&quot;:&quot;processing&quot;,&quot;TIMESTRING&quot;:&quot;2019-04-16 23:52:08.000&quot;}
 {&quot;ROWTIME&quot;:1555511270573,&quot;ROWKEY&quot;:&quot;null&quot;,&quot;ID&quot;:8945,&quot;CONTACT_ID&quot;:1472,&quot;SUBJECT&quot;:&quot;sync-test&quot;,&quot;STATUS&quot;:&quot;waiting&quot;,&quot;TIMESTRING&quot;:&quot;2019-04-17 00:10:38.000&quot;}
 {&quot;ROWTIME&quot;:1555511270573,&quot;ROWKEY&quot;:&quot;null&quot;,&quot;ID&quot;:8952,&quot;CONTACT_ID&quot;:1472,&quot;SUBJECT&quot;:&quot;another sync ticket&quot;,&quot;STATUS&quot;:&quot;new&quot;,&quot;TIMESTRING&quot;:&quot;2019-04-17 00:11:23.000&quot;}
 {&quot;ROWTIME&quot;:1555511270573,&quot;ROWKEY&quot;:&quot;null&quot;,&quot;ID&quot;:8952,&quot;CONTACT_ID&quot;:1472,&quot;SUBJECT&quot;:&quot;another sync ticket&quot;,&quot;STATUS&quot;:&quot;close-request&quot;,&quot;TIMESTRING&quot;:&quot;2019-04-17 00:12:04.000&quot;}
</code></pre>
</li>
<li>
<p>Register the stream</p>
<pre><code> CREATE STREAM TICKETS (ID INT, 
                       CONTACT_ID VARCHAR, 
                       SUBJECT VARCHAR, 
                       STATUS VARCHAR, 
                       TIMESTRING VARCHAR) 
         WITH (KAFKA_TOPIC='tickets', 
         VALUE_FORMAT='JSON');
</code></pre>
</li>
<li>
<p>Query the data</p>
<pre><code> ksql&gt; SET 'auto.offset.reset' = 'earliest';
 ksql&gt; SELECT * FROM TICKETS;
 1555502643806 | null | 2216 | 1472 | Test Bodenbach | closed | 2012-11-08 10:34:30.000
 1555502643806 | null | 8945 | 1472 | sync-test | waiting | 2019-04-16 23:07:01.000
 1555502643806 | null | 8945 | 1472 | sync-test | processing | 2019-04-16 23:52:08.000
 1555502643806 | null | 8945 | 1472 | sync-test | waiting | 2019-04-17 00:10:38.000
 1555502643806 | null | 8952 | 1472 | another sync ticket | new | 2019-04-17 00:11:23.000
 1555502643806 | null | 8952 | 1472 | another sync ticket | close-request | 2019-04-17 00:12:04.000
</code></pre>
</li>
<li>
<p>At this point we can use <code>CASE</code> to pivot the aggregates:</p>
<pre><code> SELECT CONTACT_ID, 
       SUM(CASE WHEN STATUS='new' THEN 1 ELSE 0 END) AS TICKETS_NEW, 
       SUM(CASE WHEN STATUS='processing' THEN 1 ELSE 0 END) AS TICKETS_PROCESSING, 
       SUM(CASE WHEN STATUS='waiting' THEN 1 ELSE 0 END) AS TICKETS_WAITING, 
       SUM(CASE WHEN STATUS='close-request' THEN 1 ELSE 0 END) AS TICKETS_CLOSEREQUEST ,
       SUM(CASE WHEN STATUS='closed' THEN 1 ELSE 0 END) AS TICKETS_CLOSED
   FROM TICKETS 
   GROUP BY CONTACT_ID;

   1472 | 1 | 1 | 2 | 1 | 1
</code></pre>
<p>But, you&rsquo;ll notice that the answer isn&rsquo;t as expected. This is because we&rsquo;re counting all six input <strong>events</strong>.</p>
<p>Let&rsquo;s look at a single ticket, ID <code>8945</code>—this goes through three state changes (<code>waiting</code> -&gt; <code>processing</code> -&gt; <code>waiting</code>) which each get included in the aggregate. We can validate this as follows with a simple predicate:</p>
<pre><code> SELECT CONTACT_ID, 
       SUM(CASE WHEN STATUS='new' THEN 1 ELSE 0 END) AS TICKETS_NEW, 
       SUM(CASE WHEN STATUS='processing' THEN 1 ELSE 0 END) AS TICKETS_PROCESSING, 
       SUM(CASE WHEN STATUS='waiting' THEN 1 ELSE 0 END) AS TICKETS_WAITING, 
       SUM(CASE WHEN STATUS='close-request' THEN 1 ELSE 0 END) AS TICKETS_CLOSEREQUEST ,
       SUM(CASE WHEN STATUS='closed' THEN 1 ELSE 0 END) AS TICKETS_CLOSED
   FROM TICKETS 
   WHERE ID=8945
   GROUP BY CONTACT_ID;

 1472 | 0 | 1 | 2 | 0 | 0
</code></pre>
</li>
<li>
<p>What we actually want is the <em>current state</em> for each ticket. So repartition the data on ticket ID:</p>
<pre><code> CREATE STREAM TICKETS_BY_ID AS SELECT * FROM TICKETS PARTITION BY ID;

 CREATE TABLE TICKETS_TABLE (ID INT, 
                       CONTACT_ID INT, 
                       SUBJECT VARCHAR, 
                       STATUS VARCHAR, 
                       TIMESTRING VARCHAR) 
         WITH (KAFKA_TOPIC='TICKETS_BY_ID', 
         VALUE_FORMAT='JSON',
         KEY='ID');
</code></pre>
</li>
<li>
<p>Compare <em>event stream</em> vs <em>current state</em></p>
<ul>
<li>
<p>Event stream (KSQL Stream)</p>
<pre><code>  ksql&gt; SELECT ID, TIMESTRING, STATUS FROM TICKETS;
  2216 | 2012-11-08 10:34:30.000 | closed
  8945 | 2019-04-16 23:07:01.000 | waiting
  8945 | 2019-04-16 23:52:08.000 | processing
  8945 | 2019-04-17 00:10:38.000 | waiting
  8952 | 2019-04-17 00:11:23.000 | new
  8952 | 2019-04-17 00:12:04.000 | close-request
</code></pre>
</li>
<li>
<p>Current state (KSQL Table)</p>
<pre><code>  ksql&gt; SELECT ID, TIMESTRING, STATUS FROM TICKETS_TABLE;
  2216 | 2012-11-08 10:34:30.000 | closed
  8945 | 2019-04-17 00:10:38.000 | waiting
  8952 | 2019-04-17 00:12:04.000 | close-request
</code></pre>
</li>
</ul>
</li>
<li>
<p>We want an aggregate of the table—we want to run the same <code>SUM(CASE…)…GROUP BY</code> trick that we did above, but based on the <em>current state</em> of each ticket, rather than each event:</p>
<pre><code>   SELECT CONTACT_ID, 
       SUM(CASE WHEN STATUS='new' THEN 1 ELSE 0 END) AS TICKETS_NEW, 
       SUM(CASE WHEN STATUS='processing' THEN 1 ELSE 0 END) AS TICKETS_PROCESSING, 
       SUM(CASE WHEN STATUS='waiting' THEN 1 ELSE 0 END) AS TICKETS_WAITING, 
       SUM(CASE WHEN STATUS='close-request' THEN 1 ELSE 0 END) AS TICKETS_CLOSEREQUEST ,
       SUM(CASE WHEN STATUS='closed' THEN 1 ELSE 0 END) AS TICKETS_CLOSED
   FROM TICKETS_TABLE 
   GROUP BY CONTACT_ID;
</code></pre>
<p>This gives us what we want:</p>
<pre><code>   1472 | 0 | 0 | 1 | 1 | 1
</code></pre>
</li>
<li>
<p>Let&rsquo;s feed another ticket&rsquo;s events into the topic and observe how the table&rsquo;s state changes. <em>Rows from a table are re-emitted when the state changes; you can also cancel the <code>SELECT</code> and rerun it to see the current state only.</em></p>
<p><img src="/images/2019/04/ksql_pivot.gif" alt=""></p>
<p>Sample data to try it for yourself:</p>
<pre><code> {&quot;ID&quot;:8946,&quot;CONTACT_ID&quot;:42,&quot;SUBJECT&quot;:&quot;&quot;,&quot;STATUS&quot;:&quot;new&quot;,&quot;TIMESTRING&quot;:&quot;2019-04-16 23:07:01.000&quot;}
 {&quot;ID&quot;:8946,&quot;CONTACT_ID&quot;:42,&quot;SUBJECT&quot;:&quot;&quot;,&quot;STATUS&quot;:&quot;processing&quot;,&quot;TIMESTRING&quot;:&quot;2019-04-16 23:07:01.000&quot;}
 {&quot;ID&quot;:8946,&quot;CONTACT_ID&quot;:42,&quot;SUBJECT&quot;:&quot;&quot;,&quot;STATUS&quot;:&quot;waiting&quot;,&quot;TIMESTRING&quot;:&quot;2019-04-16 23:07:01.000&quot;}
 {&quot;ID&quot;:8946,&quot;CONTACT_ID&quot;:42,&quot;SUBJECT&quot;:&quot;&quot;,&quot;STATUS&quot;:&quot;processing&quot;,&quot;TIMESTRING&quot;:&quot;2019-04-16 23:07:01.000&quot;}
 {&quot;ID&quot;:8946,&quot;CONTACT_ID&quot;:42,&quot;SUBJECT&quot;:&quot;&quot;,&quot;STATUS&quot;:&quot;waiting&quot;,&quot;TIMESTRING&quot;:&quot;2019-04-16 23:07:01.000&quot;}
 {&quot;ID&quot;:8946,&quot;CONTACT_ID&quot;:42,&quot;SUBJECT&quot;:&quot;&quot;,&quot;STATUS&quot;:&quot;closed&quot;,&quot;TIMESTRING&quot;:&quot;2019-04-16 23:07:01.000&quot;}
 {&quot;ID&quot;:8946,&quot;CONTACT_ID&quot;:42,&quot;SUBJECT&quot;:&quot;&quot;,&quot;STATUS&quot;:&quot;close-request&quot;,&quot;TIMESTRING&quot;:&quot;2019-04-16 23:07:01.000&quot;}
</code></pre>
</li>
</ol>
<hr>
<p>If you want to try this out further you can generate an stream of additional dummy data with this from <a href="https://rmoff.net/2018/05/10/quick-n-easy-population-of-realistic-test-data-into-kafka/">Mockaroo</a>, piped through <code>awk</code> to slow it down so you can see the effect on the generated aggregates as each message arrives:</p>
<pre><code>while [ 1 -eq 1 ]
  do curl -s &quot;https://api.mockaroo.com/api/f2d6c8a0?count=1000&amp;key=ff7856d0&quot; | \
      awk '{print $0;system(&quot;sleep 2&quot;);}' | \
      kafkacat -b localhost -t tickets -P
  done
</code></pre>
</article>

		</main>
		
				<div class="hide-print sans-serif f6 f5-l mt5 ph3 pb6 center nested-copy-line-height lh-copy nested-links mw-100 measure-wide">
		<div class="about-the-author">
		
			
			
				
					<hr>
<p><img src="/images/2018/05/ksldn18-01.jpg" alt="Robin Moffatt"></p>
<p><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --> <!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --> <em>Robin Moffatt is a Senior Developer Advocate at Confluent, and an Oracle ACE Director (Alumnus). He likes writing about himself in the third person, eating good breakfasts, and drinking good beer.</em></p>

				
			
		
		</div>
		
	</div>

		
		
		
		<footer class="hide-print sans-serif f6 fw1 bg-black near-white bottom-0 w-100 pa3" role="contentinfo">
			<p class="w-50 fr tr">
			<a class="no-underline near-white" href="https://github.com/xaprb/story"><img class="dib" title="Made with Hugo and Story" alt="Story logo" src="https://rmoff.net/img/story-logo-white.svg" style="width: 1.5rem; height: 1.5rem" /></a>
			</p>
			<p class="w-50 near-white">
				&copy; 2020 
			</p>
		</footer>
		
	
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-75492960-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

	
	</body>
</html>
