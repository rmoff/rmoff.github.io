<!DOCTYPE html>
<html lang="en">
	<head>
		<meta http-equiv=X-Clacks-Overhead content="GNU Terry Pratchett">
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		
		<link rel="preconnect" href="https://fonts.googleapis.com">
		<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
		<link rel="preload" as="image" href="https://rmoff.net/images/2022/09/h_IMG_8389.jpeg" >
		
		<title>Data Engineering in 2022: Storage and Access</title>
		<link rel="alternate" type="application/rss+xml" title="RSS" href="https://rmoff.net/index.xml">
		<link rel="canonical" href="https://rmoff.net/2022/09/14/data-engineering-in-2022-storage-and-access/">
		
		

		
		<meta property="og:title" content="Data Engineering in 2022: Storage and Access" />
		<meta property="og:type" content="article" />
		<meta property="og:image" content="https://rmoff.net/images/2022/09/h_IMG_8389.jpeg" />
		<meta property="og:description" content="" />
		<meta property="og:url" content="https://rmoff.net/2022/09/14/data-engineering-in-2022-storage-and-access/" />
		<meta property="og:site_name" content="Data Engineering in 2022: Storage and Access" />
		<meta name="twitter:card" content="summary_large_image" />
		<meta name="twitter:site" content="@" />


		
		<style>
			html { background-color: #FAF8F5; color: #2D2926; }
			body { opacity: 0; transition: opacity 0.1s ease; }
			body.loaded { opacity: 1; }
			.site-header { height: 60px; background-color: #FAF8F5; border-bottom: 1px solid #E8421E; }
		</style>

		
		
		<link rel="stylesheet" href="https://rmoff.net/css/redesign.css" />
		
		<link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Bricolage+Grotesque:opsz,wght@12..96,400;12..96,600;12..96,700;12..96,800&family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&family=JetBrains+Mono:wght@400;500&family=Outfit:wght@400;500;600&display=swap">
		<link href="https://fonts.googleapis.com/css2?family=Bricolage+Grotesque:opsz,wght@12..96,400;12..96,600;12..96,700;12..96,800&family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&family=JetBrains+Mono:wght@400;500&family=Outfit:wght@400;500;600&display=swap" rel="stylesheet" media="print" onload="this.media='all'">
		<noscript><link href="https://fonts.googleapis.com/css2?family=Bricolage+Grotesque:opsz,wght@12..96,400;12..96,600;12..96,700;12..96,800&family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&family=JetBrains+Mono:wght@400;500&family=Outfit:wght@400;500;600&display=swap" rel="stylesheet"></noscript>
		

		

		
		<script>
			!function(t,e){var o,n,p,r;e.__SV||(window.posthog=e,e._i=[],e.init=function(i,s,a){function g(t,e){var o=e.split(".");2==o.length&&(t=t[o[0]],e=o[1]),t[e]=function(){t.push([e].concat(Array.prototype.slice.call(arguments,0)))}}(p=t.createElement("script")).type="text/javascript",p.crossOrigin="anonymous",p.async=!0,p.src=s.api_host.replace(".i.posthog.com","-assets.i.posthog.com")+"/static/array.js",(r=t.getElementsByTagName("script")[0]).parentNode.insertBefore(p,r);var u=e;for(void 0!==a?u=e[a]=[]:a="posthog",u.people=u.people||[],u.toString=function(t){var e="posthog";return"posthog"!==a&&(e+="."+a),t||(e+=" (stub)"),e},u.people.toString=function(){return u.toString(1)+".people (stub)"},o="init capture register register_once register_for_session unregister unregister_for_session getFeatureFlag getFeatureFlagPayload isFeatureEnabled reloadFeatureFlags updateEarlyAccessFeatureEnrollment getEarlyAccessFeatures on onFeatureFlags onSessionId getSurveys getActiveMatchingSurveys renderSurvey canRenderSurvey getNextSurveyStep identify setPersonProperties group resetGroups setPersonPropertiesForFlags resetPersonPropertiesForFlags setGroupPropertiesForFlags resetGroupPropertiesForFlags reset get_distinct_id getGroups get_session_id get_session_replay_url alias set_config startSessionRecording stopSessionRecording sessionRecordingStarted captureException loadToolbar get_property getSessionProperty createPersonProfile opt_in_capturing opt_out_capturing has_opted_in_capturing has_opted_out_capturing clear_opt_in_out_capturing debug".split(" "),n=0;n<o.length;n++)g(u,o[n]);e._i.push([i,s,a])},e.__SV=1)}(document,window.posthog||[]);
            posthog.init('phc_93NEP79Ju4xqXYWXnoLbr4HMW0Iaepj1BGOVoEXYX6P',{api_host:'https://eu.i.posthog.com', person_profiles: 'identified_only'})
		</script>

		
		<script src="https://rmoff.net/js/story.js"></script>
		<script src="https://rmoff.net/js/toc.js"></script>
		<script src="https://rmoff.net/js/medium-mirror.js"></script>
	</head>
	<body class="ma0 section-post page-kind-page is-page-true ">
		<script>document.body.classList.add('loaded');</script>

		<header class="site-header hide-print">
	<div class="site-header-inner">
		<a href="https://rmoff.net/" class="site-title">rmoff's random ramblings</a>
		<nav class="site-nav">
			<a href="/categories/interesting-links/" class="nav-il"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"/><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"/></svg> Interesting Links</a>
			<span class="nav-sep"></span>
			<a href="/categories/"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"/><line x1="7" y1="7" x2="7.01" y2="7"/></svg> Categories</a>
			<a href="https://rmoff.net/search/"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="11" cy="11" r="8"/><line x1="21" y1="21" x2="16.65" y2="16.65"/></svg> Search</a>
			<a href="https://rmoff.net/index.xml"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 11a9 9 0 0 1 9 9"/><path d="M4 4a16 16 0 0 1 16 16"/><circle cx="5" cy="19" r="1"/></svg> RSS</a>
			<div class="nav-social">
				<a href="https://www.linkedin.com/in/robinmoffatt/" title="linkedin"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433a2.062 2.062 0 0 1-2.063-2.065 2.064 2.064 0 1 1 2.063 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg></a>
				<a href="https://twitter.com/rmoff/" title="twitter"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"/></svg></a>
				<a href="https://bsky.app/profile/rmoff.net" title="bluesky"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 568 501" fill="currentColor"><path d="M123.121 33.664C188.241 82.553 258.281 181.68 284 234.873c25.719-53.192 95.759-152.32 160.879-201.21C491.866-1.611 568-28.906 568 57.947c0 17.346-9.945 145.713-15.778 166.555-20.275 72.453-94.155 90.933-159.875 79.748C507.222 323.8 536.444 388.56 473.333 453.32c-119.86 122.992-172.272-30.859-185.702-70.281-2.462-7.227-3.614-10.608-3.631-7.733-.017-2.875-1.169.506-3.631 7.733-13.43 39.422-65.842 193.273-185.702 70.281-63.111-64.76-33.89-129.52 80.986-149.071-65.72 11.185-139.6-7.295-159.875-79.748C10.945 203.659 1 75.291 1 57.946 1-28.906 76.135-1.612 123.121 33.664z"/></svg></a>
				<a href="https://www.youtube.com/c/rmoff" title="youtube"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M23.498 6.186a3.016 3.016 0 0 0-2.122-2.136C19.505 3.545 12 3.545 12 3.545s-7.505 0-9.377.505A3.017 3.017 0 0 0 .502 6.186C0 8.07 0 12 0 12s0 3.93.502 5.814a3.016 3.016 0 0 0 2.122 2.136c1.871.505 9.376.505 9.376.505s7.505 0 9.377-.505a3.015 3.015 0 0 0 2.122-2.136C24 15.93 24 12 24 12s0-3.93-.502-5.814zM9.545 15.568V8.432L15.818 12l-6.273 3.568z"/></svg></a>
				<a href="https://talks.rmoff.net" title="talks"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><rect x="2" y="3" width="20" height="14" rx="0"/><line x1="12" y1="17" x2="12" y2="22"/><line x1="8" y1="22" x2="16" y2="22"/><polyline points="7 8 12 12 17 8"/></svg></a>
				<a href="https://github.com/rmoff/" title="github"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a>
			</div>
		</nav>
		<button class="nav-toggle" onclick="document.querySelector('.mobile-nav').classList.toggle('open')" aria-label="Menu">
			<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="18" x2="21" y2="18"/></svg>
		</button>
	</div>
	<nav class="mobile-nav">
		<a href="https://rmoff.net/">Home</a>
		<a href="/categories/">Categories</a>
		<a href="/categories/interesting-links/">Interesting Links</a>
		<a href="https://rmoff.net/search/">Search</a>
		<a href="https://rmoff.net/index.xml">RSS</a>
		<a href="https://www.linkedin.com/in/robinmoffatt/">linkedin</a>
		<a href="https://twitter.com/rmoff/">twitter</a>
		<a href="https://bsky.app/profile/rmoff.net">bluesky</a>
		<a href="https://www.youtube.com/c/rmoff">youtube</a>
		<a href="https://talks.rmoff.net">talks</a>
		<a href="https://github.com/rmoff/">github</a>
	</nav>
</header>


		<main role="main">
		

<div class="article-hero" style="background-image: url('https://rmoff.net/images/2022/09/h_IMG_8389.jpeg');">
	<div class="article-hero-overlay">
		<div class="article-hero-content">
			<h1>Data Engineering in 2022: Storage and Access</h1>
			<p class="article-hero-meta">
				
					<time datetime="2022-09-14T17:07:04Z">14 Sep 2022</time>
					<span class="display-print">by </span>
					 &middot; <a href="https://rmoff.net/categories/data-engineering">Data Engineering</a>, <a href="https://rmoff.net/categories/table-formats">Table Formats</a>, <a href="https://rmoff.net/categories/apache-hudi">Apache Hudi</a>, <a href="https://rmoff.net/categories/apache-iceberg">Apache Iceberg</a>, <a href="https://rmoff.net/categories/delta-lake">Delta Lake</a>, <a href="https://rmoff.net/categories/lakefs">LakeFS</a>
					<span class="display-print">at https://rmoff.net/2022/09/14/data-engineering-in-2022-storage-and-access/</span>
				
			</p>
		</div>
	</div>
</div>


<details class="toc-mobile">
	<summary>Table of Contents</summary>
	<nav id="TableOfContents">
  <ul>
    <li><a href="#_storing_and_accessing_your_data_pt_1_burn_it_all_down">Storing and Accessing Your Data pt 1: üî• Burn It All Down‚Ä¶üî•</a></li>
    <li><a href="#_storing_and_accessing_your_data_pt_2_and_then_rebuild_it_Ô∏è">Storing and Accessing Your Data pt 2: ‚Ä¶and Then Rebuild It üèóÔ∏è</a>
      <ul>
        <li><a href="#_data_lake_table_formats_data_lakehouses">Data Lake Table Formats &amp; Data Lakehouses</a></li>
        <li><a href="#_managed_data_lakehouses">Managed Data Lakehouses</a></li>
        <li><a href="#_storage_formats">Storage Formats</a></li>
        <li><a href="#_reading_more_about_table_formats_lakehouses">Reading more about Table Formats &amp; Lakehouses</a></li>
        <li><a href="#_a_note_about_open_formats">A Note About Open Formats</a></li>
      </ul>
    </li>
    <li><a href="#_git_for_data_with_lakefs"><code>git</code> For Data with LakeFS</a></li>
    <li><a href="#_data_engineering_in_2022">Data Engineering in 2022</a></li>
  </ul>
</nav>
</details>

<div class="container-fluid docs">
	<div class="row">
		<main class="docs-content" role="main">

<article class="article" data-pagefind-body>
	<span data-pagefind-filter="category" style="display:none">Data Engineering</span><span data-pagefind-filter="category" style="display:none">Table Formats</span><span data-pagefind-filter="category" style="display:none">Apache Hudi</span><span data-pagefind-filter="category" style="display:none">Apache Iceberg</span><span data-pagefind-filter="category" style="display:none">Delta Lake</span><span data-pagefind-filter="category" style="display:none">LakeFS</span>
	<img data-pagefind-meta="image[src]" src="https://rmoff.net/images/2022/09/h_IMG_8389.jpeg" style="display:none" alt="">
	<div class="paragraph">
<p>In this article I look at where we store our analytical data, how we organise it, and how we enable access to it. I‚Äôm considering here potentially large volumes of data for access throughout an organisation. I‚Äôm not looking at data stores that are used for specific purposes (caches, low-latency analytics, graph etc).</p>
</div>
<div class="paragraph">
<p>The article is <a href="/2022/09/14/stretching-my-legs-in-the-data-engineering-ecosystem-in-2022/">part of a series</a> in which I explore the world of data engineering in 2022 and how it has changed from when I started my career in data warehousing 20+ years ago. Read the <a href="/2022/09/14/stretching-my-legs-in-the-data-engineering-ecosystem-in-2022/">introduction</a> for more context and background.</p>
</div>
<div class="sect1">
<h2 id="_storing_and_accessing_your_data_pt_1_burn_it_all_down">Storing and Accessing Your Data pt 1: üî• Burn It All Down‚Ä¶üî•&nbsp;<a class="headline-hash" href="#_storing_and_accessing_your_data_pt_1_burn_it_all_down">üîó</a> </h2>
<div class="sectionbody">
<div class="paragraph">
<p>In the beginning was the word, and the word was an expensive relational datawarehouse that wasn‚Äôt flexible or scalable enough for the cool kids in Silicon Valley.</p>
</div>
<div class="paragraph">
<p>Then came Hadoop and scalability was won, at the vast cost of usability. You literally had to write your own Java code to move data around and transform it. You needed to serialise and deserialise the data yourself, and could store whatever you wanted - it didn‚Äôt have to be structured. This was sold as a benefit‚Äâ‚Äî‚Äâ&#34;Schema on Read&#34; they said, &#34;It‚Äôll be a good idea&#34;, they said. <em>&#34;Oh bugger, where‚Äôs my schema&#34;</em>, they said when they came to use it.</p>
</div>
<div class="paragraph">
<p>Through the virtues of open source a fantastic ecosystem grew particularly around the <a href="https://apache.org">Apache Software Foundation</a> and we got such wonderfully named projects as <a href="https://sqoop.apache.org/">Sqoop</a>, <a href="https://oozie.apache.org/">Oozie</a>, <a href="https://pig.apache.org/">Pig</a>, and <a href="https://flume.apache.org/">Flume</a> emerged. <a href="https://hive.apache.org/">Hive</a> brought with it the familiar and comforting bosom of SQL and table structures but with limited functionality (including no <code>DELETE</code> or <code>UPDATE</code> at first) and performance.</p>
</div>
<div class="paragraph">
<p>Over the years things improved, with <a href="https://spark.apache.org/">Spark</a> replacing <a href="https://hadoop.apache.org/">MapReduce</a> and enabling a generation of Python coders to get into the big data lark too, along with <a href="https://spark.apache.org/sql/">SQL</a>.</p>
</div>
<div class="paragraph">
<p>Amongst all of this pioneering work and technology was the assumption that the resting place for analytical data was <a href="https://hadoop.apache.org/">HDFS</a>. Other stores like <a href="https://hbase.apache.org/">HBase</a> existed for special purposes, but the general we‚Äôve-got-a-bunch-of-data-in-this-org-and-need-to-collect-it destination was HDFS. Because &#34;general dumping ground&#34; wasn‚Äôt sexy enough for the marketing folk it became sold as a &#34;Data Lake&#34; with all the associated puns and awful cliches (fishing for data, data swamp, etc etc etc).</p>
</div>
<div class="paragraph">
<p>The general pitch around the data lake was to collect all the data, structured and unstructured (<em>or structured that you‚Äôve made unstructured by chucking away its schema when you loaded it</em>), and then <del>wait for the data lake fairy to conjure magical value out of the pile of data you‚Äôve dumped there</del> make the raw data available for teams in the company to process and use for their particular purposes. This may have been direct querying of the data in place, or processing it and landing it in another data store for serving (for example, aggregated and structured for optimal query access in an RDBMS or columnar data store).</p>
</div>
<div class="paragraph">
<p>Accessing the data in HDFS was done with Hive and other tools including <a href="https://impala.apache.org/">Impala</a>, <a href="https://drill.apache.org/">Drill</a>, and <a href="https://prestodb.io/">Presto</a>. All had their pros and cons particularly in early releases, often with limitations around performance and management of the data.</p>
</div>
<div class="paragraph">
<p>All of this was built around the closely-intertwined <a href="https://hadoop.apache.org/">Hadoop</a> platform, whether self-managed on-premises including with deployments from Cloudera, MapR, and Hortonworks, or with a cloud provider such as AWS and its <a href="https://aws.amazon.com/emr/">EMR</a> service.</p>
</div>
<div class="paragraph">
<p>This was pretty much the state of the Big Data world (as it was called then) as <a href="https://www.rittmanmead.com/blog/2016/12/etl-offload-with-spark-and-amazon-emr-part-5/">I last saw it</a> before getting distracted by the world of stream processing - fragmented, more difficult to use, less functionality than an RDBMS for analytics, and evolving rapidly.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_storing_and_accessing_your_data_pt_2_and_then_rebuild_it_Ô∏è">Storing and Accessing Your Data pt 2: ‚Ä¶and Then Rebuild It üèóÔ∏è&nbsp;<a class="headline-hash" href="#_storing_and_accessing_your_data_pt_2_and_then_rebuild_it_Ô∏è">üîó</a> </h2>
<div class="sectionbody">
<div class="paragraph">
<p>Coming back to this after my attention being elsewhere for a few years means that I have the slightly uninformed but helpfully simplistic view of things. What the relational data warehouses used to do (bar scale, arguably), we are now approaching something roughly like parity again with a stack of tools that have stabilised and matured in large, with a layer on top that‚Äôs still being figured out.</p>
</div>
<div class="paragraph">
<p>Underpinning it all is the core idea of separation of storage and compute. Instead of one box (the traditional RDBMS), we have two. This is important for two vital reasons:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>It‚Äôs a lot <strong>cheaper</strong> to just store data and then only pay for compute when you want to use it.</p>
<div class="paragraph">
<p>The alternative is that you couple the two together which is what we‚Äôve generally always done and is seen in every RDBMS, like Oracle, DB2, etc etc. With the coupled approach you have a server with disks and CPUs and you‚Äôre paying for the CPUs whether they‚Äôre doing anything or not, and when you need more storage and have filled the disk bays you need to buy (and license, hi Oracle) another server (with CPUs etc).</p>
</div>
<div class="paragraph">
<p>The added element here is that you have to provision your capacity for your <strong>peak</strong> workload, which means over-provisioning and capacity sat idle potentially for much of the time depending on your business and data workload patterns.</p>
</div>
</li>
<li>
<p>If your data is held in an <strong>open format</strong> on a storage platform that has <strong>open APIs</strong> then multiple tools can use it as they want to.</p>
<div class="paragraph">
<p>Contrast this to putting your data in SQL Server (not to pick on Oracle all the time), and any tool that wants to use it has to do so through SQL Server. If a new tool comes along that does particular processing really really well and your data is sat in an RDBMS then you have to migrate that data off the RDBMS first, or query it in place.</p>
</div>
<div class="paragraph">
<p>Given the <a href="https://en.wikipedia.org/wiki/Cambrian_explosion">Cambrian explosion</a> that‚Äôs been happening in the world of software and showing no signs of abating, setting ourselves up for compatibilty and future evolution of software choices seems like the smart move.</p>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>HDFS and Hive gave us this separation, right? Well, it did, but with a <a href="https://youtu.be/nWwQMlrjhy0?t=734">long list of problems and limitations for Hive</a>. These include poor perfomance, a lack of support for transactions, point-in-time querying, streaming updates, and more. In addition, HDFS has nowadays been overtaken by S3 as the object store of choice with APIs supported by numerous non-S3 platforms, both Cloud based (e.g. <a href="https://cloud.google.com/storage/docs/interoperability">Google‚Äôs Cloud Storage (GCS)</a>, and <a href="https://developers.cloudflare.com/r2/platform/s3-compatibility/api/">Cloudflare‚Äôs R2</a>) and on-premises (e.g. <a href="https://min.io/">Minio</a>).</p>
</div>
<div class="paragraph">
<p>So if it‚Äôs not HDFS and Hive, what‚Äôs the current state and future of analytics data storage &amp; access looking like?</p>
</div>
<div class="sect2">
<h3 id="_data_lake_table_formats_data_lakehouses">Data Lake Table Formats &amp; Data Lakehouses&nbsp;<a class="headline-hash" href="#_data_lake_table_formats_data_lakehouses">üîó</a> </h3>
<div class="paragraph">
<p>So, full disclosure first:</p>
</div>
<div class="paragraph">
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">üò≥Confession: Until last week I honestly thought &quot;data lakehouse&quot; was some god-awful marketing bollocks and nothing more. <br>üôàEmbarrassed to find out there&#39;s actually a rather interesting paper from last year describing the concept in detail: <a href="https://t.co/XEI0zGSXBl">https://t.co/XEI0zGSXBl</a></p>&mdash; Robin Moffatt üçªüèÉü•ì (@rmoff) <a href="https://twitter.com/rmoff/status/1565747777992359938?ref_src=twsrc%5Etfw">September 2, 2022</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


</div>
<div class="paragraph">
<p>You can read the <a href="https://www.cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf">Lakehouse paper</a> (and <a href="https://www.databricks.com/wp-content/uploads/2020/08/p975-armbrust.pdf">more detailed one</a>) and decide for yourself <a href="https://twitter.com/gwenshap/status/1565771009902256129">its virtues</a>, but I found it a useful description of a pattern that several technologies are adopting, not just <a href="https://www.databricks.com/product/data-lakehouse">Databricks and their Delta Lake implementation of the Lakehouse</a>. <em>I‚Äôll admit, the name grates‚Äîand I miss the Hadoop days of fun names üòâ.</em></p>
</div>
<div class="paragraph">
<p>In short, the &#34;Lakehouse&#34; concept is where data is stored on object store (the Data Lake) with a layer above it providing a &#34;table format&#34; through which data can be read and written in a structured way, supporting updates and deletes to the data, as well as queried in an efficient way. The Lakehouse is the whole; the <strong>table format</strong> is the specific layer of technology that implements the access on the data in your Data Lake.</p>
</div>
<div id="img-lakehouse" class="imageblock">
<div class="content">
<a class="image" href="https://www.cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf"><img src="/images/2022/09/lakehouse_dl01.png" alt="Diagram of the evolution of the Lakehouse from Databricks"/></a>
</div>
</div>
<div class="paragraph">
<p>Whether you go for the <strong>Lakehouse</strong> term (Databricks would like you to, and <a href="https://www.snowflake.com/guides/what-data-lakehouse">Snowflake</a> are onboard too, and maybe even <a href="https://www.oracle.com/uk/data-lakehouse/what-is-data-lakehouse/">Oracle</a>) or just the <strong>Data Lake plus Table Format</strong>, it‚Äôs a really interesting idea. The bit that really catches my attention is that it enables a common table structure to be defined and accessed by a variety of compute engines - meaning that in both querying and processing (<a href="/2022/10/02/data-engineering-in-2022-architectures-terminology/">ETL/ELT</a>) the data can be structured and manipulated in the way in which you would in an RDBMS.</p>
</div>
<div class="paragraph">
<p>There are three table formats available:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://hudi.apache.org/">Apache Hudi</a></p>
</li>
<li>
<p><a href="https://iceberg.apache.org">Apache Iceberg</a></p>
</li>
<li>
<p><a href="https://delta.io">Delta Lake</a></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>All of them enable the things that we‚Äôd have taken for granted a decade ago including rich metadata, transactional access, `UPDATE`s, `DELETE`s, and ACID compliance, along with performant access when querying the data.</p>
</div>
<div class="paragraph">
<p>Both Hudi and Delta Lake have a similar conceptual diagram which illustrates things well. Note the plethora of query engines and integrations that each support.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/2022/09/hudi_dl01.png" alt="Apache Hudi and Delta Lake conceptual diagrams"/>
</div>
</div>
<div class="paragraph">
<p><em>(image credits: <a href="https://hudi.apache.org/">Apache Hudi</a> / <a href="https://delta.io">Delta Lake</a>)</em></p>
</div>
</div>
<div class="sect2">
<h3 id="_managed_data_lakehouses">Managed Data Lakehouses&nbsp;<a class="headline-hash" href="#_managed_data_lakehouses">üîó</a> </h3>
<div class="paragraph">
<p>You can run run your own, or use used hosted versions including</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://www.onehouse.ai/">Onehouse</a> (Apache Hudi)</p>
</li>
<li>
<p><a href="https://tabular.io/">Tabular</a> (Apache Iceberg)</p>
</li>
<li>
<p><a href="https://www.databricks.com/">Databricks</a> (Delta Lake)</p>
</li>
<li>
<p><strong>GCP</strong>&#39;s <a href="https://cloud.google.com/blog/products/data-analytics/unify-data-lakes-and-warehouses-with-biglake-now-generally-available">BigLake</a> (Iceberg?)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Azure</strong> have a close partnership with Databricks, so the only major cloud provider missing from this list is <strong>AWS</strong>. They have <a href="https://aws.amazon.com/lake-formation/">Lake Formation</a> and <a href="https://docs.aws.amazon.com/lake-formation/latest/dg/governed-tables.html">Governed Tables</a> which looks similar on the surface but I‚Äôve not dug into in detail (and Governed Tables aren‚Äôt even mentioned on AWS&#39; <a href="https://aws.amazon.com/blogs/big-data/build-a-lake-house-architecture-on-aws/">Build a Lakehouse Architecture on AWS</a> blog).</p>
</div>
<div class="paragraph">
<p><strong>Snowflake</strong> recently added support for <a href="https://www.snowflake.com/blog/iceberg-tables-powering-open-standards-with-snowflake-innovations/">Iceberg tables</a> (complementing the existing <a href="https://docs.snowflake.com/en/user-guide/tables-external-intro.html#delta-lake-support">support for Delta Lake external tables</a>), and are <a href="https://www.snowflake.com/blog/5-reasons-apache-iceberg/">backing Iceberg</a> ‚Äî presumably in part to try and hamper Databricks&#39; Delta Lake (see also their snarky comments about &#34;<em>Iceberg includes features that are <strong>paid in other table formats</strong></em>&#34;, &#34;<em>The Iceberg project is <strong>well-run</strong> open source</em>&#34; etc, taking a shot at the fact that Delta Lake has paid options, and the majority of committers are from Databricks).</p>
</div>
<div class="paragraph">
<p><a href="https://www.dremio.com/"><strong>Dremio</strong></a> are also in this space as one of the companies working on <a href="https://arrow.apache.org/">Apache Arrow</a> and providing a fast query engine built on it called Dremio Sonar. I‚Äôve yet to get my head around their offering, but it looks like on-premises platform as well as hosted, with support for Apache Iceberg and Delta Lake. They‚Äôve got a rich set of resources in their <a href="https://www.dremio.com/subsurface/">Subsurface</a> resource area.</p>
</div>
<div class="paragraph">
<p><strong>Oracle</strong> being Oracle are not ones to miss up the chance to jump on a buzzword or marketing bandwagon. Their version of the Lakehouse however looks to be to stick their Autonomous Data Warehouse (it‚Äôs self driving! self healing!) on top of a data lake - kinda like Snowflake have done, but without the open table format support of Apache Iceberg. The huge downside to this is that without the open table format there‚Äôs zero interoperability with other query &amp; processing engines - something Oracle are presumably not in a rush to enable.</p>
</div>
</div>
<div class="sect2">
<h3 id="_storage_formats">Storage Formats&nbsp;<a class="headline-hash" href="#_storage_formats">üîó</a> </h3>
<div class="paragraph">
<p>Regardless of which <em>table format</em> you implement, you still store your data in a format appropriate for its use - and that format is separate from the table format (confused yet? you might be). Different table formats support different storage formats but in general you‚Äôll see various open formats used:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Probably something like <a href="https://avro.apache.org/">Avro</a> for structure data that‚Äôs still to be processed</p>
</li>
<li>
<p>A columnar format such as <a href="https://parquet.apache.org/">Parquet</a> or <a href="https://orc.apache.org/">Orc</a> for data that‚Äôs going to be queried</p>
</li>
<li>
<p>It could also just be JSON (hell, use CSV if you really must)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Regardless of the format, the data is stored on storage with an open API (or at least one which is widely supported by most tools) - S3 becomes the de facto choice here.</p>
</div>
</div>
<div class="sect2">
<h3 id="_reading_more_about_table_formats_lakehouses">Reading more about Table Formats &amp; Lakehouses&nbsp;<a class="headline-hash" href="#_reading_more_about_table_formats_lakehouses">üîó</a> </h3>
<div class="paragraph">
<p>Here are some good explanations, deep-dives, and comparison posts covering the three formats:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://dacort.dev/posts/modern-data-lake-storage-layers/">An Introduction to Modern Data Lake Storage Layers</a> - <a href="https://twitter.com/dacort">Damon Cortesi</a> (AWS)</p>
</li>
<li>
<p>Comparison of Data Lake Table Formats <a href="https://www.dremio.com/subsurface/comparison-of-data-lake-table-formats-iceberg-hudi-and-delta-lake/">blog</a> / <a href="https://www.dremio.com/subsurface/subsurface-meetup-comparison-of-data-lakehouse-table-formats/">video</a> - <a href="https://twitter.com/AMdatalakehouse">Alex Merced</a> (Dremio)</p>
</li>
<li>
<p><a href="https://www.onehouse.ai/blog/apache-hudi-vs-delta-lake-vs-apache-iceberg-lakehouse-feature-comparison">Apache Hudi vs Delta Lake vs Apache Iceberg - Lakehouse Feature Comparison</a> - <a href="https://www.linkedin.com/in/lakehouse/">Kyle Weller</a> (Onehouse)</p>
</li>
<li>
<p><a href="https://lakefs.io/hudi-iceberg-and-delta-lake-data-lake-table-formats-compared/">Hudi, Iceberg and Delta Lake: Data Lake Table Formats Compared</a> - <a href="https://www.linkedin.com/in/paulsingman/">Paul Singman</a> (LakeFS)</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_a_note_about_open_formats">A Note About Open Formats&nbsp;<a class="headline-hash" href="#_a_note_about_open_formats">üîó</a> </h3>
<div class="paragraph">
<p>Whether we‚Äôre talking data lakes, Lakehouses, or other ways of storing data, open formats are important. A closed-format vendor will tell you that it‚Äôs just the &#34;vendor lockin bogeyman man&#34; pitch and how often do you re-platform anyway. I would reframe it away from this and suggest that just as with tools such as Apache Kafka, an open format enables you to keep your data in a neutral place, accessible by many different tools and technologies. Why do so many support it? Because it‚Äôs open!</p>
</div>
<div class="paragraph">
<p>In a technology landscape which has not stopped moving at this pace for several years now and probably won‚Äôt for many more, the alternative to an open format is betting big on a closed platform and hoping that nothing better comes along in the envisaged lifetime of the data platform. Open formats give you the flexibility to hedge your bets, to evaluate newer tools and technologies as they come along, and to not be beholden to a particular vendor or technology if it falls behind what you need.</p>
</div>
<div class="paragraph">
<p>In previous times the use of an open format may have been moot given the dearth of alternatives when it came to processing the data‚Äînever mind the fact that the storage of data was usually coupled to the compute making it even more irrelevant. Nowadays there are multiple &#34;big hitters&#34; in each processing category with a dozen other options nibbling at their feet. Using a open format gives you the freedom to trial whichever ones you want to.</p>
</div>
<div class="paragraph">
<p>Just a tip to vendors: that‚Äôs great if you‚Äôre embracing open formats, but check your hubris if you start to brag about it whilst simultaneously throwing FUD at open source. <a href="https://www.linkedin.com/posts/robinmoffatt_choosing-open-wisely-snowflake-blog-activity-6973309528628973568-gjOJ?utm_source=share&amp;utm_medium=member_desktop">Just sayin&#39;</a>.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_git_for_data_with_lakefs"><code>git</code> For Data with LakeFS&nbsp;<a class="headline-hash" href="#_git_for_data_with_lakefs">üîó</a> </h2>
<div class="sectionbody">
<div class="paragraph">
<p>Leaving aside table formats and lakehouses for the moment‚Äîand coming back to the big picture of how we store and access data nowadays‚Äîone idea that‚Äôs caught my attention is that of being able to apply git-like semantics <strong>to the data itself</strong>. Here‚Äôs a copy of <a href="https://twitter.com/rmoff/status/1567829714865102853">a recent Twitter thread that I wrote</a>.</p>
</div>
<hr/>
<div class="paragraph">
<p>Having <a href="https://www.youtube.com/watch?v=uixZ7NcGoeE">watched @gwenshap and @ozkatz100 talk about &#34;git for data&#34;</a> I would definitely say is a serious idea.
However to the point at the end of the video, RTFM‚Äîit took reading <a href="https://docs.lakefs.io/using_lakefs/data-devenv.html">page from the docs</a> and some other pages subsequently to really grok the concept in practice.</p>
</div>
<div class="paragraph">
<p>Where I struggled at first with the git analogy alone was that data changes, and I couldn‚Äôt see how branch/merge fitted into that outside of the idea of branching for throwaway testing alone. The <a href="https://www.youtube.com/watch?v=uixZ7NcGoeE&amp;t=1401s">1PB accidental deletion example</a> was useful for illustrating the latter point for sure.</p>
</div>
<div class="paragraph">
<p>But then reading <a href="https://docs.lakefs.io/understand/roadmap.html#improved-streaming-support-for-apache-kafka">this page</a> made me realise that I was thinking about the whole thing from a streaming PoV‚Äîwhen actually the idea of running a batch against a branch with a hook to validate and then merge is a freakin awesome idea</p>
</div>
<div class="paragraph">
<p>(As the roadmap issue notes, doing this for streaming data is conceptually possible but more complex to implement.)</p>
</div>
<div class="paragraph">
<p>I‚Äôm also still trying to think through the implications of <a href="https://docs.lakefs.io/understand/model.html#merge">merging one branch into another</a> in which there are changes; can data really be treated the same as code in that sense, or could one end up with inconsistent data sets?</p>
</div>
<div class="paragraph">
<p>Lastly, having been reading up on table formats, I‚Äôd be interested to dig into quite how much LakeFS works already with them vs roadmap alone (the docs are not entirely consistent on this point)‚Äîbut with both in place it sounds like a fantastic place for data eng to be heading.</p>
</div>
<hr/>
<div class="paragraph">
<p>The &#34;git for data&#34; pitch is a great way to articulate things, but it also shifted my brain off some of the central uses. For code, <code>git</code> is an integral part of the development process but once it hits Production <code>git</code> steps back from an active role. However, in the case of LakeFS some of their most exciting use cases are <em>as part of the Production data process</em>. <a href="https://docs.lakefs.io/understand/roadmap.html#improved-streaming-support-for-apache-kafka">The docs</a> have several examples which I think are just great:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>When your batch pipeline runs, it does so against a branch of the data. Before merging that branch back into trunk, a hook can be configured to do various data quality checks (just as you‚Äôd configure hooks in GitHub etc to check for code quality, test suites, etc etc). This could be things like checking for PII slipping through, or simply &#34;did we process the approximate number of records that we would expect&#34;. If that kind of check fails because the source data‚Äôs gone bad or failed up stream then you potentially save yourself a ton of unpicking that you‚Äôd have to do if it‚Äôs updated directly in the Production data lake.</p>
</li>
<li>
<p>As above, the batch pipeline creates a new branch when it runs, and when (or if) it completes successfully and merges that back into the trunk, that merge can have attached to it a bunch of metadata to do with the pipeline execution. What version of the code was it running, what version of the underlying frameworks on which it executed, and so on. Invaluable for tracing particular problems at a later date.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><em>I kicked the tyres on LakeFS and wrote about it <a href="/2022/09/16/data-engineering-in-2022-exploring-lakefs-with-jupyter-and-pyspark/">here</a></em></p>
</div>
<hr/>
</div>
</div>
<div class="sect1">
<h2 id="_data_engineering_in_2022">Data Engineering in 2022&nbsp;<a class="headline-hash" href="#_data_engineering_in_2022">üîó</a> </h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p><a href="/2022/09/14/stretching-my-legs-in-the-data-engineering-ecosystem-in-2022/">Introduction</a></p>
</li>
<li>
<p><a href="/2022/09/16/data-engineering-in-2022-exploring-lakefs-with-jupyter-and-pyspark/">Exploring LakeFS with Jupyter and PySpark</a></p>
</li>
<li>
<p><a href="/2022/10/02/data-engineering-in-2022-architectures-terminology/">Architectures &amp; Terminology</a></p>
</li>
<li>
<p><a href="/2022/10/20/data-engineering-in-2022-exploring-dbt-with-duckdb/">Exploring dbt with DuckDB</a></p>
</li>
<li>
<p><a href="/2022/10/24/data-engineering-in-2022-wrangling-the-feedback-data-from-current-22-with-dbt">Wrangling the feedback data from Current 22 with dbt</a></p>
</li>
<li>
<p><a href="/2022/11/08/data-engineering-in-2022-elt-tools/">ELT tools</a></p>
</li>
<li>
<p>Query &amp; Transformation Engines [TODO]</p>
</li>
<li>
<p><a href="/2022/09/14/data-engineering-resources/">Resources</a></p>
</li>
</ul>
</div>
</div>
</div>
	<hr>
	<div class="giscus-container">
		<script src="https://giscus.app/client.js"
				data-repo="rmoff/rmoff-blog"
				data-repo-id="MDEwOlJlcG9zaXRvcnkxNTE3NDg2MTE="
				data-category="Announcements"
				data-category-id="DIC_kwDOCQuAA84CvP5T"
				data-mapping="pathname"
				data-strict="1"
				data-reactions-enabled="1"
				data-emit-metadata="0"
				data-input-position="bottom"
				data-theme="light"
				data-lang="en"
				crossorigin="anonymous"
				async>
		</script>
	</div>
</article>
      </main>
    
      
      <div class="docs-toc">
        <ul class="nav toc-top">
          <li><a href="#" id="back_to_top" class="docs-toc-title">On this page</a></li>
        </ul>
        <nav id="TableOfContents">
  <ul>
    <li><a href="#_storing_and_accessing_your_data_pt_1_burn_it_all_down">Storing and Accessing Your Data pt 1: üî• Burn It All Down‚Ä¶üî•</a></li>
    <li><a href="#_storing_and_accessing_your_data_pt_2_and_then_rebuild_it_Ô∏è">Storing and Accessing Your Data pt 2: ‚Ä¶and Then Rebuild It üèóÔ∏è</a>
      <ul>
        <li><a href="#_data_lake_table_formats_data_lakehouses">Data Lake Table Formats &amp; Data Lakehouses</a></li>
        <li><a href="#_managed_data_lakehouses">Managed Data Lakehouses</a></li>
        <li><a href="#_storage_formats">Storage Formats</a></li>
        <li><a href="#_reading_more_about_table_formats_lakehouses">Reading more about Table Formats &amp; Lakehouses</a></li>
        <li><a href="#_a_note_about_open_formats">A Note About Open Formats</a></li>
      </ul>
    </li>
    <li><a href="#_git_for_data_with_lakefs"><code>git</code> For Data with LakeFS</a></li>
    <li><a href="#_data_engineering_in_2022">Data Engineering in 2022</a></li>
  </ul>
</nav>
      </div>
      
    
    </div>
  </div>
</div>


		</main>

		

		
		<footer class="site-footer hide-print" role="contentinfo">
			<span>&copy; 2026 </span>
		</footer>
		

		
	</body>
</html>
