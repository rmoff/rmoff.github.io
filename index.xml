<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>rmoff&#39;s random ramblings</title>
    <link>https://rmoff.net/</link>
    <description>Recent content on rmoff&#39;s random ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>2025-10-31</lastBuildDate>
    
        <atom:link href="https://rmoff.net/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Interesting links - October 2025</title>
      <link>https://rmoff.net/2025/10/31/interesting-links-october-2025/</link>
      <pubDate>2025-10-31</pubDate>
      
      <guid>https://rmoff.net/2025/10/31/interesting-links-october-2025/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2025/10/h_IMG_2723.webp" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;What with Current NOLA 2025 happening this week, and some &lt;em&gt;very&lt;/em&gt; last minute preparations for the demo at the keynote on day 2, this monthâ€™s links roundup is pushing it right up to the wire :)
The demo was pretty cool, and finally I have a good example of how this AI stuff actually fits into a workflow ;)
Iâ€™ll write it up as a blog post (or two, probably)â€”stay tuned!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Some self-promotion to begin with:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;This month a couple of colleagues and I launched &lt;a href=&#34;https://flink-watermarks.wtf/&#34;&gt;Flink Watermarksâ€¦WTF&lt;/a&gt;.
Itâ€™s an interactive explainer about watermarks in Apache Flink.
Try it out and let me know what you think.&lt;/p&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Oh, and I even designed some stickers for it!&lt;/p&gt;
&lt;div class=&#34;paragraph&#34;&gt;



&lt;video width=&#34;100%&#34;
  
  autoplay
  loop
  muted
  playsinline&gt;
  &lt;source src=&#34;https://rmoff.net/images/2025/10/flink-watermarks.wtf.mp4&#34; type=&#34;video/mp4&#34;&gt;
  &lt;source src=&#34;https://rmoff.net/images/2025/10/flink-watermarks.wtf.webm&#34; type=&#34;video/webm&#34;&gt;
  Your browser does not support the video tag.
&lt;/video&gt;

&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I gave a talk about &lt;a href=&#34;https://rmoff.net/talk/blog-writing-for-developers/&#34;&gt;Blog Writing for Developers&lt;/a&gt; - check out the link for slides and audio recording&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I was a guest on the Confluent Developer podcast - ðŸŽ¥ &lt;a href=&#34;https://www.youtube.com/watch?v=U0t5cCl9BWM&#34;&gt;video here&lt;/a&gt;, ðŸŽ§ &lt;a href=&#34;https://confluent.buzzsprout.com/186154/episodes/18059785-how-kafka-expert-robin-moffat-tackles-open-source-problems-ep-6&#34;&gt;audio here&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;With that, on with the interesting links!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;Not got time for all this? Iâ€™ve marked ðŸ”¥ for my top reads of the month&lt;/em&gt; :)&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_kafka_and_event_streaming&#34;&gt;Kafka and Event Streaming&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Probably the biggest discussion in the Apache Kafka community at the moment is the direction of the project with regards to &amp;#34;Diskless&amp;#34; (or &amp;#34;Direct-to-S3&amp;#34;).
Hereâ€™s a round-up of some of the key reading:&lt;/p&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ Summary from &lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/The+Path+Forward+for+Saving+Cross-AZ+Replication+Costs+KIPs&#34;&gt;Luke Chen&lt;/a&gt; of the different proposals, and more recently analysis and commentary from &lt;a href=&#34;https://jack-vanlightly.com/blog/2025/10/22/a-fork-in-the-road-deciding-kafkas-diskless-future&#34;&gt;Jack Vanlightly&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Discussion of the KIP-1150 proposal on the &lt;a href=&#34;https://lists.apache.org/thread/ljxc495nf39myp28pmf77sm2xydwjm6d&#34;&gt;Apache Kafka mailing list&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;More analysis and commentary from Freshaâ€™s &lt;a href=&#34;https://medium.com/fresha-data-engineering/the-good-the-bad-and-the-automq-5aa7a8748e71&#34;&gt;Anton Borisov&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Updated recently, Hans-Peter Grahsl and Gunnar Morlingâ€™s &lt;a href=&#34;https://a-great-day-out-with.github.io/kafka/index.html&#34;&gt;A Great Day Out Withâ€¦â€‹ Apache Kafka&lt;/a&gt; is a useful map of the tools and ecosystem.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Vu Trinh does &lt;a href=&#34;https://blog.dataengineerthings.org/is-your-data-valid-why-bufstream-guarantees-what-kafka-cant-ed84a1fcfcc9&#34;&gt;a deep-dive on how the Kafka-compatible Bufstream handles data validation&lt;/a&gt;, comparing it to the Kafka + Schema Registry approach&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://dev.to/ijuren/good-things-compression-take-time-1aed&#34;&gt;Interesting analysis&lt;/a&gt; from Ivan Juren on the &lt;code&gt;linger.ms&lt;/code&gt; setting in Kafka and the throughput/latency/CPU trade-off.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ Federico Valeri has published a very well-written &lt;a href=&#34;https://developers.redhat.com/articles/2025/09/17/deep-dive-apache-kafkas-kraft-protocol#&#34;&gt;deep dive into Kafkaâ€™s KRaft protocol&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A nice &lt;a href=&#34;https://github.com/dustin10/kaftui&#34;&gt;TUI for Kafka&lt;/a&gt; from Dustin Dobervich.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The Queues feature for Kafka was added recently - &lt;a href=&#34;https://github.com/ifnesi/queues-for-kafka&#34;&gt;this demo from Italo Nesi&lt;/a&gt; is a neat way to explore it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Klaviyoâ€™s Chinmay Sawaji has written a good post explaining how they &lt;a href=&#34;https://klaviyo.tech/building-a-resilient-event-publisher-with-dual-failure-capture-518749cb5600&#34;&gt;build their Kafka producers to be resilient to failures&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In a fantastic example of both &amp;#34;just because I can&amp;#34; &lt;em&gt;and&lt;/em&gt; &amp;#34;Iâ€™m going to explain this thing using a cool example&amp;#34;, Leandro ProenÃ§a shows how to &lt;a href=&#34;https://leandronsp.com/articles/you-dont-need-kafka-building-a-message-queue-with-only-two-unix-signals&#34;&gt;rebuild Kafka using UNIX signals&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In a somewhat more serious approach (I think?) Stanislav Kozlovski makes the case for &lt;a href=&#34;https://topicpartition.io/blog/postgres-pubsub-queue-benchmarks&#34;&gt;using Postgres instead of Kafka in many situations&lt;/a&gt;.
Oliver Russell wrote last year about how his team actually do use &lt;a href=&#34;https://leontrolski.github.io/postgres-as-queue.html&#34;&gt;Postgres as a queue&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Backfilling data in Kafka is definitely a &amp;#34;day 2&amp;#34; type problem, but definitely a real oneâ€”and &lt;a href=&#34;https://nejckorasa.github.io/posts/kafka-backfill/&#34;&gt;Nejc Korasa has a nice write-up&lt;/a&gt; of some of the patterns to consider.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A &lt;a href=&#34;https://github.com/j3-signalroom/kafka_cluster-topic-key_distribution_analyzer-tool&#34;&gt;tool&lt;/a&gt; from Jeffrey Jonathan Jennings to &lt;a href=&#34;https://thej3.com/you-cant-optimize-what-you-can-t-measure-4db0cbf99b9b&#34;&gt;analyse key distribution&lt;/a&gt; and help avoid hot partitions.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_stream_processing&#34;&gt;Stream Processing&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Very cool blog post from the team at Grab on &lt;a href=&#34;https://engineering.grab.com/ml-predictive-autoscaling-for-flink&#34;&gt;using machine learning to predict workloads and scale Flink automagically&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Milind Srivastava and colleagues at CMU have published a library of &lt;a href=&#34;https://github.com/ProjectASAP/FlinkSketch&#34;&gt;sketching algorithms&lt;/a&gt; for Flinkâ€™s DataStream API.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tools to use Flink from &lt;a href=&#34;https://github.com/exness/go-flink-sql&#34;&gt;Go&lt;/a&gt; and &lt;a href=&#34;https://github.com/devstress/FlinkDotnet&#34;&gt;.NET&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ Yennick Trevels has published both a &lt;a href=&#34;https://kafkastreamsfieldguide.com/articles/kafka-streams-monitoring&#34;&gt;Kafka Streams monitoring guide&lt;/a&gt; as well as an excellent &lt;a href=&#34;https://kafkastreamsfieldguide.com/articles/kafka-streams-grafana-dashboard&#34;&gt;Grafana dashboard for Kafka Streams&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Flinkâ€™s Hadoop-rooted support for S3 has caused plenty of travails for lots of people, &lt;a href=&#34;https://www.decodable.co/blog/troubleshooting-flink-sql-s3-problems&#34;&gt;including me&lt;/a&gt;â€”and the community has recognised this with &lt;a href=&#34;https://lists.apache.org/thread/2bllhqlbv0pz6t95tsjbszpm9bp9911c&#34;&gt;a discussion beginning&lt;/a&gt; about creating native support for S3 within Flink.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A &lt;a href=&#34;https://www.streamingdata.tech/p/flink-forward-2025&#34;&gt;report from Flink Forward 2025&lt;/a&gt; by Yaroslav Tkachenko.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Hands-on example from Gal Krispel at Riskified on &lt;a href=&#34;https://medium.com/riskified-technology/overcoming-flinksql-limitations-with-a-hybrid-api-approach-9bbe6b569431&#34;&gt;how they use Flinkâ€™s DataStream API to validate and pre-process data to make their Flink SQL pipelines more resilient&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Netflixâ€™s Adrian Taruc and James Dalton describe &lt;a href=&#34;https://netflixtechblog.com/how-and-why-netflix-built-a-real-time-distributed-graph-part-1-ingesting-and-processing-data-80113e124acc&#34;&gt;how theyâ€™ve used Kafka, Flink, and Iceberg to build a real-time distributed graph&lt;/a&gt;.
Thereâ€™s some good detail in there about the processing that Flink does, and their experiences in scaling it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Redditâ€™s Vignesh Raja and Jerry Chu write about their experience with Flinkâ€™s tumbling window joins and &lt;a href=&#34;https://www.reddit.com/r/RedditEng/comments/1o0lscn/evolving_signalsjoiner_with_custom_joins_in/&#34;&gt;their own custom join implementation&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_streaming_analytics&#34;&gt;Streaming Analytics&lt;/h3&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ Excellent &lt;a href=&#34;https://duckdb.org/2025/10/13/duckdb-streaming-patterns&#34;&gt;article&lt;/a&gt; (and &lt;a href=&#34;https://github.com/guillesd/duckdb-streaming-patterns/tree/main&#34;&gt;accompanying code repo&lt;/a&gt;) from Guillermo Sanchez showing how low-latency analytics on data from Kafka can be done in DuckDB.
Definitely adding this to my list to try out and write about myself :)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In a similar vein, Yuxia Luo has published &lt;a href=&#34;https://github.com/luoyuxia/duckdb-extension-fluss&#34;&gt;a DuckDB extension to directly query Apache Fluss&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_analytics&#34;&gt;Analytics&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Aakash Pradeep and his colleagues at Twilio built Odin, which is a &lt;a href=&#34;https://aws.amazon.com/blogs/big-data/how-twilio-built-a-multi-engine-query-platform-using-amazon-athena-and-open-source-presto/&#34;&gt;multi-engine query platform enabling them to offer Amazon Athena alongside the existing Presto&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Details of how Chinese ride-sharing company DiDiâ€™s &lt;a href=&#34;https://medium.com/starrocks-engineering/how-didi-transformed-real-time-risk-engineering-with-starrocks-33979acc6cb9&#34;&gt;evaluation of StarRocks against ClickHouse&lt;/a&gt;.
Also from StarRocks is a look at VBillâ€™s &lt;a href=&#34;https://medium.com/starrocks-engineering/empowering-instant-insights-how-vbill-payment-powers-real-time-analytics-at-tens-of-billions-scale-c714a5a740aa&#34;&gt;migration of a real-time data pipeline&lt;/a&gt; from a Kudu/HBase/Hive architecture to StarRocks and some of the optimisations implemented.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ankit Sultana and his colleagues at Uber &lt;a href=&#34;https://www.uber.com/blog/rebuilding-ubers-apache-pinot-query-architecture/&#34;&gt;write about their migration&lt;/a&gt; from a Presto-based proxy in front of Pinot toward a Pinot-native architecture including Pinotâ€™s Multi-Stage Engine Lite Mode to serve real-time analytics workloads.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_data_platforms_architectures_and_modelling&#34;&gt;Data Platforms, Architectures, and Modelling&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ &lt;a href=&#34;https://practicaldatamodeling.substack.com/p/how-to-sell-data-modeling&#34;&gt;Practical advice from Joe Reis on data modeling&lt;/a&gt;â€”specifically, how to get buy-in from your company to actually do it properly.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;An updated version of a16zâ€™s 2020 post looking at &lt;a href=&#34;https://a16z.com/emerging-architectures-for-modern-data-infrastructure/&#34;&gt;Emerging Architectures for Modern Data Infrastructure&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Getting everyone (in the small world that is data engineering) all excited, Fivetran and dbt merged recently. Michael Driscoll has &lt;a href=&#34;https://www.linkedin.com/posts/medriscoll_its-official-fivetran-and-dbt-have-coalesced-activity-7383593000905588736-jEC7/&#34;&gt;a measured analysis of it&lt;/a&gt; over on LinkedIn.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Taking a broader look at whatâ€™s become of the Modern Data Stack is &lt;a href=&#34;https://moderndata101.substack.com/p/the-modern-data-stacks-final-act&#34;&gt;this excellent article&lt;/a&gt; from Travis Thompson and Animesh Kumar.
Insightful and detailed analysis with plenty of evidence to back up their hypotheses.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;My Confluent colleague Alex Stuart wrote a good post about &lt;a href=&#34;https://www.confluent.io/blog/data-lake-governance-tableflow/&#34;&gt;Building a Better-Governed Data Lake Architecture&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;An interesting architecture idea from Ananth Packkildurai: &lt;a href=&#34;https://www.dataengineeringweekly.com/p/revisiting-medallion-architecture-760&#34;&gt;Data Vault in Silver, Dimensional Modeling in Gold&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Where should data contracts go? Mark Freeman and Chad Sanderson &lt;a href=&#34;https://dataproducts.substack.com/p/your-data-contracts-are-in-the-wrong&#34;&gt;tell us&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_data_engineering_pipelines_and_cdc&#34;&gt;Data Engineering, Pipelines, and CDC&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://debezium.io/blog/2025/10/27/debezium-3-4-alpha1-released/&#34;&gt;Debezium 3.4.0.Alpha1&lt;/a&gt; has been released, which includes support for Postgres 18, OpenLineage output from Debezium Server, improvements to the Oracle LogMiner support, and more.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Whatâ€™s the best way to add a new table in Debezium? Fiore Mario Vitale &lt;a href=&#34;https://debezium.io/blog/2025/10/06/add-new-table-to-capture-list/&#34;&gt;explains it here, including things to watch out for&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I enjoyed reading this one, as my assumption about partitioning is exactly what Kirill Bobrov says here is &lt;a href=&#34;https://luminousmen.com/post/how-not-to-partition-data-in-s3-and-what-to-do-instead/&#34;&gt;not the way to do it&lt;/a&gt; (and explains an alternative approach instead).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ It canâ€™t really be a month of interesting links without at least one from Jack Vanlightly, and this month we have three :)
This post is this well-reasoned argument as to why he &lt;a href=&#34;https://jack-vanlightly.com/blog/2025/10/15/why-im-not-a-fan-of-zero-copy-apache-kafka-apache-iceberg&#34;&gt;is not a fan of zero-copy for getting data from Kafka to Iceberg&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A two-part series from Kakao describing their &lt;a href=&#34;https://tech.kakao.com/posts/776&#34;&gt;implementation&lt;/a&gt; and &lt;a href=&#34;https://tech.kakao.com/posts/777&#34;&gt;troubleshooting&lt;/a&gt; of a CDC pipeline with Kafka Connect from Postgres to Elasticsearch.
&lt;em&gt;Itâ€™s in Korean but if you open it in Chrome etc the in-browser translation tool will work wonders :)&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A decent &lt;a href=&#34;https://www.onehouse.ai/blog/kafka-connect-vs-flink-vs-spark-choosing-the-right-ingestion-framework&#34;&gt;comparison of the open-source data ingestion frameworks&lt;/a&gt; (Flink/Kafka Connect/Spark) from Shiyan Xu at Onehouse.
If you notice a recurring theme of Spark cost and performance optimisation then Iâ€™m sure itâ€™s not because Onehouse have their own tool to fix that ;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A summary from ByteByteGo on &lt;a href=&#34;https://blog.bytebytego.com/p/how-pinterest-transfers-hundreds&#34;&gt;how Pinterest use CDC&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fresha have burst onto the data engineering blogging scene in recent months, sharing all sorts of excellent details about their platforms.
This post from Emiliano Mancuso explains &lt;a href=&#34;https://medium.com/fresha-data-engineering/from-json-to-avro-in-the-cdc-pipeline-ff24ac9c9abc&#34;&gt;why they moved from JSON to Avro&lt;/a&gt; in their CDC pipelines to Snowflake.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_open_table_formats_otf_catalogs_lakehouses_etc&#34;&gt;Open Table Formats (OTF), Catalogs, Lakehouses etc.&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Jackâ€™s back!
With a hat-trick of entries in this monthâ€™s post, here heâ€™s looking at &lt;a href=&#34;https://jack-vanlightly.com/blog/2025/10/8/beyond-indexes-how-open-table-formats-optimize-query-performance&#34;&gt;How Open Table Formats Optimize Query Performance&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Anton Borisov &lt;a href=&#34;https://medium.com/fresha-data-engineering/iceberg-cdc-stream-a-little-dream-of-me-a7c9f9e6e11d&#34;&gt;takes a look at the proposal for the next version of the Iceberg spec&lt;/a&gt; and how it could improve things when working with CDC data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Vincent Daniel at Expedia writes about &lt;a href=&#34;https://medium.com/expedia-group-tech/why-you-should-prefer-merge-into-over-insert-overwrite-in-apache-iceberg-b6b130cc27d2&#34;&gt;Why You Should Prefer &lt;code&gt;MERGE INTO&lt;/code&gt; Over &lt;code&gt;INSERT OVERWRITE&lt;/code&gt;&lt;/a&gt; in Iceberg.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Iceberg catalog &lt;a href=&#34;https://polaris.apache.org/&#34;&gt;Apache Polaris&lt;/a&gt; has released v1.2, and Alex Merced has written &lt;a href=&#34;https://www.dremio.com/blog/whats-new-in-apache-polaris-1-2-0-fine-grained-access-event-persistence-and-better-federation/&#34;&gt;an article about whatâ€™s new&lt;/a&gt;.
Meanwhile, &lt;a href=&#34;https://github.com/apache/gravitino/releases/tag/v1.0.0&#34;&gt;Apache Gravitino&lt;/a&gt; (with bigger ambitions beyond just an Iceberg catalog) has released v1.0.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ Dipankar Mazumdar has a good article &lt;a href=&#34;https://dipankar-tnt.medium.com/apache-parquet-vs-newer-file-formats-btrblocks-fastlanes-lance-vortex-cdf02130182c&#34;&gt;comparing Apache Parquet with newer file formats such as Lance and Vortex&lt;/a&gt;.
If new formats are your thing, a recent SIGMOD paper announced the open-source &lt;a href=&#34;https://db.cs.cmu.edu/papers/2025/zeng-sigmod2025.pdf&#34;&gt;F3 (Future-proof File Format)&lt;/a&gt;.
Also doing the rounds this month was news of &lt;a href=&#34;https://github.com/indextables/indextables_spark/&#34;&gt;IndexTables&lt;/a&gt; describes itself as &amp;#34;an experimental open-table format for Apache Spark that enables fast retrieval and full-text search across large-scale data&amp;#34;, whilst &lt;a href=&#34;https://github.com/microsoft/amudai&#34;&gt;Project Amudai&lt;/a&gt; is an &amp;#34;advanced columnar storage format [â€¦designed to] address the limitations of existing data lake formats, such as Apache Parquet&amp;#34;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Petrica Leuca has an interesting post about &lt;a href=&#34;https://medium.com/@petrica.leuca/d4ec74f76c55?sk=1a91e2a84bbddea6db54311129d3347b&#34;&gt;time travel and versioning in DuckLake&lt;/a&gt;.
Iâ€™m even more of a fan because it starts from the point of investigating SCD type 2â€”whatâ€™s not to like!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;As well as writing from Kafka to Iceberg, Confluentâ€™s TableFlow now supports &lt;a href=&#34;https://www.confluent.io/blog/tableflow-delta-lake-unity-catalog-azure/&#34;&gt;writing to Delta Lake, upserts, and dead-letter queues&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Kinda like benchmarks, feature comparisons published by vendors are inherently biasedâ€”whether consciously or not.
Kyle Weller at Onehouseâ€”who contribute to the Apache Hudi formatâ€”has published an updated &lt;a href=&#34;https://www.onehouse.ai/blog/apache-hudi-vs-delta-lake-vs-apache-iceberg-lakehouse-feature-comparison&#34;&gt;feature comparison of Iceberg, Hudi, and Delta Lake&lt;/a&gt;.
You can guess which one comes out on top ;)
&lt;a href=&#34;https://imgflip.com/i/aaq1pi&#34;&gt;Snark aside&lt;/a&gt;, itâ€™s still a useful article if only to look at the positioning and strengths of Hudi.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Videos from the recent &lt;a href=&#34;https://www.youtube.com/playlist?list=PL3IALGSANhzXdkQfSBRaXoHYkOCWd2aUR&#34;&gt;Greater Seattle&lt;/a&gt; and &lt;a href=&#34;https://www.youtube.com/playlist?list=PL3IALGSANhzWxlZpyGgwZiRYjhIStmBdq&#34;&gt;San Francisco&lt;/a&gt; Iceberg meetups have been added to their respective playlists.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Shuiqiang Chen describes &lt;a href=&#34;https://www.alibabacloud.com/blog/building-a-unified-lakehouse-for-large-scale-recommendation-systems-with-apache-paimon-at-tiktok_602568&#34;&gt;how TikTok uses Apache Paimon in their recommendation systems&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_rdbms&#34;&gt;RDBMS&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A nice concise list from Jordan Goodman of &lt;a href=&#34;https://datamethods.substack.com/p/sql-anti-patterns-you-should-avoid&#34;&gt;SQL Anti-Patterns You Should Avoid&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;What happens when you run DuckDB with a 10TB dataset on a 64 core/512GB machine?
Mimoune Djouallah &lt;a href=&#34;https://datamonkeysite.com/2025/10/19/running-duckdb-at-10-tb-scale/&#34;&gt;found out&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Alexey Makhotkin has some excellent content on his blog, including this one looking at the &lt;a href=&#34;https://kb.databasedesignbook.com/posts/systematic-design-of-join-queries/&#34;&gt;systematic design of multi-join &lt;code&gt;GROUP BY&lt;/code&gt; queries&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ Having recently helped build &lt;a href=&#34;https://flink-watermarks.wtf/&#34;&gt;&lt;code&gt;flink-watermarks.wtf&lt;/code&gt;&lt;/a&gt; I now pay much more attention to examples of &lt;em&gt;scrollytelling&lt;/em&gt;â€”and this one from Nanda Syahrasyad showing how to &lt;a href=&#34;https://www.nan.fyi/database&#34;&gt;Build Your Own Database&lt;/a&gt; is really good!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Postgres 18 was released recently, and Ben Dicken did some &lt;a href=&#34;https://planetscale.com/blog/benchmarking-postgres-17-vs-18&#34;&gt;benchmarking comparing it to Postgres 17&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_general_data_stuff&#34;&gt;General Data Stuff&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ Datadog process over &lt;em&gt;100 &lt;strong&gt;trillion&lt;/strong&gt; events per day&lt;/em&gt;, and wrote their own event store called Husky to handle it.
Theyâ€™ve written previously in depth about how it handles &lt;a href=&#34;https://www.datadoghq.com/blog/engineering/husky-deep-dive/&#34;&gt;exactly-once ingestion&lt;/a&gt; and &lt;a href=&#34;https://www.datadoghq.com/blog/engineering/husky-storage-compaction/&#34;&gt;compaction&lt;/a&gt;, and in their most recent post Sami Tabet explains how they built its &lt;a href=&#34;https://www.datadoghq.com/blog/engineering/husky-query-architecture/&#34;&gt;interactive querying capabilities&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Otter/CloudKitchens found both Stackdriver and OpenSearch too expensive for their logging needsâ€”so &lt;a href=&#34;https://techblog.cloudkitchens.com/p/our-journey-to-affordable-logging&#34;&gt;they wrote their own&lt;/a&gt; (in Rust, of course). They claim some impressive numbersâ€”&amp;#34;&lt;em&gt;750+ TiB of logs at 4.4x lower cost than self-hosted OpenSearch[â€¦]50x cheaper than managed alternatives&lt;/em&gt;&amp;#34;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I &lt;a href=&#34;https://speakerdeck.com/rmoff/analysing-the-panama-papers-with-oracle-big-data-spatial-and-graph&#34;&gt;do like a property graph&lt;/a&gt;, and am interested to look more into &lt;a href=&#34;https://graphar.apache.org/&#34;&gt;Apache GraphAr (incubating)&lt;/a&gt; which Sem Sinchenko describes &lt;a href=&#34;https://semyonsinchenko.github.io/ssinchenko/post/dreams-about-graph-in-lakehouse/#headline-11&#34;&gt;in this article&lt;/a&gt; as a standard for Property Graph storage.
In other graph news, DuckDB has a &lt;a href=&#34;https://duckdb.org/community_extensions/extensions/duckpgq&#34;&gt;graph community extension&lt;/a&gt; that DaniÃ«l ten Wolde &lt;a href=&#34;https://duckdb.org/2025/10/22/duckdb-graph-queries-duckpgq#property-graphs-in-duckdb&#34;&gt;shows in action here&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/Basekick-Labs/arc&#34;&gt;Arc&lt;/a&gt; [not the web-browser] is a time-series database built on DuckDB, Parquet, and Arrow, and claims ingestion rates of 2.4M records/sec.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Described as an &amp;#34;&lt;em&gt;open-source immutable SQL database with comprehensive time-travel&lt;/em&gt;&amp;#34;, XTDB &lt;a href=&#34;https://xtdb.com/blog/launching-xtdb-v2&#34;&gt;released v2&lt;/a&gt; earlier this year.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Robert Yokota writes about the Robustness Principle (a.k.a. Postelâ€™s Law) in the context of &lt;a href=&#34;https://yokota.blog/2025/10/07/json-schema-compatibility-and-the-robustness-principle/&#34;&gt;JSON Schema compatibility&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;OpenAIâ€™s Bohan Zhang spoke at PGConf this year about their &lt;a href=&#34;https://www.youtube.com/watch?v=Ni1SGhNu-Q4&#34;&gt;use of Postgres and experience scaling it&lt;/a&gt;.
For more details of OpenAIâ€™s data platforms check out this blog post summarising &lt;a href=&#34;https://blog.bytebytego.com/p/how-openai-uses-kubernetes-and-apache&#34;&gt;how they deploy Kafka and Flink on Kubernetes&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Itâ€™s more about &lt;em&gt;video&lt;/em&gt; streams than &lt;em&gt;event&lt;/em&gt; streams, but this &lt;a href=&#34;https://netflixtechblog.com/behind-the-streams-live-at-netflix-part-1-d23f917c2f40&#34;&gt;three&lt;/a&gt; &lt;a href=&#34;https://netflixtechblog.com/building-a-reliable-cloud-live-streaming-pipeline-for-netflix-8627c608c967&#34;&gt;part&lt;/a&gt; &lt;a href=&#34;https://netflixtechblog.com/behind-the-streams-real-time-recommendations-for-live-events-e027cb313f8f&#34;&gt;series&lt;/a&gt; from Netflix is a fascinating behind-the-scenes explainer of how things work.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_ai&#34;&gt;AI&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;I warned you &lt;a href=&#34;https://rmoff.net/2025/09/30/interesting-links-september-2025/#_ai&#34;&gt;last month&lt;/a&gt;â€¦this AI stuff is here to stay, and itâ€™d be short-sighted to think otherwise.&lt;/em&gt;
&lt;em&gt;As I read and learn more about it, Iâ€™m going to share interesting links (the clue is in the blog post title) that I findâ€”whilst trying to avoid the breathless hype and slop.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;I wrote a post trying to get my head around &lt;em&gt;what&lt;/em&gt; we mean by &lt;a href=&#34;https://rmoff.net/2025/10/06/stumbling-into-ai-part-5agents/&#34;&gt;Agents&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://basicmemory.com/&#34;&gt;Basic Memory&lt;/a&gt; is a very cool MCP server that integrates with your AI tool and acts as a memory of your conversations, storing the information locally in Markdown.
It integrates very neatly with Obsidian.
Iâ€™m a big fan.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Confluent announced a bunch of neat stuff at Current this week including a &lt;a href=&#34;https://www.confluent.io/blog/introducing-real-time-context-engine-ai/&#34;&gt;real time context engine&lt;/a&gt; and &lt;a href=&#34;https://www.confluent.io/blog/2025-q4-streaming-agents-update/&#34;&gt;streaming agents&lt;/a&gt;.
Product blog posts are mâ€™kay I guess but I always like to see the hands-on detail, and so I enjoyed reading my colleague Yash Anandâ€™s example of &lt;a href=&#34;https://medium.com/confluent/building-streaming-ai-agents-with-flink-sql-on-confluent-cloud-e3bb9fe3337a&#34;&gt;building with streaming agents&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ Very cool talk (&lt;a href=&#34;https://www.youtube.com/watch?v=jp-fBw07r7c&#34;&gt;video&lt;/a&gt; / &lt;a href=&#34;https://dpe.org/wp-content/uploads/2024/06/Adam-Huda-and-Ty-Smith-Uber-AI.pptx.pdf&#34;&gt;slides&lt;/a&gt;) from Ty Smith and Adam Huda with real-world examples of how Uberâ€™s developers are using AI and what benefits theyâ€™re seeing.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://flink.apache.org/2025/10/15/apache-flink-agents-0.1.0-release-announcement/&#34;&gt;Apache Flink Agents&lt;/a&gt; is a sub-project of Apache Flink, and they just had their first release.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.anthropic.com/news/skills&#34;&gt;Claude Skills&lt;/a&gt; are the &lt;a href=&#34;https://simonwillison.net/2025/Oct/16/claude-skills/#skills-compared-to-mcp&#34;&gt;latest hawtness&lt;/a&gt; (at least until the next thing comes along tomorrow), and Gordon Murray has published a &lt;a href=&#34;https://github.com/gordonmurray/data-engineering-skills&#34;&gt;set of them&lt;/a&gt; with support for technologies including Flink, Fluss, and Iceberg.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;As well as changing how we get things done, AI is probably going to change how we build platforms too.
Ananth Packkildurai has &lt;a href=&#34;https://www.dataengineeringweekly.com/p/what-supporting-our-ai-overlords&#34;&gt;a good analysis&lt;/a&gt; of two papers looking at how Agents use data and how systems might be better designed for that, and
Ciro Greco looks at how Agents involved in carrying out data engineering tasks might &lt;a href=&#34;https://gradientflow.substack.com/p/the-convergence-of-data-ai-and-agents&#34;&gt;drive platform requirements&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_and_finally&#34;&gt;And finallyâ€¦&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;Nothing to do with data, but stuff that Iâ€™ve found interesting or has made me smile.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_think&#34;&gt;Think&lt;/h3&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://bradstulberg.substack.com/p/a-simple-formula-for-responding-not&#34;&gt;A Simple Formula for Responding not Reacting&lt;/a&gt; - Brad Stulberg&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ &lt;a href=&#34;https://theoatmeal.com/comics/ai_art&#34;&gt;A cartoonistâ€™s review of AI art&lt;/a&gt; - The Oatmeal&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Michael Lopp (a.k.a Rands) has an excellent &lt;a href=&#34;https://randsinrepose.com/archives/so-you-want-to-be-promoted-pt-1/&#34;&gt;two&lt;/a&gt; &lt;a href=&#34;https://randsinrepose.com/archives/so-you-want-to-be-promoted-pt-2/&#34;&gt;part&lt;/a&gt; series: So You Want to Be Promoted.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ &lt;a href=&#34;https://terriblesoftware.org/2025/10/01/stop-avoiding-politics/&#34;&gt;Stop Avoiding Politics&lt;/a&gt; is a great blog post by Matheus Lima.
I wish I could go back several years and show it to younger-me ;)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_tool&#34;&gt;Tool&lt;/h3&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;I used &lt;code&gt;freedium.cfd&lt;/code&gt; in previous editions of this series, and unfortunately itâ€™s gone offline.
&lt;a href=&#34;https://scribe.rip/&#34;&gt;&lt;code&gt;scribe.rip&lt;/code&gt;&lt;/a&gt; is similar in conceptâ€”read Medium articles, without having to go to Medium.com (because, paywall, etc).
Iâ€™m not going to use it on the links in this blog post (like I did with &lt;code&gt;freedium.cfd&lt;/code&gt;) because everything breaks if/when it goes offline.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://time.is/GMT&#34;&gt;&lt;code&gt;time.is&lt;/code&gt;&lt;/a&gt; is a very useful site that displays the current time for any timezone.
Itâ€™s got a lovely clean interface, and a neat UX where you can just append the timezone to the URL: &lt;code&gt;&lt;a href=&#34;https://time.is/gmt&#34; class=&#34;bare&#34;&gt;https://time.is/gmt&lt;/a&gt;&lt;/code&gt;, &lt;code&gt;&lt;a href=&#34;https://time.is/pt&#34; class=&#34;bare&#34;&gt;https://time.is/pt&lt;/a&gt;&lt;/code&gt;, etc.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_watch&#34;&gt;Watch&lt;/h3&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=o4TdHrMi6do&#34;&gt;A laser pointer at 2 billion fps&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ &lt;a href=&#34;https://www.youtube.com/watch?app=desktop&amp;amp;v=cUbIkNUFs-4&#34;&gt;The Original Square Hole Girl Video + The Redemption&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=w3ma9iYx4rg&#34;&gt;Fred Dibnah shows how to erect a chimney scaffold at 200 feet&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_nerd&#34;&gt;Nerd&lt;/h3&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;An interactive simulation of a &lt;a href=&#34;https://andyjakubowski.github.io/statechart-watch/&#34;&gt;Citizen Quartz Multi Alarm III watch&lt;/a&gt;, by Andy Jakubowski&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Nothing motivates a nerd more than a perceived wrong, and this is a fantastic example of the lengths folk will go to :)
&lt;a href=&#34;https://blog.pixelmelt.dev/kindle-web-drm/&#34;&gt;How I Reversed Amazonâ€™s Kindle Web Obfuscation Because Their App Sucked&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ Donâ€™t stop to ask WHY, just click on the link and admire the goodness that is a &lt;a href=&#34;https://dmkskd.github.io/sql-shader/&#34;&gt;Shaderâ€¦written in SQL&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;hr/&gt;
&lt;div class=&#34;admonitionblock tip&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td class=&#34;icon&#34;&gt;
&lt;div class=&#34;title&#34;&gt;Tip&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&#34;content&#34;&gt;
If you like these kind of links you might like to read about &lt;a href=&#34;https://rmoff.net/2024/05/22/how-i-try-to-keep-up-with-the-data-tech-world-a-list-of-data-blogs/&#34;&gt;How I Try To Keep Up With The Data Tech World (A List of Data Blogs)&lt;/a&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
    </item>
    <item>
      <title>Blog Writing for Developers</title>
      <link>https://rmoff.net/talk/blog-writing-for-developers/</link>
      <pubDate>2025-10-22</pubDate>
      
      <guid>https://rmoff.net/talk/blog-writing-for-developers/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2025/10/t_IMG_2896.jpeg" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;A presentation about effective blog writing for developers, covering why to blog, what to write about, and how to structure your content.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This presentation covers:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Why&lt;/strong&gt; developers should blog&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;What&lt;/strong&gt; topics to write about&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;How&lt;/strong&gt; to structure and write effective content&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tools and platforms for technical writing&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Using AI in the writing process&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;iframe src=&#34;slides.html&#34; width=&#34;100%&#34; height=&#34;600&#34; frameborder=&#34;0&#34; allowfullscreen=&#34;&#34;&gt;&lt;/iframe&gt;
&lt;div class=&#34;admonitionblock tip&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td class=&#34;icon&#34;&gt;
&lt;div class=&#34;title&#34;&gt;Tip&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&#34;content&#34;&gt;
Click in the presentation iframe and then press &lt;code&gt;f&lt;/code&gt; to view it full screen.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;The presentation is built from AsciiDoc source using reveal.js.&lt;/em&gt;
&lt;em&gt;You can find the source &lt;a href=&#34;https://raw.githubusercontent.com/rmoff/rmoff-blog/refs/heads/main/content/talk/blog-writing-for-developers/slides.adoc&#34;&gt;here&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_recording&#34;&gt;ðŸŽ§ Recording&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;No video, but you can listen to the recording here (or download it for offline listening).
Apologies for the voice qualityâ€”I was getting over a bad cold! ðŸ¤§&lt;/p&gt;
&lt;/div&gt;
&lt;iframe width=&#34;100%&#34; height=&#34;300&#34; scrolling=&#34;no&#34; frameborder=&#34;no&#34; allow=&#34;autoplay&#34; src=&#34;https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/soundcloud%3Atracks%3A2196346439%3Fsecret_token%3Ds-O1uGJxAW12D&amp;amp;color=%23ff5500&amp;amp;auto_play=false&amp;amp;hide_related=false&amp;amp;show_comments=true&amp;amp;show_user=true&amp;amp;show_reposts=false&amp;amp;show_teaser=true&amp;amp;visual=true&#34;&gt;&lt;/iframe&gt;&lt;div style=&#34;font-size: 10px; color: #cccccc;line-break: anywhere;word-break: normal;overflow: hidden;white-space: nowrap;text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif;font-weight: 100;&#34;&gt;&lt;a href=&#34;https://soundcloud.com/rmoff&#34; title=&#34;rmoff&#34; target=&#34;_blank&#34; style=&#34;color: #cccccc; text-decoration: none;&#34;&gt;rmoff&lt;/a&gt; Â· &lt;a href=&#34;https://soundcloud.com/rmoff/blog-writing-for-developers/s-O1uGJxAW12D&#34; title=&#34;Blog Writing for Developers&#34; target=&#34;_blank&#34; style=&#34;color: #cccccc; text-decoration: none;&#34;&gt;Blog Writing for Developers&lt;/a&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
    </item>
    <item>
      <title>Stumbling into AI: Part 5â€”Agents</title>
      <link>https://rmoff.net/2025/10/06/stumbling-into-ai-part-5agents/</link>
      <pubDate>2025-10-06</pubDate>
      
      <guid>https://rmoff.net/2025/10/06/stumbling-into-ai-part-5agents/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2025/10/t_IMG_2745.webp" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;A &lt;a href=&#34;https://rmoff.net/categories/stumbling-into-ai&#34;&gt;short series&lt;/a&gt; of notes for myself as I learn more about the AI ecosystem as of Autumn [Fall] 2025.&lt;/em&gt;
&lt;em&gt;The driver for all this is understanding more about Apache Flinkâ€™s &lt;a href=&#34;https://github.com/apache/flink-agents&#34;&gt;&lt;strong&gt;Flink Agents&lt;/strong&gt;&lt;/a&gt; project, and Confluentâ€™s &lt;a href=&#34;https://www.confluent.io/product/streaming-agents/&#34;&gt;&lt;strong&gt;Streaming Agents&lt;/strong&gt;&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I started off &lt;a href=&#34;https://rmoff.net/categories/stumbling-into-ai/&#34;&gt;this series&lt;/a&gt;â€”somewhat randomly, with hindsightâ€”looking at &lt;a href=&#34;https://rmoff.net/2025/09/04/stumbling-into-ai-part-1mcp/&#34;&gt;Model Context Protocol (&lt;strong&gt;MCP&lt;/strong&gt;)&lt;/a&gt;.
Itâ€™s a helper technology to make things easier to use and provide a richer experience.
Next I tried to wrap my head around &lt;a href=&#34;https://rmoff.net/2025/09/08/stumbling-into-ai-part-2models/&#34;&gt;&lt;strong&gt;Models&lt;/strong&gt;&lt;/a&gt;â€”mostly LLMs, but also with an &lt;a href=&#34;https://rmoff.net/2025/09/08/stumbling-into-ai-part-2models/#_addendum_there_are_models_and_then_there_are_models_a_k_a_not_all_models_are_llms&#34;&gt;addendum&lt;/a&gt; discussing other types of model too.
Along the lines of MCP, &lt;a href=&#34;https://rmoff.net/2025/09/12/stumbling-into-ai-part-3rag/&#34;&gt;Retrieval Augmented Generation (&lt;strong&gt;RAG&lt;/strong&gt;)&lt;/a&gt; is another helper technology that on its own doesnâ€™t do anything but combined with an LLM gives it added smarts.
I took a brief moment in part 4 to try and build a clearer understanding of &lt;a href=&#34;https://rmoff.net/2025/09/16/stumbling-into-ai-part-4terminology-tidy-up-and-a-little-rant/&#34;&gt;&lt;strong&gt;the difference between ML and AI&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;So whilst RAG and MCP combined make for a bunch of nice capabilities beyond models such as LLMs alone, what Iâ€™m really circling around here is what we can do when we combine all these things: &lt;strong&gt;Agents&lt;/strong&gt;!
Butâ€¦what &lt;em&gt;is&lt;/em&gt; an Agent, both conceptually and in practice?
Letâ€™s try and figure it out.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_start_with_the_obvious_what_is_an_agent&#34;&gt;Start with the obvious: What &lt;em&gt;is&lt;/em&gt; an Agent?&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;admonitionblock tip&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td class=&#34;icon&#34;&gt;
&lt;i class=&#34;fa icon-tip&#34; title=&#34;Tip&#34;&gt;&lt;/i&gt;
&lt;/td&gt;
&lt;td class=&#34;content&#34;&gt;
Turns out this isnâ€™t so straightforward a question to answer.
Below are various definitions and discussions, around which some form of concept starts to coagulate.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Letâ€™s begin with &lt;a href=&#34;https://en.wikipedia.org/wiki/Software_agent&#34;&gt;Wikipediaâ€™s definition&lt;/a&gt;:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In computer science, a software agent is a computer program that &lt;strong&gt;acts for a user or another program in a relationship of agency&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;We can get more specialised if we look at Wikipediaâ€™s entry for an &lt;a href=&#34;https://en.wikipedia.org/wiki/Intelligent_agent&#34;&gt;Intelligent Agent&lt;/a&gt;:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In artificial intelligence, an intelligent agent is an entity that perceives its environment, &lt;strong&gt;takes actions autonomously to achieve goals&lt;/strong&gt;, and may improve its performance through machine learning or by &lt;strong&gt;acquiring knowledge&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;admonitionblock note&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td class=&#34;icon&#34;&gt;
&lt;i class=&#34;fa icon-note&#34; title=&#34;Note&#34;&gt;&lt;/i&gt;
&lt;/td&gt;
&lt;td class=&#34;content&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Citing Wikipedia is perhaps the laziest ever blog authorâ€™s trick, but I offer no apologies ðŸ˜œ.
Behind all the noise and fuss, this is what weâ€™re talking about: a bit of software thatâ€™s going to go and do something for you (or your company) &lt;em&gt;autonomously&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;hr/&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;LangChain have &lt;a href=&#34;https://blog.langchain.com/what-is-an-agent/&#34;&gt;their own definition&lt;/a&gt; of an Agent, explicitly identifying the use of an LLM:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;An AI agent is a system that uses an LLM to decide the control flow of an application.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.langchain.com/what-is-an-agent/&#34;&gt;The blog post from LangChain&lt;/a&gt; as a whole gives more useful grounding in this area and is worth a read.
In fact, if you want to really get into it, the &lt;a href=&#34;https://academy.langchain.com/courses/intro-to-langgraph&#34;&gt;LangChain Academy&lt;/a&gt; is free and the Introduction to LangGraph course gives a really good primer on Agents and more.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Meanwhile, the Anthropic team have a chat about &lt;a href=&#34;https://www.youtube.com/watch?v=XuvKFsktX0Q&amp;amp;t=150s&#34;&gt;&lt;em&gt;their&lt;/em&gt; definition of an Agent&lt;/a&gt;.
In &lt;a href=&#34;https://www.anthropic.com/engineering/building-effective-agents&#34;&gt;a blog post&lt;/a&gt; Anthropic differentiates between &lt;em&gt;Workflows&lt;/em&gt; (that use LLMs) and Agents:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Workflows are systems where LLMs and tools are orchestrated through predefined code paths.
Agents, on the other hand, are systems where LLMs dynamically direct their own processes and tool usage, maintaining control over how they accomplish tasks.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;hr/&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Independent researcher Simon Willison also uses the LLM word in his definition:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;An LLM agent runs tools in a loop to achieve a goal.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;He explores the definition in a recent blog post: &lt;a href=&#34;https://simonwillison.net/2025/Sep/18/agents/&#34;&gt;&lt;em&gt;I think â€œagentâ€ may finally have a widely enough agreed upon definition to be useful jargon now&lt;/em&gt;&lt;/a&gt;, in which &lt;a href=&#34;https://x.com/josh_bickett/status/1725556267014595032&#34;&gt;Josh Bickettâ€™s meme&lt;/a&gt; demonstrates how much of a journey this definition has been on:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2025/10/josh_bickett_agent.webp&#34; alt=&#34;josh bickett agent&#34; width=&#34;800&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;That thereâ€™s still discussion and ambiguity nearly two years after this meme was created is telling.&lt;/p&gt;
&lt;/div&gt;
&lt;hr/&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;My colleague &lt;a href=&#34;https://www.linkedin.com/in/seanf/&#34;&gt;Sean Falconer&lt;/a&gt; knows a &lt;em&gt;lot&lt;/em&gt; more this than I do.
He was a guest on &lt;a href=&#34;https://roundup.getdbt.com/p/the-pragmatic-guide-to-ai-agents&#34;&gt;a recent podcast episode&lt;/a&gt; in which he spells things out:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;[Agentic AI] involves AI systems that can reason, dynamically choose tasks, gather information, and perform actions as a more complete software system.
&lt;sup class=&#34;footnote&#34;&gt;[&lt;a id=&#34;_footnoteref_1&#34; class=&#34;footnote&#34; href=&#34;#_footnotedef_1&#34; title=&#34;View footnote.&#34;&gt;1&lt;/a&gt;]&lt;/sup&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;[Agents] are software that can dynamically decide its own control flow: choosing tasks, workflows, and gathering context as needed. Realistically, &lt;strong&gt;current enterprise agents have limited agency[â€¦]. Theyâ€™re mostly workflow automations rather than fully autonomous systems&lt;/strong&gt;.
&lt;sup class=&#34;footnote&#34;&gt;[&lt;a id=&#34;_footnoteref_2&#34; class=&#34;footnote&#34; href=&#34;#_footnotedef_2&#34; title=&#34;View footnote.&#34;&gt;2&lt;/a&gt;]&lt;/sup&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In many ways [â€¦] &lt;strong&gt;an agent [is] just a microservice&lt;/strong&gt;.
&lt;sup class=&#34;footnote&#34;&gt;[&lt;a id=&#34;_footnoteref_3&#34; class=&#34;footnote&#34; href=&#34;#_footnotedef_3&#34; title=&#34;View footnote.&#34;&gt;3&lt;/a&gt;]&lt;/sup&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_okay_okaybut_what_is_an_ai_agent&#34;&gt;Okay okayâ€¦but what is an [AI] Agent?&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;A straightforward software Agent might do something like:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Order more biscuits when there are only two left&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The pseudo-code looks like this:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code data-lang=&#34;vb&#34;&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;10&lt;/span&gt;      &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;BISCUITS&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;FN_CHECK_BISCUIT_LEVEL&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;()&lt;/span&gt;
&lt;span style=&#34;color: #ae81ff&#34;&gt;20&lt;/span&gt;      &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;IF&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;BISCUITS&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;THEN&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;CALL&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;ORDER_MORE_BISCUITS&lt;/span&gt;
&lt;span style=&#34;color: #ae81ff&#34;&gt;30&lt;/span&gt;      &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;GOTO&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;10&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;We take this code, stick it on a server and leave it to run.
One happy Agent, done.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;An &lt;em&gt;AI&lt;/em&gt; Agent could look more like this:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code data-lang=&#34;vb&#34;&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;10&lt;/span&gt;      &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;BISCUITS&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;FN_CHECK_BISCUIT_LEVEL&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;()&lt;/span&gt;
&lt;span style=&#34;color: #ae81ff&#34;&gt;20&lt;/span&gt;      &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;IF&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;BISCUITS&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;THEN&lt;/span&gt;
        &lt;span style=&#34;color: #75715e;font-style: italic&#34;&gt;REM (Here&amp;#39;s the clever AI stuff ðŸ‘‡)&lt;/span&gt;
            &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;Look&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;at&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;what&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;biscuits&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;are&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;stock&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;at&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;the&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;supplier&lt;/span&gt;
            &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;Work&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;out&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;who&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;the&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;office&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;next&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;week&lt;/span&gt;
            &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;Based&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;on&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;what&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;you&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;know&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;about&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;staff&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;biscuit&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;preferences&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;choose&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;the&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;best&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;ones&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;that&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;are&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;stock&lt;/span&gt;
            &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;Place&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;biscuit&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;order&lt;/span&gt;
&lt;span style=&#34;color: #ae81ff&#34;&gt;30&lt;/span&gt;      &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;GOTO&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;10&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Other examples of AI Agents include:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Coding Agents&lt;/strong&gt;.
Everyoneâ€™s favourite tool (when used right).
It can reason about code, it can write code, it can review PRs.&lt;/p&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;One of the trends that Iâ€™ve noticed recently (October 2025) is the use of Agents to help with some of the up-front jobs in software engineering (such as &lt;a href=&#34;https://www.bigdataldn.com/en-gb/conference/session-details.4500.251751.mcp-at-the-helm-of-autonomous-event-architecture.html&#34;&gt;data modelling&lt;/a&gt; and &lt;a href=&#34;https://roundup.getdbt.com/i/172909726/the-early-days-of-using-redshift-were-such-a-visceral-experience-relative-to-what-came-before-if-i-hadnt-interacted-with-it-directly-i-wouldnt-have-understood-how-big-a-state-change-cloud-data-was-this-feels-like-another-one-of-those-moments-if-you-dont-have-hands-on-experience-youre-not-going-to-really-get-it-fair&#34;&gt;writing tests&lt;/a&gt;), rather than full-blown code thatâ€™s going to ship to production.
Thatâ€™s not to say that coding Agents arenâ€™t being used for that, but by using AI to accelerate certain tasks whilst retaining human oversight (a.k.a. &lt;a href=&#34;#_human_in_the_loop_hitl&#34;&gt;HITL&lt;/a&gt;) it makes it easier to review the output rather than just trusting to luck that reams and reams of code are correct.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Thereâ€™s &lt;a href=&#34;https://dpe.org/wp-content/uploads/2024/06/Adam-Huda-and-Ty-Smith-Uber-AI.pptx.pdf&#34;&gt;a good talk from Uber&lt;/a&gt; on how theyâ€™re using AI in the development process, including code conversion, and testing.&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Travel booking&lt;/strong&gt;.
Perhaps you tell it when you want to go, the kind of vacation you like, and what your budget is; it then goes and finds where itâ€™s nice at that time of year, figures out travel plans within your budget, and either proposes an itinerary or even books it for you.
Another variation could be you tell it &lt;strong&gt;where&lt;/strong&gt;, and then it integrates with your calendar to figure out the &lt;em&gt;when&lt;/em&gt;.&lt;/p&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;This is a canonical example that is oft-cited; Iâ€™d be interested if anyone can point me to an actual implementation of it, even if just a toy one&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;admonitionblock tip&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td class=&#34;icon&#34;&gt;
&lt;i class=&#34;fa icon-tip&#34; title=&#34;Tip&#34;&gt;&lt;/i&gt;
&lt;/td&gt;
&lt;td class=&#34;content&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I saw this in &lt;a href=&#34;https://simonwillison.net/2025/Sep/18/agents/&#34;&gt;a blog post&lt;/a&gt; from Simon Willison that made me wince, but am leaving the above in anyway just to serve as an example of the confusion/hype that exists in this space:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2025/10/travel_agents.png&#34; alt=&#34;There remains an almost unlimited set of alternative definitions: if you talk to people outside of the technical field of building with LLMs youâ€™re still likely to encounter travel agent analogies or employee replacements or excitable use of the word â€œautonomousâ€&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_agentic_ai&#34;&gt;&lt;em&gt;Agentic&lt;/em&gt; AI?&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;code&gt;Agentic&lt;/code&gt; comes from &lt;code&gt;Agent&lt;/code&gt; plus &lt;code&gt;ic&lt;/code&gt;, the latter meaning &lt;em&gt;of, relating to, or characterised by&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;So &lt;code&gt;Agentic AI&lt;/code&gt; is simply AI that is &lt;em&gt;characterised by&lt;/em&gt; an Agent, or Agency.
Contrast that to AI thatâ€™s you sat at the ChatGPT prompt asking it to draw pictures of &lt;a href=&#34;https://chatgpt.com/s/m_68de54147ff88191aba256f96cce54ea&#34;&gt;a duck dressed as a clown&lt;/a&gt;.
Nothing Agentic about thatâ€”just a human-led and human-driven interaction.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&amp;#34;AI Agents&amp;#34; becomes a bit of a mouthful with the qualifier, so much of the current industry noise is simply around &amp;#34;Agents&amp;#34;.
That said, &amp;#34;Agentic AI&amp;#34; sounds cool, so gets used as the marketing term in place of &amp;#34;AI&amp;#34; alone.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_building_an_agent&#34;&gt;Building an Agent&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;So weâ€™ve muddled our way through to some kind of understanding of what an Agent is, and what we mean by Agentic AI.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;But how do we actually build one?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;All we need is an LLM (such as access to the API for &lt;a href=&#34;https://platform.openai.com/docs/overview&#34;&gt;OpenAI&lt;/a&gt; or &lt;a href=&#34;https://claude.com/platform/api&#34;&gt;Claude&lt;/a&gt;), something to call that API (there are worse choices than &lt;code&gt;curl&lt;/code&gt;!), and a way to call external services (e.g. MCP servers) if the LLM determines that it needs to use them.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;So &lt;em&gt;in theory&lt;/em&gt; we could build an Agent with some lines of bash, some API calls, and a bunch of &lt;a href=&#34;https://en.wiktionary.org/wiki/sticky-backed_plastic&#34;&gt;sticky-backed plastic&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/10/simple-agent.excalidraw.png&#34; alt=&#34;A flowchart showing an AI agent workflow. User input flows to a central process that loops between calling an LLM (like GPT-5) and invoking tools (like servers&#34; width=&#34;files&#34; height=&#34;command prompt) until the task is complete. The system is labeled &#34; my-agent.sh&#34;.&#34;=&#34;&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This is a grossly oversimplified example (and is missing elements such as memory)â€”but it hopefully illustrates what weâ€™re building at the core of an Agent.
On top of this goes all the general software engineering requirements of any system that gets built (suitable programming language and framework, error handling, LLM output validation, guard rails, observability, tests, etc etc).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The other nuance that Iâ€™ve noticed is that whilst the above simplistic diagram is 100% driven by an LLM (it decides what tools to call, it decides when to iterate) there are plenty of cases where an Agent is to some degree rules-driven.
So perhaps the LLM does &lt;em&gt;some&lt;/em&gt; of the autonomous work, but then thereâ€™s a bunch of good ol&amp;#39; &lt;code&gt;IFâ€¦ELSEâ€¦&lt;/code&gt; statements in there too.
This is also borne out by the notion of &amp;#34;Workflows&amp;#34; when people talk about Agents.
An Agent doesnâ€™t wake up in the morning and set out on its day serving only to fulfill its own goals and enrichment.
More often than not an Agent is going to be tightly bound into a pre-defined path with a &lt;em&gt;limited&lt;/em&gt; range of autonomy.&lt;/p&gt;
&lt;/div&gt;
&lt;hr/&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;What if you want to &lt;em&gt;actually&lt;/em&gt; build this kind of thing for real?
Thatâ€™s where tools like &lt;a href=&#34;https://www.langchain.com/langgraph&#34;&gt;LangGraph&lt;/a&gt; and &lt;a href=&#34;https://www.langchain.com/langchain&#34;&gt;LangChain&lt;/a&gt; come in.
&lt;a href=&#34;https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-1/agent.ipynb&#34;&gt;Hereâ€™s a notebook&lt;/a&gt; with an example of an actual Agent built with these tools.
&lt;a href=&#34;https://www.llamaindex.ai/llamaindex&#34;&gt;LlamaIndex&lt;/a&gt; is another framework, with details of &lt;a href=&#34;https://developers.llamaindex.ai/python/framework/understanding/agent&#34;&gt;building an Agent&lt;/a&gt; in their docs.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_other_components_of_an_agent&#34;&gt;Other components of an Agent&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;As we build up from the so-simple-it-is-laughable strawman example of an Agent above, one of the features weâ€™ll soon encounter is the concept of memory.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The difference between a crappy response and a holy-shit-thatâ€™s-magic response from an LLM is often down to &lt;em&gt;context&lt;/em&gt;.
The richer the context, the better a chance it has at generating a more accurate output.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;So if an Agent can look back on what it did previously, determining what worked well and what didnâ€™t, perhaps even taking into account human feedback, it can then generate a more successful response the next time.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;You can read a lot more about memory in &lt;a href=&#34;https://docs.google.com/document/d/1asVTObtzIye0I9ypAztaeeI_sr_Hx2TORE02uUuqH_c/edit?tab=t.0#heading=h.v6u4ntwfeghw&#34;&gt;this chapter&lt;/a&gt; of &lt;a href=&#34;https://docs.google.com/document/d/1rsaK53T3Lg5KoGwvf8ukOUvbELRtH-V0LnOIFDxBryE/preview?tab=t.0#heading=h.pxcur8v2qagu&#34;&gt;Agentic Design Patterns&lt;/a&gt; by &lt;a href=&#34;https://www.linkedin.com/in/searchguy/&#34;&gt;Antonio Gulli&lt;/a&gt;.
This blog post from &amp;#34;The BIG DATA guy&amp;#34; is also useful: &lt;a href=&#34;https://thebigdataguy.substack.com/p/agentic-ai-agent-memory-and-context&#34;&gt;Agentic AI, Agent Memory, &amp;amp; Context Engineering&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This diagram from &lt;a href=&#34;https://arxiv.org/pdf/2304.03442&#34;&gt;Generative Agents: Interactive Simulacra of Human Behavior&lt;/a&gt; (J.S. Park, J.C. Oâ€™Brien, C.J. Cai, M.R. Morris, P. Liang, M.S. Bernstein) gives a good overview of a much richer definition of an Agentâ€™s implementation.
The additional concepts include memory (discussed briefly above), planning, and reflection:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/2025-09-16T16-12-50-980Z.png&#34; alt=&#34;2025 09 16T16 12 50 980Z&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Also check out Paul Iusztinâ€™s talk from QCon London 2025 on &lt;a href=&#34;https://www.infoq.com/presentations/llm-data-code-model-prompt/&#34;&gt;The Data Backbone of LLM Systems&lt;/a&gt;.
Around the 35-minute mark he goes into some depth around Agent architectures.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_other_agent_terminology&#34;&gt;Other Agent terminology&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_multi_agent_system_mas&#34;&gt;Multi-Agent System (MAS)&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Just as you can build computer systems as monoliths (everything done in one place) or microservices (multiple programs, each responsible for a discrete operation or domain), you can also have one big Agent trying to do everything (probably not such a good idea) or individual Agents each good at their particular thing that are then hooked together into whatâ€™s known as a Multi-Agent System (MAS).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Sean Falconerâ€™s &lt;a href=&#34;https://seanfalconer.medium.com/building-a-meal-planning-agent-with-apache-kafka-and-apache-flink-254bc5a8d7c5&#34;&gt;family meal planning demo&lt;/a&gt; is a good example of a MAS.
One Agent plans the kids&amp;#39; meals, one the adults&amp;#39; meals, another combines the two into a single plan, and so on.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_human_in_the_loop_hitl&#34;&gt;Human in the Loop (HITL)&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This is a term youâ€™ll come across referring to the fact that Agents might be pretty good, but theyâ€™re not infallible.
In the travel booking example above, do we &lt;em&gt;really&lt;/em&gt; trust the Agent to book the best holiday for us?
Almost certainly weâ€™d wantâ€”at a minimumâ€”the option to sign off on the booking before it goes ahead and sinks Â£10k on an all-inclusive trip to Bognor Regis.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Then again, weâ€™re probably happy enough for an Agent to access our calendars without asking permission, and as to whether they need permission or not to create a meeting is up to us and how much we trust them.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;When it comes to coding, having an Agent write code, test it, fix the broken tests, compare it to a spec, and iterate is really neat.
On the other hand, letting it decide to run &lt;code&gt;rm -rf /&lt;/code&gt;â€¦less so ðŸ˜….&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Every time an Agent requires HITL, it reduces its autonomy and/or responsiveness to situations.
As well as simply using smarter models that make fewer mistakes, there are other things that an Agent can do to reduce the need for HITL such as using guardrails to define acceptable parameters.
For example, an Agent is allowed to book travel but only up to a defined threshold.
That way the user gets to trade off convenience (no HITL) with risk (unintended first-class flight to Hawaii).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_further_reading&#34;&gt;Further reading&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ðŸ“ƒ &lt;a href=&#34;https://arxiv.org/pdf/2304.03442&#34;&gt;Generative Agents: Interactive Simulacra of Human Behavior&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸŽ¥ Paul Iusztin - &lt;a href=&#34;https://www.infoq.com/presentations/llm-data-code-model-prompt/&#34;&gt;The Data Backbone of LLM Systems&lt;/a&gt; - QCon London 2025&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ“– Antonio Gulli - &lt;a href=&#34;https://docs.google.com/document/d/1rsaK53T3Lg5KoGwvf8ukOUvbELRtH-V0LnOIFDxBryE/preview?tab=t.0#&#34;&gt;Agentic Design Patterns&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ“– Sean Falconer - &lt;a href=&#34;https://seanfalconer.medium.com/&#34; class=&#34;bare&#34;&gt;https://seanfalconer.medium.com/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_butthis_guy_is_talking_nonsense&#34;&gt;Butâ€¦this guy is talking nonsense!&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The purpose of this blog series is for me to take notes as I try to build my understanding of this space.
If Iâ€™ve got anything wrong, or am missing some important nuancesâ€”please let me know in the comments below ðŸ˜ ðŸ‘‡&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;footnotes&#34;&gt;
&lt;hr/&gt;
&lt;div class=&#34;footnote&#34; id=&#34;_footnotedef_1&#34;&gt;
&lt;a href=&#34;#_footnoteref_1&#34;&gt;1&lt;/a&gt;. &lt;a href=&#34;https://roundup.getdbt.com/i/169885043/youve-written-about-three-waves-of-ai-can-you-describe-these&#34; class=&#34;bare&#34;&gt;https://roundup.getdbt.com/i/169885043/youve-written-about-three-waves-of-ai-can-you-describe-these&lt;/a&gt;
&lt;/div&gt;
&lt;div class=&#34;footnote&#34; id=&#34;_footnotedef_2&#34;&gt;
&lt;a href=&#34;#_footnoteref_2&#34;&gt;2&lt;/a&gt;. &lt;a href=&#34;https://roundup.getdbt.com/i/169885043/lets-clarify-agents-what-makes-software-truly-agentic&#34; class=&#34;bare&#34;&gt;https://roundup.getdbt.com/i/169885043/lets-clarify-agents-what-makes-software-truly-agentic&lt;/a&gt;
&lt;/div&gt;
&lt;div class=&#34;footnote&#34; id=&#34;_footnotedef_3&#34;&gt;
&lt;a href=&#34;#_footnoteref_3&#34;&gt;3&lt;/a&gt;. &lt;a href=&#34;https://roundup.getdbt.com/i/169885043/is-an-agent-just-a-microservice&#34; class=&#34;bare&#34;&gt;https://roundup.getdbt.com/i/169885043/is-an-agent-just-a-microservice&lt;/a&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
    </item>
    <item>
      <title>Interesting links - September 2025</title>
      <link>https://rmoff.net/2025/09/30/interesting-links-september-2025/</link>
      <pubDate>2025-09-30</pubDate>
      
      <guid>https://rmoff.net/2025/09/30/interesting-links-september-2025/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2025/09/t_IMG_2719.webp" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Sneaking it in &lt;em&gt;just&lt;/em&gt; before the end of the month!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Itâ€™s a bumper set of links this monthâ€”I started with an original backlog of 125 links to get through.
Some fell by the wayside, but plenty of others (78, to be precise) made the cut.
With no further ado, letâ€™s get cracking!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;Not got time for all this? Iâ€™ve marked ðŸ”¥ for my top reads of the month&lt;/em&gt; :)&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_data_engineering_and_architecture&#34;&gt;Data Engineering and Architecture&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Some blog posts donâ€™t need to be long.
This, from Lawrence Kesteloot, is one of them.
&lt;a href=&#34;https://www.teamten.com/lawrence/programming/use-singular-nouns-for-database-table-names.html&#34;&gt;Use singular nouns for database table names&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DuckDB and DuckLake in action in &lt;a href=&#34;https://developyr.medium.com/the-local-lakehouse-how-i-built-a-production-grade-data-platform-on-my-laptop-508a421efbae&#34;&gt;this blog post&lt;/a&gt; from Daniel Wallace&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Simon SpÃ¤ti has published an in-depth &lt;a href=&#34;https://www.ssp.sh/blog/practical-data-modeling-clickhouse/&#34;&gt;Data Modeling Guide for Real-Time Analytics with ClickHouse&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ Itâ€™s all kicked off again in the blogosphere, with Daniel Beach calling out the &lt;a href=&#34;https://www.confessionsofadataguy.com/the-medallion-architecture-farce/&#34;&gt;Medallion Architecture Farce&lt;/a&gt;, before pondering whether the architecture itself is &lt;a href=&#34;https://dataengineeringcentral.substack.com/p/medallion-architecture-truth-or-fiction&#34;&gt;Truth or Fiction?&lt;/a&gt;.
He also took a moment to raise concerns that &lt;a href=&#34;https://www.confessionsofadataguy.com/is-data-modeling-dead/&#34;&gt;data modeling may be dead&lt;/a&gt;.
Ananth Packkildurai posted &lt;a href=&#34;https://www.dataengineeringweekly.com/p/revisiting-medallion-architecture&#34;&gt;a calm and measured analysis&lt;/a&gt; of the architecture, and Joe Reis reminded us that the medallion architecture is &lt;a href=&#34;https://practicaldatamodeling.substack.com/p/medallion-architecture-is-not-a-data&#34;&gt;NOT a Data Model&lt;/a&gt;. Iâ€™ll even chuck in &lt;a href=&#34;https://rmoff.net/2022/10/02/data-engineering-in-2022-architectures-terminology/#_reference_architectures&#34;&gt;my earlier thoughts on it&lt;/a&gt;, in which I draw clear parallels Oracleâ€™s reference architecture back in 2013â€¦ ðŸ˜&lt;/p&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Meanwhile, Robert Anderson &lt;a href=&#34;https://medium.com/@rdo.anderson/the-joke-of-data-vault-generation-1ef8c170ce55&#34;&gt;shared&lt;/a&gt; his scepticism of Data Vault.&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://duckdb.org/2025/09/16/announcing-duckdb-140&#34;&gt;DuckDB 1.4 was released&lt;/a&gt;, and with it the first LTS (Long Term Support) version.
New features include support for writing Apache Iceberg files (see below), &lt;code&gt;MERGE&lt;/code&gt;, and database encryption.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Max Gabrielsson discusses the use of &lt;a href=&#34;https://duckdb.org/2025/08/08/spatial-joins.html&#34;&gt;spatial data in DuckDB&lt;/a&gt; and the improvements made to performance of spatial joins in 1.3.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Getting data from Kafka to Snowflake can be done in several different ways; Emma Amor covers two of them in &lt;a href=&#34;https://medium.com/ml-cheat-sheet/building-a-modern-real-time-data-streaming-architecture-two-paths-from-kafka-to-snowflake-135a2520fbbf&#34;&gt;this blog post&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_ai&#34;&gt;AI&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;admonitionblock note&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td class=&#34;icon&#34;&gt;
&lt;div class=&#34;title&#34;&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&#34;content&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;Wait, whatâ€™s this? A new section this month, all about AI?&lt;/em&gt;
&lt;em&gt;Is Robin now drinking the hype-juice too?&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Donâ€™t worry, this isnâ€™t a rebranding of &lt;code&gt;rmoff.net&lt;/code&gt; to &lt;code&gt;ai-ai-ai-vc-money.plz&lt;/code&gt; (at least not yet).
Whilst Iâ€™ve been an avid user &lt;em&gt;of&lt;/em&gt; AI for some time now (mostly through &lt;a href=&#34;https://rmoff.net/categories/raycast/&#34;&gt;Raycast&lt;/a&gt;&amp;#39;s AI features), Iâ€™ve started to take an interest in understanding it in more detail.
This month I wrote up a few note-taking articles as I learn more about &lt;a href=&#34;https://rmoff.net/2025/09/04/stumbling-into-ai-part-1mcp/&#34;&gt;MCP&lt;/a&gt;, &lt;a href=&#34;https://rmoff.net/2025/09/08/stumbling-into-ai-part-2models/&#34;&gt;Models&lt;/a&gt;, &lt;a href=&#34;https://rmoff.net/2025/09/12/stumbling-into-ai-part-3rag/&#34;&gt;RAG&lt;/a&gt;, and &lt;a href=&#34;https://rmoff.net/2025/09/16/stumbling-into-ai-part-4terminology-tidy-up-and-a-little-rant/&#34;&gt;some general rambling and corrections&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;AI is important, and itâ€™s here to stay.&lt;/strong&gt;
To the nay-sayers who scoff at the errors it makes and laugh at the idea that it can do our jobsâ€¦you are missing the point.
Some of the attitudes Iâ€™ve encountered give me heavy vibes of Oracle DBAs 15 years ago who derided the idea of &amp;#34;The Cloud&amp;#34;.
That came to pass, completely upending how we build thingsâ€”and so will AI.
(Weâ€™ll ignore Blockchain for nowâ€¦not every hype turns into reality ðŸ˜‰).&lt;/p&gt;
&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;ðŸ”¥ Sam Newman &lt;a href=&#34;https://www.linkedin.com/posts/samnewman_to-those-of-you-who-are-deeply-pessimistic-activity-7373683325925900288-gFqC/&#34;&gt;posted an excellent note&lt;/a&gt; on LinkedIn, which begins:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;To those of you who are deeply pessimistic around the use of AI in software delivery, the old quote from John Maynard Keynes comes to mind:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&amp;#34;The market can remain irrational longer than you can remain solvent&amp;#34;.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Go read the rest of the post (itâ€™s not long).
In addition, Scott Wernerâ€™s article ðŸ”¥ &lt;a href=&#34;https://worksonmymachine.ai/p/the-only-skill-that-matters-now&#34;&gt;The Only Skill That Matters Now&lt;/a&gt; puts it even more clearly into focus, with a nice analogy about how &amp;#34;skating to the puck&amp;#34; is no longer a viable strategy (tl;dr the rate of change in AI means you have no idea where the puck will even be).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The impact of AI going to be felt universally.
Here are some interesting articles that Iâ€™ve come across this month about it in the sphere of data:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A paper titled &lt;a href=&#34;https://arxiv.org/pdf/2509.00997&#34;&gt;Supporting Our AI Overlords: Redesigning Data Systems to be Agent-First&lt;/a&gt; discussing the ways in which LLMs want to retrieve data and how we might change how we model data to support that.
Murat Demirbas has a nice &lt;a href=&#34;https://muratbuffalo.blogspot.com/2025/09/supporting-our-ai-overlords-redesigning.html&#34;&gt;analysis and commentary&lt;/a&gt; on the paper.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A summary of a presentation given by Xintong Song on the new &lt;a href=&#34;https://medium.com/@Joannahe/flink-agents-an-event-driven-ai-agent-framework-based-on-apache-flink-45688be46dad&#34;&gt;Flink Agents&lt;/a&gt; project (a formal sub-project of Apache Flink itself)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MCP servers are a nice way to provide standard interoperability between LLMs and other computer systems.
Iâ€™ve not these ones out specifically but the idea of being able to chat to Claude about &lt;a href=&#34;https://github.com/cledar/flink-mcp&#34;&gt;Flink&lt;/a&gt;, &lt;a href=&#34;https://github.com/kanapuli/mcp-kafka&#34;&gt;Kafka&lt;/a&gt;, and &lt;a href=&#34;https://github.com/confluentinc/mcp-confluent&#34;&gt;Confluent Cloud&lt;/a&gt; certainly sounds a cool idea :)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A &lt;a href=&#34;https://www.pedronasc.com/articles/lessons-building-ai-data-analyst&#34;&gt;good account&lt;/a&gt; from Pedro Nascimento of why what sounds like a simple enough idea (&amp;#34;build an AI-powered data analyst&amp;#34;) is a lot more complex than you may think.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_iceberg_and_other_otfdata_lake_stuff&#34;&gt;Iceberg (and other OTF/Data Lake stuff)&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;I mean, there may be some Delta Lake, Hudi, and DuckLake in hereâ€¦but in my corner of the internet itâ€™s Iceberg all the wayâ€¦&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/apache/iceberg/releases/tag/apache-iceberg-1.10.0&#34;&gt;Apache Iceberg 1.10&lt;/a&gt; was released&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DuckDBâ€™s support for writing to Iceberg is covered by &lt;a href=&#34;https://medium.com/@neuw84/iceberg-on-duckdb-end-to-end-example-with-amazon-s3-tables-5506e8537b33&#34;&gt;Angel Conde&lt;/a&gt; and &lt;a href=&#34;https://dwickyferi.medium.com/writing-iceberg-tables-with-duckdb-1-4-0-a-practical-starter-guide-54d6da4c4bce&#34;&gt;Dwicky Feri&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ Anton Borisov has been busy this month, with  a deep-dive on &lt;a href=&#34;https://medium.com/fresha-data-engineering/iceberg-mor-the-hard-way-starrocks-code-dive-fee5e1be66f5&#34;&gt;Icebergâ€™s Merge-on-Read (MoR) support in StarRocks&lt;/a&gt;, along with a practical guide to the evolution and key differences between &lt;a href=&#34;https://medium.com/fresha-data-engineering/how-tables-grew-a-brain-iceberg-hudi-delta-paimon-ducklake-a617f34da6ce&#34;&gt;Iceberg, Delta, Paimon, Delta, and DuckLake&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://duckdb.org/2025/09/17/ducklake-03.html&#34;&gt;DuckLake 0.3&lt;/a&gt; was released, including support for copying to and from Iceberg.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There are several interesting Iceberg performance articles, including a &lt;a href=&#34;https://overcast.blog/11-apache-iceberg-optimization-tools-you-should-know-5b43211aac65&#34;&gt;grab-bag of 11 tools and tips&lt;/a&gt;, discussion from Vincent Daniel of the &lt;a href=&#34;https://medium.com/@vincent_daniel/boost-iceberg-performance-and-cut-compute-costs-with-well-scoped-merge-statements-e0a8f702c321&#34;&gt;&lt;code&gt;MERGE&lt;/code&gt; statement&lt;/a&gt;, and a write-up from Ancestry on their &lt;a href=&#34;https://aws.amazon.com/blogs/big-data/how-ancestry-optimizes-a-100-billion-row-iceberg-table/&#34;&gt;optimisation of a 100-billion row Iceberg table&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;As well as Iceberg optimisation (above), Vincent Daniel also has &lt;a href=&#34;https://medium.com/expedia-group-tech/chill-your-data-with-iceberg-write-audit-publish-746c9eb3db48&#34;&gt;a good blog post&lt;/a&gt; about WAP (Write, Audit, Publish) in Iceberg.
This is something I spent some time looking at &lt;a href=&#34;https://lakefs.io/blog/data-engineering-patterns-write-audit-publish/&#34;&gt;in the past&lt;/a&gt; too, and still think is a good data engineering pattern to draw on.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Jeffrey Jonathan Jennings has a nice hands-on example of deploying a platform of &lt;a href=&#34;https://thej3.com/confluent-trifecta-kafka-flink-iceberg-ae7bf8beb46f&#34;&gt;Kafka, Flink, and Iceberg with Confluent Cloud&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ A thoughtful write-up from Ananth Packkildurai (he of Data Engineering Weekly fame) addressing the challenge of &lt;a href=&#34;https://www.dataengineeringweekly.com/p/when-dimensions-change-too-fast-for?publication_id=73271&amp;amp;post_id=173724688&amp;amp;isFreemail=true&amp;amp;r=3b0y7&amp;amp;triedRedirect=true&#34;&gt;Fast Changing Dimensions (FCD)&lt;/a&gt; in Iceberg, and examining some alternative architectures and technologies.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ A well-written and spicy take from WarpStreamâ€™s Richie Artoul on &lt;a href=&#34;https://www.warpstream.com/blog/the-case-for-an-iceberg-native-database-why-spark-jobs-and-zero-copy-kafka-wont-cut-it&#34;&gt;getting data from Kafka into Iceberg&lt;/a&gt; and where he sees some of the proposals from the community as flawed.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;On the admin side of things, Nimtableâ€™s &lt;a href=&#34;https://github.com/nimtable/iceberg-compaction&#34;&gt;compaction runtime&lt;/a&gt; for Iceberg has been released (open source/Apache 2.0), and Apache Amoro claim &lt;a href=&#34;https://medium.com/@jinsong.zhou1990/10x-efficiency-boost-compared-to-spark-rewritefiles-procedure-how-apache-amoro-efficiently-7e7a993950d7&#34;&gt;10x performance improvements&lt;/a&gt; from their table maintenance feature.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The Iceberg community is thriving and growing, and you can find talks from several recent meetups in Europe &lt;a href=&#34;https://www.youtube.com/playlist?list=PL3IALGSANhzUjNrcpEZUcXYbFe-YIEua2&#34;&gt;online here&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_kafka_and_event_streaming&#34;&gt;Kafka and Event Streaming&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://kafka.apache.org/blog#apache_kafka_410_release_announcement&#34;&gt;Apache Kafka 4.1 was released&lt;/a&gt;.
Sandon Jacobs has a useful summary of the key &lt;a href=&#34;https://thenewstack.io/apache-kafka-4-1-the-3-big-things-developers-need-to-know/&#34;&gt;new features&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Shruti Mantri has &lt;a href=&#34;https://medium.com/@shruti1810/queues-for-apache-kafka-a-detailed-overview-a11c15d994d3&#34;&gt;a good article&lt;/a&gt; about Queues for Apache Kafka.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ A few nice bits from Stanislav Kozlovski this month, with a deep-dive on &lt;a href=&#34;https://newsletter.systemdesign.one/p/how-kafka-works&#34;&gt;How Kafka Works&lt;/a&gt;, an infographic of the &lt;a href=&#34;https://www.reddit.com/r/apachekafka/comments/1mzs6lt/top_5_largest_kafka_deployments/&#34;&gt;Top 5 largest Kafka deployments&lt;/a&gt;, and advice on &lt;a href=&#34;https://getkafkanated.substack.com/p/how-to-size-your-kafka-tiered-storage-cluster&#34;&gt;sizing a Kafka cluster thatâ€™s using tiered storage&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Aleksei Aleinikov writes about &lt;a href=&#34;https://blog.dataengineerthings.org/kafka-at-scale-why-acls-fail-and-roles-win-in-2025-3a384c7f3704&#34;&gt;why and how you should do authorisation with roles in Kafka&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ A nice deep-dive &lt;a href=&#34;https://blog.evacchi.dev/posts/2025/08/25/extending-kafka-the-hard-way-part-1/&#34;&gt;two&lt;/a&gt; &lt;a href=&#34;https://blog.evacchi.dev/posts/2025/09/03/extending-kafka-the-hard-way-part-2/&#34;&gt;part&lt;/a&gt; series from Edoardo Vacchi looking at extending the Kafka broker&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;PagerDuty had an outage last month, at the heart of which was Kafka and an error in the implementation of an application using it.
Read the gory details &lt;a href=&#34;https://www.pagerduty.com/eng/august-28-kafka-outages-what-happened-and-how-were-improving/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Klaviyo migrated from RabbitMQ to Kafka - read about &lt;a href=&#34;https://klaviyo.tech/rebuilding-event-infrastructure-at-scale-bebfe764bd8f&#34;&gt;why and how&lt;/a&gt; and &lt;a href=&#34;https://klaviyo.tech/building-a-distributed-priority-queue-in-kafka-1b2d8063649e&#34;&gt;impact&lt;/a&gt; in these two blog posts.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&amp;#34;&lt;em&gt;Does Kafka Guarantee Message Delivery?&lt;/em&gt;&amp;#34; is a question that prompted &lt;a href=&#34;https://levelup.gitconnected.com/does-kafka-guarantee-message-delivery-dedbcb44971c&#34;&gt;this blog post&lt;/a&gt; and some &lt;a href=&#34;https://old.reddit.com/r/apachekafka/comments/1ne40fi/does_kafka_guarantee_message_delivery/&#34;&gt;discussion over on r/apachekafka&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Jaehyeon Kim built a custom SMT (Single Message Transform) for &lt;a href=&#34;https://old.reddit.com/r/apachekafka/comments/1napcme/i_built_a_custom_smt_to_get_automatic_openlineage/&#34;&gt;Kafka Connect to add observability&lt;/a&gt; into a pipeline.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_stream_processing&#34;&gt;Stream Processing&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://flink.apache.org/2025/09/26/apache-flink-cdc-3.5.0-release-announcement/&#34;&gt;Flink CDC 3.5 has been released&lt;/a&gt;, which includes new pipeline connectors for Apache Fluss and Postgres&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Lorenzo Nicora and Felix John published a &lt;a href=&#34;https://aws.amazon.com/blogs/big-data/part-1-deep-dive-into-the-amazon-managed-service-for-apache-fink-application-lifecycle/&#34;&gt;two&lt;/a&gt; &lt;a href=&#34;https://aws.amazon.com/blogs/big-data/part-2-deep-dive-into-the-amazon-managed-service-for-apache-fink-application-lifecycle/&#34;&gt;part&lt;/a&gt; blog series on application lifecycle when using Amazonâ€™s Managed service for Flink (MSF).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Jack Vanlightly published one of his fantastic deep-dives, this time looking in great detail at &lt;a href=&#34;https://jack-vanlightly.com/blog/2025/9/2/understanding-apache-fluss&#34;&gt;Apache Fluss&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ &lt;a href=&#34;https://medium.com/fresha-data-engineering/what-the-fuss-with-fluss-flink-delta-force-1ab3d6be5c98&#34;&gt;Anton Borisov writes&lt;/a&gt; about Fluss, comparing it in use with Flink 2.1â€™s DeltaJoin feature to standalone solutions from RisingWave and Feldera&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A nice little &lt;a href=&#34;https://github.com/gordonmurray/apache_fluss_flink_and_paimon&#34;&gt;GitHub repo from Gordon Murray&lt;/a&gt; in which he shows how to get up and running with Fluss, Paimon, and Flink.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;An example application from Sebastien Viale showing how to &lt;a href=&#34;https://github.com/michelin/kafka-streams-ensure-explicit-resource-naming&#34;&gt;ensure Kafka Streams uses explicit resource naming&lt;/a&gt; (added in Kafka 4.1 with KIP-1111)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Details from a talk by Yuan Mei about &lt;a href=&#34;https://www.alibabacloud.com/blog/flink-state-management-a-journey-from-core-primitives-to-next-generation-incremental-computation_602503&#34;&gt;Flink state management&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_general_data_stuff&#34;&gt;General Data Stuff&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ A thorough history and &lt;a href=&#34;https://timodechau.com/the-end-of-digital-analytics/&#34;&gt;analysis of digital analytics&lt;/a&gt; from Timo Dechau, covering Google Analytics, GA4, and more, up to the current state of affairs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Andrew Lamb writes about &lt;a href=&#34;https://datafusion.apache.org/blog/2025/08/15/external-parquet-indexes/&#34;&gt;performance improvements&lt;/a&gt; when working with Parquet files.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cloudflare &lt;a href=&#34;https://blog.cloudflare.com/cloudflare-data-platform/&#34;&gt;announced&lt;/a&gt; their Data Platform, including the Arroyo-acquisition driven Cloudflare Pipelines, R2 Data Catalog, and a distributed SQL engine called &lt;a href=&#34;https://blog.cloudflare.com/r2-sql-deep-dive/&#34;&gt;R2 SQL&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;InfoQ published their &lt;a href=&#34;https://www.infoq.com/articles/ai-ml-data-engineering-trends-2025/&#34;&gt;AI, ML and Data Engineering Trends Report&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/DavidLiedle/DriftDB&#34;&gt;DriftDB&lt;/a&gt; is an &amp;#34;experimental append-only database with built-in time travel&amp;#34;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Avinash Sajjanshetty muses on &lt;a href=&#34;https://avi.im/blag/2025/db-cache/&#34;&gt;replacing a cache service with a database&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.postgresql.org/about/news/postgresql-18-released-3142/&#34;&gt;Postgres 18 was released&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Postgres 18 adds the ability to &lt;a href=&#34;https://www.crunchydata.com/blog/postgres-18-old-and-new-in-the-returning-clause&#34;&gt;get current and previous row values&lt;/a&gt; in the &lt;code&gt;RETURNING&lt;/code&gt; clause which sounds neat.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/xataio/pgstream&#34;&gt;pgstream&lt;/a&gt; is an Apache 2.0 licensed project from Xata that offers Postgres replication to targets including &lt;a href=&#34;https://github.com/xataio/pgstream/blob/main/docs/tutorials/postgres_kafka.md&#34;&gt;Kafka&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ Good &lt;a href=&#34;https://redmonk.com/sogrady/2025/09/02/documentdb/&#34;&gt;analysis&lt;/a&gt; from RedMonkâ€™s Stephen Oâ€™Grady on the open-source data storage space, including Postgres vs MySQL, MongoDB, and DocumentDB.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_data_in_action&#34;&gt;Data in Action&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Details of how &lt;a href=&#34;https://netflixtechblog.com/building-a-resilient-data-platform-with-write-ahead-log-at-netflix-127b6712359a&#34;&gt;Netflix&lt;/a&gt; built a Write-Ahead-Log (WAL) to make their data platform more resilient.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cursor &lt;a href=&#34;https://xcancel.com/vmg/status/1961481692817813538&#34;&gt;migrated&lt;/a&gt; from AWS Aurora Limitless to PlanetScale.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Wix saved 50% of their data platform costs by moving their Spark workloads from EMR to EMR on EKSâ€”they cover why and how in this &lt;a href=&#34;https://www.wix.engineering/post/how-wix-slashed-spark-costs-by-60-and-migrated-5-000-daily-workflows-from-emr-to-emr-on-eks&#34;&gt;two&lt;/a&gt; &lt;a href=&#34;https://www.wix.engineering/post/how-wix-cut-50-of-its-data-platform-costs-without-sacrificing-performance-part-2&#34;&gt;part&lt;/a&gt; series.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://medium.com/blablacar/scaling-success-the-dbt-ecosystem-at-blablacar-c214c4b8f0cb&#34;&gt;dbt in action&lt;/a&gt; at BlaBlaCar.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ Netflix built their &lt;a href=&#34;https://netflixtechblog.com/scaling-muse-how-netflix-powers-data-driven-creative-insights-at-trillion-row-scale-aa9ad326fd77&#34;&gt;Muse analytics platform&lt;/a&gt; originally on Druid with offline Spark, but in order to meet performance requirements moved to using their homegrown &lt;a href=&#34;https://hollow.how/&#34;&gt;Hollow&lt;/a&gt; tool for pre-aggregating data, along with Druid still plus Spark and Iceberg offline.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Some details of the data architecture at &lt;a href=&#34;https://pola.rs/posts/case-decathlon/&#34;&gt;Decathlon&lt;/a&gt;, and how they use Polars.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;How &lt;a href=&#34;https://stripe.com/blog/how-we-built-it-real-time-analytics-for-stripe-billing&#34;&gt;Stripe&lt;/a&gt; use Apache Flink for real-time analytics.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Details of how &lt;a href=&#34;https://www.uber.com/en-GB/blog/building-ubers-data-lake-batch-data-replication-using-hivesync/&#34;&gt;Uber&lt;/a&gt; replicate between their two HDFS-based datalakes using HiveSync.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ A nice under-the-covers look at &lt;a href=&#34;https://medium.com/fresha-data-engineering/data-lakehouse-infrastructure-218d1c0776aa&#34;&gt;Freshaâ€™s data lakehouse architecture&lt;/a&gt; from Paritosh Anand.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Chick-fil-Aâ€™s Caleb Lampert describes their &lt;a href=&#34;https://medium.com/chick-fil-atech/data-asset-certification-how-soup-can-inspire-us-to-steward-our-data-better-4d1812b0b128&#34;&gt;Data Asset Certification Framework&lt;/a&gt; (and its relationship to soupâ€¦)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Airbnb built their own K/V store called Musselâ€”read about the &lt;a href=&#34;https://medium.com/airbnb-engineering/mussel-airbnbs-key-value-store-for-derived-data-406b9fa1b296&#34;&gt;original V1&lt;/a&gt; and the &lt;a href=&#34;https://medium.com/airbnb-engineering/building-a-next-generation-key-value-store-at-airbnb-0de8465ba354&#34;&gt;re-architected V2&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Metagenomi write about &lt;a href=&#34;https://aws.amazon.com/blogs/architecture/a-scalable-elastic-database-and-search-solution-for-1b-vectors-built-on-lancedb-and-amazon-s3/&#34;&gt;how they use LanceDB on S3&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A &lt;a href=&#34;https://www.databricks.com/blog/databricks-databricks-scaling-database-reliability&#34;&gt;write-up&lt;/a&gt; of &lt;a href=&#34;https://www.usenix.org/conference/srecon25americas/presentation/jiang&#34;&gt;a talk&lt;/a&gt; given by Xiaotong Jiang from Databricks on how they approach OLTP database performance and optimisation in a multi-tenant architecture.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Details of &lt;a href=&#34;https://blog.developer.bazaarvoice.com/2025/08/25/how-we-migrated-millions-of-ugc-records-to-aurora-mysql/&#34;&gt;how Bazaarvoice migrated&lt;/a&gt; from RDS MySQL to AWS Aurora.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ A deep-dive on &lt;a href=&#34;https://www.infoq.com/presentations/scale-embedded-database/&#34;&gt;how Motherduck is built&lt;/a&gt; by Stephanie Wang (previously a founding engineer at Motherduck).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Practical tips from Sadeq Dousti at Trade Republic on the &lt;a href=&#34;https://engineering.traderepublic.com/postgresql-outbox-pattern-revamped-part-1-90827bc395f4&#34;&gt;implementation of the outbox pattern&lt;/a&gt;, based on their experiences.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;How Grab use Pinot (and Kafka and Flink) for &lt;a href=&#34;https://engineering.grab.com/pinot-partnergateway-tech-blog&#34;&gt;low-latency analytics&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_newsletters&#34;&gt;Newsletters&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;If you canâ€™t wait for this monthly round-up of links, you might like the following:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.dataengineeringweekly.com/&#34;&gt;Ananth Packkildurai - Data Engineering Weekly&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://tldr.tech/signup?rh_ref=2a491949&amp;amp;sl_campaign=MF39827fc26915&#34;&gt;TLDR&lt;/a&gt; (thereâ€™s a general tech edition, plus additional specialist ones for data, AI, etc)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.beachgeek.co.uk/tags/oss-newsletter/&#34;&gt;Ricardo Sueiras - AWS open source newsletter&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_and_finally&#34;&gt;And finallyâ€¦&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;Nothing to do with data, but stuff that Iâ€™ve found interesting or has made me smile.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ Kirill Bobrov - &lt;a href=&#34;https://blog.dataengineerthings.org/how-the-community-turned-into-a-saas-commercial-82a58778e816&#34;&gt;How the Community Turned Into a SaaS Commercial&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;TIL: &lt;a href=&#34;https://daniel.lawrence.lu/blog/y2025m09d21/&#34;&gt;Line Scan Cameras&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ &lt;a href=&#34;https://anniemueller.com/posts/how-i-a-non-developer-read-the-tutorial-you-a-developer-wrote-for-me-a-beginner#fn:3&#34;&gt;How I, a non-developer, read the tutorial you, a developer, wrote for me, a beginner&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://thegrowtheq.com/where-have-all-the-serious-people-gone/&#34;&gt;Where Have All the Serious People Gone?&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.theguardian.com/money/2025/sep/04/calling-your-boss-a-dickhead-is-not-a-sackable-offence-tribunal-rules&#34;&gt;Calling boss a dickhead was not a sackable offence, tribunal rules&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://bigboxcollection.com/&#34;&gt;Nostalgia blast&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.noemamag.com/the-last-days-of-social-media/&#34;&gt;The Last Days Of Social Media&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://bogdanthegeek.github.io/blog/projects/vapeserver/&#34;&gt;Hosting a WebSite on a Disposable Vape&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.asciinema.org/post/three-point-o/&#34;&gt;asciinema 3.0 released&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Dayvi Schuster - &lt;a href=&#34;https://dayvster.com/blog/dev-culture-is-dying-the-curious-developer-is-gone/&#34;&gt;Dev Culture Is Dying The Curious Developer Is Gone&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;hr/&gt;
&lt;div class=&#34;admonitionblock note&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td class=&#34;icon&#34;&gt;
&lt;div class=&#34;title&#34;&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&#34;content&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If you like these kind of links you might like to read about &lt;a href=&#34;https://rmoff.net/2024/05/22/how-i-try-to-keep-up-with-the-data-tech-world-a-list-of-data-blogs/&#34;&gt;How I Try To Keep Up With The Data Tech World (A List of Data Blogs)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
    </item>
    <item>
      <title>Stumbling into AI: Part 4â€”Terminology Tidy-up (and a little rant)</title>
      <link>https://rmoff.net/2025/09/16/stumbling-into-ai-part-4terminology-tidy-up-and-a-little-rant/</link>
      <pubDate>2025-09-16</pubDate>
      
      <guid>https://rmoff.net/2025/09/16/stumbling-into-ai-part-4terminology-tidy-up-and-a-little-rant/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2025/09/t_IMG_2251.webp" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Having looked at &lt;a href=&#34;https://rmoff.net/2025/09/04/stumbling-into-ai-part-1mcp/&#34;&gt;MCP&lt;/a&gt;, &lt;a href=&#34;https://rmoff.net/2025/09/08/stumbling-into-ai-part-2models/&#34;&gt;Models&lt;/a&gt;, and &lt;a href=&#34;https://rmoff.net/2025/09/12/stumbling-into-ai-part-3rag/&#34;&gt;RAG&lt;/a&gt;, I realised that Iâ€™ve been mentally skirting around something that I donâ€™t really understand, so Iâ€™m going to expose myself to some ridicule here and try to understand better: whatâ€™s the difference between AI and ML? Arenâ€™t they just the same?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_whats_the_difference_between_ai_and_ml&#34;&gt;Whatâ€™s the difference between AI and ML?&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;OK weâ€™re doing this are we?&lt;/em&gt;
&lt;em&gt;I thought AI was just âœ¨magicâœ¨?&lt;/em&gt;
&lt;em&gt;And ML was the thing that got data scientists mad stacks ten years ago before everyone realised you couldnâ€™t do shit without good data and processes?&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;To me, a layperson in this space, watching it from the sidelines, AI and ML have been interchangeable.
In fact, youâ€™d get conferences and conference tracks titled &amp;#34;AI/ML&amp;#34;â€”because &lt;em&gt;itâ€™s all kind of the same thing anyway, right?&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This is, of course, factually incorrect and presumably infuriating to anyone actually working in the field.
The whole purpose of this blog series has been for me to at least reduce the number of &lt;a href=&#34;https://en.wikipedia.org/wiki/There_are_unknown_unknowns&#34;&gt;&lt;em&gt;unknown unknowns&lt;/em&gt;&lt;/a&gt; in my knowledge in this spaceâ€”to build up a mental map of the different areas and terms so that I at least I know where to go and look when encountering something that I know I donâ€™t know.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;With that framing in mind, this is roughly how I understand the terms &lt;code&gt;AI&lt;/code&gt; and &lt;code&gt;ML&lt;/code&gt;:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Artificial Intelligence (AI) in its vernacular understanding in 2025 basically refers to using models (such as LLMs) that generate new output, often coupled with &lt;a href=&#34;https://rmoff.net/2025/09/12/stumbling-into-ai-part-3rag/&#34;&gt;RAG&lt;/a&gt; and/or &lt;a href=&#34;https://rmoff.net/2025/09/04/stumbling-into-ai-part-1mcp/&#34;&gt;MCP&lt;/a&gt;, giving the semblance of &amp;#34;intelligence&amp;#34;.
So far as Iâ€™m concerned, &lt;strong&gt;this is the wrong definition to associate with AI&lt;/strong&gt;, but itâ€™s driven by something new that companies can use as a marketing angle.&lt;/p&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;AI is a lot more than this&lt;/strong&gt;â€”this is why the term &amp;#34;GenAI&amp;#34; or &amp;#34;Generative AI&amp;#34; is used; to differentiate AI as has been done for many years from that enabled by foundational models such as LLMs.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;A lot of AI &lt;em&gt;isnâ€™t&lt;/em&gt; generative.
Some AI is deterministic, some of it isnâ€™t.
AI includes spam filtering, image recognition, recommendation engines (how &lt;em&gt;does&lt;/em&gt; YouTube always know to show &lt;em&gt;that&lt;/em&gt; video?), traffic-aware GPS navigation, and lots more.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;AI is not new; it goes back decades.
Sometimes AI is simply a list of &lt;code&gt;IF â€¦ ELSEIF â€¦ ELSEIF â€¦&lt;/code&gt; statements to give the semblance of autonomous intelligence when actually a human had hard-coded the rules
(the posh name for this is &lt;a href=&#34;https://en.wikipedia.org/wiki/Expert_system&#34;&gt;&lt;em&gt;Expert Systems&lt;/em&gt;&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Machine Learning (ML) is the discipline of training (and I use this as a broad term, to also include fine-tuning, reinforcement learning, etc) models using data.
The models are what are then used in AI, through a process called &lt;em&gt;inference&lt;/em&gt;.&lt;/p&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;These ML models include foundational ones like LLMs used for generating text, but this is just one subset of them.
Other uses of different model types include clustering, classification, anomaly detection, sentiment analysis, and prediction.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;ML includes terms like &lt;em&gt;supervised learning&lt;/em&gt;, &lt;em&gt;unsupervised learning&lt;/em&gt;, and &lt;em&gt;reinforcement learning&lt;/em&gt;.
It is also where the cool stuff like neural networks and deep learning fits too (&lt;em&gt;I am aware how casually I am inserting a whole swathe of academic research here; this is just my mental bracketing exercise, feel free to flame me in the comments below&lt;/em&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_my_godits_full_of_marketing_bs_but_that_doesnt_make_it_untrue&#34;&gt;My Godâ€¦itâ€™s full of marketing BS (but that doesnâ€™t make it untrue)&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Just like Cloud and Blockchain were previously, AI has become a lightning rod for every manner of ridiculous marketing claim and overinflated startup valuation.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Just like Cloud, at the heart of AI is a fundamentally &lt;em&gt;new and important&lt;/em&gt; technological paradigm (JFC did I just write that un-ironically?), but at which itâ€™s hard to get for the clamour of snake-oil salesmen around it promising the moon on a stick.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;Just like Cloud, itâ€™s a fool who dismisses AI as a fad.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Just like Cloud, itâ€™s a reasonable person who wants to take a step back and understand what the all the fuss is &lt;em&gt;actually&lt;/em&gt; about.
And thatâ€™s what Iâ€™m trying my best to do in &lt;a href=&#34;https://rmoff.net/categories/stumbling-into-ai/&#34;&gt;this series of blog posts&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;admonitionblock tip&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td class=&#34;icon&#34;&gt;
&lt;i class=&#34;fa icon-tip&#34; title=&#34;Tip&#34;&gt;&lt;/i&gt;
&lt;/td&gt;
&lt;td class=&#34;content&#34;&gt;
If you spotted the omission of Blockchain in the subsequent statements above, that is not an error ðŸ˜‰
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_dont_just_take_my_word_for_it&#34;&gt;Donâ€™t just take my word for it&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Sam Newman &lt;a href=&#34;https://www.linkedin.com/posts/samnewman_to-those-of-you-who-are-deeply-pessimistic-activity-7373683325925900288-gFqC/&#34;&gt;posted an excellent note&lt;/a&gt; on LinkedIn, which begins:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;To those of you who are deeply pessimistic around the use of AI in software delivery, the old quote from John Maynard Keynes comes to mind:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&amp;#34;The market can remain irrational longer than you can remain solvent&amp;#34;.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Go read the rest of the post (itâ€™s not long).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In addition, Scott Wernerâ€™s article ðŸ”¥ &lt;a href=&#34;https://worksonmymachine.ai/p/the-only-skill-that-matters-now&#34;&gt;The Only Skill That Matters Now&lt;/a&gt; puts it even more clearly into focus, with a nice analogy about how &amp;#34;skating to the puck&amp;#34; is no longer a viable strategy (tl;dr the rate of change in AI means you have no idea where the puck will even be).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
    </item>
    <item>
      <title>Stumbling into AI: Part 3â€”RAG</title>
      <link>https://rmoff.net/2025/09/12/stumbling-into-ai-part-3rag/</link>
      <pubDate>2025-09-12</pubDate>
      
      <guid>https://rmoff.net/2025/09/12/stumbling-into-ai-part-3rag/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2025/09/t_IMG_2311.webp" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;A &lt;a href=&#34;https://rmoff.net/categories/stumbling-into-ai&#34;&gt;short series&lt;/a&gt; of notes for myself as I learn more about the AI ecosystem as of September 2025.&lt;/em&gt;
&lt;em&gt;The driver for all this is understanding more about Apache Flinkâ€™s &lt;a href=&#34;https://github.com/apache/flink-agents&#34;&gt;&lt;strong&gt;Flink Agents&lt;/strong&gt;&lt;/a&gt; project, and Confluentâ€™s &lt;a href=&#34;https://www.confluent.io/product/streaming-agents/&#34;&gt;&lt;strong&gt;Streaming Agents&lt;/strong&gt;&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Having &lt;a href=&#34;https://rmoff.net/2025/09/04/stumbling-into-ai-part-1mcp/&#34;&gt;poked around MCP&lt;/a&gt; and &lt;a href=&#34;https://rmoff.net/2025/09/08/stumbling-into-ai-part-2models/&#34;&gt;Models&lt;/a&gt;, next up is RAG.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;RAG has been one of the buzzwords of the last couple of years, with any vendor worth its salt finding a way to crowbar it into their product.
Iâ€™d been sufficiently put off it by the hype to steer away from actually understanding what it is.
In this blog post, letâ€™s fix thatâ€”because if Iâ€™ve understood it correctly, itâ€™s a pattern thatâ€™s not scary at all.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_rag_basics&#34;&gt;RAG basics&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;First up: RAG stands for &lt;strong&gt;Retrieval-Augmented Generation&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Put another way, itâ€™s about &lt;strong&gt;Generation&lt;/strong&gt; (using LLMs, like we saw &lt;a href=&#34;https://rmoff.net/2025/09/08/stumbling-into-ai-part-2models/&#34;&gt;before&lt;/a&gt; and like you use every day), in which the prompt given to the LLM is &lt;strong&gt;Augmented&lt;/strong&gt; by the &lt;strong&gt;Retrieval&lt;/strong&gt; of additional context.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;It is literally the difference between this prompt &amp;amp; response from an LLM:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Respond to this prompt: whatâ€™s the latest version of kafka?&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Apache Kafka 3.7 (released on May 12, 2023)&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;and this one:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;Using this data: The latest version of Apache Kafka is 4.1&lt;/strong&gt;. Respond to this prompt: whatâ€™s the latest version of kafka?&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The latest version of Apache Kafka is 4.1.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The second exampleâ€™s &lt;strong&gt;generation&lt;/strong&gt; has been &lt;strong&gt;augmented&lt;/strong&gt; by the &lt;strong&gt;retrieval&lt;/strong&gt; of additional information thatâ€™s then added to the prompt prior to submission to the LLM.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This may seem stupidâ€”why would I tell the LLM the latest version, and then ask it the latest version?
But itâ€™s not me asking!
In a typical interaction youâ€™ll have the end-user entering a prompt, and the prompt given to the LLM will be the userâ€™s question, plus context (information) added by some kind of lookup.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/rag1.webp&#34; alt=&#34;rag1&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The LLM uses the additional context in order to provide an answer that is much more likely to be accurate, avoiding the issue of hallucinations (when LLMs make shit up) or simply out of date information (on which the LLM was trained; itâ€™s not their fault really).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/rag4.webp&#34; alt=&#34;rag4&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;admonitionblock tip&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td class=&#34;icon&#34;&gt;
&lt;i class=&#34;fa icon-tip&#34; title=&#34;Tip&#34;&gt;&lt;/i&gt;
&lt;/td&gt;
&lt;td class=&#34;content&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;If you like videos, I really liked this video from IBMâ€™s Marina Danilevsky that explains the concept.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;She uses the analogy of her kid asking her which planet has the most moons, and the fact that her &amp;#34;training dataset&amp;#34; was from several decades ago, and discoveries have been made since then that could render her answer, given in good faith, incorrect.
The RAG bit of the analogy is that she would go and check the latest datasource from somewhere like NASA before giving the answer to her child.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/T-D1OfcDW1M&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;So far, so simple, really.
RAG==a fancy way for giving LLMs more context with which to hopefully give you a better answer.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The Kafka version number example is somewhat trite and could be picked apart in multiple ways.
Why do I need an LLM to tell me that? Why canâ€™t I just go to the datasource that gave the additional context to the prompt myself?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The point with RAG is that youâ€™re still wanting an LLM to do its thingâ€”but to do so either with much greater accuracy (e.g. Kafka version), or in a way that it simply couldnâ€™t do without the additional context.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;RAGs really come into their own for &lt;strong&gt;enriching&lt;/strong&gt; the behaviour of LLMs with data, often thatâ€™s held within our business.
As a customer, we all expect companies to know &amp;#34;everything&amp;#34; about us, right?
After all, we completely the forms, we checked the boxesâ€”why are you asking me to type in a bunch of data that you already know?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Hereâ€™s a simple example of this concept.
Imagine we want to know where &lt;em&gt;our&lt;/em&gt; nearest airport is?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;Yes yes, we could just open Google Maps, but hear me out.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;If we ask an LLM this, itâ€™s not got a clueâ€”it has no &lt;em&gt;context&lt;/em&gt;:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Where is Rickâ€™s nearest airport? Single answer only.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Iâ€™m not aware of any information about Rick, so Iâ€™ll need more context or details about who or what &amp;#34;Rick&amp;#34; refers to.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Whereas if we already hold information about our customer &amp;#39;Rick&amp;#39;, we can look that information up and pass it to the LLM:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Using this data: &lt;strong&gt;Rick lives in Dulwich.&lt;/strong&gt; Respond to this prompt: Where is Rickâ€™s nearest airport? Single answer only.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;London Gatwick Airport (LGW)&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/rag3.webp&#34; alt=&#34;rag3&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_embeddings_and_vectors&#34;&gt;Embeddings and Vectors&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;So how do we get this additional context?
Or rather, how do we do the &lt;strong&gt;Retrieval&lt;/strong&gt; of data with which we can &lt;strong&gt;Augment&lt;/strong&gt; our &lt;strong&gt;Generation&lt;/strong&gt;?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Well, you could literally run a SQL query, as illustrated above.
You could have your client make API calls to get data, you could even use an &lt;a href=&#34;https://rmoff.net/2025/09/04/stumbling-into-ai-part-1mcp/&#34;&gt;MCP server&lt;/a&gt;â€”the end result is the same: the LLM is getting additional context to help it do what you want it to do.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;One common pattern for the implementation of RAG is the use of vector databases.
In fact, so common I would say itâ€™s become synonymous.
The reason that itâ€™s so widely used is that whilst a SQL lookup is excellent for working with &lt;em&gt;structured&lt;/em&gt; data (e.g. &amp;#34;where does my customer live&amp;#34;), thatâ€™s often not the kind of additional context that we want to provide to the LLM.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;What if weâ€™re working with &lt;em&gt;text&lt;/em&gt;?
Whilst LLMs are trained on a metric crap-ton of publicly available text, thereâ€™s material out there that they donâ€™t know about.
That could be content that was created after the LLM was trained (for example, the release notes for the latest version of Apache Kafka).
Often, in the context of RAG, itâ€™s material internal to a company such as documentation, wikis, emails, Slack conversationsâ€¦any manner of content.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;To use this text data in RAG, a representation (&amp;#34;&lt;em&gt;embedding&lt;/em&gt;&amp;#34;) of the &lt;em&gt;semantic meaning&lt;/em&gt; of the text is created, and stored as a &lt;em&gt;vector&lt;/em&gt;.
This is the &lt;em&gt;RAG Ingestion&lt;/em&gt; part.
Once the data is stored, it can be used in &lt;em&gt;RAG Retrieval&lt;/em&gt;.
What this does is take the userâ€™s query and convert that to an embedding too.
It then compares the queryâ€™s vector with those held in the vector store (populated by the ingest process) and finds the piece of textual data (&amp;#34;embedding&amp;#34;) thatâ€™s most closely related to it.
This piece of additional information is then included in the LLM request, in exactly the same manner we saw aboveâ€”adding context to the existing prompt.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The &lt;a href=&#34;https://ollama.com/blog/embedding-models&#34;&gt;Ollama blog&lt;/a&gt; has a nice example which Iâ€™m going to use here, demonstrating the Kafka version example I showed above.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_rag_ingestion_populating_a_vector_database_with_embeddings&#34;&gt;RAG Ingestion: Populating a vector database with embeddings&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;First, set up the environment.
Weâ€™re using &lt;a href=&#34;https://docs.trychroma.com/&#34;&gt;ChromaDB&lt;/a&gt; as an in-memory vector store.
&lt;a href=&#34;https://ollama.com/&#34;&gt;Ollama&lt;/a&gt; is a tool for running models locally.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;ollama&lt;/span&gt;
&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;chromadb&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;client&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;chromadb&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;Client&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;()&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;collection&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;client&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;create_collection&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;docs&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Now we define our &amp;#39;documents&amp;#39;.
This is a very simplified example.
In practice we could be ingesting entire wikis or codebases of information.
The vital bit is how we carve it up, which is known as &lt;em&gt;chunking&lt;/em&gt;.
A &lt;em&gt;chunk&lt;/em&gt; is what will get passed to the LLM for enriching the context, so it needs to be big enough to be useful, but not so big that it is unhelpful (e.g. blows the token limit on the LLM, provides context that is not specific enough, etc).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Here Iâ€™ve manually pasted excerpts of the &lt;a href=&#34;https://kafka.apache.org/blog&#34;&gt;Apache Kafka 4.1.0 release blog post&lt;/a&gt; (Iâ€™ve cropped the text in the code sample here, just for clarity of layout):&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;documents&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;[&lt;/span&gt;
  &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;4 September 2025 - We are proud to announce the release of Apache KafkaÂ® 4.1.0. This release contai[â€¦]&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;
  &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;KIP-877: Mechanism for plugins and connectors to register metrics Many client-side plugins can now [â€¦]&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;
  &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;KIP-932: Queues for Kafka (Early Access) This KIP introduces the concept of a share group as a way [â€¦]&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;
  &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;KIP-996: Pre-Vote KIP-996 introduces a &amp;#39;Pre-Vote&amp;#39; mechanism to reduce unnecessary KRaft leader elec[â€¦]&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;For each of these documents we call an &lt;em&gt;embedding model&lt;/em&gt; (which is &lt;strong&gt;not&lt;/strong&gt; an LLM!) which captures the semantic meaning of the text and encodes it in a series of vectors which are added to the ChromaDB &lt;code&gt;collection&lt;/code&gt;:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;i&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;d&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;enumerate&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;documents&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;):&lt;/span&gt;
  &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;response&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;ollama&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;embed&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;model&lt;/span&gt;&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;mxbai-embed-large&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;input&lt;/span&gt;&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;d&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;)&lt;/span&gt;
  &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;embeddings&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;response&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;embeddings&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;]&lt;/span&gt;

  &lt;span style=&#34;color: #75715e;font-style: italic&#34;&gt;# Store the embeddings in ChromaDB
&lt;/span&gt;  &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;collection&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;add&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt;
    &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;ids&lt;/span&gt;&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;str&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;i&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;)],&lt;/span&gt;
    &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;embeddings&lt;/span&gt;&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;embeddings&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;
    &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;documents&lt;/span&gt;&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;d&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;]&lt;/span&gt;
  &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The model used here is &lt;a href=&#34;https://www.mixedbread.com/blog/mxbai-embed-large-v1&#34;&gt;&lt;code&gt;mxbai-embed-large&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;For interest, hereâ€™s what the data weâ€™re storing in the vector database looks like:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code&gt;ID: 0
Document: 4 September 2025 - We are proud to announce the release of Apache KafkaÂ® 4.1.0. This relea[â€¦]
Embedding: [ 0.05642379 -0.02119605 -0.04147635  0.05452667 -0.01146116]...

ID: 1
Document: KIP-877: Mechanism for plugins and connectors to register metrics Many client-side plugins[â€¦]
Embedding: [-0.01764962 -0.00686921 -0.03395142  0.00759143 -0.02553692]...

ID: 2
Document: KIP-932: Queues for Kafka (Early Access) This KIP introduces the concept of a share group [â€¦]
Embedding: [0.05048409 0.00816069 0.00764809 0.03790297 0.00651639]...

ID: 3
Document: KIP-996: Pre-Vote KIP-996 introduces a &amp;#39;Pre-Vote&amp;#39; mechanism to reduce unnecessary KRaft le[â€¦]
Embedding: [ 0.04927347 -0.02349585  0.01001445  0.01915772 -0.010186  ]...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;So the vector database holds the &lt;em&gt;actual document (chunk) data&lt;/em&gt;, along with the embedding representation.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Thatâ€™s all, so far.
A static set of text data, stored in a way that represents the &lt;em&gt;semantic meaning&lt;/em&gt; of the data.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;You do this process once, or add to the vector database as new documents are needed (for example, when Apache Kafka 4.2.0 is released).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_rag_retrieval_using_embeddings_to_provide_context_to_an_llm&#34;&gt;RAG Retrieval: Using embeddings to provide context to an LLM&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Now our merry user arrives with their LLM client, and wants to know the latest version of Kafka.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Left to its own devices, the LLM only knows what it was trained with, which will have a cutoff date.
Sometimes the LLM will tell you that, sometimes it wonâ€™t.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Instead of &lt;code&gt;ollama.embed&lt;/code&gt;, letâ€™s use &lt;code&gt;ollama.generate&lt;/code&gt; with the &lt;code&gt;llama3.2&lt;/code&gt; LLM to generate the answer to the question with no additional context:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;user_input&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;what&amp;#39;s the latest version of kafka?&amp;#34;&lt;/span&gt;

&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;prompt&lt;/span&gt;&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;Respond to this prompt: &lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;user_input&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;

&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;output&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;ollama&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;generate&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt;
  &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;model&lt;/span&gt;&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;llama3.2&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;
  &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;prompt&lt;/span&gt;&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;prompt&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;)&lt;/span&gt;
&lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;print&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;prompt&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;-----&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;output&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;response&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;]&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;\n\n&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;=-=-=-=-&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code&gt;Respond to this prompt: what&amp;#39;s the latest version of kafka?
____
As of my knowledge cutoff in December 2023, the latest version of Apache Kafka is 3.4.&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;OKâ€”so as expected, not up-to-date, at all.
What weâ€™d like to do is help out the LLM by giving it some more context.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;We canâ€™t throw our entire library of knowledge at itâ€”that wouldnâ€™t work (too many tokens, not specific enough).
Instead, weâ€™re going to work out within our library, which document &lt;em&gt;is most relevant &lt;strong&gt;to the query&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The first step is to generate an embedding for our query, using the same model with which we created the embeddings for the documents in the vector database (the &amp;#34;library&amp;#34; to which Iâ€™m figuratively referring).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;user_input&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;what&amp;#39;s the latest version of kafka?&amp;#34;&lt;/span&gt;

&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;response&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;ollama&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;embed&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt;
  &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;model&lt;/span&gt;&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;mxbai-embed-large&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;
  &lt;span style=&#34;color: #f8f8f2&#34;&gt;input&lt;/span&gt;&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;user_input&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The vector looks like this:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code&gt;[[0.017346583, -0.021703502, -0.0436593, 0.045320738, -0.0005510414, -0.038553298, 0.016 [â€¦]&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;which to you or I might not mean much, but when passed to the vector database as a &lt;code&gt;.query&lt;/code&gt;:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;results&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;collection&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;query&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt;
  &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;query_embeddings&lt;/span&gt;&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;response&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;embeddings&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;],&lt;/span&gt;
  &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;n_results&lt;/span&gt;&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;1&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;)&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;data&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;results&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;documents&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;][&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;][&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;returns the document that is the most closely related, semantically:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code&gt;4 September 2025 - We are proud to announce the release of Apache KafkaÂ® 4.1.0. This release contains many new features and improvements. [â€¦]&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Weâ€™ve now &lt;strong&gt;retrieved&lt;/strong&gt; the &lt;strong&gt;additional&lt;/strong&gt; context with which we can now do the generation.
The prompt is the same as before, except we include the document that we retrieved from the vector database in it too:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;prompt&lt;/span&gt;&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;Using this data: &lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;data&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;. Respond to this prompt: &lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;user_input&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;output&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;ollama&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;generate&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt;
  &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;model&lt;/span&gt;&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;llama3.2&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;
  &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;prompt&lt;/span&gt;&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;prompt&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code&gt;Using this data: 4 September 2025 - We are proud to announce the release of Apache KafkaÂ® 4.1.0. This release contains many new features and improvements. This blog post will highlight some of the more prominent ones. For a full list of changes, be sure to check the release notes. Queues for Kafka (KIP-932) is now in preview. It&amp;#39;s still not ready for production but you can start evaluating and testing it. See the preview release notes for more details. This release also introduces a new Streams Rebalance Protocol (KIP-1071) in early access. It is based on the new consumer group protocol (KIP-848). See the Upgrading to 4.1 section in the documentation for the list of notable changes and detailed upgrade steps..
Respond to this prompt: what&amp;#39;s the latest version of kafka?
____
The latest version of Kafka mentioned in the data is Apache Kafka 4.1.0, which was released on September 4, 2025.&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;There we goâ€“our LLM used the context from the release notes to not only tell us the latest version, but also its release date.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_and_then_the_snake_ate_its_own_tail&#34;&gt;And then the snake ate its own tail&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In writing this article I made a rookie mistake.
No surprise there; but one worth illustrating here.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I use LLMs a lot to help my writingâ€”never to &lt;em&gt;write&lt;/em&gt; but to help generate code, for example.
The embeddings example on the &lt;a href=&#34;https://ollama.com/blog/embedding-models&#34;&gt;Ollama blog&lt;/a&gt; had these documents:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;documents&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;[&lt;/span&gt;
  &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;Llamas are members of the camelid family meaning they&amp;#39;re pretty closely related to vicuÃ±as and camels&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;
  &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;Llamas were first domesticated and used as pack animals 4,000 to 5,000 years ago in the Peruvian highlands&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;
  &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;Llamas can grow as much as 6 feet tall though the average llama between 5 feet 6 inches and 5 feet 9 inches tall&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;
  &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;Llamas weigh between 280 and 450 pounds and can carry 25 to 30 percent of their body weight&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;
  &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;Llamas are vegetarians and have very efficient digestive systems&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;
  &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;Llamas live to be about 20 years old, though some only live for 15 years and others live to be 30 years old&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Cute, but nothing to do with my domain.
So I did as I often doâ€”chuck it over to an LLM.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/8310d728162d567b92f79e2be71aebb3f6b7e66fee68d6d0d7fcee0f3a62c8c5.webp&#34; alt=&#34;8310d728162d567b92f79e2be71aebb3f6b7e66fee68d6d0d7fcee0f3a62c8c5&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Feeling smug, I copied this into my Python code and added a couple more documents (chunks) to illustrate the point about release version freshness:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;documents&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;[&lt;/span&gt;
    &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;The latest version of Apache Kafka is 4.1&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;
    &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;KIP-932 adds support for traditional message queue semantics to Kafka&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;
    &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;Apache Kafka is a distributed event streaming platform originally developed by LinkedIn and later open-sourced to the Apache Software Foundation&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;
    &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;Kafka was first released in 2011 and is written primarily in Scala and Java, designed to handle high-throughput, low-latency data streaming&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;
    &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;Kafka clusters can scale horizontally across multiple servers and can handle millions of messages per second with sub-millisecond latency&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;
    &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;Kafka uses a publish-subscribe messaging model where producers write data to topics and consumers read from those topics in real-time&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;
    &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;Kafka provides durability through configurable data replication and can retain messages for days, weeks, or even indefinitely depending on configuration&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;
    &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;Kafka is widely used by companies like Netflix, Uber, Airbnb, and thousands of other organizations for real-time analytics, log aggregation, and event-driven architectures&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;But when it came to comparing LLM responses using RAG and this data, it didnâ€™t really make much difference in some cases:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code&gt;Respond to this prompt: what is Apache Kafka? Give me one sentence. &lt;i class=&#34;conum&#34; data-value=&#34;1&#34;&gt;&lt;/i&gt;&lt;b&gt;(1)&lt;/b&gt;
____
Apache Kafka is a distributed streaming platform that enables real-time data processing and event-driven architecture, providing fault-tolerant and scalable messaging capabilities for large-scale data ingestion, storage, and analysis.

=-=-=-=-
Using this data: Apache Kafka is a distributed event streaming platform originally developed by LinkedIn and later open-sourced to the Apache Software Foundation. Respond to this prompt: what is Apache Kafka? Give me one sentence. &lt;i class=&#34;conum&#34; data-value=&#34;2&#34;&gt;&lt;/i&gt;&lt;b&gt;(2)&lt;/b&gt;
____
Apache Kafka is a distributed event streaming platform that enables scalable, fault-tolerant, and secure data processing and consumption for real-time applications.

=-=-=-=-&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;colist arabic&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;&lt;i class=&#34;conum&#34; data-value=&#34;1&#34;&gt;&lt;/i&gt;&lt;b&gt;1&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;No RAG&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;i class=&#34;conum&#34; data-value=&#34;2&#34;&gt;&lt;/i&gt;&lt;b&gt;2&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;With RAG&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Whyâ€™s the output basically the same?
Because the LLM &lt;em&gt;already knows&lt;/em&gt; what Apache Kafka is!
If it didnâ€™t, how would it have generated the &lt;code&gt;documents&lt;/code&gt; array above?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;(technically I used Claude 4 Sonnet to generate the array and Llama 3.2 in my Python scriptâ€”but basically the same principle)&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;One lesson, but to express in two different ways from this:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;RAG content only makes sense if itâ€™s not already in the LLM&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Donâ€™t use LLMs to generate RAG content&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;There are probably a bunch of nuances to this.
For example, could you use a more powerful LLM to distill down content for use in RAG by a smaller LLM (cheaper/faster to run)?
Tell me in the comments belowâ€”Iâ€™m here to learn :)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_further_reading&#34;&gt;Further reading&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ðŸŽ¥ &lt;a href=&#34;https://www.youtube.com/watch?v=T-D1OfcDW1M&#34;&gt;Marina Danilevsky - What is RAG&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tons of great content in &lt;a href=&#34;https://www.infoq.com/presentations/llm-data-code-model-prompt/&#34;&gt;this talk from Paul Iusztin at QCon London 2025&lt;/a&gt;, including lots about RAG (at around 24 minutes in).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
    </item>
    <item>
      <title>Stumbling into AI: Part 2â€”Models</title>
      <link>https://rmoff.net/2025/09/08/stumbling-into-ai-part-2models/</link>
      <pubDate>2025-09-08</pubDate>
      
      <guid>https://rmoff.net/2025/09/08/stumbling-into-ai-part-2models/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2025/09/t_IMG_2446.webp" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;A &lt;a href=&#34;https://rmoff.net/categories/stumbling-into-ai&#34;&gt;short series&lt;/a&gt; of notes for myself as I learn more about the AI ecosystem as of September 2025.&lt;/em&gt;
&lt;em&gt;The driver for all this is understanding more about Apache Flinkâ€™s &lt;a href=&#34;https://github.com/apache/flink-agents&#34;&gt;&lt;strong&gt;Flink Agents&lt;/strong&gt;&lt;/a&gt; project, and Confluentâ€™s &lt;a href=&#34;https://www.confluent.io/product/streaming-agents/&#34;&gt;&lt;strong&gt;Streaming Agents&lt;/strong&gt;&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Having &lt;a href=&#34;https://rmoff.net/2025/09/04/stumbling-into-ai-part-1mcp/&#34;&gt;poked around MCP&lt;/a&gt; and got a broad idea of what it is, I want to next look at Models.
What used to be as simple as &amp;#34;&lt;em&gt;I used AI&lt;/em&gt;&amp;#34; actually boils down into several discrete areas, particularly when one starts looking at using LLMs beyond writing &lt;a href=&#34;https://rmoff.net/images/2025/09/13d0418e1ddd2f60eef260aa512cb2a27aed080a4702fd7f01e73ef7b8ba5c2b.webp&#34;&gt;a rap about Apache Kafka in the style of Monty Python&lt;/a&gt; and using it to build agents (like the Flink Agents that prompted this exploration in the first place).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/models.excalidraw.webp&#34; alt=&#34;models.excalidraw&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_models_large_language_ones_to_be_precise&#34;&gt;Models (Large Language ones, to be precise)&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This is the what itâ€™s all about right here.
Large Language Models (LLMs) are what piqued the interest of nerds outside the academic community in 2023 and the broader public a year or so later.
What used to be a &amp;#34;&lt;em&gt;OMFG have you seen this&lt;/em&gt;&amp;#34; moment is now somewhat passÃ©.
Of &lt;em&gt;course&lt;/em&gt; I can ask my computer to write my homework assignment for me.
Of &lt;em&gt;course&lt;/em&gt; I can use my phone to explain the nuances of the leg-before-wicket rule in Cricket.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/models1.excalidraw.webp&#34; alt=&#34;models1.excalidraw&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Without a model, the whole AI sandcastle collapses.
There are &lt;a href=&#34;https://en.wikipedia.org/wiki/List_of_large_language_models&#34;&gt;many dozens of LLMs&lt;/a&gt;.
The most well-known ones are grouped into families and include &lt;a href=&#34;https://platform.openai.com/docs/models&#34;&gt;GPT&lt;/a&gt;, &lt;a href=&#34;https://docs.anthropic.com/en/docs/about-claude/models/overview#model-names&#34;&gt;Claude&lt;/a&gt;, and &lt;a href=&#34;https://ai.google.dev/gemini-api/docs/models&#34;&gt;Gemini&lt;/a&gt;.
Within these there are different models, such as GPT-5, Claude 4.1, and so on.
Often these models themselves have variants, specific to certain tasks like writing software code, generating images, or understanding audio.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_companies&#34;&gt;Companies&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The big companies behind the models include:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;OpenAI (GPT)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Anthropic (Claude)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Google (Gemini)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Meta (Llama)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_how_does_it_work&#34;&gt;How does it work?&lt;/h3&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Any sufficiently advanced technology is indistinguishable from magic.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;â€” &lt;a href=&#34;https://en.wikipedia.org/wiki/Clarke%27s_three_laws#cite_note-:1-2&#34;&gt;Arthur C. Clarke&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Srsly tho, Iâ€™m not going to even pretend to try and understand how LLMs works.
Just as I couldnâ€™t tell you how the CPU in my laptop works, but I know that itâ€™s there and &lt;em&gt;waves hands&lt;/em&gt; does stuff, the same is true for LLMs.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;You give them text, they give you a response.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;If you want a really good overview of LLMs, have a look at this excellent talk from one of the OGs in the LLM space, Andrej Karpathy:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/zjkBMFhNj_g&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_hallucinations&#34;&gt;Hallucinations&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;One of my favourite descriptions of LLMs likened them to an &lt;strong&gt;over-eager, hungover, intern&lt;/strong&gt;.
They can do a lot, and know a lot of the words, but youâ€™d never quite trust what they write.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;As LLMs improve, itâ€™s less likely youâ€™ll get completely BS responses from them, but part of the risk is that they usually express themselves extremely confidently.
Hereâ€™s what an LLM told me about my home town:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Ilkley:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Known for its stunning lakes (Lythwaite Lake) and the Dung scale viaduct, which provides a breathtaking view of the surrounding landscape.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Has a rich history, including being part of the Lancashire cotton industry in the 1800s.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Sounds plausible, right?
But &lt;code&gt;Lythwaite Lake&lt;/code&gt; and &lt;code&gt;Dung scale viaduct&lt;/code&gt; &lt;em&gt;do not exist&lt;/em&gt; (nor is there a lake or viaduct near the town).
And &lt;a href=&#34;https://en.wikipedia.org/wiki/Wars_of_the_Roses&#34;&gt;worse&lt;/a&gt;, Ilkley is very much in Yorkshire, not Lancashire!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Of course, itâ€™s easy to cherry-pick these examples.
If I ask a better model about Ilkley, it is &lt;a href=&#34;https://en.wikipedia.org/wiki/Ilkley&#34;&gt;completely right&lt;/a&gt;:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Ilkley:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Known for its dramatic moorland (Ilkley Moor) and the Cow and Calf rocks, offering sweeping views over Wharfedale and inspiring the song â€œOn Ilkla Moor Baht â€™at.â€&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Has a rich history, from its Roman fort (Olicana) and medieval origins to becoming a Victorian spa town famed for hydrotherapy and elegant architecture.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_tokens&#34;&gt;Tokens&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The input and output of LLMs is measuredâ€”and in many cases, chargedâ€”on the basis of &lt;em&gt;tokens&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;admonitionblock tip&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td class=&#34;icon&#34;&gt;
&lt;i class=&#34;fa icon-tip&#34; title=&#34;Tip&#34;&gt;&lt;/i&gt;
&lt;/td&gt;
&lt;td class=&#34;content&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Just like the video above explaining how LLMs work, if you want to know about details of tokenisation check out this explainer:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/zduSFxRajkE&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In some cases, the number of words is equivalent to the number of tokens:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;$ &lt;/span&gt;ttok never gonna give you up
5&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;but often not:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;$ &lt;/span&gt;ttok apache flink
3
&lt;span style=&#34;color: #f8f8f2&#34;&gt;$ &lt;/span&gt;ttok supercalifragilisticexpialidocious
11&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Different LLMs may use different tokenisation too.
You can use the &lt;a href=&#34;https://github.com/simonw/ttok&#34;&gt;ttok&lt;/a&gt; tool (shown above) to explore tokenisation in more detail.
Some tools, such as Goose, will also show you how many tokens are used:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/441a2e716c8ec369ff81988cb0c369a67ffdfd10d292d87bd42d0c3bc65a770a.webp&#34; alt=&#34;441a2e716c8ec369ff81988cb0c369a67ffdfd10d292d87bd42d0c3bc65a770a&#34; width=&#34;600px&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Youâ€™ll notice that as well as the token count, thereâ€™s a dollar amount next to it.
Since Iâ€™m running the model locally (using &lt;a href=&#34;https://ollama.com/&#34;&gt;Ollama&lt;/a&gt;) thereâ€™s no direct cost for the invocation of it.
Where the token count matters is when youâ€™re using remote models, like GPT or Claude.
These are &lt;a href=&#34;https://platform.openai.com/docs/pricing?latest-pricing=standard#text-tokens&#34;&gt;charged&lt;/a&gt; based on the number of tokens used, often listed as a cost per 1M tokens.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Nine tokens might seem like a drop in the ocean of a million, but look at this:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/c4ad35ade6245a62812b3aa3026cd7e2765c76d781b2d08339bbbfa0923e8596.webp&#34; alt=&#34;c4ad35ade6245a62812b3aa3026cd7e2765c76d781b2d08339bbbfa0923e8596&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The same input prompt (&lt;code&gt;supercalifragilisticexpialidocious&lt;/code&gt;) but somehow I just used nearly 10k tokens!
If you read my &lt;a href=&#34;https://rmoff.net/2025/09/04/stumbling-into-ai-part-1mcp/&#34;&gt;blog post about MCP&lt;/a&gt; youâ€™ll know that LLMs can make use of MCP servers (often generically referred to as &amp;#34;tools&amp;#34; or &amp;#34;extensions&amp;#34;).
They can be used to look up further information to support the userâ€™s request (&amp;#34;&lt;em&gt;what films have they rated the highest&lt;/em&gt;&amp;#34;), or even invoke actions (&amp;#34;&lt;em&gt;book two tickets at the local cinema to see Top Gun on Monday at 8pm&lt;/em&gt;&amp;#34;).
So when I gave the agent the prompt &lt;code&gt;supercalifragilisticexpialidocious&lt;/code&gt;, what it actually did was include information about all of the tools configured, so that the LLM could choose to use them or notâ€”and this took up a lot of tokens, because there were several tools configured.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;So if I disable the tools/MCP servers, the token count should be back to just that of the input expression?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/1cb6fa8178df3c00a5e73f57459124f2afee02714fc43659881fd2baf3dde655.webp&#34; alt=&#34;1cb6fa8178df3c00a5e73f57459124f2afee02714fc43659881fd2baf3dde655&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Not so.
And thatâ€™s because most of the time you use an LLM youâ€™re doing so with a particular purpose or framing, and so a &lt;em&gt;system prompt&lt;/em&gt; will help focus it on what you want it to do.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;For example, here is the same input, but with two different system prompts.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;$ &lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;Internet&amp;#34;&lt;/span&gt; | &lt;span style=&#34;color: #ae81ff&#34;&gt;\ &lt;/span&gt;                                        &lt;i class=&#34;conum&#34; data-value=&#34;1&#34;&gt;&lt;/i&gt;&lt;b&gt;(1)&lt;/b&gt;
    llm &lt;span style=&#34;color: #f92672&#34;&gt;-m&lt;/span&gt; gpt-oss:latest &lt;span style=&#34;color: #ae81ff&#34;&gt;\&lt;/span&gt;
        &lt;span style=&#34;color: #f92672&#34;&gt;-s&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;Define this word. Be concise.&amp;#34;&lt;/span&gt;                    &lt;i class=&#34;conum&#34; data-value=&#34;2&#34;&gt;&lt;/i&gt;&lt;b&gt;(2)&lt;/b&gt;
&lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;**&lt;/span&gt;Internet&lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;**&lt;/span&gt; â€“ a global network of interconnected computers that exchange data using standardized protocols, enabling communication, information sharing, and services across the world.

&lt;span style=&#34;color: #f8f8f2&#34;&gt;$ &lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;Internet&amp;#34;&lt;/span&gt; | &lt;span style=&#34;color: #ae81ff&#34;&gt;\ &lt;/span&gt;                                        &lt;i class=&#34;conum&#34; data-value=&#34;1&#34;&gt;&lt;/i&gt;&lt;b&gt;(1)&lt;/b&gt;
    llm &lt;span style=&#34;color: #f92672&#34;&gt;-m&lt;/span&gt; gpt-oss:latest &lt;span style=&#34;color: #ae81ff&#34;&gt;\&lt;/span&gt;
        &lt;span style=&#34;color: #f92672&#34;&gt;-s&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;Define this word to a five year old. Be concise.&amp;#34;&lt;/span&gt; &lt;i class=&#34;conum&#34; data-value=&#34;2&#34;&gt;&lt;/i&gt;&lt;b&gt;(2)&lt;/b&gt;
The internet is like a giant invisible playground &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;for &lt;/span&gt;computers. It lets them share pictures, videos, games, and messages so you can learn, play, and talk to friends from anywhere.&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;colist arabic&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;&lt;i class=&#34;conum&#34; data-value=&#34;1&#34;&gt;&lt;/i&gt;&lt;b&gt;1&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;User input&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;i class=&#34;conum&#34; data-value=&#34;2&#34;&gt;&lt;/i&gt;&lt;b&gt;2&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;System prompt&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Ultimately the system prompt is just a bunch of tokens that get passed to the LLM; and thatâ€™s probably what weâ€™re seeing in the screenshot above where the token count is higher than that of the input text alone.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect3&#34;&gt;
&lt;h4 id=&#34;_why_does_this_matter&#34;&gt;Why does this matter?&lt;/h4&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Because someone has to pay for all this fun, and how many tokens you use determines how much youâ€™ll pay.
You might be using the LLM providerâ€™s API directly and thus directly exposed to the token cost, or you might be using a tool whose authoring company pays the API bills and in turn will cap your invocation through the tool at a certain point.
You might think a million tokens sounds a lot, but this can easily get burnt through with things like:
* MCP usage, in which the output from an API call might be a long JSON document - and often multiple API calls will get strung together to satisfy a single user request
* Coding help, when the LLM will have to be given reams of code across potentially many files&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect3&#34;&gt;
&lt;h4 id=&#34;_context_window&#34;&gt;Context Window&lt;/h4&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;When you interact with an LLM, it can &amp;#39;remember&amp;#39; what youâ€™ve told itâ€”and what itâ€™s told youâ€”before.
This is called the context window, and is measured in tokens.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Generally, the smaller the context window the faster a model will return, compared to a larger window.
Once the window is full youâ€™ll see the model start to &amp;#34;forget&amp;#34; things, or just refuse to run.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Some AI tools will expose the current context window size, like Goose:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/e40e0845d3e3e37bd2448014a136da8709c6ea48287465e4d65f24cb45d98b08.webp&#34; alt=&#34;e40e0845d3e3e37bd2448014a136da8709c6ea48287465e4d65f24cb45d98b08&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;You can also sometimes &amp;#39;compact&amp;#39; the context window, which will in effect summarise everything &amp;#34;discussed&amp;#34; so far with the LLM and start a new conversation.
Since the summary will be shorter than the dialogue from which it was created, the context window will be smaller.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_weights_parameters&#34;&gt;Weights &amp;amp; Parameters&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;After many years working with open source software, I was puzzled by the new terminology that I started to hear in relation to LLMs: &amp;#34;Open Weight&amp;#34;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In terms of software alone, open source has &lt;a href=&#34;https://opensource.org/osd&#34;&gt;a strict set of definitions&lt;/a&gt;, but one of the key ones from an end-user point of view is that I can access all the source code and in theory could build the program from scratch myself.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;When it comes to LLMs itâ€™s not quite so straightforward.
Watching &lt;a href=&#34;https://www.youtube.com/watch?v=zjkBMFhNj_g&#34;&gt;Andrej Karpathyâ€™s video&lt;/a&gt; Iâ€™ve picked up the basic understanding that youâ€™ve got the mega-expensive pre-training in which vast swathes of the internet and beyond are boiled down into a model.
He &lt;a href=&#34;https://youtu.be/zjkBMFhNj_g?feature=shared&amp;amp;t=258&#34;&gt;gives the example&lt;/a&gt; of Llama 2 costing $2M and taking 12 days to train.
The size of the model is defined by the number of parameters.
Broadly, the greater the number of parameters, the greater the accuracy of the LLM.
Fewer parameters means less computing power needed and potentially less accurate resultsâ€”but depending on what youâ€™re asking the LLM to do can sometimes be a good tradeoff.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Out of this pre-training is then a core model which is then trained further in whatâ€™s known as fine-tuning.
This is cheaper, and faster, to do.
It can be used to specialise the model towards particular tasks or domains.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Companies approach the sharing of models in different ways.
Some keep absolutely everything to themselves, giving the end user simply an API endpoint or web page with which to interact with the model that theyâ€™ve built.
Others will perhaps share the pre-trained model (but not the source data or code that went into training it), giving people the opportunity to then train it further with their own fine-tuning.
This is the &amp;#34;Open Weight&amp;#34; approach.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;You can read more about &lt;a href=&#34;https://ai.meta.com/blog/llama-4-multimodal-intelligence/&#34;&gt;Llama 4&lt;/a&gt; and &lt;a href=&#34;https://ai.meta.com/research/publications/the-llama-3-herd-of-models/&#34;&gt;Llama 3&lt;/a&gt; on the Meta AI blog, as well as &lt;a href=&#34;https://openai.com/index/introducing-gpt-oss/&#34;&gt;GPT-OSS from OpenAI&lt;/a&gt;.
This post on Reddit is also interesting: &lt;a href=&#34;https://www.reddit.com/r/LocalLLaMA/comments/1iw1xn7/the_paradox_of_open_weights_but_closed_source/&#34;&gt;The Paradox of Open Weights, but Closed Source&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_clients&#34;&gt;Clients&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;OK, so weâ€™ve got our models.
They come in different shapes and sizes, and some are better than others.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;To use an LLM, one needs a client.
Clients take various forms:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Desktop and Web clients, specific to the AI company developing a family of LLMs.
These include &lt;a href=&#34;https://chatgpt.com/&#34;&gt;ChatGPT&lt;/a&gt; and &lt;a href=&#34;https://claude.ai/download&#34;&gt;Claude&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/claudeandchatgpt.webp&#34; alt=&#34;claudeandchatgpt&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tools built around AI functionality (e.g. Cursor) or with it bolted on whether you want it or not (&lt;em&gt;i.e. every bloody application out there these days&lt;/em&gt; ðŸ˜œ).
Some of these will give you access to a set of models, whilst others will mask the model itself and just call it &lt;del&gt;&amp;#34;magic&amp;#34;&lt;/del&gt;&amp;#34;AI&amp;#34;&lt;/p&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/79ab812d942ed692f1dc202e96075596a5578951d89e2f9c76123284b38b01e7.webp&#34; alt=&#34;79ab812d942ed692f1dc202e96075596a5578951d89e2f9c76123284b38b01e7&#34; width=&#34;600px&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/cursor00.webp&#34; alt=&#34;cursor00&#34; width=&#34;600px&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Model-agnostic interfaces, including:&lt;/p&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://manual.raycast.com/ai&#34;&gt;Raycast&lt;/a&gt;, which as part of its application gives the user the option to interact with dozens of different LLMs&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Simon Willisonâ€™s &lt;a href=&#34;https://llm.datasette.io/en/stable/&#34;&gt;&lt;code&gt;llm&lt;/code&gt; CLI&lt;/a&gt;:&lt;/p&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color: #75715e;font-style: italic&#34;&gt;# Use GPT-OSS model&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2&#34;&gt;$ &lt;/span&gt;llm &lt;span style=&#34;color: #f92672&#34;&gt;-m&lt;/span&gt; gpt-oss:latest &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;What year was the world wide web invented? Be concise&amp;#39;&lt;/span&gt;
1989.

&lt;span style=&#34;color: #75715e;font-style: italic&#34;&gt;# Use Llama 3.1 model&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2&#34;&gt;$ &lt;/span&gt;llm &lt;span style=&#34;color: #f92672&#34;&gt;-m&lt;/span&gt; llama3.1:latest &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;What year was the world wide web invented? Be concise&amp;#39;&lt;/span&gt;
The World Wide Web &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;(&lt;/span&gt;WWW&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;)&lt;/span&gt; was invented &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;in &lt;/span&gt;1989 by Tim Berners-Lee.&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://block.github.io/goose/&#34;&gt;Goose&lt;/a&gt;, which is an &lt;em&gt;an extensible open source AI agent&lt;/em&gt;.
Iâ€™ve not used it a ton yet but at first glance it at least gives you a UI and CLI for interacting with LLMs and MCPs:&lt;/p&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/bb72744c933acfc7a85a9127f70f8161872462e7f95648fa66d47119718de9c0.webp&#34; alt=&#34;bb72744c933acfc7a85a9127f70f8161872462e7f95648fa66d47119718de9c0&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_where_the_model_runs&#34;&gt;Where the model runs&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Running LLMs takes some grunt, which is why theyâ€™re particularly well suited to being provided as hosted services since someone else can absorb the cost of provisioning the expensive hardware necessary to run them.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;There are 3 broad options for getting access to running a model (assuming youâ€™re using a client that has pluggable models; if youâ€™re using something like ChatGPT then you just access the models through that alone and they run the models for you):&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;My cloud&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;My laptop, my on-premises servers with some big fat GPUs, etc&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Their cloud&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Servers run by the model publishers themselves; &lt;a href=&#34;https://platform.openai.com/docs/overview&#34;&gt;OpenAI&lt;/a&gt;, &lt;a href=&#34;https://www.anthropic.com/api&#34;&gt;Anthropic&lt;/a&gt;, etc.
Usually theyâ€™ll only offer access to their own models.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Someone elseâ€™s cloud&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Models hosted by 3rd party providers, including &lt;a href=&#34;https://aws.amazon.com/bedrock/&#34;&gt;Amazon Bedrock&lt;/a&gt;, &lt;a href=&#34;https://ai.azure.com/&#34;&gt;Azure AI Foundry&lt;/a&gt;, &lt;a href=&#34;https://openrouter.ai/&#34;&gt;OpenRouter&lt;/a&gt;, etc.
The big providers like Azure and Amazon will usually have partnerships with some model companies and provide access to their models, whilst others may only offer access to publicly-available models (basically what you or I could run on our own locally, but with the necessary hardware behind it to perform well).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Iâ€™ve found &lt;a href=&#34;https://openrouter.ai/&#34;&gt;OpenRouter&lt;/a&gt; particularly useful as it gives you access to free models, and the ability to run the same prompt across different models:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/0371e711472c4996419299c514fe5027c8963e680292df55dc7aafb1815bb2be.webp&#34; alt=&#34;0371e711472c4996419299c514fe5027c8963e680292df55dc7aafb1815bb2be&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;It also has a good catalog of models and details of which provider offers them.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Finally, OpenRouter is a pragmatic way to make use of the free models; &lt;code&gt;gpt-oss:120b&lt;/code&gt; might sound nice and make claims about being as good as some of the closed-weights GPT models, but itâ€™s irrelevant if it wonâ€™t run locally.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_routers&#34;&gt;Routers&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The final piece of the puzzle, for now, is &lt;strong&gt;routers&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Given that there are multiple models, and multiple places in which to run them, how do you decide which one to call?
Different models are better at different tasks; or put another way, the big expensive models are usually good at everything but you may get a faster or cheaper (or perhaps even just more accurate) response from a specialised model.
You could take the artisanal approach, and curate your model access based on your in-depth understanding of all models each time you want to call one.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Alternatively, you use a router, which is a model itself and one that is specialised in understanding LLMs strengths, analysing the type of workload you want to run, and routing it to the most suitable one.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Some routers include:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;OpenRouterâ€™s &lt;a href=&#34;https://openrouter.ai/openrouter/auto&#34;&gt;AutoRouter&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/SomeOddCodeGuy/WilmerAI&#34;&gt;WilmerAI&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.aurelio.ai/semantic-router&#34;&gt;Semantic Router&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;admonitionblock tip&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td class=&#34;icon&#34;&gt;
&lt;i class=&#34;fa icon-tip&#34; title=&#34;Tip&#34;&gt;&lt;/i&gt;
&lt;/td&gt;
&lt;td class=&#34;content&#34;&gt;
You donâ€™t have to use a router, but youâ€™ll possibly see mention of them which is why Iâ€™m mentioning them here.
Also, because I got confused by &lt;code&gt;OpenRouter&lt;/code&gt; also being a service provider, not just a router :)
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_addendum_there_are_models_and_then_there_are_models_a_k_a_not_all_models_are_llms&#34;&gt;Addendum: There are Models, and then there are &lt;em&gt;Models&lt;/em&gt; (a.k.a. not all Models are LLMs)&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;As I wrote &lt;a href=&#34;https://rmoff.net/2025/09/12/stumbling-into-ai-part-3rag/&#34;&gt;the third part&lt;/a&gt; in this little voyage of discovery I realised that my understanding of modelsâ€”as I wrote about them in this articleâ€”was incomplete.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;There are different types of model, and there are different purposes to which a model is put.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;LLMs as Iâ€™ve discussed in this blog post are &lt;em&gt;generative&lt;/em&gt;.
They create (generate) new material based on their training over large datasets of text.
There are other &lt;em&gt;generative&lt;/em&gt; models that are not LLMs.
These include those you might have also heard of like &lt;a href=&#34;https://openai.com/index/dall-e-2/&#34;&gt;DALL-E&lt;/a&gt; and &lt;a href=&#34;https://www.midjourney.com/home&#34;&gt;Midjourney&lt;/a&gt;, for generating images.
There are also models for generating &lt;a href=&#34;https://huggingface.co/microsoft/VibeVoice-1.5B&#34;&gt;speech&lt;/a&gt;, &lt;a href=&#34;https://ace-step.github.io/#RapMachine&#34;&gt;music&lt;/a&gt;, and &lt;a href=&#34;https://huggingface.co/alibaba-pai/Wan2.2-VACE-Fun-A14B/blob/main/README_en.md#video-result&#34;&gt;video&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Other models that arenâ€™t generative do tasks such as:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Creating embeddings (as used in &lt;a href=&#34;https://rmoff.net/2025/09/12/stumbling-into-ai-part-3rag/&#34;&gt;RAG&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Sentiment analysis&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Anomaly detection&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Forecasting and prediction&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Analysing video, image, or audio, e.g.&lt;/p&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Detecting objects&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Transcribing speech&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;admonitionblock tip&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td class=&#34;icon&#34;&gt;
&lt;i class=&#34;fa icon-tip&#34; title=&#34;Tip&#34;&gt;&lt;/i&gt;
&lt;/td&gt;
&lt;td class=&#34;content&#34;&gt;
Regardless of the type, what you call a model to get it to do something, itâ€™s called &lt;em&gt;inference&lt;/em&gt;.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
    </item>
    <item>
      <title>Stumbling into AI: Part 1â€”MCP</title>
      <link>https://rmoff.net/2025/09/04/stumbling-into-ai-part-1mcp/</link>
      <pubDate>2025-09-04</pubDate>
      
      <guid>https://rmoff.net/2025/09/04/stumbling-into-ai-part-1mcp/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2025/09/2025-09-03T10-32-54-772Z.webp" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;A &lt;a href=&#34;https://rmoff.net/categories/stumbling-into-ai&#34;&gt;short series&lt;/a&gt; of notes for myself as I learn more about the AI ecosystem as of September 2025.&lt;/em&gt;
&lt;em&gt;The driver for all this is understanding more about Apache Flinkâ€™s &lt;a href=&#34;https://github.com/apache/flink-agents&#34;&gt;&lt;strong&gt;Flink Agents&lt;/strong&gt;&lt;/a&gt; project, and Confluentâ€™s &lt;a href=&#34;https://www.confluent.io/product/streaming-agents/&#34;&gt;&lt;strong&gt;Streaming Agents&lt;/strong&gt;&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The first thing I want to understand better is MCP.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/2025-09-03T10-32-54-772Z.webp&#34; alt=&#34;2025 09 03T10 32 54 772Z&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;For context, so far Iâ€™ve been a keen end-user of LLMs, for &lt;a href=&#34;https://rmoff.net/2023/12/07/productivity-tools-ai-image-generators/&#34;&gt;generating images&lt;/a&gt;, proof-reading my blog posts, and general lazyweb stuff like getting it to spit out the right syntax for a bash one-liner.
I use &lt;a href=&#34;https://rmoff.net/categories/raycast/&#34;&gt;Raycast&lt;/a&gt; with its &lt;a href=&#34;https://manual.raycast.com/ai&#34;&gt;Raycast AI&lt;/a&gt; capabilities to interact with different models, and Iâ€™ve used Cursor to &lt;em&gt;vibe-code&lt;/em&gt; some &lt;a href=&#34;https://github.com/rmoff/rmoff-blog/pull/153&#34;&gt;useful&lt;/a&gt; (and &lt;a href=&#34;https://github.com/rmoff/rmoff-blog/pull/154/commits/30f43034ddd1217df8ad7db0d57b3153bb745f9c&#34;&gt;less useful&lt;/a&gt;, fortunately never deployed) functionality for this blog.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;But what Iâ€™ve not done so far is dig any further into the ecosystem beyond.
Letâ€™s fix that!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_mcp&#34;&gt;MCP&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;So, what is MCP?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;Model Context Protocol&lt;/em&gt; sounds fancy and intimidating, but on first pass after a couple of hours poking around hereâ€™s my rough take:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;MCP exists as an open standard defining a way for LLMs to interact with APIs.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This makes a ton of sense, because the alternative is something awful like vibe coding some piece of boilerplate code to call the API to feedback to the LLM.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/mcp-01.excalidraw.webp&#34; alt=&#34;mcp 01.excalidraw&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The &lt;a href=&#34;https://modelcontextprotocol.io/docs/learn/server-concepts#core-building-blocks&#34;&gt;MCP core concepts&lt;/a&gt; are &lt;strong&gt;tools&lt;/strong&gt; (the API calls Iâ€™m talking about above), &lt;strong&gt;resources&lt;/strong&gt;, and &lt;strong&gt;prompts&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The MCP website has a useful guide to &lt;a href=&#34;https://modelcontextprotocol.io/docs/learn/architecture#data-layer-2&#34;&gt;how MCP clients and servers interact&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Youâ€™ll find plenty of &lt;a href=&#34;https://mcpservers.org/&#34;&gt;lists&lt;/a&gt; &lt;a href=&#34;https://mseep.ai/&#34;&gt;of&lt;/a&gt; &lt;a href=&#34;https://github.com/modelcontextprotocol/servers&#34;&gt;MCP&lt;/a&gt; &lt;a href=&#34;https://github.com/jaw9c/awesome-remote-mcp-servers&#34;&gt;servers&lt;/a&gt; &lt;a href=&#34;https://glama.ai/mcp/servers&#34;&gt;online&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;admonitionblock tip&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td class=&#34;icon&#34;&gt;
&lt;i class=&#34;fa icon-tip&#34; title=&#34;Tip&#34;&gt;&lt;/i&gt;
&lt;/td&gt;
&lt;td class=&#34;content&#34;&gt;
This article is basically a journal of my journey figuring out MCP in my head, taking somewhat rambling twists and turns.
However, if youâ€™d like to watch a clearly organised and crystal-clear explanation of MCP from one of the industryâ€™s best, check out this video from Tim Berglund:

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/FLpS7OfD5-s&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_local_or_remote&#34;&gt;Local or Remote&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The APIs that the MCP server interacts with could be local (e.g. your filesystem, a database, etc), or remote (e.g. a SaaS platform like AWS or simply a website like AirBnb or Strava).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;MCP servers can be run locally, which youâ€™d do if youâ€™re accessing local resources, or if you are developing the MCP server yourself (or want to run one that someone else has written and isnâ€™t provided as a hosted service).
You can also host MCP servers remotely (there are a bunch &lt;a href=&#34;https://github.com/jaw9c/awesome-remote-mcp-servers&#34;&gt;listed here&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Where you want your MCP server also depends on where your LLM client is running.
Thereâ€™s no point running your MCP locally if your LLM client is in the cloud somewhere.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_stdio_sse_wtf&#34;&gt;stdio, sse, wtf?&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;If your MCP server is running local to the client, it can communicate using &lt;code&gt;stdio&lt;/code&gt; (good ole&amp;#39; &lt;a href=&#34;https://tldp.org/LDP/lpg/node10.html&#34;&gt;Linux pipes&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;MCP servers can also use &lt;code&gt;HTTP&lt;/code&gt; or &lt;code&gt;HTTP SSE&lt;/code&gt;, enabling clients to work with them over a network.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;See &lt;a href=&#34;https://docs.anthropic.com/en/docs/claude-code/mcp#installing-mcp-servers&#34;&gt;Anthropicâ€™s guide&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_using_mcp&#34;&gt;Using MCP&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;To use an MCP youâ€™ll usually configure your AI tool with it, as an MCP client.
&lt;a href=&#34;https://platform.openai.com/docs/mcp&#34;&gt;ChatGPT&lt;/a&gt; and &lt;a href=&#34;https://docs.anthropic.com/en/docs/claude-code/mcp&#34;&gt;Claude&lt;/a&gt; are the biggies here.
I like using Raycast as it gives me access to a bunch of different LLMs, and also &lt;a href=&#34;https://manual.raycast.com/model-context-protocol&#34;&gt;supports MCPs&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;admonitionblock tip&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td class=&#34;icon&#34;&gt;
&lt;i class=&#34;fa icon-tip&#34; title=&#34;Tip&#34;&gt;&lt;/i&gt;
&lt;/td&gt;
&lt;td class=&#34;content&#34;&gt;
This is where Flink Agents enter the room, as they use MCPs too
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Hereâ€™s a Raycast conversation using a &lt;a href=&#34;https://github.com/r-huijts/strava-mcp?tab=readme-ov-file&#34;&gt;Strava MCP&lt;/a&gt; running locally:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/2025-09-02T15-11-39-940Z.webp&#34; alt=&#34;2025 09 02T15 11 39 940Z&#34; width=&#34;600&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Looking at it, itâ€™s quite clearly just a wrapper around the &lt;a href=&#34;https://developers.strava.com/docs/reference/#api-Activities-getActivityById&#34;&gt;Strava API&lt;/a&gt; (which is totally cool, itâ€™s all it claims to be too).
Itâ€™s just giving the LLM clear parameters and on how to use the APIâ€”as well as, crucially, a description of what the API does.
For example, rather than just â€œget-recent-activitiesâ€, it tells the LLM â€œFetches the most recent activities for the authenticated athlete.â€.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;When I ask my question, the LLM draws on the fact that it has Strava MCP available with the explanations of what each &amp;#34;tool&amp;#34; (API call) provides.
It uses this to work out what to tell the client (Raycast) to request from the MCP server:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/mcp-02.excalidraw.webp&#34; alt=&#34;mcp 02.excalidraw&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The responseâ€”a lump of JSONâ€”is passed back to the LLM, which then does its LLM magic and uses the information to answer my question:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/mcp-03.excalidraw.webp&#34; alt=&#34;mcp 03.excalidraw&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;admonitionblock tip&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td class=&#34;icon&#34;&gt;
&lt;i class=&#34;fa icon-tip&#34; title=&#34;Tip&#34;&gt;&lt;/i&gt;
&lt;/td&gt;
&lt;td class=&#34;content&#34;&gt;
The text in red is the actual &amp;#34;&lt;em&gt;Thinking&lt;/em&gt;&amp;#34; that the LLM does; you can usually access this in your client, such as Raycast here:
&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/strava-mcp-local.webp&#34; alt=&#34;strava mcp local&#34;/&gt;&lt;/span&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_poking_around&#34;&gt;Poking around&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;You can use the &lt;a href=&#34;https://modelcontextprotocol.io/legacy/tools/inspector#feature-overview&#34;&gt;Inspector tool&lt;/a&gt; to look at MCP servers and understand more about how they interact with clients.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code data-lang=&#34;bash&#34;&gt;npx @modelcontextprotocol/inspector node&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;(thereâ€™s also a &lt;a href=&#34;https://github.com/wong2/mcp-cli?tab=readme-ov-file&#34;&gt;CLI MCP inspector&lt;/a&gt;, if you prefer)&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;You can specify both local or remote MCP servers.
Hereâ€™s the above local Strava MCP server.
Itâ€™s a &lt;code&gt;stdio&lt;/code&gt; server and so I just specify the command to launch itâ€”&lt;code&gt;node&lt;/code&gt; plus the code file of the server:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/fa29490d2144779ec1176a9e1c36b136a80808501590524648faec44011cb56a.webp&#34; alt=&#34;fa29490d2144779ec1176a9e1c36b136a80808501590524648faec44011cb56a&#34; width=&#34;600&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Once connected, &lt;code&gt;List Tools&lt;/code&gt; will show me the available tools (in this case, the API calls that the MCP server is a wrapper for), and you can invoke a tool to see the output:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/strava1.webp&#34; alt=&#34;strava1&#34; width=&#34;900&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The list of tools describes to the LLM what each does, the output itâ€™ll getâ€”and what input it can give to the command.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/strava2.webp&#34; alt=&#34;strava2&#34; width=&#34;800&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;For example, I might use natural language to ask for some running recommendations, and the LLM will understand that it can use this particular tool (API call) to look up some routes:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/2025-09-03T11-34-53-950Z.webp&#34; alt=&#34;2025 09 03T11 34 53 950Z&#34; width=&#34;600&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;By using the MCP Inspector you can look at the actual output from the tool (API call); the above image shows how the LLM then weaves this output into the conversation:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/2025-09-03T11-37-04-569Z.webp&#34; alt=&#34;2025 09 03T11 37 04 569Z&#34; width=&#34;400&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_the_sum_is_greater_than_the_parts&#34;&gt;The sum is greater than the parts&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In the example above I showed the LLM getting running routes from the Strava MCP.
If you look closer though, the LLM is using another MCP server (the &amp;#34;Location&amp;#34; one that Raycast provides) to find out the latitude and longitude of Ilkley.
Thatâ€™s because the LLM itself doesnâ€™t know where Ilkley actually &lt;em&gt;is&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This is a nice example of where the natural language side of LLMs can benefit from all the data enrichment that MCP servers can provide.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/strava-mcp-local1.webp&#34; alt=&#34;strava mcp local1&#34; width=&#34;400&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_its_not_all_just_api_calls&#34;&gt;Itâ€™s not all just API calls&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;So API calls == MCP Server &lt;a href=&#34;https://modelcontextprotocol.io/docs/learn/server-concepts#tools-ai-actions&#34;&gt;Tools&lt;/a&gt;.
There are also &lt;a href=&#34;https://modelcontextprotocol.io/docs/learn/server-concepts#resources-context-data&#34;&gt;Resources&lt;/a&gt;, and &lt;a href=&#34;https://modelcontextprotocol.io/docs/learn/server-concepts#prompts-interaction-templates&#34;&gt;Prompts&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Hereâ€™s an example of a Prompt from an MCP server provided by Cloudflare:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/2025-09-03T13-37-18-832Z.webp&#34; alt=&#34;2025 09 03T13 37 18 832Z&#34; width=&#34;900&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Bringing all three together is the &lt;a href=&#34;https://github.com/github/github-mcp-server&#34;&gt;GitHub MCP Server&lt;/a&gt;.
First up are the &lt;strong&gt;tools&lt;/strong&gt;, which are similar to what we saw above - nice wrappers around an existing API:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/2025-09-03T14-22-35-415Z.webp&#34; alt=&#34;2025 09 03T14 22 35 415Z&#34; width=&#34;900&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Paired with an LLM they make it easy to &amp;#34;talk&amp;#34; to your repos:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/2025-09-03T14-21-38-119Z.webp&#34; alt=&#34;2025 09 03T14 21 38 119Z&#34; width=&#34;600&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Next are the &lt;strong&gt;prompts&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/2025-09-03T14-29-41-547Z.webp&#34; alt=&#34;2025 09 03T14 29 41 547Z&#34; width=&#34;500&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;And then finally &lt;strong&gt;resources&lt;/strong&gt;.
These are accessed either directly (if provided by the MCP, which theyâ€™re not here) or via &lt;strong&gt;resource templates&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/2025-09-03T14-31-31-468Z.webp&#34; alt=&#34;2025 09 03T14 31 31 468Z&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;A resource template explains to the LLM the fields to provide to identify a particular resource.
For example, if you wanted your LLM to access a particular file in the repository it would be able to find it.
Hereâ€™s an example of accessing &lt;a href=&#34;https://github.com/rmoff/rmoff-blog/blob/main/README.adoc&#34;&gt;my blog repositoryâ€™s README&lt;/a&gt;:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2025/09/2025-09-03T14-35-32-057Z.webp&#34; alt=&#34;2025 09 03T14 35 32 057Z&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This means that an LLM can then (with the appropriate permissions) access files in GitHub, which is pretty handy.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_more_reading&#34;&gt;More reading&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://modelcontextprotocol.io/&#34;&gt;The MCP specification&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸŽ¥ &lt;a href=&#34;https://www.youtube.com/watch?v=FLpS7OfD5-s&#34;&gt;Model Context Protocol with Tim Berglund&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.reddit.com/r/mcp/&#34;&gt;r/mcp&lt;/a&gt;: &lt;a href=&#34;https://www.reddit.com/r/mcp/comments/1mj0fxs/i_spent_3_weeks_building_my_dream_mcp_setup_and/&#34;&gt;&amp;#34;I spent 3 weeks building my &amp;#34;dream MCP setup&amp;#34; and honestly, most of it was useless&amp;#34;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.confluent.io/blog/ai-agents-using-anthropic-mcp/&#34;&gt;A good MCP explanation, plus examples using Confluent MCP server&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://seanfalconer.medium.com/is-mcp-the-new-rest-or-the-next-betamax-a9151ba8ccb3&#34;&gt;â€‹â€‹Is MCP the New REST or the Next Betamax? - Sean Falconer&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
    </item>
    <item>
      <title>Interesting links - August 2025</title>
      <link>https://rmoff.net/2025/08/21/interesting-links-august-2025/</link>
      <pubDate>2025-08-21</pubDate>
      
      <guid>https://rmoff.net/2025/08/21/interesting-links-august-2025/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2025/08/t_IMG_2177.webp" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;Not got time for all this? Iâ€™ve marked ðŸ”¥ for my top reads of the month&lt;/em&gt; :)&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;admonitionblock tip&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td class=&#34;icon&#34;&gt;
&lt;div class=&#34;title&#34;&gt;Tip&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&#34;content&#34;&gt;
You can find previous editions of &lt;em&gt;Interesting Links&lt;/em&gt; &lt;a href=&#34;https://rmoff.net/categories/interesting-links/&#34;&gt;here&lt;/a&gt;.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_data_engineering&#34;&gt;Data Engineering&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ Ben Rogojan (a.k.a. SeattleDataGuy) has a great list of &lt;a href=&#34;https://seattledataguy.substack.com/p/5-things-in-data-engineering-that&#34;&gt;5 Things in Data Engineering That Still Hold True After 10 Years&lt;/a&gt; (&lt;em&gt;guess what: data modelling matters, if you start with crap data youâ€™ll end with crap data, and so onâ€¦&lt;/em&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Veronika Durgin shares some &lt;a href=&#34;https://freedium.cfd/https://medium.com/@durginv/self-recovering-data-pipelines-c1e4e6b7fbce&#34;&gt;good tips for building resilient data pipelines&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Some good pointers for why you might want to &lt;a href=&#34;https://freedium.cfd/https://blog.dataengineerthings.org/data-platform-modernization-how-to-pick-your-stack-in-2025-part-1-da9045b0b4ed&#34;&gt;modernise your data platform&lt;/a&gt;, and &lt;a href=&#34;https://freedium.cfd/https://blog.dataengineerthings.org/data-platform-modernization-how-to-pick-your-stack-in-2025-part-2-023308ffc276&#34;&gt;how to pick your stack if you do so&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ Aleksandr Klein has a thoughtful post about &lt;a href=&#34;https://freedium.cfd/https://medium.com/justeattakeaway-tech/the-mythic-journey-of-data-quality-maturity-df7b14524180&#34;&gt;The Mythic Journey of Data Quality Maturity&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A useful post from Fiore Mario Vitale showing the use of OpenLineage to &lt;a href=&#34;https://debezium.io/blog/2025/07/21/openlineage-debezium-flink/&#34;&gt;troubleshoot data pipelines&lt;/a&gt; in Debezium and Flink.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_data_in_action&#34;&gt;Data in Action&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Building your own data ingestion framework may be a siren song for many, but Cloudflare operate at the kind of scale where itâ€™s perhaps worth it. Read about &lt;a href=&#34;https://blog.cloudflare.com/building-jetflow-a-framework-for-flexible-performant-data-pipelines-at-cloudflare/&#34;&gt;Jetflow&lt;/a&gt; here.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Nubank have published a &lt;a href=&#34;https://building.nubank.com/scaling-fraud-defense-how-nubank-evolved-its-risk-analysis-platform/&#34;&gt;series&lt;/a&gt; of &lt;a href=&#34;https://building.nubank.com/mastering-streaming-data/&#34;&gt;interesting&lt;/a&gt; &lt;a href=&#34;https://building.nubank.com/avalanche-stack-and-real-time-streaming-applications-at-nu/&#34;&gt;blog posts&lt;/a&gt; about their use of stream processing, including with Kafka and Flink. Thereâ€™s also a &lt;a href=&#34;https://www.youtube.com/watch?v=awhhBlg1SqY&#34;&gt;meetup recording&lt;/a&gt; (in Spanish) that looks like it has lots more details.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Details from UK Bank Monzo on their Go-based &lt;a href=&#34;https://monzo.com/blog/build-a-reactive-fraud-prevention-platform&#34;&gt;fraud prevention platform&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ Excellent blog post from Anton Borisov at Fresha detailing why and how they &lt;a href=&#34;https://freedium.cfd/https://medium.com/fresha-data-engineering/how-we-accidentally-became-one-of-uks-first-starrocks-production-pioneers-7db249f10010&#34;&gt;adopted StarRocks&lt;/a&gt; after finding that Snowflake &amp;#34;&lt;em&gt;wasnâ€™t cost-effective â€” or fast enough â€” for chatty, near-real-time product and operational analytics.&lt;/em&gt;&amp;#34;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Guidewire have published a couple of interesting blog posts looking at their &lt;a href=&#34;https://freedium.cfd/https://medium.com/guidewire-engineering-blog/how-to-test-data-ingestion-pipeline-performance-at-scale-in-the-cloud-2862a86e598d&#34;&gt;data platform design, testing&lt;/a&gt;, and &lt;a href=&#34;https://freedium.cfd/https://medium.com/guidewire-engineering-blog/how-we-cut-operating-costs-by-80-while-ensuring-data-integrity-at-scale-fc798ecc35fc&#34;&gt;optimisation&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_apache_kafka&#34;&gt;Apache Kafka&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Trendyolâ€™s Ahmet Tortumlu walks through the process they follow when &lt;a href=&#34;https://freedium.cfd/https://medium.com/trendyol-tech/node-replacement-in-kafka-lessons-from-a-kraft-controller-08dc5badb018&#34;&gt;replacing KRaft controller nodes&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A look at how you could use Kafka to &lt;a href=&#34;https://freedium.cfd/https://medium.com/@denizhan.aras/coding-the-standards-i-real-time-baggage-tracking-system-with-iata-r753-spring-boot-kafka-b1f5e8c568c1&#34;&gt;implement the international baggage tracking system (&amp;#34;IATA R753&amp;#34;)&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ The &lt;a href=&#34;https://old.reddit.com/r/apachekafka&#34;&gt;&lt;code&gt;r/apachekafka&lt;/code&gt; subreddit&lt;/a&gt; recently hit 17k members. Itâ€™s a funny place, with a mix of shills, trolls, n00bs who wonâ€™t even help themselvesâ€”and some lovely community conversations that remind me why I continue to enjoy being part of it :) Here are a handful of threads that caught my eye if you want to sample the fare:&lt;/p&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://old.reddit.com/r/apachekafka/comments/1mtnm1l/best_way_to_idenditfy_job_completion_when/&#34;&gt;Best way to identify job completionâ€¦&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://old.reddit.com/r/apachekafka/comments/1mjz2xk/did_we_forget_the_primary_use_case_for_kafka/&#34;&gt;Did we forget the primary use case for Kafka?&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://old.reddit.com/r/apachekafka/comments/1mp2hjb/built_an_83000_rps_ticket_reservation_system_and/&#34;&gt;Built an 83,000+ RPS ticket reservation systemâ€¦&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Another month, another Kafka UIâ€”this time a TUI (Text User Interface) with a name Iâ€™ll drink to: &lt;a href=&#34;https://github.com/jonas-grgt/ktea&#34;&gt;ktea&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A &lt;a href=&#34;https://freedium.cfd/https://medium.com/cloudnativepub/evolving-kafka-integration-strategy-choosing-the-right-tool-as-requirements-grow-d9f7aaf56d80&#34;&gt;practical guide on different techniques to use&lt;/a&gt; when using Kafka for integration.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A well-written &lt;a href=&#34;https://freedium.cfd/https://newfrontcreative.medium.com/escaping-the-void-of-the-data-abyss-337770a39fbc&#34;&gt;two&lt;/a&gt; &lt;a href=&#34;https://freedium.cfd/https://newfrontcreative.medium.com/beyond-the-data-abyss-6bf2d1e6e34a&#34;&gt;part&lt;/a&gt; account of Nikeâ€™s journey from TSV (&lt;em&gt;shudder&lt;/em&gt;) to Protobuf for their data pipelines.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;After talks about Northguard and Xinfra in April, LinkedInâ€™s Stream Processing meetup continued with its impressive content in July hosting three talks:&lt;/p&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=J55KzysEPHk&amp;amp;t=35s&#34;&gt;Scaling Kafka for Netflixâ€™s Record-Breaking Live Events&lt;/a&gt; (Harshit Mittal, Netflix)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=J55KzysEPHk&amp;amp;t=1920s&#34;&gt;Kafka-less, Cloud-Native Stream Processing with Apache Beam and Iceberg&lt;/a&gt; (Talat Uyarer, Google)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ &lt;a href=&#34;https://www.youtube.com/watch?v=J55KzysEPHk&amp;amp;t=4316s&#34;&gt;Scaling Real-Time Usage Billing to Billions of Events per Day&lt;/a&gt; (Nick Dellamaggiore, Metronome)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_open_table_formats_catalogs&#34;&gt;Open Table Formats &amp;amp; Catalogs&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;Letâ€™s be honest, itâ€™s mostly just Apache Icebergâ€¦&lt;/em&gt;ðŸ˜…&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ I spent some time looking into Flink vs Kafka Connect vs Tableflow for getting data into Iceberg, and wrote up some of the comparison points: &lt;a href=&#34;https://rmoff.net/2025/08/18/kafka-to-iceberg-exploring-the-options/&#34;&gt;Kafka to Iceberg - Exploring the Options&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Aiven published &lt;a href=&#34;https://github.com/Aiven-Open/tiered-storage-for-apache-kafka/blob/main/iceberg_whitepaper.md&#34;&gt;a whitepaper&lt;/a&gt; with details of their plans for writing to Iceberg directly from Kafka&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;David Reger published a &lt;a href=&#34;https://blog.msgdataplatform.com/from-kafka-topics-to-iceberg-with-confluent-tableflow-5708e02d0d0a&#34;&gt;detailed writeup&lt;/a&gt; of Tableflow (Confluentâ€™s tool for getting data from Kafka to Iceberg).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A while back &lt;a href=&#34;https://lakefs.io/blog/data-engineering-patterns-write-audit-publish/&#34;&gt;I wrote about&lt;/a&gt; the Write-Audit-Publish pattern, and so enjoyed reading these two blog posts from TurÃ³czy Attila about &lt;a href=&#34;https://freedium.cfd/https://medium.com/@aturoczy/elegant-etl-with-apache-iceberg-branching-489a3bb89a41&#34;&gt;branching&lt;/a&gt; and &lt;a href=&#34;https://freedium.cfd/https://medium.com/@aturoczy/tagging-in-apache-iceberg-fdb7a19c0bf2&#34;&gt;tagging&lt;/a&gt; in Apache Iceberg.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ Details of taking practical advantage of more Iceberg features including time travel and schema evolution are covered in this article about building &lt;a href=&#34;https://www.infoq.com/articles/reproducible-ml-iceberg/&#34;&gt;reproducible ML systems with Iceberg and SparkSQL&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A nice hands-on example of &lt;a href=&#34;https://freedium.cfd/https://medium.com/@aalopatin/from-kafka-to-iceberg-sinking-kafka-topics-into-iceberg-tables-e23edec2777b&#34;&gt;using the Kafka Connect Iceberg sink&lt;/a&gt; with Nessie and MinIO.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The columnar format &lt;a href=&#34;https://github.com/vortex-data/vortex&#34;&gt;Vortex&lt;/a&gt; has been &lt;a href=&#34;https://www.linuxfoundation.org/press/lf-ai-data-foundation-hosts-vortex-project-to-power-high-performance-data-access-for-ai-and-analytics&#34;&gt;donated&lt;/a&gt; to the Linux Foundation. Earlier this year there was a &lt;a href=&#34;https://spiraldb.com/post/vortex-on-ice&#34;&gt;PoC to show how it can speed up Iceberg queries&lt;/a&gt;, with an &lt;a href=&#34;https://www.youtube.com/watch?v=p6ZKY8JViCA&#34;&gt;interesting talk&lt;/a&gt; at Iceberg Summit on the same.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A &lt;a href=&#34;https://www.alibabacloud.com/blog/apache-paimon-real-time-lake-storage-with-iceberg-compatibility-2025_602485&#34;&gt;comprehensive introduction&lt;/a&gt; summarised from &lt;a href=&#34;https://www.youtube.com/watch?v=LEdz53_diW4&amp;amp;list=PLDX4T_cnKjD2qa7EwyxHb9H8pBACbGkkE&amp;amp;index=4&#34;&gt;a talk&lt;/a&gt; at this yearâ€™s Flink Forward Asia conference about &amp;#34;the other&amp;#34; open table format that people often forgetâ€”Apache Paimon. TIL it supports integration with Iceberg.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_stream_processing&#34;&gt;Stream Processing&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://flink.apache.org/2025/07/31/apache-flink-2.1.0-ushers-in-a-new-era-of-unified-real-time-dataâ€”â€‹ai-with-comprehensive-upgrades/&#34;&gt;Apache Flink 2.1.0&lt;/a&gt; has been released&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ming Hung Tsai wrote a &lt;a href=&#34;https://itnext.io/scaling-to-1-million-ticket-reservations-part-1-dataflow-architecture-c6d0c792244a&#34;&gt;three&lt;/a&gt; &lt;a href=&#34;https://itnext.io/scaling-to-1-million-ticket-reservations-part-2-data-driven-optimizations-228c6a52e00a&#34;&gt;part&lt;/a&gt; &lt;a href=&#34;https://itnext.io/scaling-to-1-million-ticket-reservations-part-3-infra-observability-load-test-6bb55b850c72&#34;&gt;series&lt;/a&gt; showing how you could use Kafka Streams to implement a ticket reservation system (&lt;em&gt;also discussed in the Reddit thread linked above&lt;/em&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ Sometimes the old ones are the bestâ€”and this article from Tyler Akidau nine years ago is still just as important to read today if youâ€™re thinking about stream processing: &lt;a href=&#34;https://www.oreilly.com/radar/the-world-beyond-batch-streaming-102/&#34;&gt;Streaming 102: The world beyond batchâ€”The what, where, when, and how of unbounded data processing&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LinkedInâ€™s Jiangjie Qin, a PMC member for both Apache Flink and Apache Kafka, spoke at QCon SF about &lt;a href=&#34;https://www.infoq.com/presentations/stream-finch/&#34;&gt;Stream and Batch Processing Convergence in Flink&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Should you use a hammer to tighten a screw? Should you try and express &lt;em&gt;all&lt;/em&gt; your stream processing needs in SQL? &lt;a href=&#34;https://nussknacker.io/blog/why-streaming-sql-is-not-the-right-tool-for-authoring-event-driven-stream-based-algorithms/&#34;&gt;also no&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://lists.apache.org/thread/x02d8klqxqst3nwzmg2g4vh17zpg53sz&#34;&gt;FLIP-541&lt;/a&gt; is a proposal to make PyFlink more Pythonic, and looks to have wide support in the community.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Databricks &lt;a href=&#34;https://www.databricks.com/blog/introducing-real-time-mode-apache-sparktm-structured-streaming&#34;&gt;announced&lt;/a&gt; the public preview of a real-time mode for Spark Structured Streaming. It will be donated to the Apache Spark project but is currently only available on Databricks.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_rdbms_cdc&#34;&gt;RDBMS + CDC&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Debezium &lt;a href=&#34;https://debezium.io/blog/2025/08/13/debezium-3-2-1-final-released/&#34;&gt;3.2.1.Final&lt;/a&gt; and &lt;a href=&#34;https://debezium.io/blog/2025/08/05/debezium-3-3-alpha1-released/&#34;&gt;3.3.0.Alpha1&lt;/a&gt; have been released&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Yingjun Wu has written a &lt;a href=&#34;https://freedium.cfd/https://medium.com/@yingjunwu/why-we-didnt-rewrite-debezium-in-rust-66c35ae9dce8&#34;&gt;good explanation&lt;/a&gt; about why RisingWave use the embedded &lt;a href=&#34;https://debezium.io/documentation//reference/stable/development/engine.html&#34;&gt;Debezium Engine&lt;/a&gt; in their productâ€”and why they didnâ€™t rewrite it in Rust to match the rest of their product code.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A practical guide from Nick Tobey on &lt;a href=&#34;https://www.dolthub.com/blog/2024-06-25-polymorphic-associations/&#34;&gt;choosing a database schema for polymorphic data&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ Richard van der Hoff writes about something to strike fear into any DBAâ€™s heart: corruption in the database. In this case, a &lt;a href=&#34;https://matrix.org/blog/2025/07/postgres-corruption-postmortem/&#34;&gt;corrupted Postgres index&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;More Postgres goodness, this time from Gunnar Morling: &lt;a href=&#34;https://www.morling.dev/blog/postgres-replication-slots-confirmed-flush-lsn-vs-restart-lsn/&#34;&gt;Postgres Replication Slots: Confirmed Flush LSN vs. Restart LSN&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_general_data_stuff&#34;&gt;General Data Stuff&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ðŸ”¥ Hot off the press is another banger from Jack Vanlightly, this time looking at &lt;a href=&#34;https://jack-vanlightly.com/blog/2025/8/21/a-conceptual-model-for-storage-unification&#34;&gt;A Conceptual Model for Storage Unification&lt;/a&gt;. If youâ€™re interested in things like writing Kafka data to Iceberg, this is a vital foundation for understanding the design considerations and trade-offs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;How Klaviyo use Ray for their &lt;a href=&#34;https://freedium.cfd/https://klaviyo.tech/ray-data-train-tune-at-klaviyo-bca9f14abf21&#34;&gt;scalable data processing, training, and optimization&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Prompted by &lt;a href=&#34;https://www.youtube.com/watch?v=z5t3b3EAc84&amp;amp;t=360s&#34;&gt;a talk that Tesla gave&lt;/a&gt; about ingesting metrics into ClickHouse, Javier Santana at TinyBird &lt;a href=&#34;https://www.tinybird.co/blog-posts/1b-rows-per-second-clickhouse&#34;&gt;set out to reproduce the feat using a 50-node ClickHouse cluster&lt;/a&gt;. In a sense these exercises are somewhat BSD and clickbait-y, but I do like the clear steps and detail that he showed in the blog post :).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ If anyone is going to need to build their own time-series database (TSDB), Datadog is going to be one of the top contenders. In &lt;a href=&#34;https://www.datadoghq.com/blog/engineering/rust-timeseries-engine/&#34;&gt;this blog post&lt;/a&gt; they write about how they built it using Rust and the benefits they saw (60x ingest, 5x query). Also interesting is &lt;a href=&#34;https://www.datadoghq.com/blog/engineering/rust-timeseries-engine/#how-we-built-the-6th-generation-of-our-real-time-metrics-storage&#34;&gt;the history&lt;/a&gt; of their previous TSDB platforms.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cwida/FastLanes&#34;&gt;FastLanes&lt;/a&gt; describes itself as a &lt;em&gt;Next-Gen Big Data File Format&lt;/em&gt;, aimed as a replacement to columnar formats such as the somewhat-ubiquitous Parquet. Beyond several &lt;a href=&#34;https://github.com/cwida/FastLanes?tab=readme-ov-file#publications&#34;&gt;conference papers&lt;/a&gt; itâ€™s unclear if thereâ€™s any adoption of the format in the wild yet.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_and_finally&#34;&gt;And finallyâ€¦&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;Nothing to do with data, but stuff that Iâ€™ve found interesting or has made me smile.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ðŸ”¥ Brad Stulbergâ€™s article &lt;a href=&#34;https://freedium.cfd/https://bstulberg.medium.com/motivation-is-overrated-heres-what-works-instead-7c5744efd82f&#34;&gt;Motivation is Overrated: Hereâ€™s What Works Instead&lt;/a&gt; is down to earth and well worth a read.&lt;/p&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;you cannot replace negative thinking with positive thinking. But you can replace negative thinking with positive action.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Iâ€™m not going to even pretend to understand the first thing in these organic simulation algorithms, but gosh, &lt;a href=&#34;https://bleuje.com/physarum-explanation/&#34;&gt;donâ€™t they make pretty pictures&lt;/a&gt;!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.al3rez.com/todo-txt-journey&#34;&gt;I Tried Every Todo App and Ended Up With a &lt;code&gt;.txt&lt;/code&gt; File&lt;/a&gt; â€” This one hit a bit close to homeâ€¦&lt;/p&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Iâ€™d devour blog posts about getting things done or spot a cool app and think â€œthis is it, this will finally organize me.â€ Iâ€™d burn hours building the perfect system, creating categories, tags, projects, labels. Setting it up felt like work.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A healthy dose of nostalgia from &lt;a href=&#34;https://blog.decryption.net.au/posts/macpaint.html&#34;&gt;MacPaint Art From The Mid-80s Still Looks Great Today&lt;/a&gt; (&lt;em&gt;although cards on the table, I was on the BBC Micro/Acorn Archimedes side of things&lt;/em&gt; ðŸ˜…)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It may seem odd to compile a list of &amp;#34;Why I want to leave&amp;#34; the day that you start a new job, but &lt;a href=&#34;https://blog.incrementalforgetting.tech/p/the-why-i-want-to-leave-list&#34;&gt;this article makes a compelling case&lt;/a&gt; for starting, and maintaining, such a list.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;hr/&gt;
&lt;div class=&#34;admonitionblock note&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td class=&#34;icon&#34;&gt;
&lt;div class=&#34;title&#34;&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&#34;content&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If you like these kind of links you might like to read about &lt;a href=&#34;https://rmoff.net/2024/05/22/how-i-try-to-keep-up-with-the-data-tech-world-a-list-of-data-blogs/&#34;&gt;How I Try To Keep Up With The Data Tech World (A List of Data Blogs)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Iâ€™m linking out to &lt;a href=&#34;https://freedium.cfd/&#34;&gt;Freedium&lt;/a&gt; versions of Medium posts, because Medium seems to be pay-walling a bunch of otherwise-freely accessible content.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
    </item>
    <item>
      <title>Kafka to Iceberg - Exploring the Options</title>
      <link>https://rmoff.net/2025/08/18/kafka-to-iceberg-exploring-the-options/</link>
      <pubDate>2025-08-18</pubDate>
      
      <guid>https://rmoff.net/2025/08/18/kafka-to-iceberg-exploring-the-options/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2025/08/t_IMG_1923.webp" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Youâ€™ve got data in &lt;a href=&#34;https://www.youtube.com/watch?v=9CrlA0Wasvk&#34;&gt;Apache Kafka&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;You want to get that data into &lt;a href=&#34;https://www.youtube.com/watch?v=TsmhRZElPvM&#34;&gt;Apache Iceberg&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Whatâ€™s the best way to do it?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2025/08/kafka-to-iceberg.png&#34; alt=&#34;kafka to iceberg&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Perhaps invariably, the answer is: &lt;strong&gt;IT DEPENDS&lt;/strong&gt;.
But fear not: here is a guide to help you navigate your way to choosing the best solution &lt;em&gt;for you&lt;/em&gt; ðŸ«µ.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_the_candidates&#34;&gt;The Candidates&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Iâ€™m considering three technologies in this blog post:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-master/docs/dev/table/sql/gettingstarted/#hello-world&#34;&gt;Apache Flink SQL&lt;/a&gt; (open source)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://kafka.apache.org/documentation.html#connect&#34;&gt;Kafka Connect&lt;/a&gt; (open source)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.confluent.io/product/tableflow/&#34;&gt;Confluent Tableflow&lt;/a&gt; ($)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;There are others, and Iâ€™ll mention those &lt;a href=&#34;#_but_what_about_this_other_tool&#34;&gt;at the end&lt;/a&gt;.
The one that Iâ€™ve really not looked at, and is perhaps conspicuous by its absence, is Apache Spark.
If youâ€™re interested in Spark, check out &lt;a href=&#34;https://www.youtube.com/watch?v=5pXfznKniGg&#34;&gt;this video from Danica Fine&lt;/a&gt; in which she covers it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;admonitionblock note&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td class=&#34;icon&#34;&gt;
&lt;i class=&#34;fa icon-note&#34; title=&#34;Note&#34;&gt;&lt;/i&gt;
&lt;/td&gt;
&lt;td class=&#34;content&#34;&gt;
&lt;em&gt;Disclaimer: I work for Confluent, but will do my best to remain impartial in this article.&lt;/em&gt; ðŸ˜€
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_the_approach&#34;&gt;The Approach&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Iâ€™ve framed this blog post around the key areas that you can use as the basis for making your decision.
Some of these will be show-stoppers and rule a particular option out, whilst others are simply gentle nudges that one tool might be preferred over another.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Iâ€™m going to break the areas of consideration down into two (and a bit) areas:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Your data&lt;/strong&gt;: including where itâ€™s from, what youâ€™re doing with it, how itâ€™s structured, and how many topics&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Living with it&lt;/strong&gt;: important factors such as whatâ€™s your existing deployment (if any), preference for self-managed vs SaaS, and table maintenance&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Other&lt;/strong&gt;: licensing, support for other formats, other bits and pieces&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_tool_overview&#34;&gt;Tool overview&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Before we get into it, letâ€™s take a quick look at what the three tools are and how they integrate with Iceberg.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_apache_flink_sql&#34;&gt;Apache Flink SQL&lt;/h3&gt;
&lt;div class=&#34;admonitionblock tip&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td class=&#34;icon&#34;&gt;
&lt;i class=&#34;fa icon-tip&#34; title=&#34;Tip&#34;&gt;&lt;/i&gt;
&lt;/td&gt;
&lt;td class=&#34;content&#34;&gt;
Read more: &lt;a href=&#34;https://rmoff.net/2025/06/24/writing-to-apache-iceberg-on-s3-using-flink-sql-with-glue-catalog/&#34;&gt;Writing to Apache Iceberg using Flink SQL&lt;/a&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Flink SQL jobs run on a Flink cluster.
They do not require Kafka (unless you are specifically reading or writing to itâ€”such as in this article).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Source and targets are defined as tables using DDL, with the integration (such as Kafka or Iceberg) specified as a connector type.
Target tables are loaded as a stream using either &lt;code&gt;CREATE TABLE â€¦ AS SELECT&lt;/code&gt; or a standalone &lt;code&gt;INSERT INTO&lt;/code&gt; after defining the target table first.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;There are some &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-master/docs/connectors/table/overview/#supported-connectors&#34;&gt;connectors available within Flink&lt;/a&gt;, along with notable standalone connectors including &lt;a href=&#34;https://nightlies.apache.org/flink/flink-cdc-docs-master/docs/connectors/flink-sources/overview/&#34;&gt;Flink CDC&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_kafka_connect&#34;&gt;Kafka Connect&lt;/h3&gt;
&lt;div class=&#34;admonitionblock tip&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td class=&#34;icon&#34;&gt;
&lt;i class=&#34;fa icon-tip&#34; title=&#34;Tip&#34;&gt;&lt;/i&gt;
&lt;/td&gt;
&lt;td class=&#34;content&#34;&gt;
Read more: &lt;a href=&#34;https://rmoff.net/2025/07/04/writing-to-apache-iceberg-on-s3-using-kafka-connect-with-glue-catalog/&#34;&gt;Writing to Apache Iceberg using Kafka Connect&lt;/a&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Kafka Connect runs on a Kafka Connect worker cluster.
It is a pluggable ecosystem, providing an integration runtime that handles common tasks whilst individual connectors handle the technology-specific requirements.
It uses a Kafka broker to track configuration and processing status.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;You define &lt;em&gt;connector&lt;/em&gt; jobs using JSON configuration, submitted using a REST API.
There are &lt;a href=&#34;https://hub.confluent.io&#34;&gt;hundreds of connectors&lt;/a&gt; available for Kafka Connect.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_tableflow&#34;&gt;Tableflow&lt;/h3&gt;
&lt;div class=&#34;admonitionblock tip&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td class=&#34;icon&#34;&gt;
&lt;i class=&#34;fa icon-tip&#34; title=&#34;Tip&#34;&gt;&lt;/i&gt;
&lt;/td&gt;
&lt;td class=&#34;content&#34;&gt;
Read more: &lt;a href=&#34;https://www.confluent.io/blog/building-streaming-data-pipelines-part-1/#exposing-apache-kafka-topics-as-apache-icebergtm%EF%B8%8F-tables-with-tableflow&#34;&gt;Exposing Kafka Topics as Iceberg Tables With Tableflow&lt;/a&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Tableflow is a managed service as part of Confluent Cloud for streaming data from Apache Kafka topics into Apache Iceberg tables.
You can use it with any topic in Confluent Cloud that has a schema.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Confluent Cloud also provides &lt;a href=&#34;https://docs.confluent.io/cloud/current/connectors/overview.html&#34;&gt;managed connectors&lt;/a&gt; (giving you access to a &lt;a href=&#34;https://hub.confluent.io&#34;&gt;huge ecosystem of source connectors&lt;/a&gt;) and &lt;a href=&#34;https://docs.confluent.io/cloud/current/flink/overview.html&#34;&gt;managed Flink SQL&lt;/a&gt; (for doing any processing on the data before sending it to Iceberg).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_your_data&#34;&gt;Your Data&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;Letâ€™s start off the comparison by thinking about the data that weâ€™ve got in Kafka and want to get into Iceberg.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_where_is_the_data_coming_from&#34;&gt;Where is the data coming from?&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This article is focussed on data &lt;strong&gt;in&lt;/strong&gt; Kafka, but that data came from somewhere.
Perhaps itâ€™s applications writing directly to it, in which case it has no bearing on your technology of choice.
However, if your data is coming into Kafka from other systems, youâ€™ll find that &lt;strong&gt;Kafka Connect&lt;/strong&gt; and Confluent Cloud (for &lt;strong&gt;Tableflow&lt;/strong&gt;) have a richer set of connectors than &lt;strong&gt;Flink&lt;/strong&gt;.
Flink does have several, including Flink CDC (which is built on Debezium).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Under this consideration also think about whether you want the data in Kafka for other purposes.
Flink can take data directly from a source (e.g. RDBMS) directly into Iceberg and not write it in Kafka.
This might simplify your pipeline, but it also means the same source data isnâ€™t then available for use by other integrations or applications.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_how_many_topics_do_you_have&#34;&gt;How many topics do you have?&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;There are two variants of this.
The first is where you have multiple topics for &lt;em&gt;different entities&lt;/em&gt;.
For example, youâ€™ve got &lt;code&gt;orders&lt;/code&gt;, &lt;code&gt;customers&lt;/code&gt;, &lt;code&gt;products&lt;/code&gt;, &lt;code&gt;inventory&lt;/code&gt;â€¦theyâ€™re all different, and theyâ€™re all going to their own respective Iceberg table.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2025/08/different-topics.excalidraw.png&#34; alt=&#34;different topics.excalidraw&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The second is where itâ€™s multiple instances of &lt;em&gt;the same entity&lt;/em&gt;.
This is very common in multi-tenant architectures.
Maybe each customer has their own &lt;code&gt;transactions&lt;/code&gt; topic, and youâ€™re wanting to populate a single consolidated Iceberg table from them.
Another example of this would be where topics are geographically isolated (perhaps across Kafka different clusters, and then replicated into a central one), from where theyâ€™re all to be written to a single Iceberg table.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2025/08/same-topics.excalidraw.png&#34; alt=&#34;same topics.excalidraw&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;So, if either of these scenarios apply to your data, how does it impact your tool choice?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In &lt;strong&gt;Flink SQL&lt;/strong&gt; every unique source schema must be explicitly defined.
Thereâ€™s no automagic population from a schema registry.
This means that if you have four different topics you need to declare eight Flink SQL tables.
Bear in mind with Flink SQL itâ€™s not only the table name but its schema too that needs specifying.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;TABLE&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;src&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;orders&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;orderID&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;INT&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;customerID&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;INT&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;product&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;STRING&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;quantity&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;INT&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;orderTS&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;TIMESTAMP&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;3&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;)&lt;/span&gt;
    &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;WITH&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;connector&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;kafka&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;topic&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;orders&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #960050;background-color: #1e0010&#34;&gt;â€¦&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;]);&lt;/span&gt;

&lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;TABLE&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;src&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;customers&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;customerID&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;INT&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;firstName&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;STRING&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;lastName&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;STRING&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;email&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;STRING&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;createdTS&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;TIMESTAMP&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;3&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;)&lt;/span&gt;
    &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;WITH&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;connector&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;kafka&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;topic&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;customers&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #960050;background-color: #1e0010&#34;&gt;â€¦&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;]);&lt;/span&gt;

&lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;TABLE&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;src&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;products&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;productID&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;INT&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;sku&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;STRING&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;name&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;STRING&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;unitPrice&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;DECIMAL&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;10&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;),&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;updatedTS&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;TIMESTAMP&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;3&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;)&lt;/span&gt;
    &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;WITH&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;connector&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;kafka&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;topic&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;products&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #960050;background-color: #1e0010&#34;&gt;â€¦&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;]);&lt;/span&gt;

&lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;TABLE&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;src&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;inventory&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;productID&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;INT&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;locationID&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;STRING&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;onHand&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;INT&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;reserved&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;INT&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;invTS&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;TIMESTAMP&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;3&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;)&lt;/span&gt;
    &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;WITH&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;connector&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;kafka&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;topic&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;inventory&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #960050;background-color: #1e0010&#34;&gt;â€¦&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;]);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Now if you want to write these to Iceberg tables, you need to declare an Iceberg table for each:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;dest&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;orders&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;WITH&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;connector&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;iceberg&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #960050;background-color: #1e0010&#34;&gt;â€¦&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;])&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;AS&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;FROM&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;src&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;orders&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;;&lt;/span&gt;
&lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;dest&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;customers&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;WITH&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;connector&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;iceberg&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #960050;background-color: #1e0010&#34;&gt;â€¦&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;])&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;AS&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;FROM&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;src&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;customers&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;;&lt;/span&gt;
&lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;dest&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;products&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;WITH&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;connector&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;iceberg&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #960050;background-color: #1e0010&#34;&gt;â€¦&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;])&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;AS&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;FROM&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;src&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;products&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;;&lt;/span&gt;
&lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;dest&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;inventory&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;WITH&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;connector&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;iceberg&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #960050;background-color: #1e0010&#34;&gt;â€¦&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;])&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;AS&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;FROM&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;src&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;inventory&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;However, if youâ€™ve got multiple topics &lt;em&gt;with the same schema&lt;/em&gt; then things are a bit easier since &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-master/docs/connectors/table/kafka/#connector-options&#34;&gt;the Kafka connector in Flink SQL&lt;/a&gt; does support wildcards (&lt;code&gt;topic-pattern&lt;/code&gt;) or a list of topics (&lt;code&gt;topic&lt;/code&gt; with semi-colon separated topics).
You can also add &lt;code&gt;topic&lt;/code&gt; as a &lt;em&gt;metadata&lt;/em&gt; column to your source table so that it is exposed for writing to Icebergâ€”important if you want to retain the lineage information of your data.
Hereâ€™s an example of fan-in (N:1) in Flink SQL.
First, create the source table reading from multiple topics:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;TABLE&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;src&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;kafka_transactions_all&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt;
    &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;transaction_id&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;STRING&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;user_id&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;STRING&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;amount&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;DECIMAL&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;10&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;),&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;currency&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;STRING&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;merchant&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;STRING&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;transaction_time&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;TIMESTAMP&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;3&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;),&lt;/span&gt;
    &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;src_topic&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;STRING&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;METADATA&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;FROM&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;topic&amp;#39;&lt;/span&gt; &lt;i class=&#34;conum&#34; data-value=&#34;1&#34;&gt;&lt;/i&gt;&lt;b&gt;(1)&lt;/b&gt;
&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;WITH&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;(&lt;/span&gt;
    &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;connector&amp;#39;&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;kafka&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;properties.bootstrap.servers&amp;#39;&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;broker:9092&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;format&amp;#39;&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;json&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;scan.startup.mode&amp;#39;&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;earliest-offset&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;
    &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;topic-pattern&amp;#39;&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;transactions&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;\.&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;.*&amp;#39;&lt;/span&gt; &lt;i class=&#34;conum&#34; data-value=&#34;2&#34;&gt;&lt;/i&gt;&lt;b&gt;(2)&lt;/b&gt;
&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;colist arabic&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;&lt;i class=&#34;conum&#34; data-value=&#34;1&#34;&gt;&lt;/i&gt;&lt;b&gt;1&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;Topic metadata column included in the table definition&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;i class=&#34;conum&#34; data-value=&#34;2&#34;&gt;&lt;/i&gt;&lt;b&gt;2&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;Wildcard pattern for source Kafka topics&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Now letâ€™s write that to a single Iceberg table:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;TABLE&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;my_iceberg_catalog&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;my_glue_db&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;transactions_all&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;AS&lt;/span&gt;
    &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;FROM&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;src&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;kafka_transactions_all&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;You can also do fan-in (N:1) in Flink SQL using the &lt;code&gt;UNION ALL&lt;/code&gt; operator.
For example, if the above Kafka topics were defined as individual Flink SQL tables (perhaps with slightly different schemas that need unifying), you could do something like this to write them all to a single Iceberg table:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;TABLE&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;my_iceberg_catalog&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;my_glue_db&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;transactions_all&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;AS&lt;/span&gt;
    &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;SELECT&lt;/span&gt;  &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;uk&amp;#39;&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;src_topic&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;transaction_id&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;user_id&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;amount&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;currency&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;merchant&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;transaction_time&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;FROM&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;src&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;kafka_transactions_uk&lt;/span&gt;
    &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;UNION&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;ALL&lt;/span&gt;
    &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;SELECT&lt;/span&gt;  &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;eu&amp;#39;&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;src_topic&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;transaction_id&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;user_id&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;amount&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;currency&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;merchant&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;transaction_time&lt;/span&gt; &lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;FROM&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;src&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;kafka_transactions_eu&lt;/span&gt;
    &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #960050;background-color: #1e0010&#34;&gt;â€¦&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Further more to Flink SQLâ€™s flexibility is the &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-master/docs/dev/table/sql/insert/#insert-into-multiple-tables&#34;&gt;&lt;em&gt;statement sets&lt;/em&gt;&lt;/a&gt; feature, which you can use for fan-out (1:N)â€”routing data from the same source table to different target tables.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Moving onto &lt;strong&gt;Kafka Connect&lt;/strong&gt;, it supports wildcards and can do &lt;a href=&#34;https://rmoff.net/2025/07/04/writing-to-apache-iceberg-on-s3-using-kafka-connect-with-glue-catalog/#_n1_fan_in_writing_many_topics_to_one_table&#34;&gt;fan-in (N:1)&lt;/a&gt; using the &lt;code&gt;topics.regex&lt;/code&gt; parameter:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code data-lang=&#34;javascript&#34;&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;topics.regex&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;src.*&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;It can also do fan-out (1:N) using the &lt;code&gt;iceberg.tables.route-field&lt;/code&gt; parameter for the Iceberg sink connector, described &lt;a href=&#34;https://rmoff.net/2025/07/04/writing-to-apache-iceberg-on-s3-using-kafka-connect-with-glue-catalog/#_1n_fan_out_writing_one_topic_to_many_tables&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;Tableflow&lt;/strong&gt; has a 1:1 relationship between Kafka topics and Iceberg tables.
It can be enabled for multiple topics easily either through the UI, or from the CLI:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color: #75715e;font-style: italic&#34;&gt;# Write topics `my_topic[1-5]` to an Iceberg table&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2&#34;&gt;$ &lt;/span&gt;confluent tableflow topic create my_topic1
&lt;span style=&#34;color: #f8f8f2&#34;&gt;$ &lt;/span&gt;confluent tableflow topic create my_topic2
&lt;span style=&#34;color: #f8f8f2&#34;&gt;$ &lt;/span&gt;confluent tableflow topic create my_topic3
&lt;span style=&#34;color: #f8f8f2&#34;&gt;$ &lt;/span&gt;confluent tableflow topic create my_topic4
&lt;span style=&#34;color: #f8f8f2&#34;&gt;$ &lt;/span&gt;confluent tableflow topic create my_topic5&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;You can achieve fan-in either by using Kafka Connect on Confluent Cloud to ingest to a single topic from multiple sources&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2025/08/kc-tf-flink-fan-in.excalidraw.png&#34; alt=&#34;kc tf flink fan in.excalidraw&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;or using Confluent Cloud for Apache Flink to &lt;code&gt;UNION&lt;/code&gt; multiple topics into one.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2025/08/tf-flink-fan-in.excalidraw.png&#34; alt=&#34;tf flink fan in.excalidraw&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Similarly, fan-out can be done using Flink to route the source topics into multiple destination ones, each of which is then enabled for Tableflow.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2025/08/tf-flink-fan-out.excalidraw.png&#34; alt=&#34;tf flink fan out.excalidraw&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_whither_schema&#34;&gt;Whither Schema?&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Sure, your data has a schema.
But does it have a &lt;em&gt;schema&lt;/em&gt;?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;If your data is just a lump of JSON like this:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code data-lang=&#34;javascript&#34;&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;{&lt;/span&gt;
    &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;click_ts&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;2023-02-01T14:30:25Z&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;
    &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;ad_cost&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;1.50&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;
    &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;is_conversion&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;
    &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;user_id&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;001234567890&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;What should the target Iceberg table look like?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;One option is that you manually created it first.
Doing this you can at least make sure that the data types are set correctly.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;If youâ€™re &lt;a href=&#34;https://rmoff.net/2025/06/24/writing-to-apache-iceberg-on-s3-using-flink-sql-with-glue-catalog/#_define_the_kafka_source&#34;&gt;using &lt;strong&gt;Flink SQL&lt;/strong&gt; to write to Iceberg&lt;/a&gt; you have to declare the datatypes as part of the source Flink table DDL.
For &lt;strong&gt;every. single. table&lt;/strong&gt;.
But at least theyâ€™ll be correct (so long as you didnâ€™t make a mistake in typing out all that DDL!).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://rmoff.net/2025/07/04/writing-to-apache-iceberg-on-s3-using-kafka-connect-with-glue-catalog/#_schemas&#34;&gt;&lt;strong&gt;Kafka Connect&lt;/strong&gt;&lt;/a&gt; will give you the option to play fast-and-loose with your schema if you want, and YOLO it by guessing.
It might work, but you might also get this:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code&gt;+----------------+----------+
|      Name      |  Type    |
+----------------+----------+
|  click_ts      |  string  | &lt;i class=&#34;conum&#34; data-value=&#34;3&#34;&gt;&lt;/i&gt;&lt;b&gt;(3)&lt;/b&gt;
|  ad_cost       |  string  | &lt;i class=&#34;conum&#34; data-value=&#34;2&#34;&gt;&lt;/i&gt;&lt;b&gt;(2)&lt;/b&gt;
|  user_id       |  string  |
|  is_conversion |  string  | &lt;i class=&#34;conum&#34; data-value=&#34;1&#34;&gt;&lt;/i&gt;&lt;b&gt;(1)&lt;/b&gt;
+----------------+----------+&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;colist arabic&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;&lt;i class=&#34;conum&#34; data-value=&#34;1&#34;&gt;&lt;/i&gt;&lt;b&gt;1&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;Storing a boolean as a string? not ideal.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;i class=&#34;conum&#34; data-value=&#34;2&#34;&gt;&lt;/i&gt;&lt;b&gt;2&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;Storing a currency as a string? not good.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;i class=&#34;conum&#34; data-value=&#34;3&#34;&gt;&lt;/i&gt;&lt;b&gt;3&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;Storing a timestamp as a string? gross.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;A better way all round to do this if youâ€™re using &lt;strong&gt;Kafka Connect&lt;/strong&gt; or &lt;strong&gt;Tableflow&lt;/strong&gt; is to have your topics&amp;#39; schemas in the &lt;a href=&#34;https://docs.confluent.io/platform/current/schema-registry/index.html&#34;&gt;Schema Registry&lt;/a&gt;.
This way the target Iceberg table can be defined correctly based on the actual schema of the dataâ€”not a guess at it:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code&gt;+----------------+-----------------+
|      Name      |  Type           |
+----------------+-----------------+
|  click_ts      |  timestamp      |
|  ad_cost       |  decimal(38,2)  |
|  user_id       |  string         |
|  is_conversion |  boolean        |
+----------------+-----------------+&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_schema_evolution&#34;&gt;Schema Evolution&lt;/h3&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Nothing is stable, even what is close to us in time&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Another consideration to bear in mind is what happens when your schema changes.
And at some point, your schema &lt;strong&gt;will&lt;/strong&gt; change.
So how do you make sure that the target Iceberg reflects those changes?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In &lt;strong&gt;Flink SQL&lt;/strong&gt; there is no way to do this without duplicating records.
Youâ€™d need to make sure that youâ€™re using &lt;code&gt;scan.startup.mode=group-offsets&lt;/code&gt; and have set &lt;code&gt;properties.group.id&lt;/code&gt; in your original DDL, then cancel the job, amend the table DDL to reflect the new schema, and then restart the job (with an &lt;code&gt;INSERT INTO&lt;/code&gt; if you were using a &lt;code&gt;CREATE TABLEâ€¦AS SELECT&lt;/code&gt; originally).
Even then, youâ€™re going to duplicate the records that were written before Flink checkpointed and saved the Kafka topic offset that it had got to.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The &lt;strong&gt;Kafka Connect&lt;/strong&gt; Iceberg sink supports &lt;a href=&#34;https://rmoff.net/2025/07/04/writing-to-apache-iceberg-on-s3-using-kafka-connect-with-glue-catalog/#_schema_evolution&#34;&gt;schema evolution&lt;/a&gt;, just make sure youâ€™ve set &lt;code&gt;iceberg.tables.evolve-schema-enabled=true&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.confluent.io/cloud/current/topics/tableflow/overview.html#schematization-and-schema-evolution&#34;&gt;&lt;strong&gt;Tableflow&lt;/strong&gt; supports schema evolution&lt;/a&gt; out of the box.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_do_you_want_some_processing_to_go_with_that&#34;&gt;Do you want some processing to go with that?&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Perhaps youâ€™re just wanting a big &amp;#39;ole dumb pipe through which to dump your data into Iceberg.
Perhaps, however, youâ€™ve decided that it would be useful to mask a few columns or filter some rows.
Maybe, even, youâ€™ve decided to &lt;a href=&#34;https://www.youtube.com/watch?v=FiZmyl1Npg0&#34;&gt;shift left&lt;/a&gt; and move a bunch of your batch workload out of the datalake and closer to the point at which the dataâ€™s created (per &lt;a href=&#34;https://ssbipolar.com/2021/05/31/roches-maxim/&#34;&gt;Rocheâ€™s maxim&lt;/a&gt;)&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This can contribute a significant amount of weighting to your tool choice.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;admonitionblock tip&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td class=&#34;icon&#34;&gt;
&lt;i class=&#34;fa icon-tip&#34; title=&#34;Tip&#34;&gt;&lt;/i&gt;
&lt;/td&gt;
&lt;td class=&#34;content&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;An added dimension to consider is &lt;em&gt;what kind of processing&lt;/em&gt; youâ€™re doing (or plausibly would want to do in the future without needing to change your architecture).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;Stateless&lt;/em&gt; means literally what it says; there is no state.
If you can process each record as it arrives without needing to build up state (like a counter, for example, or a lookup table), itâ€™s stateless.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;Stateful&lt;/em&gt;, on the other hand, is where you &lt;em&gt;do&lt;/em&gt; use state.
Common examples would be an aggregation (&lt;code&gt;COUNT&lt;/code&gt;, &lt;code&gt;SUM&lt;/code&gt;, etc), a join to enrich the data, and so on.&lt;/p&gt;
&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;If integration is Kafka Connectâ€™s &lt;em&gt;raison dâ€™Ãªtre&lt;/em&gt;, processing is Flinkâ€™s.
Itâ€™s where &lt;strong&gt;Flink SQL&lt;/strong&gt; really comes into its own, particularly for state&lt;em&gt;ful&lt;/em&gt; transformations.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;If you can express it in SQL, you can probably do it in Flink.
Joining to other data (whether in Kafka, or other systems), time-based aggregations (orders per hour, for example), sessionising and pattern matchingâ€”all of this is Flinkâ€™s bread and butter.
Flink SQL can also do stateless processing (filtering, schema projection, etc) too, and compared to Kafka Connectâ€™s Single Message Transforms (see below) definitely easier to configure (itâ€™s just SQL) and also richer in functionality.
Youâ€™ll sometimes find with Single Message Transforms that thereâ€™s a particular transformation that you need and it just doesnâ€™t exist yet.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;Kafka Connect&lt;/strong&gt; can do &lt;em&gt;stateless&lt;/em&gt; processing using Single Message Transforms.
These are configured through bits of JSON configuration, and whilst not the most intuitive way to express a transformation, they are remarkably powerful.
For example, to drop named fields from the source table so that they arenâ€™t included in the Iceberg table schema, youâ€™d add this to your connector configuration:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code data-lang=&#34;javascript&#34;&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;{&lt;/span&gt;
    &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;connector.class&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;org.apache.iceberg.connect.IcebergSinkConnector&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;
    &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #960050;background-color: #1e0010&#34;&gt;â€¦&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;]&lt;/span&gt;
    &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;transforms&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;                 &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;dropCC&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;
    &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;transforms.dropCC.type&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;     &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;org.apache.kafka.connect.transforms.ReplaceField$Value&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;,&lt;/span&gt;
    &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;transforms.dropCC.exclude&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;  &lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;col1, col4&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;There are lots of other transformations available, many part of Apache Kafka itself, others provided by the community.
I wrote a blog series about these previously: &lt;a href=&#34;https://rmoff.net/categories/twelvedaysofsmt/&#34;&gt;Twelve Days of SMT&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;Tableflow&lt;/strong&gt; is part of Confluent Cloud which means you already have access to Confluent Cloud for Apache Flink for your processingâ€”the best of both worlds!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2025/08/tf-flink.excalidraw.png&#34; alt=&#34;tf flink.excalidraw&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;If your Kafka data is coming from Kafka Connect upstream using a managed connector in Confluent Cloud you can also use Single Message Transforms at ingest.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_insert_overwrite_and_upsert&#34;&gt;&lt;code&gt;INSERT OVERWRITE&lt;/code&gt; and &lt;code&gt;UPSERT&lt;/code&gt;&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Just as schemas may change, so may the data itself.
This could be an aggregate (such as a &lt;code&gt;COUNT&lt;/code&gt;) for which more records have been received and so needs updating, or late-arriving data or data thatâ€™s been restated and needs to replace whatâ€™s there.
For whatever reason, youâ€™ll need to plan how youâ€™re going to handle this in your Iceberg table.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;One option is using &lt;code&gt;UPSERT&lt;/code&gt; or &lt;code&gt;INSERT OVERWRITE&lt;/code&gt; semantics:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;UPSERT&lt;/code&gt; is a portmanteau of the operation that it describes: attempt to &lt;strong&gt;&lt;code&gt;UP&lt;/code&gt;&lt;/strong&gt;&lt;code&gt;DATE&lt;/code&gt; a keyâ€™s value, and if the key doesnâ€™t exist then &lt;code&gt;IN&lt;/code&gt;&lt;strong&gt;&lt;code&gt;SERT&lt;/code&gt;&lt;/strong&gt; it instead.
This is a common pattern used in data engineering when loading data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;INSERT OVERWRITE&lt;/code&gt; takes a more extreme approach, and does what it says on the tin: insert values, and overwrite whatâ€™s there currently.
This would more likely be used for data housekeeping (e.g. replacing the contents of a dayâ€™s partition with a restatement of the data once late data has arrived), or dimension table repopulation (replace the entire contents of the table with the latest version of the dimension).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;Flink SQL&lt;/strong&gt; supports both &lt;a href=&#34;https://rmoff.net/2025/06/24/writing-to-apache-iceberg-on-s3-using-flink-sql-with-glue-catalog/#_upsert&#34;&gt;&lt;code&gt;UPSERT&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://rmoff.net/2025/06/24/writing-to-apache-iceberg-on-s3-using-flink-sql-with-glue-catalog/#_insert_overwrite&#34;&gt;&lt;code&gt;INSERT OVERWRITE&lt;/code&gt;&lt;/a&gt; (the latter in batch mode only, understandably).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;Kafka Connect&lt;/strong&gt; does not support either of these operations.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;admonitionblock note&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td class=&#34;icon&#34;&gt;
&lt;i class=&#34;fa icon-note&#34; title=&#34;Note&#34;&gt;&lt;/i&gt;
&lt;/td&gt;
&lt;td class=&#34;content&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The current (v1.10) version of the Apache Iceberg connector for Kafka Connect does not support &lt;code&gt;UPSERT&lt;/code&gt;.
However, an earlier incarnation of the connectorâ€”authored by Tabular, before being donated to the Apache Iceberg projectâ€”&lt;em&gt;did&lt;/em&gt; support it including for CDC-sourced data.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This means that you may see mention of the functionality, including configuration options such as &lt;code&gt;iceberg.tables.iceberg.tables.upsert-mode-enabled&lt;/code&gt; and &lt;code&gt;iceberg.tables.cdc-field&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;For more information and latest status, see &lt;a href=&#34;https://github.com/apache/iceberg/pull/12070&#34;&gt;the PR to add the functionality&lt;/a&gt;, &lt;a href=&#34;https://github.com/apache/iceberg/issues/10842&#34;&gt;the GitHub issue&lt;/a&gt;, and a &lt;a href=&#34;https://lists.apache.org/thread/96dhf3sj5pc4ql0l8yk8sxgtr78bchrd&#34;&gt;mailing list discussion&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;Tableflow&lt;/strong&gt; will support &lt;code&gt;UPSERT&lt;/code&gt; soon.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_delivery_semantics&#34;&gt;Delivery Semantics&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;Flink SQL&lt;/strong&gt; reading from Kafka and writing to Iceberg will have exactly-once semantics so long as you enable checkpointing:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;color: #66d9ef;font-weight: bold&#34;&gt;SET&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;execution.checkpointing.interval&amp;#39;&lt;/span&gt; &lt;span style=&#34;color: #f92672;font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;30s&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://iceberg.apache.org/docs/nightly/kafka-connect/#requirements&#34;&gt;&lt;strong&gt;Kafka Connect&lt;/strong&gt;&lt;/a&gt; and &lt;strong&gt;Tableflow&lt;/strong&gt; both have out-of-the-box support for exactly-once semantics for writing to Iceberg.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_living_with_it&#34;&gt;Living with it&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;So far Iâ€™ve looked at the areas to think about with regards to the data that youâ€™re sending to Iceberg.
Thatâ€™s only part of the puzzle though.
It might be a fun science experiment to put together random technologies based on their feature-support alone, but in the real world we have to live with the design choices we make too.
Letâ€™s look at some more factors to include in our weighing up of options.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_existing_ecosystem&#34;&gt;Existing Ecosystem&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;If you already run &lt;strong&gt;Apache Flink&lt;/strong&gt; or &lt;strong&gt;Kafka Connect&lt;/strong&gt; (or are already a &lt;strong&gt;Confluent Cloud&lt;/strong&gt; user) then that should be your assumed default.
From that default position you can then weigh in the other factors described in this article and decide if any warrant deploying new technology.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_iceberg_housekeeping&#34;&gt;Iceberg Housekeeping&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Iceberg does some thingsâ€”but not all.
One of the things that it doesnâ€™t do out of the box is its own housekeeping.
Particularly with streaming ingest into Iceberg, you can very quickly end up with lots of small data and metadata files, which will become a problem over time for performance.
I wrote more about this &lt;a href=&#34;https://rmoff.net/2025/07/14/keeping-your-data-lakehouse-in-order-table-maintenance-in-apache-iceberg/#_combining_data_files_into_fewer_data_files&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;If youâ€™re using &lt;strong&gt;Apache Flink&lt;/strong&gt; or &lt;strong&gt;Kafka Connect&lt;/strong&gt; to get your data into Iceberg, youâ€™ll need to do the housekeeping yourself.
This could be a custom job using something like Trino or Apache Spark, or a tool such as &lt;a href=&#34;https://amoro.apache.org/quick-start/#check-self-optimizing&#34;&gt;Apache Amoro&lt;/a&gt; or &lt;a href=&#34;https://github.com/nimtable/nimtable&#34;&gt;Nimtable&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;Tableflow&lt;/strong&gt; includes &lt;a href=&#34;https://docs.confluent.io/cloud/current/topics/tableflow/overview.html#table-maintenance-and-optimizations&#34;&gt;built-in table maintenance&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_ease_of_use&#34;&gt;Ease of Use&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Thereâ€™s a reason I gave a conference talk called &lt;a href=&#34;https://talks.rmoff.net/9GpIYA/the-joy-of-jars-and-other-flink-sql-troubleshooting-tales&#34;&gt;&lt;em&gt;The Joy of JARs&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2025/08/my-god-it-is-full-of-java.webp&#34; alt=&#34;My God&#34; width=&#34;It&amp;#39;s full of Java&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;Flink SQL&lt;/strong&gt; is SQL on the surface, but &lt;a href=&#34;https://rmoff.net/2025/06/24/writing-to-apache-iceberg-on-s3-using-flink-sql-with-glue-catalog/#_random_jiggling_hadoop_jars&#34;&gt;a morass of Java underneath&lt;/a&gt;, which matters for users and operators alike.
If youâ€™re already using Flink SQL then youâ€™ll know what Iâ€™m talking about.
If youâ€™re not and youâ€™re looking for a warm fuzzy SQL-embrace, forget it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;Kafka Connect&lt;/strong&gt; is built on Java too, but generally isolates the user from it.
You can use &lt;a href=&#34;https://hub.confluent.io&#34;&gt;Confluent Hub&lt;/a&gt; to install the Iceberg connector (or build it yourself, if thatâ€™s what you like doing).
Configuration isnâ€™t &lt;em&gt;pretty&lt;/em&gt;, but it is &amp;#34;just&amp;#34; JSON.
Use &lt;a href=&#34;https://github.com/kcctl/kcctl&#34;&gt;kcctl&lt;/a&gt; to make your life easier.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;Tableflow&lt;/strong&gt; is ridiculously simple to use.
Click &amp;#34;Enable Tableflow&amp;#34;, and thatâ€™s it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2025/08/tableflow.webp&#34; alt=&#34;tableflow&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;You can use the Confluent CLI instead if youâ€™d rather:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;color: #f8f8f2;background-color: #49483e&#34;&gt;&lt;code data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;$ &lt;/span&gt;confluent tableflow topic create my_topic1&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_self_managed_vs_fully_managed&#34;&gt;Self-Managed vs Fully-Managed&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;Tableflow&lt;/strong&gt; is available on Confluent Cloud, which is a fully-managed option and includes Kafka brokers and Flink SQL (plus Kafka Connect if you want it for ingest).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;If you want to self-manage then both &lt;strong&gt;Flink SQL&lt;/strong&gt; and &lt;strong&gt;Kafka Connect&lt;/strong&gt; (plus the necessary Apache Kafka) can be hosted yourself either on-premises or on a cloud provider.
Plenty of people do this so youâ€™ll not have a shortage of content online to help you set this up and keep it running.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_cost&#34;&gt;Cost&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;Apache Flink&lt;/strong&gt;, Apache Kafka (of which &lt;strong&gt;Kafka Connect&lt;/strong&gt; is part), and the Apache Iceberg connector for Kafka Connect are all Apache 2.0 open source, owned by the Apache Software Foundation.
Youâ€™re free to run them and modify them as you want (and youâ€™re also then reliant on the community for any support requirements).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;Tableflow&lt;/strong&gt; is a proprietary component of Confluent Cloud and usage of it is &lt;a href=&#34;https://docs.confluent.io/cloud/current/topics/tableflow/concepts/tableflow-billing.html&#34;&gt;billed&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_i_used_to_be_indecisivenow_im_not_so_sure&#34;&gt;I used to be indecisiveâ€¦now Iâ€™m not so sureâ€¦&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Canâ€™t decide between Apache Iceberg and &lt;a href=&#34;https://delta.io/&#34;&gt;Delta Lake&lt;/a&gt; as your open table format of choice?
Want to leave options open for the future, or other teams in your organisation?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;Flink SQL&lt;/strong&gt; has a &lt;a href=&#34;https://github.com/delta-io/delta/tree/master/connectors/flink/&#34;&gt;Delta Lake connector&lt;/a&gt; (open source).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;There is a &lt;a href=&#34;https://docs.confluent.io/kafka-connectors/databricks-delta-lake-sink/current/overview.html&#34;&gt;Delta Lake connector for &lt;strong&gt;Kafka Connect&lt;/strong&gt;&lt;/a&gt; but it is not open source and requires a paid Confluent subscription.
The &lt;a href=&#34;https://github.com/delta-io/kafka-delta-ingest&#34;&gt;&lt;code&gt;kafka-delta-ingest&lt;/code&gt;&lt;/a&gt; project is part of the Delta project and open source, but does not use the Kafka Connect framework.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;Tableflow&lt;/strong&gt; &lt;a href=&#34;https://docs.confluent.io/cloud/current/topics/tableflow/overview.html#tableflow-and-delta-lake-tables&#34;&gt;has support&lt;/a&gt; for both Apache Iceberg and Delta Lake.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_but_what_about_this_other_tool&#34;&gt;bUt wHaT aBoUt tHiS oThEr tOoL?&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The aim of this blog post is not to give a comprehensive listing of all the ways of getting data into Iceberg from Kafka, but to look in more detail at the most common options that I see in use.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;As well as Flink SQL, Kafka Connect, and Tableflow, other options include:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://iceberg.apache.org/docs/nightly/spark-getting-started/&#34;&gt;Apache Spark&lt;/a&gt; (Danica Fine covers this in her video &lt;a href=&#34;https://www.youtube.com/watch?v=5pXfznKniGg&#34;&gt;here&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Flink CDC added a &lt;a href=&#34;https://nightlies.apache.org/flink/flink-cdc-docs-master/docs/connectors/pipeline-connectors/iceberg/&#34;&gt;pipeline connector for Iceberg&lt;/a&gt; in the 3.5 release.
Thereâ€™s no source connector for Kafka, but if your data is coming from &lt;a href=&#34;https://nightlies.apache.org/flink/flink-cdc-docs-master/docs/connectors/pipeline-connectors/postgres/&#34;&gt;Postgres&lt;/a&gt; or &lt;a href=&#34;https://nightlies.apache.org/flink/flink-cdc-docs-master/docs/connectors/pipeline-connectors/mysql/&#34;&gt;MySQL&lt;/a&gt; this might be an interesting option to look into.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;a href=&#34;https://memiiso.github.io/debezium-server-iceberg/&#34;&gt;Debezium Iceberg Consumer&lt;/a&gt; is a community project that integrates with Debezium Server as a sink to Iceberg.
Similar to Flink CDC Pipelines, youâ€™d not use it for reading from Kafka but if youâ€™ve got a Debezium-supported RDBMS as source and youâ€™re not already running Kafka, this could be worth a look.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Aiven recently published &lt;a href=&#34;https://github.com/Aiven-Open/tiered-storage-for-apache-kafka/blob/main/iceberg_whitepaper.md#upcoming-work&#34;&gt;a whitepaper&lt;/a&gt; describing &lt;code&gt;Iceberg Topics for Apache Kafka&lt;/code&gt;.
Itâ€™s very early days and it has yet to be proven in production, and has significant gaps including lack of schema evolution.
Itâ€™ll be interesting to see how the project develops and the traction that itâ€™ll get.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_tldr&#34;&gt;tl;dr&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Flink SQL&lt;/strong&gt; is fantastic if you want to process data before sending it to Iceberg, typically as part of an analytics pipeline.
If you just need a &amp;#34;dumb pipe&amp;#34; itâ€™s less easy to justify.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Kafka Connect&lt;/strong&gt; excels as a &amp;#34;dumb pipe&amp;#34;, and also has support for stateless transformations.
If you want to do stateful processing youâ€™ll want to pair it with a stream processor (hey, such as Flink SQL!).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Tableflow&lt;/strong&gt; is a fully-managed tool for getting data from Kafka into Iceberg.
Itâ€™s part of Confluent Cloud so you also have access to Flink SQL through Confluent Cloud for Apache Flink if you want to pre-process any of the data before sending it to Iceberg.
Tableflow includes table maintenance, which youâ€™d have to do yourself if using Flink SQL or Kafka Connect to send the data to Iceberg.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_references&#34;&gt;References&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://rmoff.net/2025/07/14/keeping-your-data-lakehouse-in-order-table-maintenance-in-apache-iceberg/&#34;&gt;Keeping your Data Lakehouse in Order: Table Maintenance in Apache Iceberg&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://rmoff.net/2025/06/24/writing-to-apache-iceberg-on-s3-using-flink-sql-with-glue-catalog/&#34;&gt;Writing to Apache Iceberg on S3 using Flink SQL with Glue catalog&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://rmoff.net/2025/07/04/writing-to-apache-iceberg-on-s3-using-kafka-connect-with-glue-catalog/&#34;&gt;Writing to Apache Iceberg on S3 using Kafka Connect with Glue catalog&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸŽ¥ &lt;a href=&#34;https://current.confluent.io/post-conference-videos-2025/tableflow-not-just-another-kafka-to-iceberg-connector-lnd25&#34;&gt;Tableflow: Not Just Another Kafka-to-Iceberg Connector!&lt;/a&gt; (Alex Sorokoumov)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸ“‘ &lt;a href=&#34;https://microsites.databricks.com/sites/default/files/dais/2025/D25B3065_v2-Adi_Polak_DAIS_2025_kafka2iceberg.pdf&#34;&gt;No More Fragile Pipelines: Kafka and Iceberg the Declarative Way - Adi Polak&lt;/a&gt; (&lt;a href=&#34;https://www.youtube.com/watch?v=zDVaYolMoJg&#34;&gt;ðŸŽ¥ Video&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ðŸŽ¥ &lt;a href=&#34;https://www.youtube.com/watch?v=5pXfznKniGg&#34;&gt;Iced Kaf-fee: Chilling Kafka Data into Iceberg Tables by Danica Fine&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
    </item>
    
  </channel>
</rss>