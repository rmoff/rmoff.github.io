<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>rmoff&#39;s random ramblings</title>
    <link>https://rmoff.net/</link>
    <description>Recent content on rmoff&#39;s random ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>2023-11-16</lastBuildDate>
    
        <atom:link href="https://rmoff.net/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Hugo not detecting changed pages on Mac</title>
      <link>https://rmoff.net/2023/11/16/hugo-not-detecting-changed-pages-on-mac/</link>
      <pubDate>2023-11-16</pubDate>
      
      <guid>https://rmoff.net/2023/11/16/hugo-not-detecting-changed-pages-on-mac/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2023/11/t_IMG_6379.webp" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;p&gt;I&amp;rsquo;ve used Hugo for my blog for several years now, and it&amp;rsquo;s great. One of the things I love about it is the fast build time coupled with it&amp;rsquo;s live-reload feature. Using this I can edit my source (Markdown or Asciidoc) in one window, hit save, and see the preview update in my browser window next to it pretty much instantaneously. For copy-editing, experimenting with images, etc this is really helpful.&lt;/p&gt;
&lt;p&gt;üò≠ But then it stopped working.&lt;/p&gt;
&lt;p&gt;ü§î Running Hugo on my M1 MacBookPro it would build and serve the site locally, but if I changed a file it wouldn&amp;rsquo;t get detected, let alone re-built.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://discourse.gohugo.io/t/live-reload-not-detecting-changes-after-first-edit/14155&#34;&gt;Various&lt;/a&gt; &lt;a href=&#34;https://discourse.gohugo.io/t/hugo-server-watch-not-er-watching/1592&#34;&gt;Google&lt;/a&gt; &lt;a href=&#34;https://discourse.gohugo.io/t/live-reload-not-detecting-changes-after-first-edit/14155&#34;&gt;hits&lt;/a&gt; were either old, irrelevant, or dead-ends. And then I thought‚Ä¶what else has changed?&lt;/p&gt;
&lt;p&gt;üí° Docker. Or rather, not Docker.&lt;/p&gt;
&lt;p&gt;I run Hugo with Docker because it&amp;rsquo;s self-contained, reproducable, portable, and all those good things:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;docker run --rm -it &lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;&lt;/span&gt;  -v &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;$(&lt;/span&gt;&lt;span style=&#34;color:#008000&#34;&gt;pwd&lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;)&lt;/span&gt;:/src &lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;&lt;/span&gt;  -p 1313:1313 &lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;&lt;/span&gt;  klakegg/hugo:0.105.0-asciidoctor-onbuild &lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;&lt;/span&gt;  server --buildFuture --buildDrafts
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;And the one thing that had changed was that I&amp;rsquo;d moved from running &lt;a href=&#34;https://www.docker.com/products/docker-desktop/&#34;&gt;Docker Desktop&lt;/a&gt; to &lt;a href=&#34;https://orbstack.dev/&#34;&gt;Orbstack&lt;/a&gt;. Until now I&amp;rsquo;d not noticed a single difference‚Äîit&amp;rsquo;s the same &lt;code&gt;docker&lt;/code&gt; CLI commands as before, it&amp;rsquo;s just not Docker Desktop.&lt;/p&gt;
&lt;p&gt;üëâ Switching back to Docker Desktop and re-running Hugo resolved the issue. My changes are now being detected automagically and rebuilt:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Change detected, rebuilding site.
2023-11-16 16:33:59.561 +0000
Source changed WRITE         &amp;#34;/src/content/post/lafs01e05.md&amp;#34;
Total in 163 ms
&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;
&lt;p&gt;I found &lt;a href=&#34;https://github.com/orbstack/orbstack/issues/58&#34;&gt;this issue&lt;/a&gt; but it says it&amp;rsquo;s fixed in OrbStack  0.8, and I&amp;rsquo;m running 1.1.0.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/orbstack/orbstack/issues/739&#34;&gt;This issue&lt;/a&gt; is more recent but not directly relevant from what I can see.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Using Apache Kafka with ngrok</title>
      <link>https://rmoff.net/2023/11/01/using-apache-kafka-with-ngrok/</link>
      <pubDate>2023-11-01</pubDate>
      
      <guid>https://rmoff.net/2023/11/01/using-apache-kafka-with-ngrok/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2023/11/ngrok02.webp" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;p&gt;Sometimes you might want to access Apache Kafka that&amp;rsquo;s running on your local machine from another device not on the same network. I&amp;rsquo;m not sure I can think of a production use-case, but there are a dozen examples for sandbox, demo, and playground environments.&lt;/p&gt;
&lt;p&gt;In this post we&amp;rsquo;ll see how you can use &lt;a href=&#34;https://ngrok.com/&#34;&gt;ngrok&lt;/a&gt; to, in their words, &lt;code&gt;Put localhost on the internet&lt;/code&gt;. And specifically, your local Kafka broker on the internet.&lt;/p&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;Why? In my case, I wanted to expose my local Kafka as a source (and target) to &lt;a href=&#34;https://decodable.co/&#34;&gt;Decodable&lt;/a&gt; so that I can process streams of data with Apache Flink through the managed service that Decodable provides.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/11/ngrok01.webp&#34; alt=&#34;Overview of Kafka solution&#34;&gt;&lt;/p&gt;
&lt;p&gt;The example I&amp;rsquo;m going to show has ngrok and the Kafka broker running in a Docker Compose environment:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/11/ngrok02.webp&#34; alt=&#34;Overview of Kafka/ngrok solution&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;ngrok&#34;&gt;ngrok&lt;/h3&gt;
&lt;p&gt;ngrok has a free tier to use which works just fine for this, but you will need to &lt;a href=&#34;https://dashboard.ngrok.com/signup&#34;&gt;create a free account&lt;/a&gt; to get your &lt;a href=&#34;https://dashboard.ngrok.com/get-started/your-authtoken&#34;&gt;auth token&lt;/a&gt;. In this article I&amp;rsquo;m assuming you&amp;rsquo;ve exported your auth token to the environment variable &lt;code&gt;NGROK_AUTH_TOKEN&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;kafka-and-listeners-and-advertised-listenersoh-my&#34;&gt;Kafka and Listeners and Advertised Listeners‚Ä¶oh my&lt;/h2&gt;
&lt;p&gt;In theory, using ngrok is straightforward. You configure a &lt;em&gt;tunnel&lt;/em&gt; which routes a publicly-accessible host/port to one accessed from the ngrok agent running locally. Here we&amp;rsquo;re telling it to route the public tunnel to a machine called &lt;code&gt;broker&lt;/code&gt; on port &lt;code&gt;9092&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ngrok tcp broker:9092 --authtoken &lt;span style=&#34;color:#19177c&#34;&gt;$NGROK_AUTH_TOKEN&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;From this you get the tunnel url details:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;t=2023-11-01T10:57:41+0000 lvl=info msg=&amp;#34;started tunnel&amp;#34; obj=tunnels name=command_line addr=//broker:9092 url=tcp://6.tcp.eu.ngrok.io:13075
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The tunnel URL is &lt;code&gt;6.tcp.eu.ngrok.io:13075&lt;/code&gt;. This is accessible from anywhere on the interwebz‚Äîlocally or remote. Let&amp;rsquo;s try accessing our Kafka broker from another machine. I&amp;rsquo;m using my favourite tool, &lt;code&gt;kcat&lt;/code&gt;. We&amp;rsquo;ll start by interogating the broker (&lt;code&gt;-b&lt;/code&gt;) for metadata (&lt;code&gt;-L&lt;/code&gt;):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ kcat -L -b 6.tcp.eu.ngrok.io:13075
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Metadata &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;for&lt;/span&gt; all topics &lt;span style=&#34;color:#666&#34;&gt;(&lt;/span&gt;from broker -1: 6.tcp.eu.ngrok.io:13075/bootstrap&lt;span style=&#34;color:#666&#34;&gt;)&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt; brokers:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  broker &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt; at localhost:9092 &lt;span style=&#34;color:#666&#34;&gt;(&lt;/span&gt;controller&lt;span style=&#34;color:#666&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt; topics:
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Look at that! It worked! üëè&lt;/p&gt;
&lt;p&gt;Or did it‚Ä¶&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ &lt;span style=&#34;color:#008000&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;hello world&amp;#34;&lt;/span&gt; | kcat -b 6.tcp.eu.ngrok.io:13075 -P -t test_topic
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;%3|1698837177.570|FAIL|rdkafka#producer-1| &lt;span style=&#34;color:#666&#34;&gt;[&lt;/span&gt;thrd:localhost:9092/1&lt;span style=&#34;color:#666&#34;&gt;]&lt;/span&gt;: localhost:9092/1: Connect to ipv4#127.0.0.1:9092 failed: Connection refused &lt;span style=&#34;color:#666&#34;&gt;(&lt;/span&gt;after 0ms in state CONNECT&lt;span style=&#34;color:#666&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% ERROR: Local: Broker transport failure: localhost:9092/1: Connect to ipv4#127.0.0.1:9092 failed: Connection refused &lt;span style=&#34;color:#666&#34;&gt;(&lt;/span&gt;after 0ms in state CONNECT&lt;span style=&#34;color:#666&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;%3|1698837177.804|FAIL|rdkafka#producer-1| &lt;span style=&#34;color:#666&#34;&gt;[&lt;/span&gt;thrd:localhost:9092/1&lt;span style=&#34;color:#666&#34;&gt;]&lt;/span&gt;: localhost:9092/1: Connect to ipv6#&lt;span style=&#34;color:#666&#34;&gt;[&lt;/span&gt;::1&lt;span style=&#34;color:#666&#34;&gt;]&lt;/span&gt;:9092 failed: Connection refused &lt;span style=&#34;color:#666&#34;&gt;(&lt;/span&gt;after 0ms in state CONNECT&lt;span style=&#34;color:#666&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% ERROR: Local: Broker transport failure: localhost:9092/1: Connect to ipv6#&lt;span style=&#34;color:#666&#34;&gt;[&lt;/span&gt;::1&lt;span style=&#34;color:#666&#34;&gt;]&lt;/span&gt;:9092 failed: Connection refused &lt;span style=&#34;color:#666&#34;&gt;(&lt;/span&gt;after 0ms in state CONNECT&lt;span style=&#34;color:#666&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#666&#34;&gt;[&lt;/span&gt;‚Ä¶&lt;span style=&#34;color:#666&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;oh no! üòñ&lt;/p&gt;
&lt;p&gt;So here&amp;rsquo;s what&amp;rsquo;s happening. Kafka is a distributed system; it&amp;rsquo;s only in sandbox/demo environments that you&amp;rsquo;d ever be running just a single broker. For this reason, you have a &lt;em&gt;bootstrap&lt;/em&gt; address for one or more servers in the cluster. When you &lt;em&gt;initially&lt;/em&gt; connect it&amp;rsquo;s to the bootstrap server (&lt;code&gt;6.tcp.eu.ngrok.io:13075&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/11/ngrok03a.webp&#34; alt=&#34;The initial bootstrap connection between Kafka broker and client&#34;&gt;&lt;/p&gt;
&lt;p&gt;The server returns the &lt;strong&gt;&lt;code&gt;advertised.listener&lt;/code&gt;&lt;/strong&gt; for each of the brokers in the cluster as the address at which each of them can be found for subsequent connections.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/11/ngrok03b.webp&#34; alt=&#34;The advertised listeners exchange between Kafka broker and client&#34;&gt;&lt;/p&gt;
&lt;p&gt;After the initial bootstrap connection, the client uses the address that was returned to connect to when producing or consuming records.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/11/ngrok04.webp&#34; alt=&#34;The Kafka client using advertised.listener to find which the broker&amp;amp;rsquo;s connection address for produce/consume&#34;&gt;&lt;/p&gt;
&lt;p&gt;If we introduce ngrok into the mix it looks like this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The Kafka client connects via the public ngrok tunnel address to the broker for bootstrap connection&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/11/ngrok05.webp&#34; alt=&#34;Kafka client connects via ngrok to the broker for bootstrap&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The Kafka broker returns a list of available brokers, with their &lt;code&gt;advertised.listener&lt;/code&gt; address (&lt;code&gt;localhost:9092&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/11/ngrok06.webp&#34; alt=&#34;The Kafka broker returns a list of available brokers, with their advertised.listener address&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The Kafka client tries to connect to the address given‚Äî&lt;code&gt;localhost:9092&lt;/code&gt;‚Äîto produce/consume data. Since there&amp;rsquo;s no Kafka broker running local to the Kafka client (i.e. at &lt;code&gt;localhost:9092&lt;/code&gt;) the connection fails.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/11/ngrok07.webp&#34; alt=&#34;The Kafka client tries to connect to the address given‚Äîlocalhost:9092‚Äîto produce/consume data. Since there&amp;amp;rsquo;s no Kafka broker running local to the Kafka client (i.e. at localhost:9092) the connection fails.&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;(If you want to get into this in more detail about this please see my previous article about &lt;a href=&#34;https://rmoff.net/2018/08/02/kafka-listeners-explained/&#34;&gt;working with advertised.listeners&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;making-it-work&#34;&gt;Making it work&lt;/h2&gt;
&lt;p&gt;We need to get the ngrok tunnel URL and configure that as the Kafka broker&amp;rsquo;s advertised.listener:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/11/ngrok08.webp&#34; alt=&#34;Correct configuration of Kafka and ngrok&#34;&gt;&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s look at what&amp;rsquo;s actually involved in doing this.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m using Docker to run Kafka, so the configuration I&amp;rsquo;m going to discuss is through the environment variables passed to the image.&lt;/p&gt;
&lt;p&gt;The first thing is to configure the &lt;strong&gt;listeners&lt;/strong&gt;. This defines where the broker binds to for listening to inbound connections. I&amp;rsquo;m using two listeners; one for regular traffic between Docker containers, and the other for ngrok traffic. Listeners can be arbitrarily named, so I&amp;rsquo;m using nice clear labels here. The listener&amp;rsquo;s label servers as a prefix to the host and port.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;DOCKER&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NGROK&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The only‚Äîbut crucial‚Äîdifference is the port on which they listen. &lt;strong&gt;The port on which a connection receives determines the listener used, and therefore the advertised listener that&amp;rsquo;s served in response.&lt;/strong&gt;&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;KAFKA_LISTENERS: DOCKER://broker:29092, NGROK://broker:9092
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now we configure the &lt;strong&gt;advertised listeners&lt;/strong&gt;:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;KAFKA_ADVERTISED_LISTENERS: DOCKER://broker:29092, NGROK://6.tcp.eu.ngrok.io:13075
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;For completeness, we need two more listener configuration items:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;KAFKA_INTER_BROKER_LISTENER_NAME: DOCKER
KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: DOCKER:PLAINTEXT,NGROK:PLAINTEXT
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;automating-it&#34;&gt;Automating it&lt;/h2&gt;
&lt;p&gt;Now, this is all very well. But there&amp;rsquo;s a complication. ngrok uses a random host and port &lt;em&gt;each time the tunnel is created&lt;/em&gt;. This means that to configure the Kafka broker with the correct advertised listener we need to know the tunnel &lt;em&gt;first&lt;/em&gt;. That also makes building a static configuration for our Kafka broker tricky‚Äîfor example, in Docker Compose.&lt;/p&gt;
&lt;p&gt;So what we need to do is:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Launch ngrok and create tunnel&lt;/li&gt;
&lt;li&gt;Determine the tunnel URL and add it to the advertised listener configuration for Kafka&lt;/li&gt;
&lt;li&gt;Launch the Kafka broker&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;What prompted this whole exercise was wanting to build a standalone artefact that could be used to easily spin up Kafka locally to connect to Decodable in the cloud. Manually hacking around config is fine as a one-off, but I wanted something repeatable and as automated as possible.&lt;/p&gt;
&lt;h2 id=&#34;wrangling-around-docker-compose&#34;&gt;Wrangling around Docker Compose&lt;/h2&gt;
&lt;p&gt;This is what I ended up doing in Docker Compose. I&amp;rsquo;d love to hear your feedback if there&amp;rsquo;s a smarter or more idiomatic way in which to accomplish the same :)&lt;/p&gt;
&lt;p&gt;First, run ngrok and create the tunnel. This is hardcoded to direct traffic to the Kafka container at &lt;code&gt;broker:9092&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;ngrok&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;image&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;ngrok/ngrok:latest&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;container_name&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;ngrok&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;command&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;tcp broker:9092 --log stdout --authtoken $NGROK_AUTH_TOKEN&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;ports&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#666&#34;&gt;4040&lt;/span&gt;:&lt;span style=&#34;color:#666&#34;&gt;4040&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;ngrok has a REST API, which we can query to get the tunnel URL (&lt;code&gt;public_url&lt;/code&gt;):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;&#34;&gt;curl&lt;/span&gt; &lt;span style=&#34;&#34;&gt;http:&lt;/span&gt;&lt;span style=&#34;color:#408080;font-style:italic&#34;&gt;//localhost:4040/api/tunnels/command_line | jq &amp;#39;.&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#408080;font-style:italic&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;command_line&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;&amp;#34;ID&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;10c495e397bd65f42f3d4ebbd1bb74f5&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;&amp;#34;uri&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;/api/tunnels/command_line&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;&amp;#34;public_url&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;tcp://0.tcp.eu.ngrok.io:16761&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;&amp;#34;proto&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;tcp&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;&amp;#34;config&amp;#34;&lt;/span&gt;: {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;&amp;#34;addr&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;broker:9092&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;&amp;#34;inspect&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;false&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  },
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now we are ready to look at the Kafka broker. The chaining is defined with the Docker Compose&amp;rsquo;s &lt;code&gt;depends_on&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;depends_on&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;- zookeeper&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;- ngrok&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;What I&amp;rsquo;ve done is define the &lt;em&gt;constant&lt;/em&gt; listener variables in the Docker Compose service entry for the broker, whilst leaving &lt;code&gt;KAFKA_ADVERTISED_LISTENERS&lt;/code&gt; with a single entry and nothing for ngrok yet:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;KAFKA_LISTENERS&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;DOCKER://broker:29092, NGROK://broker:9092&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;KAFKA_ADVERTISED_LISTENERS&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;DOCKER://broker:29092&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;KAFKA_INTER_BROKER_LISTENER_NAME&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;DOCKER&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;KAFKA_LISTENER_SECURITY_PROTOCOL_MAP&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;DOCKER:PLAINTEXT,NGROK:PLAINTEXT&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;I&amp;rsquo;ve then overriden the &lt;code&gt;entrypoint&lt;/code&gt; of the container. First, it will wait for the tunnel to be created:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;Waiting for ngrok tunnel to be created&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;while&lt;/span&gt; : ; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;do&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#19177c&#34;&gt;curl_status&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;$(&lt;/span&gt;curl -s -o /dev/null -w %&lt;span style=&#34;color:#666&#34;&gt;{&lt;/span&gt;http_code&lt;span style=&#34;color:#666&#34;&gt;}&lt;/span&gt; http://ngrok:4040/api/tunnels/command_line&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#008000&#34;&gt;echo&lt;/span&gt; -e &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;$(&lt;/span&gt;date&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;\tTunnels API HTTP state: &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#19177c&#34;&gt;$curl_status&lt;/span&gt; &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34; (waiting for 200)&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;[&lt;/span&gt; &lt;span style=&#34;color:#19177c&#34;&gt;$curl_status&lt;/span&gt; -eq &lt;span style=&#34;color:#666&#34;&gt;200&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;]&lt;/span&gt; ; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;then&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#008000&#34;&gt;break&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;fi&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    sleep &lt;span style=&#34;color:#666&#34;&gt;5&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;done&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;ngrok tunnel is up&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Then‚Äîin the absence of &lt;code&gt;jq&lt;/code&gt; on the &lt;code&gt;confluentinc/cp-kafka&lt;/code&gt; image‚ÄîI use some fairly nasty shell tool code (which will probably break if the JSON structure from the ngrok API changes) to add the tunnel&amp;rsquo;s URL to the advertised listeners environment variable:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#19177c&#34;&gt;NGROK_LISTENER&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;$(&lt;/span&gt;curl -s  http://ngrok:4040/api/tunnels/command_line | grep -Po &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;&amp;#34;public_url&amp;#34;:.*?[^\\]&amp;#34;,&amp;#39;&lt;/span&gt; | cut -d&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;:&amp;#39;&lt;/span&gt; -f2- | tr -d &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;,&amp;#34;&amp;#39;&lt;/span&gt; | sed &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;s/tcp:\/\//NGROK:\/\//g&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#19177c&#34;&gt;KAFKA_ADVERTISED_LISTENERS&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#19177c&#34;&gt;$KAFKA_ADVERTISED_LISTENERS&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;, &lt;/span&gt;&lt;span style=&#34;color:#19177c&#34;&gt;$NGROK_LISTENER&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;KAFKA_ADVERTISED_LISTENERS is set to &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#19177c&#34;&gt;$KAFKA_ADVERTISED_LISTENERS&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;And then, finally, we launch the Kafka broker (using the original value of the Docker image&amp;rsquo;s &lt;code&gt;entrypoint&lt;/code&gt;):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;/etc/confluent/docker/run
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;ngrok-with-kafka-on-docker-compose-in-action&#34;&gt;ngrok with Kafka on Docker Compose, in action&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;You can find the Docker Compose file &lt;a href=&#34;https://rmoff.net/code/docker-compose-ngrok-kafka.yml&#34;&gt;here&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Launch the Docker Compose stack:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ docker compose up
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Get the ngrok tunnel URL:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ curl -s localhost:4040/api/tunnels | jq -r &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;.tunnels[0].public_url&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tcp://2.tcp.eu.ngrok.io:16738
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;(you can also use the Web UI at http://localhost:4040 to get this info)&lt;/p&gt;
&lt;p&gt;Now from anywhere on the interwebz, use your local Kafka broker based on the URL returned from ngrok (minus the &lt;code&gt;tcp://&lt;/code&gt; prefix):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ &lt;span style=&#34;color:#008000&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;hello world&amp;#34;&lt;/span&gt; | kcat -b 2.tcp.eu.ngrok.io:16738 -P -t test_topic
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ kcat -b 2.tcp.eu.ngrok.io:16738 -C -t test_topic
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello world
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% Reached end of topic test_topic &lt;span style=&#34;color:#666&#34;&gt;[&lt;/span&gt;0&lt;span style=&#34;color:#666&#34;&gt;]&lt;/span&gt; at offset &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If you go and have a look at your Docker Compose log you&amp;rsquo;ll see information about network traffic flowing through the tunnel:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;ngrok      | t=2023-11-01T12:17:59+0000 lvl=info msg=&amp;#34;join connections&amp;#34; obj=join id=8db744a20159 l=192.168.117.4:9092 r=82.20.253.111:34870
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So there we have it‚Äîngrok and Kafka, nicely automated in a standalone Docker Compose file üòé&lt;/p&gt;</description>
    </item>
    <item>
      <title>Learning Apache Flink S01E05: Installing PyFlink (with some bumps along the way‚Ä¶)</title>
      <link>https://rmoff.net/2023/10/25/learning-apache-flink-s01e05-installing-pyflink-with-some-bumps-along-the-way/</link>
      <pubDate>2023-10-25</pubDate>
      
      <guid>https://rmoff.net/2023/10/25/learning-apache-flink-s01e05-installing-pyflink-with-some-bumps-along-the-way/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2023/10/IMG_6173.webp" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;p&gt;When I started &lt;a href=&#34;https://rmoff.net/categories/laf/&#34;&gt;my journey learning Apache Flink&lt;/a&gt; one of the things that several people expressed an interest in hearing more about was PyFlink.  This appeals to me too, because whilst Java is just something I don&amp;rsquo;t know and feels beyond me to try and learn, Python is something that I know enough of to at least hack my way around it. I&amp;rsquo;ve previously &lt;a href=&#34;https://rmoff.net/2022/09/16/data-engineering-in-2022-exploring-lakefs-with-jupyter-and-pyspark/&#34;&gt;had fun with PySpark&lt;/a&gt;, and whilst &lt;a href=&#34;https://rmoff.net/categories/flink-sql/&#34;&gt;Flink SQL&lt;/a&gt; will probably be one of my main focusses, I also want to get a feel for PyFlink.&lt;/p&gt;
&lt;p&gt;The first step to using PyFlink is installing it - which should be simple, right?&lt;/p&gt;
&lt;p&gt;Right?&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/10/padame.webp&#34; alt=&#34;Padame looking concerned when she realises that something isn&amp;amp;rsquo;t as she&amp;amp;rsquo;d assumed&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;step-1-install-pyflink&#34;&gt;Step 1: Install PyFlink‚Ä¶&lt;/h2&gt;
&lt;p&gt;The &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/dev/python/datastream_tutorial/#how-to-follow-along&#34;&gt;docs&lt;/a&gt; are a useful start here, and tell us that we need to install Flink as a Python library first:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ pip install apache-flink
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;no-matching-distribution-found-for-numpy1214&#34;&gt;&lt;code&gt;No matching distribution found for numpy==1.21.4&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;This failed with the following output (truncated, for readability)&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ pip install apache-flink
Collecting apache-flink
  Using cached apache-flink-1.18.0.tar.gz (1.2 MB)
  Preparing metadata (setup.py) ... done
[‚Ä¶]
  Installing build dependencies ... error
  error: subprocess-exited-with-error

  √ó pip subprocess to install build dependencies did not run successfully.
  ‚îÇ exit code: 1
  ‚ï∞‚îÄ&amp;gt; [12 lines of output]
      Collecting packaging==20.5
        Using cached packaging-20.5-py2.py3-none-any.whl (35 kB)
      Collecting setuptools==59.2.0
        Using cached setuptools-59.2.0-py3-none-any.whl (952 kB)
      Collecting wheel==0.37.0
        Using cached wheel-0.37.0-py2.py3-none-any.whl (35 kB)
      ERROR: Ignored the following versions that require a different python version: 1.21.2 Requires-Python &amp;gt;=3.7,&amp;lt;3.11; 1.21.3 Requires-Python &amp;gt;=3.7,&amp;lt;3.11; 1.21.4 Requires-Python &amp;gt;=3.7,&amp;lt;3.11; 1.21.5 Requires-Python &amp;gt;=3.7,&amp;lt;3.11; 1.21.6 Requires-Python &amp;gt;=3.7,&amp;lt;3.11
      ERROR: Could not find a version that satisfies the requirement numpy==1.21.4 (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 1.13.3, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0, 1.21.1, 1.22.0, 1.22.1, 1.22.2, 1.22.3, 1.22.4, 1.23.0rc1, 1.23.0rc2, 1.23.0rc3, 1.23.0, 1.23.1, 1.23.2, 1.23.3, 1.23.4, 1.23.5, 1.24.0rc1, 1.24.0rc2, 1.24.0, 1.24.1, 1.24.2, 1.24.3, 1.24.4, 1.25.0rc1, 1.25.0, 1.25.1, 1.25.2, 1.26.0b1, 1.26.0rc1, 1.26.0, 1.26.1)
      ERROR: No matching distribution found for numpy==1.21.4

      [notice] A new release of pip is available: 23.2.1 -&amp;gt; 23.3
      [notice] To update, run: python3.11 -m pip install --upgrade pip
      [end of output]

  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

√ó pip subprocess to install build dependencies did not run successfully.
‚îÇ exit code: 1
‚ï∞‚îÄ&amp;gt; See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;try-installing-the-next-newest-version&#34;&gt;Try installing the next newest version&lt;/h2&gt;
&lt;p&gt;Looking at the error I spot &lt;code&gt;No matching distribution found for numpy==1.21.4&lt;/code&gt; so maybe I just try a different version?&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ pip install numpy==1.22.0
Collecting numpy==1.22.0
  Downloading numpy-1.22.0.zip (11.3 MB)
     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11.3/11.3 MB 443.6 kB/s eta 0:00:00
  Installing build dependencies ... done
  Getting requirements to build wheel ... error
  error: subprocess-exited-with-error

  √ó Getting requirements to build wheel did not run successfully.
  ‚îÇ exit code: 1
  ‚ï∞‚îÄ&amp;gt; [93 lines of output]
[‚Ä¶]
     AttributeError: fcompiler. Did you mean: &amp;#39;compiler&amp;#39;?
      [end of output]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Hey, a different error! I found a GitHub issue for this error that suggests &lt;a href=&#34;https://github.com/pypa/setuptools/issues/3549#issuecomment-1709347140&#34;&gt;a newer version&lt;/a&gt; of numpy will work&lt;/p&gt;
&lt;h2 id=&#34;try-installing-the-latest-version-of-numpy&#34;&gt;Try installing the latest version of numpy&lt;/h2&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ pip install numpy==1.26.1
Collecting numpy==1.26.1
  Downloading numpy-1.26.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (115 kB)
     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 115.1/115.1 kB 471.4 kB/s eta 0:00:00
Downloading numpy-1.26.1-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)
   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14.0/14.0 MB 473.2 kB/s eta 0:00:00
Installing collected packages: numpy
Successfully installed numpy-1.26.1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Yay!&lt;/p&gt;
&lt;p&gt;But‚Ä¶ still no dice with installing PyFlink&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ pip install apache-flink
[‚Ä¶]
      ERROR: No matching distribution found for numpy==1.21.4
      [end of output]
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;rtfem-read-the-fscking-error-message&#34;&gt;RTFEM (Read The Fscking Error Message)&lt;/h2&gt;
&lt;p&gt;Going back to the original error, looking at it more closely and breaking the lines you can see this:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;      ERROR: Ignored the following versions that require a different python version: 
	  1.21.2 Requires-Python &amp;gt;=3.7,&amp;lt;3.11; 
	  1.21.3 Requires-Python &amp;gt;=3.7,&amp;lt;3.11; 
      1.21.4 Requires-Python &amp;gt;=3.7,&amp;lt;3.11; 
      1.21.5 Requires-Python &amp;gt;=3.7,&amp;lt;3.11; 
      1.21.6 Requires-Python &amp;gt;=3.7,&amp;lt;3.11
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Let&amp;rsquo;s look at my Python version on the system:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ python3 --version
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Python 3.11.5
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;So this matches‚Äîthe numpy install needs less than 3.11 and we&amp;rsquo;re on 3.11.5.&lt;/p&gt;
&lt;h2 id=&#34;install-a-different-version-of-python&#34;&gt;Install a different version of Python&lt;/h2&gt;
&lt;p&gt;A quick Google throws up &lt;code&gt;pyenv&lt;/code&gt; as a good tool for managing Python versions (let me know if that&amp;rsquo;s not the case!). It installs on my Mac with brew nice and easily:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ brew install pyenv
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ &lt;span style=&#34;color:#008000&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;PATH=$(pyenv root)/shims:$PATH&amp;#39;&lt;/span&gt; &amp;gt;&amp;gt; ~/.zshrc
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Install a new version:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ pyenv install 3.10
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Activate the newly-installed version&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ pyenv global 3.10.13
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Start a new shell to pick up the change, and validate that we&amp;rsquo;re now using this version:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ python --version
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Python 3.10.13
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;try-the-pyflink-install-again&#34;&gt;Try the PyFlink install again&lt;/h2&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ pip install apache-flink

[‚Ä¶]
Successfully installed apache-beam-2.48.0 apache-flink-1.18.0 apache-flink-libraries-1.18.0 avro-python3-1.10.2 certifi-2023.7.22 charset-normalizer-3.3.1 cloudpickle-2.2.1 crcmod-1.7 dill-0.3.1.1 dnspython-2.4.2 docopt-0.6.2 fastavro-1.8.4 fasteners-0.19 find-libpython-0.3.1 grpcio-1.59.0 hdfs-2.7.3 httplib2-0.22.0 idna-3.4 numpy-1.24.4 objsize-0.6.1 orjson-3.9.9 pandas-2.1.1 pemja-0.3.0 proto-plus-1.22.3 protobuf-4.23.4 py4j-0.10.9.7 pyarrow-11.0.0 pydot-1.4.2 pymongo-4.5.0 pyparsing-3.1.1 python-dateutil-2.8.2 pytz-2023.3.post1 regex-2023.10.3 requests-2.31.0 six-1.16.0 typing-extensions-4.8.0 tzdata-2023.3 urllib3-2.0.7 zstandard-0.21.0
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;üëè Success!&lt;/p&gt;
&lt;p&gt;Now to go and actually use PyFlink‚Ä¶stay tuned :-D&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Note: thanks to Sergey Nuyanzin for pointing out that in Flink 1.19 there will be support for Python 3.11 (&lt;a href=&#34;https://issues.apache.org/jira/browse/FLINK-33030&#34;&gt;FLINK-33030&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Learning Apache Flink S01E04: A [Partial] Exploration of the Flink SQL Client</title>
      <link>https://rmoff.net/2023/10/10/learning-apache-flink-s01e04-a-partial-exploration-of-the-flink-sql-client/</link>
      <pubDate>2023-10-10</pubDate>
      
      <guid>https://rmoff.net/2023/10/10/learning-apache-flink-s01e04-a-partial-exploration-of-the-flink-sql-client/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2023/10/squirrel.webp" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;p&gt;So far I&amp;rsquo;ve plotted out a bit of a &lt;a href=&#34;https://rmoff.net/2023/09/29/learning-apache-flink-s01e01-where-do-i-start/&#34;&gt;map for my exploration&lt;/a&gt; of Apache Flink, looked at &lt;a href=&#34;https://rmoff.net/2023/10/02/learning-apache-flink-s01e02-what-is-flink/&#34;&gt;what  Flink &lt;em&gt;is&lt;/em&gt;&lt;/a&gt;, and &lt;a href=&#34;https://rmoff.net/2023/10/05/learning-apache-flink-s01e03-running-my-first-flink-cluster-and-application/&#34;&gt;run my first Flink application&lt;/a&gt;. Being an absolutely abysmal coder‚Äîbut knowing a thing or two about SQL‚ÄîI figure that Flink SQL is where my focus is going to lie (&lt;em&gt;I&amp;rsquo;m also intrigued by PyFlink, but that&amp;rsquo;s for another day‚Ä¶&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;So let&amp;rsquo;s start exploring Flink SQL! I&amp;rsquo;ll use the &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/try-flink/local_installation/#starting-and-stopping-a-local-cluster&#34;&gt;same local cluster that I started last time&lt;/a&gt;, against which I&amp;rsquo;m going to run the &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/dev/table/sqlclient/#sql-client&#34;&gt;SQL Client&lt;/a&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;./bin/sql-client.sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;üêøÔ∏è From here we get the most wonderful ASCII art squirrel, which put a smile on my face.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;
                                   ‚ñí‚ñì‚ñà‚ñà‚ñì‚ñà‚ñà‚ñí
                               ‚ñì‚ñà‚ñà‚ñà‚ñà‚ñí‚ñí‚ñà‚ñì‚ñí‚ñì‚ñà‚ñà‚ñà‚ñì‚ñí
                            ‚ñì‚ñà‚ñà‚ñà‚ñì‚ñë‚ñë        ‚ñí‚ñí‚ñí‚ñì‚ñà‚ñà‚ñí  ‚ñí
                          ‚ñë‚ñà‚ñà‚ñí   ‚ñí‚ñí‚ñì‚ñì‚ñà‚ñì‚ñì‚ñí‚ñë      ‚ñí‚ñà‚ñà‚ñà‚ñà
                          ‚ñà‚ñà‚ñí         ‚ñë‚ñí‚ñì‚ñà‚ñà‚ñà‚ñí    ‚ñí‚ñà‚ñí‚ñà‚ñí
                            ‚ñë‚ñì‚ñà            ‚ñà‚ñà‚ñà   ‚ñì‚ñë‚ñí‚ñà‚ñà
                              ‚ñì‚ñà       ‚ñí‚ñí‚ñí‚ñí‚ñí‚ñì‚ñà‚ñà‚ñì‚ñë‚ñí‚ñë‚ñì‚ñì‚ñà
                            ‚ñà‚ñë ‚ñà   ‚ñí‚ñí‚ñë       ‚ñà‚ñà‚ñà‚ñì‚ñì‚ñà ‚ñí‚ñà‚ñí‚ñí‚ñí
                            ‚ñà‚ñà‚ñà‚ñà‚ñë   ‚ñí‚ñì‚ñà‚ñì      ‚ñà‚ñà‚ñí‚ñí‚ñí ‚ñì‚ñà‚ñà‚ñà‚ñí
                         ‚ñë‚ñí‚ñà‚ñì‚ñì‚ñà‚ñà       ‚ñì‚ñà‚ñí    ‚ñì‚ñà‚ñí‚ñì‚ñà‚ñà‚ñì ‚ñë‚ñà‚ñë
                   ‚ñì‚ñë‚ñí‚ñì‚ñà‚ñà‚ñà‚ñà‚ñí ‚ñà‚ñà         ‚ñí‚ñà    ‚ñà‚ñì‚ñë‚ñí‚ñà‚ñí‚ñë‚ñí‚ñà‚ñí
                  ‚ñà‚ñà‚ñà‚ñì‚ñë‚ñà‚ñà‚ñì  ‚ñì‚ñà           ‚ñà   ‚ñà‚ñì ‚ñí‚ñì‚ñà‚ñì‚ñì‚ñà‚ñí
                ‚ñë‚ñà‚ñà‚ñì  ‚ñë‚ñà‚ñë            ‚ñà  ‚ñà‚ñí ‚ñí‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñí ‚ñà‚ñà‚ñì‚ñë‚ñí
               ‚ñà‚ñà‚ñà‚ñë ‚ñë ‚ñà‚ñë          ‚ñì ‚ñë‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñí‚ñë‚ñë    ‚ñë‚ñà‚ñë‚ñì  ‚ñì‚ñë
              ‚ñà‚ñà‚ñì‚ñà ‚ñí‚ñí‚ñì‚ñí          ‚ñì‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñë       ‚ñí‚ñà‚ñí ‚ñí‚ñì ‚ñì‚ñà‚ñà‚ñì
           ‚ñí‚ñà‚ñà‚ñì ‚ñì‚ñà ‚ñà‚ñì‚ñà       ‚ñë‚ñí‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñì‚ñí‚ñë         ‚ñà‚ñà‚ñí‚ñí  ‚ñà ‚ñí  ‚ñì‚ñà‚ñí
           ‚ñì‚ñà‚ñì  ‚ñì‚ñà ‚ñà‚ñà‚ñì ‚ñë‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñí              ‚ñí‚ñà‚ñà‚ñì           ‚ñë‚ñà‚ñí
           ‚ñì‚ñà    ‚ñà ‚ñì‚ñà‚ñà‚ñà‚ñì‚ñí‚ñë              ‚ñë‚ñì‚ñì‚ñì‚ñà‚ñà‚ñà‚ñì          ‚ñë‚ñí‚ñë ‚ñì‚ñà
           ‚ñà‚ñà‚ñì    ‚ñà‚ñà‚ñí    ‚ñë‚ñí‚ñì‚ñì‚ñà‚ñà‚ñà‚ñì‚ñì‚ñì‚ñì‚ñì‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñí            ‚ñì‚ñà‚ñà‚ñà  ‚ñà
          ‚ñì‚ñà‚ñà‚ñà‚ñí ‚ñà‚ñà‚ñà   ‚ñë‚ñì‚ñì‚ñí‚ñë‚ñë   ‚ñë‚ñì‚ñà‚ñà‚ñà‚ñà‚ñì‚ñë                  ‚ñë‚ñí‚ñì‚ñí  ‚ñà‚ñì
          ‚ñà‚ñì‚ñí‚ñí‚ñì‚ñì‚ñà‚ñà  ‚ñë‚ñí‚ñí‚ñë‚ñë‚ñë‚ñí‚ñí‚ñí‚ñí‚ñì‚ñà‚ñà‚ñì‚ñë                            ‚ñà‚ñì
          ‚ñà‚ñà ‚ñì‚ñë‚ñí‚ñà   ‚ñì‚ñì‚ñì‚ñì‚ñí‚ñë‚ñë  ‚ñí‚ñà‚ñì       ‚ñí‚ñì‚ñì‚ñà‚ñà‚ñì    ‚ñì‚ñí          ‚ñí‚ñí‚ñì
          ‚ñì‚ñà‚ñì ‚ñì‚ñí‚ñà  ‚ñà‚ñì‚ñë  ‚ñë‚ñí‚ñì‚ñì‚ñà‚ñà‚ñí            ‚ñë‚ñì‚ñà‚ñí   ‚ñí‚ñí‚ñí‚ñë‚ñí‚ñí‚ñì‚ñà‚ñà‚ñà‚ñà‚ñà‚ñí
           ‚ñà‚ñà‚ñë ‚ñì‚ñà‚ñí‚ñà‚ñí  ‚ñí‚ñì‚ñì‚ñí  ‚ñì‚ñà                ‚ñà‚ñë      ‚ñë‚ñë‚ñë‚ñë   ‚ñë‚ñà‚ñí
           ‚ñì‚ñà   ‚ñí‚ñà‚ñì   ‚ñë     ‚ñà‚ñë                ‚ñí‚ñà              ‚ñà‚ñì
            ‚ñà‚ñì   ‚ñà‚ñà         ‚ñà‚ñë                 ‚ñì‚ñì        ‚ñí‚ñà‚ñì‚ñì‚ñì‚ñí‚ñà‚ñë
             ‚ñà‚ñì ‚ñë‚ñì‚ñà‚ñà‚ñë       ‚ñì‚ñí                  ‚ñì‚ñà‚ñì‚ñí‚ñë‚ñë‚ñë‚ñí‚ñì‚ñà‚ñë    ‚ñí‚ñà
              ‚ñà‚ñà   ‚ñì‚ñà‚ñì‚ñë      ‚ñí                    ‚ñë‚ñí‚ñà‚ñí‚ñà‚ñà‚ñí      ‚ñì‚ñì
               ‚ñì‚ñà‚ñí   ‚ñí‚ñà‚ñì‚ñí‚ñë                         ‚ñí‚ñí ‚ñà‚ñí‚ñà‚ñì‚ñí‚ñí‚ñë‚ñë‚ñí‚ñà‚ñà
                ‚ñë‚ñà‚ñà‚ñí    ‚ñí‚ñì‚ñì‚ñí                     ‚ñì‚ñà‚ñà‚ñì‚ñí‚ñà‚ñí ‚ñë‚ñì‚ñì‚ñì‚ñì‚ñí‚ñà‚ñì
                  ‚ñë‚ñì‚ñà‚ñà‚ñí                          ‚ñì‚ñë  ‚ñí‚ñà‚ñì‚ñà  ‚ñë‚ñë‚ñí‚ñí‚ñí
                      ‚ñí‚ñì‚ñì‚ñì‚ñì‚ñì‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñë‚ñë‚ñì‚ñì  ‚ñì‚ñë‚ñí‚ñà‚ñë

    ______ _ _       _       _____  ____  _         _____ _ _            _  BETA
   |  ____| (_)     | |     / ____|/ __ \| |       / ____| (_)          | |
   | |__  | |_ _ __ | | __ | (___ | |  | | |      | |    | |_  ___ _ __ | |_
   |  __| | | | &amp;#39;_ \| |/ /  \___ \| |  | | |      | |    | | |/ _ \ &amp;#39;_ \| __|
   | |    | | | | | |   &amp;lt;   ____) | |__| | |____  | |____| | |  __/ | | | |_
   |_|    |_|_|_| |_|_|\_\ |_____/ \___\_\______|  \_____|_|_|\___|_| |_|\__|
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;orientating-myself-in-the-cli-environment---result-and-runtime-modes&#34;&gt;Orientating myself in the CLI environment - result and runtime modes&lt;/h2&gt;
&lt;p&gt;When you first launch the Flink SQL Client and run a query (I used the one from &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/dev/table/sqlclient/#running-sql-queries&#34;&gt;the SQL Client guide&lt;/a&gt;):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;SELECT&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;name,&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;COUNT&lt;/span&gt;(&lt;span style=&#34;color:#666&#34;&gt;*&lt;/span&gt;)&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;AS&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;cnt&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;FROM&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;(&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;VALUES&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;Bob&amp;#39;&lt;/span&gt;),&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;Alice&amp;#39;&lt;/span&gt;),&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;Greg&amp;#39;&lt;/span&gt;),&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;Bob&amp;#39;&lt;/span&gt;))&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;AS&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;NameTable(name)&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;GROUP&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;BY&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;name;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;it defaults to an interactive table view (&lt;code&gt;result-mode&lt;/code&gt;=&lt;code&gt;table&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/10/CleanShot_2023-10-09_at_16.27.33.webp&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;This is probably useful for streaming, but perhaps less so for a one-off static query?&lt;/p&gt;
&lt;p&gt;The next &lt;code&gt;result-mode&lt;/code&gt; is similar but shows the table as a change log (a concept very familiar to me from the &lt;a href=&#34;https://www.michael-noll.com/blog/2018/04/05/of-stream-and-tables-in-kafka-and-stream-processing-part1/&#34;&gt;stream-table duality&lt;/a&gt;). The results are still shown on an updating and interactive screen.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;SET&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;sql-client.execution.result-mode&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;changelog&amp;#39;&lt;/span&gt;;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/10/CleanShot_2023-10-09_at_16.32.08.webp&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;(&lt;em&gt;If you are wondering how there is an &lt;code&gt;UPDATE&lt;/code&gt; operation in a simple &lt;code&gt;SELECT&lt;/code&gt; then take a close look at the &lt;code&gt;FROM&lt;/code&gt; clause of the SQL being run. The &lt;code&gt;name&lt;/code&gt; value &lt;code&gt;Bob&lt;/code&gt; appears twice, and so the aggregate state change from a &lt;code&gt;COUNT&lt;/code&gt; of 1 to 2&lt;/em&gt;)&lt;/p&gt;
&lt;p&gt;A more conventional way to display the results just as SQL*Plus in Oracle would, psql in PostgreSQL etc, is &lt;code&gt;tableau&lt;/code&gt;. Note that you get the changelog operations shown just as when you explicitly set it in the previous option.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;SET&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;sql-client.execution.result-mode&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;tableau&amp;#39;&lt;/span&gt;;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/10/CleanShot_2023-10-09_at_16.34.42.webp&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;For a &amp;ldquo;normal&amp;rdquo; result display (in a tabular view, no change log, just the final state) we set another parameter, &lt;code&gt;runtime-mode&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;SET&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;execution.runtime-mode&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;batch&amp;#39;&lt;/span&gt;;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/10/CleanShot_2023-10-09_at_16.38.14.webp&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;a-stream-is-a-table-is-a-stream&#34;&gt;A Stream is a Table is a Stream&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/10/Pasted_image_20231010102731.webp&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;I want to start digging into how Flink&amp;rsquo;s view of everything being a stream‚Äîjust &lt;a href=&#34;https://flink.apache.org/what-is-flink/flink-architecture/#process-unbounded-and-bounded-data&#34;&gt;bounded or unbounded&lt;/a&gt;‚Äîworks alongside the SQL semantics of a &lt;code&gt;TABLE&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;In the &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/dev/table/sqlclient/#initialize-session-using-sql-files&#34;&gt;SQL Client doc&lt;/a&gt; I noticed the syntax for &lt;code&gt;CREATE TABLE&lt;/code&gt; included the option to read from a local CSV file. I&amp;rsquo;m hoping that I can define a table on the file to read it, and then start adding rows to the CSV and use this as a crude simulation of a stream a.k.a. unbounded data to see how it works in Flink.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ve not dug into Flink&amp;rsquo;s connector capabilities yet so am navigating this one completely in the dark to start with. Looking through &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.17/&#34;&gt;the docs&lt;/a&gt; I found &lt;strong&gt;Connectors&lt;/strong&gt; on the sidebar nav, of which there are three types listed&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DataSet Connectors&lt;/li&gt;
&lt;li&gt;DataStream Connectors&lt;/li&gt;
&lt;li&gt;Table API&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;One of the areas that &lt;a href=&#34;https://rmoff.net/2023/09/29/learning-apache-flink-s01e01-where-do-i-start/&#34;&gt;I identified previously&lt;/a&gt; to look at was an understanding of Flink&amp;rsquo;s architecture and concepts‚Äîwhich I still need to do. For now, I&amp;rsquo;m going on the basis that I&amp;rsquo;ve seen &amp;ldquo;Table API&amp;rdquo; and &amp;ldquo;SQL&amp;rdquo; alongside each other before, so take a punt on the &lt;strong&gt;Table API&lt;/strong&gt; menu section, which yielded the &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/connectors/table/filesystem/&#34;&gt;FileSystem SQL Connector&lt;/a&gt;. It looks like it supports a variety of &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/connectors/table/filesystem/#file-formats&#34;&gt;formats&lt;/a&gt;, although not the option to derive columns and names from headers which is a shame.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;NOTE: there is also a &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/connectors/table/datagen/&#34;&gt;DataGen&lt;/a&gt; connector, but the File System one at this stage looked simpler for working with just a handful of rows to understand what was going on.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Using one of my favourite tools, &lt;a href=&#34;https://www.mockaroo.com/&#34;&gt;Mockaroo&lt;/a&gt;, I generate some CSV data&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;timestamp,source_ip,dest_ip,source_prt,dest_prt
2018-05-11 00:19:34,151.35.34.162,125.26.20.222,2014,68
2018-05-11 22:20:43,114.24.126.190,21.68.21.69,379,1619
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;and write this to &lt;code&gt;/tmp/firewall.csv&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s create a table on it, using some fairly straightforward syntax lifted from the docs.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;CREATE&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;TABLE&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;firewall&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;(&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;event_time&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;STRING,&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;source_ip&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;STRING,&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;dest_ip&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;STRING,&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;source_prt&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000&#34;&gt;INT&lt;/span&gt;,&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;dest_prt&lt;span style=&#34;color:#bbb&#34;&gt;   &lt;/span&gt;&lt;span style=&#34;color:#008000&#34;&gt;INT&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;)&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;WITH&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;(&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;connector&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;filesystem&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;path&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;file:///tmp/firewall.csv&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;format&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;csv&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;);&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;It worked first time‚Ä¶which always makes me suspicious‚Ä¶ ü§î&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;[INFO] Execute statement succeed.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Let&amp;rsquo;s try querying it.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Flink&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;SQL&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;SELECT&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;FROM&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;firewall;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;[ERROR]&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;Could&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;not&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;execute&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;SQL&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;statement&lt;/span&gt;.&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;Reason:&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;java.lang.NumberFormatException:&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;For&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;input&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;string:&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;source_prt&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;I knew it was too good to be true üòÖ My guess was that perhaps the header was tripping things up (trying to store the &lt;code&gt;source_prt&lt;/code&gt; as the defined &lt;code&gt;INT&lt;/code&gt;). The &lt;a href=&#34;https://stackoverflow.com/questions/67543961/flink-sql-table-backed-by-csv-with-header&#34;&gt;first hit on Stack Overflow&lt;/a&gt; was pretty useful and pointed to a few options if I needed to keep the header. For the sake of expediency, I just removed it and tried the &lt;code&gt;SELECT&lt;/code&gt; again:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Flink&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;SQL&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;SET&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;sql-client.execution.result-mode&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;tableau&amp;#39;&lt;/span&gt;;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;[INFO]&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;Execute&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;statement&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;succeed.&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;Flink&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;SQL&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;SELECT&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;FROM&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;firewall;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#408080;font-style:italic&#34;&gt;----+--------------------------------+--------------------------------+--------------------------------+-------------+-------------+
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#408080;font-style:italic&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;|&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;op&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;|&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;                     &lt;/span&gt;event_time&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;|&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;                      &lt;/span&gt;source_ip&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;|&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;                        &lt;/span&gt;dest_ip&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;|&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;source_prt&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;|&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;dest_prt&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;|&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#408080;font-style:italic&#34;&gt;----+--------------------------------+--------------------------------+--------------------------------+-------------+-------------+
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#408080;font-style:italic&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;|&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;I&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;|&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;            &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;2018&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;05&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;11&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;05&lt;/span&gt;:&lt;span style=&#34;color:#666&#34;&gt;02&lt;/span&gt;:&lt;span style=&#34;color:#666&#34;&gt;09&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;|&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;                   &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;73&lt;/span&gt;.&lt;span style=&#34;color:#666&#34;&gt;98&lt;/span&gt;.&lt;span style=&#34;color:#666&#34;&gt;97&lt;/span&gt;.&lt;span style=&#34;color:#666&#34;&gt;177&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;|&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;                  &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;41&lt;/span&gt;.&lt;span style=&#34;color:#666&#34;&gt;52&lt;/span&gt;.&lt;span style=&#34;color:#666&#34;&gt;138&lt;/span&gt;.&lt;span style=&#34;color:#666&#34;&gt;199&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;|&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;1478&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;|&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;1181&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;|&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;|&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;I&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;|&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;            &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;2018&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;05&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;11&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;07&lt;/span&gt;:&lt;span style=&#34;color:#666&#34;&gt;59&lt;/span&gt;:&lt;span style=&#34;color:#666&#34;&gt;48&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;|&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;                 &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;21&lt;/span&gt;.&lt;span style=&#34;color:#666&#34;&gt;171&lt;/span&gt;.&lt;span style=&#34;color:#666&#34;&gt;129&lt;/span&gt;.&lt;span style=&#34;color:#666&#34;&gt;233&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;|&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;                 &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;26&lt;/span&gt;.&lt;span style=&#34;color:#666&#34;&gt;203&lt;/span&gt;.&lt;span style=&#34;color:#666&#34;&gt;158&lt;/span&gt;.&lt;span style=&#34;color:#666&#34;&gt;152&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;|&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;1538&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;|&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;1680&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;|&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#408080;font-style:italic&#34;&gt;----+--------------------------------+--------------------------------+--------------------------------+-------------+-------------+
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#408080;font-style:italic&#34;&gt;&lt;/span&gt;Received&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;a&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;total&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;of&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;rows&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Nice! We&amp;rsquo;ve read from a flat file using Flink. At the moment it&amp;rsquo;s bounded data; there are two rows of data in the file, and we have read them. The boundary is the end of the file. What about if we cheat a little bit and move that boundary on and start adding some rows, making it kinda unbounded? Looking at how the query above ran and completed, we&amp;rsquo;re going to need to change something in how we run the query to tell Flink that there will be more data.&lt;/p&gt;
&lt;h2 id=&#34;reading-a-csv-file-as-a-stream&#34;&gt;Reading a CSV file as a stream&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/10/Pasted_image_20231009171747.webp&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s take a guess and change the &lt;code&gt;runtime-mode&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;SET&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;sql-client.execution.result-mode&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;changelog&amp;#39;&lt;/span&gt;;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;and query the table again:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;SELECT * FROM firewall;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I got the interactive-looking screen:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;                                                         SQL Query Result (Changelog)
 Table program finished.                                                                                                Updated: 10:45:17.909

 op                     event_time                      source_ip                        dest_ip  source_prt    dest_prt
 +I            2018-05-11 05:02:09                   73.98.97.177                  41.52.138.199        1478        1181
 +I            2018-05-11 07:59:48                 21.171.129.233                 26.203.158.152        1538        1680
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;But note the &lt;code&gt;Table program finished&lt;/code&gt; in the top left‚Äîand when I added a row to the CSV file nothing changed in the results.&lt;/p&gt;
&lt;p&gt;This is where the documentation comes in handy ;-) Above, I set the &lt;code&gt;runtime-mode&lt;/code&gt; to &lt;code&gt;batch&lt;/code&gt; - so is there a &lt;code&gt;streaming&lt;/code&gt; counterpart? I struggled to find a clear documentation of this via the search, but under &lt;strong&gt;DataStream API&lt;/strong&gt; I found &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/dev/datastream/execution_mode/#configuring-batch-execution-mode&#34;&gt;an explanation of it&lt;/a&gt;. At this stage, I&amp;rsquo;m still randomly-jiggling things but I do need to go back and understand the relationship between the APIs properly. Anyway, let&amp;rsquo;s try changing it:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;SET&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;execution.runtime-mode&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;STREAMING&amp;#39;&lt;/span&gt;;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;I got the same behaviour as before - no changes picked up by the query. What about the connector itself? &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/connectors/table/filesystem/#directory-watching&#34;&gt;It turns out&lt;/a&gt; that &lt;em&gt;it&lt;/em&gt; isn&amp;rsquo;t doing the streaming:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;By default, the file system connector is bounded&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;However, it does have an option for streaming, whereby it monitors a folder for new files. Since we&amp;rsquo;ve started down this path, let&amp;rsquo;s keep going. I&amp;rsquo;ll create a dedicated folder locally for my CSV files, and recreate the table:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;DROP&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;TABLE&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;firewall;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;CREATE&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;TABLE&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;firewall&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;(&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;event_time&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;STRING,&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;source_ip&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;STRING,&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;dest_ip&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;STRING,&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;source_prt&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000&#34;&gt;INT&lt;/span&gt;,&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;dest_prt&lt;span style=&#34;color:#bbb&#34;&gt;   &lt;/span&gt;&lt;span style=&#34;color:#008000&#34;&gt;INT&lt;/span&gt;,&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;`&lt;/span&gt;file.path&lt;span style=&#34;color:#666&#34;&gt;`&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;STRING&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;NOT&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;NULL&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;METADATA&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;)&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;WITH&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;(&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;connector&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;filesystem&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;path&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;file:///tmp/firewall/&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;format&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;csv&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;source.monitor-interval&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;1&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#408080;font-style:italic&#34;&gt;-- unclear from the docs what the unit is here
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#408080;font-style:italic&#34;&gt;&lt;/span&gt;);&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;(&lt;em&gt;I&amp;rsquo;ve added another column that I found in the docs, showing metadata for the file that was read&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;On disk I&amp;rsquo;ve got:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ ls -l /tmp/firewall
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;total &lt;span style=&#34;color:#666&#34;&gt;8&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;-rw-r--r--@ &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt; rmoff  wheel  &lt;span style=&#34;color:#666&#34;&gt;117&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;10&lt;/span&gt; Oct 10:58 1.csv
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;-rw-r--r--@ &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt; rmoff  wheel  &lt;span style=&#34;color:#666&#34;&gt;251&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;10&lt;/span&gt; Oct 12:14 2.csv
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now let&amp;rsquo;s query it, and re-issue the &lt;code&gt;runtime-mode&lt;/code&gt; and &lt;code&gt;results-mode&lt;/code&gt; settings just to keep things in one place and clear (note that you have to run the statements in the CLI one by one):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;SET&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;sql-client.execution.result-mode&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;changelog&amp;#39;&lt;/span&gt;;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;SET&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;execution.runtime-mode&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;STREAMING&amp;#39;&lt;/span&gt;;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;SELECT&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;FROM&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;firewall;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;NOW&lt;/em&gt; we are getting somewhere! ü•≥ Note how the &lt;code&gt;Updated&lt;/code&gt; field is advancing and the top left says &lt;code&gt;Refresh: Fastest&lt;/code&gt; (rather than the previous message about a table program finishing):&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/10/CleanShot_2023-10-10_at_16.29.30.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Now that the query is running continuously, let&amp;rsquo;s add some more data. &lt;a href=&#34;https://www.mockaroo.com/f6255400&#34;&gt;Mockaroo&lt;/a&gt; supports a REST API which I&amp;rsquo;ll pull straight into the new file:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;curl &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;https://api.mockaroo.com/api/f6255400?count=4&amp;amp;key=&amp;#34;&lt;/span&gt; &amp;gt; /tmp/firewall/2.csv
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Unfortunately, Flink doesn&amp;rsquo;t seem to like this, and the executing query aborts as soon as I run the &lt;code&gt;curl&lt;/code&gt; command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;[ERROR]&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;Could&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;not&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;execute&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;SQL&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;statement&lt;/span&gt;.&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;Reason:&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;java.lang.IllegalArgumentException&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;it-was-all-going-so-well-&#34;&gt;It was all going so well üòÖ‚Ä¶&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/10/Pasted_image_20231010140254.webp&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;In the root of the Flink directory (from which I launched the cluster and the SQL Client) is a folder called &lt;code&gt;log&lt;/code&gt;. In there I looked at the recently changed files and searched for &lt;code&gt;IllegalArgumentException&lt;/code&gt; which yielded the following in &lt;code&gt;flink-rmoff-standalonesession-0-asgard08.log&lt;/code&gt;:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;2023-10-10 13:45:20,609 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: firewall[3] -&amp;gt; Sink: Collect table sink (1/1) (b75ce256ec609708e0d19f8a57a84e48_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to FAILED on localhost:52591-4b9201 @ localhost (dataPort=52593).
java.lang.RuntimeException: One or more fetchers have encountered exception
        at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:261) ~[flink-connector-files-1.17.1.jar:1.17.1]
        at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:169) ~[flink-connector-files-1.17.1.jar:1.17.1]
        at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:131) ~[flink-connector-files-1.17.1.jar:1.17.1]
        at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:417) ~[flink-dist-1.17.1.jar:1.17.1]
        at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.17.1.jar:1.17.1]
        at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.17.1.jar:1.17.1]
        at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:550) ~[flink-dist-1.17.1.jar:1.17.1]
        at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.17.1.jar:1.17.1]
        at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839) ~[flink-dist-1.17.1.jar:1.17.1]
        at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788) ~[flink-dist-1.17.1.jar:1.17.1]
        at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952) ~[flink-dist-1.17.1.jar:1.17.1]
        at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931) ~[flink-dist-1.17.1.jar:1.17.1]
        at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745) ~[flink-dist-1.17.1.jar:1.17.1]
        at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562) ~[flink-dist-1.17.1.jar:1.17.1]
        at java.lang.Thread.run(Thread.java:829) ~[?:?]
Caused by: java.lang.RuntimeException: SplitFetcher thread 1 received unexpected exception while polling the records
        at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.17.1.jar:1.17.1]
        at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:114) ~[flink-connector-files-1.17.1.jar:1.17.1]
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) ~[?:?]
        at java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) ~[?:?]
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) ~[?:?]
        ... 1 more
Caused by: java.lang.IllegalArgumentException
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;and then in the &lt;code&gt;flink-rmoff-taskexecutor-1-asgard08.log&lt;/code&gt; I saw:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;2023-10-10 13:45:20,587 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Adding split(s) to reader: [FileSourceSplit: file:/tmp/firewall/2.csv [0, 0) (no host info) ID=0000004128 position=null]
2023-10-10 13:45:20,587 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Starting split fetcher 1
2023-10-10 13:45:20,588 ERROR org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager [] - Received uncaught exception.
java.lang.RuntimeException: SplitFetcher thread 1 received unexpected exception while polling the records
        at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.17.1.jar:1.17.1]
        at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:114) [flink-connector-files-1.17.1.jar:1.17.1]
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
        at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
        at java.lang.Thread.run(Thread.java:829) [?:?]
Caused by: java.lang.IllegalArgumentException
        at org.apache.flink.util.Preconditions.checkArgument(Preconditions.java:122) ~[flink-dist-1.17.1.jar:1.17.1]
        at org.apache.flink.connector.file.src.impl.StreamFormatAdapter$TrackingFsDataInputStream.&amp;lt;init&amp;gt;(StreamFormatAdapter.java:264) ~[flink-connector-files-1.17.1.jar:1.17.1]
        at org.apache.flink.connector.file.src.impl.StreamFormatAdapter.lambda$openStream$3(StreamFormatAdapter.java:180) ~[flink-connector-files-1.17.1.jar:1.17.1]
        at org.apache.flink.connector.file.src.util.Utils.doWithCleanupOnException(Utils.java:45) ~[flink-connector-files-1.17.1.jar:1.17.1]
        at org.apache.flink.connector.file.src.impl.StreamFormatAdapter.openStream(StreamFormatAdapter.java:172) ~[flink-connector-files-1.17.1.jar:1.17.1]
        at org.apache.flink.connector.file.src.impl.StreamFormatAdapter.createReader(StreamFormatAdapter.java:70) ~[flink-connector-files-1.17.1.jar:1.17.1]
        at org.apache.flink.connector.file.src.impl.FileSourceSplitReader.checkSplitOrStartNext(FileSourceSplitReader.java:112) ~[flink-connector-files-1.17.1.jar:1.17.1]
        at org.apache.flink.connector.file.src.impl.FileSourceSplitReader.fetch(FileSourceSplitReader.java:65) ~[flink-connector-files-1.17.1.jar:1.17.1]
        at org.apache.flink.connector.base.source.reader.fetcher.FetchTask.run(FetchTask.java:58) ~[flink-connector-files-1.17.1.jar:1.17.1]
        at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:162) ~[flink-connector-files-1.17.1.jar:1.17.1]
        ... 6 more
2023-10-10 13:45:20,593 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Split fetcher 1 exited.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The salient lines here seeming to be&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Adding split(s) to reader: [FileSourceSplit: file:/tmp/firewall/2.csv&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;SplitFetcher thread 1 received unexpected exception while polling the records&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Caused by: java.lang.IllegalArgumentException&lt;/code&gt;
&lt;code&gt;   at org.apache.flink.util.Preconditions.checkArgument(Preconditions.java:122) ~[flink-dist-1.17.1.jar:1.17.1]&lt;/code&gt;
&lt;code&gt;   at org.apache.flink.connector.file.src.impl.StreamFormatAdapter$TrackingFsDataInputStream.&amp;lt;init&amp;gt;(StreamFormatAdapter.java:264) ~[flink-connector-files-1.17.1.jar:1.17.1]&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Perhaps having curl stream the HTTP call output into the file is confusing things; it it better to buffer it and then give the connector a complete file to read?&lt;/p&gt;
&lt;p&gt;By using &lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt; in bash I can write the output from &lt;code&gt;curl&lt;/code&gt; to one file, and then once that completes, rename it into the &lt;code&gt;/tmp/firewall&lt;/code&gt; folder:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;curl &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;https://api.mockaroo.com/api/f6255400?count=4&amp;amp;key=ff7856d0&amp;#34;&lt;/span&gt; &amp;gt; /tmp/data.csv &lt;span style=&#34;color:#666&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;&lt;/span&gt;mv /tmp/data.csv /tmp/firewall/3.csv
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Look at that! A streaming query! üëÄ üòÑ&lt;/p&gt;
&lt;p&gt;&lt;video autoplay=&#34;true&#34; loop=&#34;false&#34; width=800 src=&#34;https://rmoff.net/images/2023/10/CleanShot_2023-10-10_at_16.34.14.mp4&#34;&gt;&lt;/video&gt;&lt;/p&gt;
&lt;h3 id=&#34;more-errors-&#34;&gt;More errors üòë&lt;/h3&gt;
&lt;p&gt;Before my celebrations had quite died, down the query itself aborted:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;[ERROR] Could not execute SQL statement. Reason:
org.apache.flink.shaded.netty4.io.netty.channel.ConnectTimeoutException: connection timed out: localhost/127.0.0.1:52596
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This in fact happened whether I added to data or not; if I left the &lt;code&gt;SELECT&lt;/code&gt; running for more than a few seconds I got this. Some kind of built-in timeout, perhaps?&lt;/p&gt;
&lt;p&gt;Remembering the Flink Web UI that I saw &lt;a href=&#34;https://rmoff.net/2023/10/05/learning-apache-flink-s01e03-running-my-first-flink-cluster-and-application/&#34;&gt;last time&lt;/a&gt; I headed over to see what I could see there. A whole lotta &lt;code&gt;CANCELED&lt;/code&gt;!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/10/CleanShot_2023-10-10_at_14.49.19.webp&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Via this you can get to the Job Manager and Task Manager logs (just as I did from the &lt;code&gt;log&lt;/code&gt; folder, but this time through the Web UI). It also reminds me that I still need to figure out where these components come in the runtime architecture üòÖ&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/10/CleanShot_2023-10-10_at_16.15.25.webp&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Job Manager&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;2023-10-10 16:13:07,606 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job collect (ffde32919ba32f82b41bbbb451ac64a2) switched from state RUNNING to CANCELLING.
2023-10-10 16:13:07,607 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: firewall[27] -&amp;gt; Sink: Collect table sink (1/1) (18449605df5a8d831d44b7cb4e2d74cb_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2023-10-10 16:13:07,612 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: firewall[27] -&amp;gt; Sink: Collect table sink (1/1) (18449605df5a8d831d44b7cb4e2d74cb_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2023-10-10 16:13:07,612 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job collect (ffde32919ba32f82b41bbbb451ac64a2) switched from state CANCELLING to CANCELED.
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Task Manager&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;2023-10-10 16:13:07,607 INFO org.apache.flink.runtime.taskmanager.Task [] - Attempting to cancel task Source: firewall[27] -&amp;gt; Sink: Collect table sink (1/1)#0 (18449605df5a8d831d44b7cb4e2d74cb_cbc357ccb763df2852fee8c4fc7d55f2_0_0).

2023-10-10 16:13:07,607 INFO org.apache.flink.runtime.taskmanager.Task [] - Source: firewall[27] -&amp;gt; Sink: Collect table sink (1/1)#0 (18449605df5a8d831d44b7cb4e2d74cb_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.

2023-10-10 16:13:07,607 INFO org.apache.flink.runtime.taskmanager.Task [] - Triggering cancellation of task code Source: firewall[27] -&amp;gt; Sink: Collect table sink (1/1)#0 (18449605df5a8d831d44b7cb4e2d74cb_cbc357ccb763df2852fee8c4fc7d55f2_0_0).

2023-10-10 16:13:07,609 INFO org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.

2023-10-10 16:13:07,610 INFO org.apache.flink.runtime.taskmanager.Task [] - Source: firewall[27] -&amp;gt; Sink: Collect table sink (1/1)#0 (18449605df5a8d831d44b7cb4e2d74cb_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;UPDATE&lt;/strong&gt;: I&amp;rsquo;ve logged &lt;a href=&#34;https://issues.apache.org/jira/browse/FLINK-33251&#34;&gt;&lt;strong&gt;[FLINK-33251] SQL Client query execution aborts after a few seconds: ConnectTimeoutException - ASF JIRA&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;One short-term workaround I did find was to simply use 1.16.2 where this error doesn&amp;rsquo;t seem to happen.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;time-out&#34;&gt;Time out&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/10/timeout.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;At this point I&amp;rsquo;ve got the basics of a query running, I&amp;rsquo;ve learnt something about tables and connectors - and I&amp;rsquo;m stuck!&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m going to step back, and learn more about the Flink architecture and components before digging myself a deeper hole on this particular issue üòÅ Particular things I&amp;rsquo;ve come across during my reading that I want to find out more about include the &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/dev/table/sql-gateway/overview/#introduction&#34;&gt;SQL Gateway&lt;/a&gt;, &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/dev/table/concepts/dynamic_tables/&#34;&gt;Dynamic Tables&lt;/a&gt;, and the &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/concepts/flink-architecture/&#34;&gt;Flink Architecture&lt;/a&gt; docs.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Join me next time for more fun and stack traces‚Ä¶&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Learning Apache Flink S01E03: Running my First Flink Cluster and Application</title>
      <link>https://rmoff.net/2023/10/05/learning-apache-flink-s01e03-running-my-first-flink-cluster-and-application/</link>
      <pubDate>2023-10-05</pubDate>
      
      <guid>https://rmoff.net/2023/10/05/learning-apache-flink-s01e03-running-my-first-flink-cluster-and-application/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2023/10/t_IMG_5439.webp" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;p&gt;üéâ I just ran my first Apache Flink cluster and application on it üéâ&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/10/flinkrun.webp&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;I followed the &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/try-flink/local_installation/&#34;&gt;&lt;strong&gt;First Steps&lt;/strong&gt; quickstart from the Flink docs&lt;/a&gt; which is a nicely-paced walk through:&lt;/p&gt;
&lt;p&gt;0Ô∏è‚É£ make sure you&amp;rsquo;ve got Java 11&lt;/p&gt;
&lt;p&gt;1Ô∏è‚É£ install Flink (&lt;a href=&#34;https://flink.apache.org/downloads/&#34;&gt;download&lt;/a&gt;, unpack (with a &lt;a href=&#34;https://rmoff.net/2023/10/04/cd-string-not-in-pwd/&#34;&gt;little detour&lt;/a&gt;))&lt;/p&gt;
&lt;p&gt;2Ô∏è‚É£ run it (&lt;code&gt;./bin/start-cluster.sh&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;3Ô∏è‚É£ submit the sample WordCount app&lt;/p&gt;
&lt;p&gt;4Ô∏è‚É£ see the execution in the web UI&lt;/p&gt;
&lt;p&gt;5Ô∏è‚É£ examine the output&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/10/flinktail.webp&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;The WebUI is a nice touch - sometimes just running everything on the CLI gives you a technically correct finish but if you&amp;rsquo;re new to something leaves you underwhelmed. The webUI lets you click around a bit and start to get a feel for what&amp;rsquo;s going on.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/10/flinkui01.webp&#34; alt=&#34;The Flink web UI&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/10/flinkui02.webp&#34; alt=&#34;The Flink web UI&#34;&gt;&lt;/p&gt;
&lt;p&gt;You can find the source for the WordCount app &lt;a href=&#34;https://github.com/apache/flink/blob/release-1.17/flink-examples/flink-examples-batch/src/main/java/org/apache/flink/examples/java/wordcount/WordCount.java&#34;&gt;here&lt;/a&gt;, and further tutorials on Flink &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/try-flink/local_installation/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>cd: string not in pwd</title>
      <link>https://rmoff.net/2023/10/04/cd-string-not-in-pwd/</link>
      <pubDate>2023-10-04</pubDate>
      
      <guid>https://rmoff.net/2023/10/04/cd-string-not-in-pwd/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2023/10/t_IMG_8657.webp" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;p&gt;A brief diversion from my &lt;a href=&#34;https://rmoff.net/categories/laf/&#34;&gt;journey learning Apache Flink&lt;/a&gt; to document an interesting &lt;code&gt;zsh&lt;/code&gt; oddity that briefly tripped me up:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd: string not in pwd: flink-1.17.1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This was on the third step of &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/try-flink/local_installation/#browsing-the-project-directory&#34;&gt;Flink First Steps&lt;/a&gt;, in which you&amp;rsquo;re instructed to browse the project directory after having downloaded and unarchived the tar.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ &lt;span style=&#34;color:#008000&#34;&gt;pwd&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;/Users/rmoff/flink
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ ls -l
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;total &lt;span style=&#34;color:#666&#34;&gt;917512&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;drwxr-xr-x@ &lt;span style=&#34;color:#666&#34;&gt;13&lt;/span&gt; rmoff  staff        &lt;span style=&#34;color:#666&#34;&gt;416&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;19&lt;/span&gt; May 12:14 flink-1.17.1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;-rw-r--r--@  &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt; rmoff  staff  &lt;span style=&#34;color:#666&#34;&gt;469413690&lt;/span&gt;  &lt;span style=&#34;color:#666&#34;&gt;4&lt;/span&gt; Oct 15:52 flink-1.17.1-bin-scala_2.12.tgz
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ &lt;span style=&#34;color:#008000&#34;&gt;cd&lt;/span&gt; flink-*
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd: string not in pwd: flink-1.17.1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Looking at the directory listing, or simply hammering the tab key to auto-complete, most of us wouldn&amp;rsquo;t bother this much more than just entering the full directory name instead:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ &lt;span style=&#34;color:#008000&#34;&gt;cd&lt;/span&gt; flink-1.17.1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ ls -l
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;total &lt;span style=&#34;color:#666&#34;&gt;320&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;-rw-r--r--@  &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt; rmoff  staff   &lt;span style=&#34;color:#666&#34;&gt;11357&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;19&lt;/span&gt; May 09:43 LICENSE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;-rw-r--r--@  &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt; rmoff  staff  &lt;span style=&#34;color:#666&#34;&gt;145829&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;19&lt;/span&gt; May 12:14 NOTICE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;-rw-r--r--@  &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt; rmoff  staff    &lt;span style=&#34;color:#666&#34;&gt;1309&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;19&lt;/span&gt; May 09:43 README.txt
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;drwxr-xr-x@ &lt;span style=&#34;color:#666&#34;&gt;24&lt;/span&gt; rmoff  staff     &lt;span style=&#34;color:#666&#34;&gt;768&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;19&lt;/span&gt; May 12:14 bin
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;drwxr-xr-x@ &lt;span style=&#34;color:#666&#34;&gt;13&lt;/span&gt; rmoff  staff     &lt;span style=&#34;color:#666&#34;&gt;416&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;19&lt;/span&gt; May 12:14 conf
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#666&#34;&gt;[&lt;/span&gt;‚Ä¶&lt;span style=&#34;color:#666&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;But the fix isn&amp;rsquo;t half as interesting as the reason :)&lt;/p&gt;
&lt;h2 id=&#34;whats-old-is-new&#34;&gt;What&amp;rsquo;s old is new?&lt;/h2&gt;
&lt;p&gt;Turns out zsh has more than one form of the &lt;code&gt;cd&lt;/code&gt; command. By using a wildcard the tutorial&amp;rsquo;s instructions avoid having to hard code the version. However, as a result the second type of invocation of zsh&amp;rsquo;s &lt;code&gt;cd&lt;/code&gt; command is triggered.&lt;/p&gt;
&lt;p&gt;Remember that the directory we&amp;rsquo;re currently in has the archive that we&amp;rsquo;ve downloaded and expanded.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ ls -l
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;total &lt;span style=&#34;color:#666&#34;&gt;917512&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;drwxr-xr-x@ &lt;span style=&#34;color:#666&#34;&gt;13&lt;/span&gt; rmoff  staff        &lt;span style=&#34;color:#666&#34;&gt;416&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;19&lt;/span&gt; May 12:14 flink-1.17.1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;-rw-r--r--@  &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt; rmoff  staff  &lt;span style=&#34;color:#666&#34;&gt;469413690&lt;/span&gt;  &lt;span style=&#34;color:#666&#34;&gt;4&lt;/span&gt; Oct 15:52 flink-1.17.1-bin-scala_2.12.tgz
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This means that the wildcard matches not just the unpacked directory, but the archive too.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ print flink-*
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;flink-1.17.1 flink-1.17.1-bin-scala_2.12.tgz
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The important point here is that there is &lt;strong&gt;more than one match to the glob&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;If there is more than one argument passed then the &lt;a href=&#34;https://zsh.sourceforge.io/Doc/Release/Shell-Builtin-Commands.html#index-cd&#34;&gt;second form of zsh&amp;rsquo;s &lt;code&gt;cd&lt;/code&gt;&lt;/a&gt; is used: &lt;em&gt;&lt;code&gt;cd old new&lt;/code&gt;&lt;/em&gt;. Here, the second argument is substituted for the first, which means that we&amp;rsquo;re effectively entering (if you expand the wildcard):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000&#34;&gt;cd&lt;/span&gt; flink-1.17.1 flink-1.17.1-bin-scala_2.12.tgz
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Which per the syntax will try to replace the value for the &amp;ldquo;old&amp;rdquo; parameter (&lt;code&gt;flink-1.17.1&lt;/code&gt;) in &lt;code&gt;pwd&lt;/code&gt; (the working directory) with the value for the &amp;ldquo;new&amp;rdquo; parameter (&lt;code&gt;flink-1.17.1-bin-scala_2.12.tgz&lt;/code&gt;)‚Äîbut the working directory is &lt;code&gt;/Users/rmoff/flink&lt;/code&gt; and thus the error &lt;code&gt;string not in pwd: flink-1.17.1&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;how-is-cd-old-new-useful&#34;&gt;How is &lt;code&gt;cd old new&lt;/code&gt; useful?&lt;/h2&gt;
&lt;p&gt;Imagine you&amp;rsquo;ve got this directory structure:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;foo
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;‚îú‚îÄ‚îÄ v1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;‚îÇ¬†¬† ‚îî‚îÄ‚îÄ bar
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ wibble
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;‚îÇ¬†¬†         ‚îî‚îÄ‚îÄ bork
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;‚îÇ¬†¬†             ‚îî‚îÄ‚îÄ bork
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;‚îÇ¬†¬†                 ‚îî‚îÄ‚îÄ bork
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;‚îî‚îÄ‚îÄ v2
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ‚îî‚îÄ‚îÄ bar
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        ‚îî‚îÄ‚îÄ wibble
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            ‚îî‚îÄ‚îÄ bork
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                ‚îî‚îÄ‚îÄ bork
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    ‚îî‚îÄ‚îÄ bork
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You&amp;rsquo;re in the &lt;code&gt;v1&lt;/code&gt; set of the folders, deep in the structure:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ &lt;span style=&#34;color:#008000&#34;&gt;pwd&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;/Users/rmoff/foo/v1/bar/wibble/bork/bork/bork
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now you want to be in same place but &lt;code&gt;v2&lt;/code&gt;. You could &lt;code&gt;cd ../../../../..&lt;/code&gt; and lose count. You could start again from the top (&lt;code&gt;cd ~/foo/v2/&lt;/code&gt; and type out the full path again). You could probably do other shell magic that you can &lt;a href=&#34;https://twitter.com/rmoff/&#34;&gt;tell me about on &lt;del&gt;Twitter&lt;/del&gt;X&lt;/a&gt;. Or you could do this:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ &lt;span style=&#34;color:#008000&#34;&gt;cd&lt;/span&gt; v1 v2
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;~/foo/v2/bar/wibble/bork/bork/bork
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;So‚Äîpossibly useful, but definitely derailing bash &lt;code&gt;cd&lt;/code&gt; glob assumptions for plenty of folk ;)&lt;/p&gt;
&lt;p&gt;(&lt;a href=&#34;https://github.com/ohmyzsh/ohmyzsh/issues/10092#issuecomment-894804081&#34;&gt;h/t&lt;/a&gt;)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Learning Apache Flink S01E02: What *is* Flink?</title>
      <link>https://rmoff.net/2023/10/02/learning-apache-flink-s01e02-what-is-flink/</link>
      <pubDate>2023-10-02</pubDate>
      
      <guid>https://rmoff.net/2023/10/02/learning-apache-flink-s01e02-what-is-flink/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2023/10/t_IMG_5412.webp" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;p&gt;My &lt;a href=&#34;https://rmoff.net/2023/09/29/learning-apache-flink-s01e01-where-do-i-start/&#34;&gt;journey&lt;/a&gt; with &lt;a href=&#34;https://flink.apache.org&#34;&gt;Apache Flink&lt;/a&gt; begins with an overview of &lt;em&gt;what Flink actually is&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;What better place to start than the &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.17/#apache-flink-documentation&#34;&gt;Apache Flink website itself&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Apache Flink&lt;/strong&gt;¬†is a framework and distributed processing engine for stateful computations over¬†&lt;em&gt;unbounded&lt;/em&gt;¬†and¬†&lt;em&gt;bounded&lt;/em&gt;¬†data streams. Flink has been designed to run in¬†&lt;em&gt;all common cluster environments&lt;/em&gt;, perform computations at¬†&lt;em&gt;in-memory&lt;/em&gt;¬†speed and at¬†&lt;em&gt;any scale&lt;/em&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/10/lafs01e02.webp&#34; alt=&#34;An image of a squirrel making notes with a big pile of books and papers behind him&#34;&gt;&lt;/p&gt;
&lt;p&gt;In this post, I&amp;rsquo;m going to summarise my current‚Äîpossibly na√Øve‚Äîunderstanding of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#so-what-is-flink&#34;&gt;What Flink is&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#use-cases&#34;&gt;What Flink is used for&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#users-of-flink&#34;&gt;Who uses Flink&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#how-do-you-run-flink&#34;&gt;How do you run Flink&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-flink-community&#34;&gt;Where to find the Flink community&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;so-what-is-flink&#34;&gt;So: What is Flink?&lt;/h2&gt;
&lt;p&gt;I found a couple of &lt;a href=&#34;https://www.dataengineeringpodcast.com/apache-flink-with-fabian-hueske-episode-57&#34;&gt;excellent&lt;/a&gt; &lt;a href=&#34;https://overcast.fm/+BAj84H3884&#34;&gt;podcasts&lt;/a&gt; from &lt;a href=&#34;https://www.linkedin.com/in/fhueske/&#34;&gt;Fabian Heuske&lt;/a&gt; and my &lt;a href=&#34;https://decodable.co/&#34;&gt;Decodable&lt;/a&gt; colleague &lt;a href=&#34;https://www.linkedin.com/in/metzgerrobert/?originalSubdomain=de&#34;&gt;Robert Metzger&lt;/a&gt; respectively that gave some really useful background on the project:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Flink started life as a research project in 2011, called &lt;a href=&#34;https://scholar.google.com/citations?view_op=view_citation&amp;amp;hl=en&amp;amp;user=Q1LJyvQAAAAJ&amp;amp;citation_for_view=Q1LJyvQAAAAJ:_FxGoFyzp5QC&#34;&gt;&lt;em&gt;Stratosphere&lt;/em&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;It was donated to &lt;a href=&#34;https://www.apache.org/&#34;&gt;Apache Software Foundation&lt;/a&gt; in 2014.&lt;/li&gt;
&lt;li&gt;Version 1.0 released 2016, latest version is &lt;a href=&#34;https://flink.apache.org/downloads/#apache-flink-1171&#34;&gt;1.17&lt;/a&gt; .&lt;/li&gt;
&lt;li&gt;Whilst it was originally designed for batch, it always used streaming principles, making its move into stream processing a logical one&lt;/li&gt;
&lt;li&gt;Hadoop revolutionised the distributed processing of data at scale, but was &amp;ldquo;dumb&amp;rdquo;. Flink aimed to use some of the principles whilst bringing in important learnings from the RDBMS world that had been missed in Hadoop. Flink includes a bunch of things that you&amp;rsquo;d have to build for yourself in Hadoop, such as pipelined execution (e.g. all stages run concurrently and stream data), native join operators, and it re-use of data properties such as the data being sorted or partitioned already in a certain way.&lt;/li&gt;
&lt;li&gt;JVM-based. &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-master/docs/dev/table/sql/overview/&#34;&gt;SQL&lt;/a&gt; and &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-master/docs/dev/python/overview/&#34;&gt;PyFlink&lt;/a&gt; added in recent years.&lt;/li&gt;
&lt;li&gt;Flink is a Distributed system. &lt;a href=&#34;https://overcast.fm/+H1YOnxO3I/05:50&#34;&gt;Each&lt;/a&gt; worker stores state.&lt;/li&gt;
&lt;li&gt;It &lt;a href=&#34;https://overcast.fm/+H1YOnxO3I/23:29&#34;&gt;supports&lt;/a&gt; exactly once state guarantee with checkpointing across workers that stores the processing state (such as aggregations), as well as the metadata of input sources (e.g. Kafka topics offsets) all on a distributed filesystem (e.g. S3)&lt;/li&gt;
&lt;li&gt;Event time processing. &lt;a href=&#34;https://overcast.fm/+H1YOnxO3I/21:42&#34;&gt;Uses&lt;/a&gt; watermarks (same as Google data flow), which enable you to trade off between completeness and latency.&lt;/li&gt;
&lt;li&gt;ü§Ø Everything is a stream; it&amp;rsquo;s just some streams are bounded, whilst others are unbounded.
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;Wait, What? Everything is a Stream?&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;From my background with Apache Kafka and the &lt;a href=&#34;https://www.michael-noll.com/blog/2018/04/05/of-stream-and-tables-in-kafka-and-stream-processing-part1/&#34;&gt;stream-table duality&lt;/a&gt;, this source-agnostic framing of events is different, and I can&amp;rsquo;t wait to explore it further. I&amp;rsquo;m interested to see if it&amp;rsquo;s just a matter of semantics, or if there is something fundamentally different in how Flink reasons about streams of events vs state for given keys.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;uses--users-of-flink&#34;&gt;Uses &amp;amp; Users of Flink&lt;/h2&gt;
&lt;h3 id=&#34;use-cases&#34;&gt;Use Cases&lt;/h3&gt;
&lt;p&gt;The documentation for Flink lays out &lt;a href=&#34;https://flink.apache.org/use-cases/&#34;&gt;three distinct use cases&lt;/a&gt; for Flink. Under each are linked several examples, mostly from the Flink Forward conference.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://flink.apache.org/use-cases/#event-driven-applications-a-nameeventdrivenappsa&#34;&gt;&lt;strong&gt;Event-driven Applications&lt;/strong&gt;&lt;/a&gt;, e.g.
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=Do7C4UJyWCM/&#34;&gt;Fraud detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=rJNH5WhWAj4/&#34;&gt;Anomaly detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=_yHds9SvMfE/&#34;&gt;Rule-based alerting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jobs.zalando.com/tech/blog/complex-event-generation-for-business-process-monitoring-using-apache-flink/&#34;&gt;Business process monitoring&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=0cJ565r2FVI/&#34;&gt;Web application (social network)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://flink.apache.org/use-cases/#data-analytics-applicationsa-nameanalyticsa&#34;&gt;&lt;strong&gt;Data Analytics Applications&lt;/strong&gt;&lt;/a&gt;, e.g.
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=izYsMQWeUbE/&#34;&gt;Quality monitoring of Telco networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=17tUR4TsvpM/&#34;&gt;Analysis of product updates &amp;amp; experiment evaluation&lt;/a&gt;¬†&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://eng.uber.com/athenax/&#34;&gt;Ad-hoc analysis of live data&lt;/a&gt;¬†&lt;/li&gt;
&lt;li&gt;Large-scale graph analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://flink.apache.org/use-cases/#data-pipeline-applications-a-namepipelinesa&#34;&gt;&lt;strong&gt;Data Pipeline Applications&lt;/strong&gt;&lt;/a&gt;, e.g.
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://ververica.com/blog/blink-flink-alibaba-search&#34;&gt;Real-time search index building&lt;/a&gt;¬†&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jobs.zalando.com/tech/blog/apache-showdown-flink-vs.-spark/&#34;&gt;Continuous ETL&lt;/a&gt;¬† (a.k.a. &amp;ldquo;Streaming ETL&amp;rdquo;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;One thing that&amp;rsquo;s interesting about the linked examples is that they are all from 6-7 years ago. One can look at this two ways. Put positively, it demonstrates what a long history and proof of success Flink has when it comes to experience in stream processing. Being snarky, one would cast it in the light that Flink is a technology of the past, on its way out with the Hadoops of this world.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;d strongly reject the latter view. You may say that is obvious given that I now work for a company offering &lt;a href=&#34;https://decodable.co/&#34;&gt;a managed Flink service&lt;/a&gt; üòâ. But this in itself is a point to counter the snark. There are multiple companies &lt;em&gt;launching&lt;/em&gt; Flink as a service‚Äîincluding companies which already had stream processing offerings based on other technology. Flink is a well-established technology with a strong &lt;a href=&#34;https://flink.apache.org/roadmap/&#34;&gt;roadmap&lt;/a&gt; and a &lt;a href=&#34;https://flink.apache.org/roadmap/#scenarios-we-focus-on&#34;&gt;modern and cloud-native vision&lt;/a&gt; for its future direction.&lt;/p&gt;
&lt;h3 id=&#34;users-of-flink&#34;&gt;Users of Flink&lt;/h3&gt;
&lt;p&gt;Whilst the rise of managed Flink services is one proof-point demonstrating Flink&amp;rsquo;s popularity, the other irrefutable one is its &lt;em&gt;continued use&lt;/em&gt; in a wide range of companies and use cases (and not just those from 6-7 years ago). A quick look through the back issues of &lt;a href=&#34;https://www.dataengineeringweekly.com/&#34;&gt;Data Engineering Weekly&lt;/a&gt; and past sessions of &lt;a href=&#34;https://www.flink-forward.org/events&#34;&gt;Flink Forward&lt;/a&gt; and other conferences demonstrates this.&lt;/p&gt;
&lt;p&gt;Users with &lt;strong&gt;recent&lt;/strong&gt; (in the last ~two years) published use cases include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://alibaba-cloud.medium.com/four-billion-records-per-second-f8eeabce934d&#34;&gt;Alibaba Cloud&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.flink-forward.org/sf-2022/conference-program#alexa--be-quiet---end-to-end-near-real-time-model-building-and-evaluation-in-amazon-alexa&#34;&gt;Amazon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.infoq.com/presentations/apache-iceberg-streaming/&#34;&gt;Apple&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=-wSbb4JSuZU&#34;&gt;Booking.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/capital-one-tech/exploring-apache-flink-aws-kda-realtime-data-streaming-7201ed4ed197&#34;&gt;Capital One&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://doordash.engineering/2021/07/14/open-source-search-indexing/&#34;&gt;DoorDash&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.flink-forward.org/seattle-2023/agenda#model-inference-in-flink-sql-using-a-custom-http-connector&#34;&gt;ING Bank&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://tech.instacart.com/building-a-flink-self-serve-platform-on-kubernetes-at-scale-c11ef19aef10&#34;&gt;Instacart&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.flink-forward.org/seattle-2023/agenda#quality-scale-with-flink&#34;&gt;JP MorganChase&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.slideshare.net/FlinkForward/building-a-fully-managed-stream-processing-platform-on-flink-at-scale-for-linkedin-252866883&#34;&gt;LinkedIn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://eng.lyft.com/wheres-my-data-a-unique-encounter-with-flink-streaming-s-kinesis-connector-6da3b11b164a&#34;&gt;Lyft&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://netflixtechblog.com/data-mesh-a-data-movement-and-processing-platform-netflix-1288bcab2873&#34;&gt;Netflix&lt;/a&gt; (&lt;a href=&#34;https://netflixtechblog.com/keystone-real-time-stream-processing-platform-a3ee651812a&#34;&gt;ad&lt;/a&gt; &lt;a href=&#34;https://www.google.com/search?q=site:netflixtechblog.com+flink&#34;&gt;infinitum&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/pinterest-engineering/lessons-from-debugging-a-tricky-direct-memory-leak-f638c722d9f2&#34;&gt;Pintrest&lt;/a&gt; (this &lt;a href=&#34;https://medium.com/pinterest-engineering/unified-flink-source-at-pinterest-streaming-data-processing-c9d4e89f2ed6&#34;&gt;older article&lt;/a&gt; lists more of their use cases)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.flink-forward.org/seattle-2023/agenda#protecting-reddit-users-at-scale-with-flink-stateful-functions&#34;&gt;Reddit&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://shopify.engineering/optimizing-apache-flink-applications-tips&#34;&gt;Shopify&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://speakerdeck.com/jeffchao/flink-forward-2022-squirreling-away-640-dollars-billion-how-stripe-leverages-flink-for-change-data-capture&#34;&gt;Stripe&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.flink-forward.org/seattle-2023/agenda#self-service-data-ingestion-platform-at-tiktok--powering--foryoupage-for--b--users&#34;&gt;TikTok&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.uber.com/en-GB/blog/real-time-exactly-once-ad-event-processing/&#34;&gt;Uber&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://vinted.engineering/2023/09/25/search-indexing-pipeline/&#34;&gt;Vinted&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;See also the Powered By Flink &lt;a href=&#34;https://flink.apache.org/powered-by/&#34;&gt;highlights&lt;/a&gt; and &lt;a href=&#34;https://cwiki.apache.org/confluence/display/FLINK/Powered+by+Flink&#34;&gt;complete list&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;what-can-flink-do-vs-where-will-you-find-flink&#34;&gt;&amp;ldquo;What Can Flink Do&amp;rdquo; vs &amp;ldquo;Where Will You Find Flink&amp;rdquo;&lt;/h3&gt;
&lt;p&gt;After I posted the first draft of this post, my colleague (and Apache Flink PMC Chair!) Robert Metzger shared this useful slide with me.&lt;/p&gt;
&lt;p&gt;I like this because it spells out &lt;em&gt;what&lt;/em&gt; Flink does (e.g. Windowing, Streaming Joins, Filtering, etc), and separately, &lt;em&gt;where&lt;/em&gt; it gets used for that.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/10/flink_uses.webp&#34; alt=&#34;Slide showing what Flink can do, and what applications it is found doing this within&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;how-do-you-run-flink&#34;&gt;How do you run Flink?&lt;/h2&gt;
&lt;h3 id=&#34;self-managed&#34;&gt;Self-Managed&lt;/h3&gt;
&lt;p&gt;Flink is a distributed system, which means that you don&amp;rsquo;t just buy one great big box and scale it up and up for capacity. Instead, you deploy it across multiple instances for both scalability and fault-tolerance.&lt;/p&gt;
&lt;p&gt;The Flink documentation has a clear set of instructions for running Flink using the &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/resource-providers/standalone/overview/&#34;&gt;binaries directly&lt;/a&gt;, under &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/resource-providers/standalone/docker/&#34;&gt;Docker&lt;/a&gt;, and with &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/resource-providers/native_kubernetes/&#34;&gt;Kubernetes&lt;/a&gt;. Betraying its Big Data history, is also still supports &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/resource-providers/yarn/&#34;&gt;YARN&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;managed-service&#34;&gt;Managed Service&lt;/h3&gt;
&lt;p&gt;Did I mention yet that &lt;a href=&#34;https://decodable.co/&#34;&gt;Decodable&lt;/a&gt; offers a fully-managed Apache Flink service? :-D&lt;/p&gt;
&lt;p&gt;You can find a list of other vendors that offer Apache Flink as a managed service in &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/overview/#vendor-solutions&#34;&gt;the Flink documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;the-flink-community&#34;&gt;The Flink Community&lt;/h2&gt;
&lt;p&gt;Just like any healthy open-source project, there is a good community around Flink. Per the Apache motto:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If it didn‚Äôt happen on a mailing list, it didn‚Äôt happen.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The &lt;a href=&#34;https://flink.apache.org/community/&#34;&gt;community&lt;/a&gt; page on the Flink site lists numerous mailing lists. &lt;code&gt;news@&lt;/code&gt; and &lt;code&gt;community@&lt;/code&gt; are both pretty stagnant, but &lt;a href=&#34;https://lists.apache.org/list.html?user@flink.apache.org&#34;&gt;users@&lt;/a&gt; is well-used with half a dozen posts per day. If you&amp;rsquo;re contributing to Flink (rather than just using it) you&amp;rsquo;ll want the &lt;code&gt;dev@&lt;/code&gt; list too.&lt;/p&gt;
&lt;p&gt;Alongside the mailing lists, there is a &lt;a href=&#34;https://join.slack.com/t/apache-flink/shared_invite/zt-22mklt3r5-89MjX41gqHsBk81ZoTDqXg&#34;&gt;Slack group&lt;/a&gt; with 3k members. It has a good layout of channels, and a handful of messages per day&lt;/p&gt;
&lt;p&gt;You&amp;rsquo;ll also find a steady stream of Flink questions and answers on &lt;a href=&#34;https://stackoverflow.com/questions/tagged/apache-flink&#34;&gt;StackOverflow&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;whats-next-for-flink&#34;&gt;What&amp;rsquo;s next for Flink?&lt;/h2&gt;
&lt;p&gt;There&amp;rsquo;s a &lt;a href=&#34;https://flink.apache.org/roadmap/&#34;&gt;comprehensive and well-maintained roadmap&lt;/a&gt; for Flink. Changes are made through FLIPs (&lt;em&gt;&lt;strong&gt;FL&lt;/strong&gt;ink &lt;strong&gt;I&lt;/strong&gt;mprovement &lt;strong&gt;P&lt;/strong&gt;roposals&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;As well as what&amp;rsquo;s coming there&amp;rsquo;s also a clear list of &lt;a href=&#34;https://flink.apache.org/roadmap/#feature-radar&#34;&gt;features that are being phased out&lt;/a&gt;. This level of insight into the project is really useful for a newbie‚Äîgiven how long Flink has been around (aeons, in internet years) there is going to be a lot of material published that is out of date and this chart will hopefully be a quick way to navigate that.&lt;/p&gt;
&lt;p&gt;The roadmap page is notable for not only a list of planned features but also the &lt;a href=&#34;https://flink.apache.org/roadmap/#scenarios-we-focus-on&#34;&gt;general strategy&lt;/a&gt; (which should help inform users as to whether their use cases are within sensible bounds) and even something close to my own heart: &lt;a href=&#34;https://flink.apache.org/roadmap/#developer-experience&#34;&gt;developer experience&lt;/a&gt;. One particularly interesting bit that caught my eye is the idea of built-in dynamic table storage, described in &lt;a href=&#34;https://cwiki.apache.org/confluence/display/FLINK/FLIP-188%3A+Introduce+Built-in+Dynamic+Table+Storage&#34;&gt;FLIP-188&lt;/a&gt; and‚Äîif I understand correctly‚Äîspun out into its own Apache Incubator project, &lt;a href=&#34;https://paimon.apache.org/&#34;&gt;Apache Paimon&lt;/a&gt;. Paimon describes itself as a &amp;ldquo;&lt;em&gt;Streaming data lake platform&lt;/em&gt;&amp;rdquo; and is definitely on my list to go and check out particularly after &lt;a href=&#34;https://rmoff.net/2022/09/14/data-engineering-in-2022-storage-and-access/&#34;&gt;my work last year on mapping out the data engineering landscape&lt;/a&gt; as at first glance I&amp;rsquo;m not sure where it fits.&lt;/p&gt;
&lt;h2 id=&#34;flink-resources&#34;&gt;Flink Resources&lt;/h2&gt;
&lt;p&gt;The &lt;a href=&#34;https://flink.apache.org&#34;&gt;Apache Flink project website&lt;/a&gt; itself is an excellent resource. Especially when compared to some other Apache projects (&lt;em&gt;cough&lt;/em&gt;), it&amp;rsquo;s extremely well laid out, thoughtfully organised, and easy to use.&lt;/p&gt;
&lt;p&gt;Some other good places for Flink information include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;a href=&#34;https://www.flink-forward.org/&#34;&gt;Flink Forward&lt;/a&gt; conference (&lt;a href=&#34;https://www.flink-forward.org/events&#34;&gt;previous events&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Podcasts
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://overcast.fm/itunes1193040557/data-engineering-podcast&#34;&gt;Stateful, Distributed Stream Processing on Flink with Fabian Hueske&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://overcast.fm/+BAj84H3884&#34;&gt;Inside Apache Flink: A Conversation with Robert Metzger&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://overcast.fm/+BAj87Wiuo4&#34;&gt;Diving Deep into Apache Flink with Robert Metzger&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cse.google.com/cse?cx=010150859881542981030:hqhxyxpwtc4&amp;amp;ie=UTF-8&amp;amp;q=Apache+Flink+&amp;amp;sa=Search&#34;&gt;Apache Flink presentations on SpeakerDeck&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Learning Apache Flink S01E01: Where Do I Start?</title>
      <link>https://rmoff.net/2023/09/29/learning-apache-flink-s01e01-where-do-i-start/</link>
      <pubDate>2023-09-29</pubDate>
      
      <guid>https://rmoff.net/2023/09/29/learning-apache-flink-s01e01-where-do-i-start/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2023/09/t_IMG_5443.webp" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;p&gt;Like a fortunate child on Christmas Day, I&amp;rsquo;ve got a brand new toy! A brand new‚Äîto me‚Äîopen-source technology to unwrap, learn, and perhaps even aspire to master elements of within.&lt;/p&gt;
&lt;p&gt;I &lt;a href=&#34;https://rmoff.net/2023/09/21/an-itch-that-just-has-to-be-scratched-or-why-am-i-joining-decodable&#34;&gt;joined Decodable&lt;/a&gt; two weeks ago, and since &lt;a href=&#34;https://decodable.co/&#34;&gt;Decodable&lt;/a&gt; is built on top of &lt;a href=&#34;https://flink.apache.org&#34;&gt;Apache Flink&lt;/a&gt; it seems like a great time to learn it. After six years learning Apache Kafka and hearing about this &amp;ldquo;Flink&amp;rdquo; thing but‚Äîfor better or worse‚Äînever investigating it, I now have the perfect opportunity to do so.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/09/20230929134244.webp&#34; alt=&#34;An image of a squirrel at a laptop looking at a map, preparing to navigate the wonderful world of Apache Flink&#34;&gt;&lt;/p&gt;
&lt;p&gt;Just like the aforementioned kid with a new toy, what else would I do except run around (figuratively) with wild excitement, clicking on all the Apache Flink links and demos and tutorials and presentations and videos that I could find! And then I realised I should take somewhat of a more measured approach to my learning, and started to map out the different areas.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/09/learningflink.webp&#34; alt=&#34;A mindmap of the areas of Apache Flink about which I want to learn&#34;&gt;&lt;/p&gt;
&lt;p&gt;Breaking this out into sub-topics gives me nice little nuggets to start exploring (and blogging about, of course!). These include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What &lt;em&gt;is&lt;/em&gt; Flink (high level)
&lt;ul&gt;
&lt;li&gt;Uses &amp;amp; Users&lt;/li&gt;
&lt;li&gt;How do you run Flink&lt;/li&gt;
&lt;li&gt;Who can use Flink?
&lt;ul&gt;
&lt;li&gt;Java nerds only, or &lt;del&gt;normal&lt;/del&gt; non-Java folk too? üòú&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Resources&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Flink Architecture, Concepts, and Components&lt;/li&gt;
&lt;li&gt;Learn some Flink!&lt;/li&gt;
&lt;li&gt;Where does Flink sit in relation to other software in this space?
&lt;ul&gt;
&lt;li&gt;A mental map for me, not a holy war of streaming projects&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Some of these are going to be fairly self-contained (what &lt;em&gt;is&lt;/em&gt; Flink) whilst others (learning Flink) are going to be a multi-year journey :)&lt;/p&gt;</description>
    </item>
    <item>
      <title>An Itch That Just Has to Be Scratched‚Ä¶ (Or, Why Am I Joining Decodable?)</title>
      <link>https://rmoff.net/2023/09/21/an-itch-that-just-has-to-be-scratched-or-why-am-i-joining-decodable/</link>
      <pubDate>2023-09-21</pubDate>
      
      <guid>https://rmoff.net/2023/09/21/an-itch-that-just-has-to-be-scratched-or-why-am-i-joining-decodable/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2023/09/t_IMG_8746.jpeg" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;p&gt;This week I joined &lt;a href=&#34;https://decodable.co&#34;&gt;Decodable&lt;/a&gt;. I&amp;rsquo;m grateful to my former colleagues at Treeverse for allowing me to &lt;a href=&#34;https://rmoff.net/2022/12/09/looking-forwards-and-looking-backwards/&#34;&gt;join them&lt;/a&gt; on the journey with &lt;a href=&#34;https://lakefs.io&#34;&gt;lakeFS&lt;/a&gt; - but something about the streaming world was too strong to resist üòÅ.&lt;/p&gt;
&lt;p&gt;I spent several years previously at Confluent bringing my data engineer&amp;rsquo;s view of the world to help &lt;a href=&#34;https://rmoff.net/categories/kafka-connect/&#34;&gt;advocate&lt;/a&gt; &lt;a href=&#34;http://youtube.com/rmoff&#34;&gt;for&lt;/a&gt; what was being built within Confluent as &lt;a href=&#34;https://ksqldb.io/&#34;&gt;ksqlDB&lt;/a&gt;‚Äîand the broader Apache Kafka community in &lt;a href=&#34;https://kafka.apache.org/documentation.html#connect&#34;&gt;Kafka Connect&lt;/a&gt;‚Äîas a coherent platform on which analytics and data integration solutions could be built.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/09/just-when-i-thought-i-was-out-they-pull-me-back-in.gif&#34; alt=&#34;Just when I thought I was out / They Pull Me Back In - Al Pacino - The Godfather&#34;&gt;&lt;/p&gt;
&lt;p&gt;Turns out, stream processing was only really just getting started. In the last 12-18 months a veritable plethora of stream processing projects and companies have shown up, demonstrating that there is not only demand for it but also different approaches to take too.&lt;/p&gt;
&lt;p&gt;The advent of real-time data stores such as &lt;a href=&#34;https://druid.apache.org/&#34;&gt;Apache Druid&lt;/a&gt;, &lt;a href=&#34;https://pinot.apache.org/&#34;&gt;Apache Pinot&lt;/a&gt;, and &lt;a href=&#34;https://clickhouse.com/&#34;&gt;Clickhouse&lt;/a&gt; further complicates the picture (or makes it more interesting, depending on your view). How much do you serve from your operational application, your streams, or your dedicated realtime store? What&amp;rsquo;s driving the need for the data, and what kind of access patterns do you have?&lt;/p&gt;
&lt;p&gt;In short, I have unfinished business with streaming.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/09/notdone-got.gif&#34; alt=&#34;I Am Not Finished! - Yara Greyjoy - Game of Thrones&#34;&gt;&lt;/p&gt;
&lt;p&gt;Unsuprising really, since event streams &lt;em&gt;are&lt;/em&gt; unbounded ü§ì &lt;code&gt;&amp;lt;groan/&amp;gt;&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;abl-always-be-learning&#34;&gt;A.B.L. (Always Be Learning)&lt;/h2&gt;
&lt;p&gt;One of the many things that excites me about joining Decodable is the opportunity to dive in and learn &lt;a href=&#34;https://flink.apache.org/&#34;&gt;Apache Flink&lt;/a&gt;. I&amp;rsquo;m planning to blog my journey with it (similar to how I did as &lt;a href=&#34;https://rmoff.net/2020/06/25/learning-golang-some-rough-notes-s01e00/&#34;&gt;a complete n00b going into Go&lt;/a&gt;), so if you have any burning questions about it already then make sure to &lt;a href=&#34;https://twitter.com/rmoff/&#34;&gt;drop me&lt;/a&gt; &lt;a href=&#34;https://www.linkedin.com/in/robinmoffatt&#34;&gt;a line&lt;/a&gt; and I&amp;rsquo;ll be happy to use it as an excuse to go and find out the answer. And find out the answer I shall, because one of the &lt;em&gt;other&lt;/em&gt; many reasons that I&amp;rsquo;m so excited about Decodable is my colleagues here:&lt;/p&gt;
&lt;h2 id=&#34;never-be-the-smartest-in-the-room&#34;&gt;Never Be The Smartest in the Room&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Well, there&amp;rsquo;s never been any danger of that at any of my previous gigs‚ÄîI&amp;rsquo;ve been fortunate to work with some excellent people‚Äîand the same holds true for Decodable&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;One of the things that really sealed the deal for me during the interview process was just how damn smart the folk were. Not in a &amp;ldquo;&lt;em&gt;I ask you stupidly pointless question to highlight how smart I am, you wriggle for an answer that I&amp;rsquo;ll not really listen to, rinse &amp;amp; repeat&lt;/em&gt;&amp;rdquo; kind of way. But in a focussed and probing and inquisitive way, with true dialogue and listening. That&amp;rsquo;s the kind of stuff you can&amp;rsquo;t LeetCode for, and is a hugely positive indicator.&lt;/p&gt;
&lt;p&gt;As well as being lovely people to chat to and sharp as a sharp thing that&amp;rsquo;s just been sharpened, there&amp;rsquo;s some extensive and deep knowledge about the stream processing world in general and the projects which Decodable uses. These include folk such as &lt;a href=&#34;https://www.linkedin.com/in/esammer/&#34;&gt;Eric Sammer&lt;/a&gt;, &lt;a href=&#34;https://www.linkedin.com/in/sharonxr/&#34;&gt;Sharon Xie&lt;/a&gt;, Flink PMC Chair &lt;a href=&#34;https://home.apache.org/phonebook.html?uid=rmetzger&#34;&gt;Robert Metzger&lt;/a&gt;, and former lead on the &lt;a href=&#34;https://debezium.io/&#34;&gt;Debezium&lt;/a&gt; project &lt;a href=&#34;https://www.morling.dev/&#34;&gt;Gunnar Morling&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;what-will-i-be-doing-at-decodable&#34;&gt;What Will I Be Doing at Decodable?&lt;/h2&gt;
&lt;p&gt;Who knows?! That&amp;rsquo;s the fun part of joining a 30-person startup üòâ.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/09/IMG_5699.jpeg&#34; alt=&#34;Conference badge that reads &amp;amp;ldquo;Robin Moffatt: Principal Shitposter and Meme Artist&amp;amp;rdquo;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Srsly tho: my starting point for this answer is my blog from earlier this year &lt;a href=&#34;https://rmoff.net/2023/05/23/what-does-this-devex-engineer-do/&#34;&gt;&lt;em&gt;What Does This DevEx Engineer Do?&lt;/em&gt;&lt;/a&gt;. But very shortly after that my answer is: getting stuck in and helping build a really awesome streaming platform. Friction logs, blogs, &lt;del&gt;shitposting&lt;/del&gt;, community, docs, making videos‚Ä¶whatever needs doing to make the experience for developers the very best üèÜ.&lt;/p&gt;
&lt;h2 id=&#34;stream-processing---weve-only-just-got-started&#34;&gt;Stream Processing - We&amp;rsquo;ve Only Just Got Started&lt;/h2&gt;
&lt;p&gt;So, time for me to get back into stream processing land. I&amp;rsquo;ll save you the fluff and gumpf about the business value of stream processing, the use cases, all the evils and perils of batch, yada yada. If you know, you know. And if you don&amp;rsquo;t, well, join me for the ride üôÉ.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/09/saddle-up-partner-dumb-and-dumber.gif&#34; alt=&#34;Saddle up, partner! Jim Carrey - Dumb &amp;amp; Dumber&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Blog Writing for Developers</title>
      <link>https://rmoff.net/2023/07/19/blog-writing-for-developers/</link>
      <pubDate>2023-07-19</pubDate>
      
      <guid>https://rmoff.net/2023/07/19/blog-writing-for-developers/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2023/07/t_IMG_3731.jpeg" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;p&gt;Writing is one of the most powerful forms of communication, and it‚Äôs useful in a multitude of roles and contexts. As a &lt;a href=&#34;https://rmoff.net&#34;&gt;blog-writing&lt;/a&gt;, &lt;a href=&#34;https://github.com/treeverse/lakeFS/pulls?q=is%3Apr+label%3Adocs+author%3Armoff+&#34;&gt;documentation-authoring&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/rmoff/status/1587382202781913089&#34;&gt;twitter-shitposting&lt;/a&gt; DevEx engineer I spend a lot of my time writing. Recently, someone paid me a very nice compliment about a blog I‚Äôd written and asked how they could learn to write like me and what resources I‚Äôd recommend.&lt;/p&gt;
&lt;p&gt;Never one to miss a chance to write and share something, here‚Äôs my response to this :)&lt;/p&gt;
&lt;p&gt;To begin with I want to cover briefly the motivations behind writing.&lt;/p&gt;
&lt;h2 id=&#34;why-do-i-write&#34;&gt;Why Do &lt;strong&gt;I&lt;/strong&gt; Write?&lt;/h2&gt;
&lt;p&gt;Firstly, I like &lt;strong&gt;to share information&lt;/strong&gt;. That could be a new &lt;a href=&#34;https://rmoff.net/2021/03/04/quick-profiling-of-data-in-apache-kafka-using-kafkacat-and-visidata/&#34;&gt;tool&lt;/a&gt; or &lt;a href=&#34;https://lakefs.io/blog/data-engineering-patterns-write-audit-publish/&#34;&gt;technique&lt;/a&gt; that I‚Äôve learnt, &lt;a href=&#34;https://rmoff.net/2020/09/30/setting-key-value-when-piping-from-jq-to-kafkacat/&#34;&gt;a clever trick&lt;/a&gt; I‚Äôve discovered, or sometimes away from the technical and into the realms of &lt;a href=&#34;https://rmoff.net/2019/02/09/travelling-for-work-with-kids-at-home/&#34;&gt;life pondering&lt;/a&gt; and &lt;a href=&#34;https://rmoff.net/2023/05/23/what-does-this-devex-engineer-do/&#34;&gt;navel gazing&lt;/a&gt;. In the case of this very blog, it‚Äôs to share my thoughts on something that interests me. I could have written some notes and sent them directly back to the person who asked the original question, but if it was useful to them it‚Äôs hopefully useful to others‚Äîso therefore it‚Äôs worth writing up and publishing.&lt;/p&gt;
&lt;p&gt;The second reason that I‚Äôll write is &lt;strong&gt;to learn about something&lt;/strong&gt;. It‚Äôs one thing to hand-wave one‚Äôs way through a presentation. It‚Äôs another to commit pen to paper (well, bytes to disk) and &lt;a href=&#34;https://rmoff.net/2018/08/02/kafka-listeners-explained/&#34;&gt;explain something&lt;/a&gt;. Quite often I‚Äôll realise that there‚Äôs a gap‚Äîor gaps‚Äîin my knowledge that I need to explore first before I can properly write about something, and that‚Äôs the very reason that I do it.&lt;/p&gt;
&lt;p&gt;There are several pleasant side-effects from writing too. Anything in the public domain (such as your blog, but also open-source project documentation, etc) helps establish your credibility in an area and awareness by others of you. We may never reach the stratospheric heights of someone such as Kelsey Hightower, who has wowed a generation of developers with their &lt;a href=&#34;https://youtu.be/HlAXp0-M6SY?t=718&#34;&gt;Tetris-playing skills&lt;/a&gt;, but being known as &lt;em&gt;that guy&lt;/em&gt; who wrote a really useful blog that helped others is still a really nice feeling :)&lt;/p&gt;
&lt;h2 id=&#34;how-do-i-write-for-developers&#34;&gt;HOW do I Write for Developers?&lt;/h2&gt;
&lt;h3 id=&#34;-stop-watch-this-first-&#34;&gt;üõë STOP! Watch This First üé•&lt;/h3&gt;
&lt;p&gt;Go and watch this excellent lecture called &lt;a href=&#34;https://www.youtube.com/watch?v=vtIzMaLkCaM&#34;&gt;The Craft of Writing Effectively&lt;/a&gt;. It‚Äôs given by Larry McEnerney who is the Director of the University of Chicago‚Äôs Writing Program and knows a thing or two about writing. There are direct parallels between his observations on how and why academics communicate, and communication between developers.&lt;/p&gt;
&lt;p&gt;üëâüèª I‚Äôve seen it recommended several times but to my embarrassment, the length put me off‚Äîbut I wish it hadn‚Äôt as it‚Äôs superb.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If you‚Äôd rather listen instead of watch you can use &lt;a href=&#34;https://github.com/yt-dlp/yt-dlp&#34;&gt;&lt;code&gt;yt-dlp&lt;/code&gt;&lt;/a&gt; to download it as audio (&lt;code&gt;--extract-audio --audio-format mp3&lt;/code&gt;).&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;so-how-do-i-write-for-developers&#34;&gt;So, how do I write for developers?&lt;/h3&gt;
&lt;p&gt;Each writer will have their own approach to writing, and it will vary based on the audience and purpose too. A report for publication in an academic journey will have a different structure to a shitpost on Twitter. A blog aimed at developers will read very differently from the documentation from the depths of a product manual. Each medium and audience is valid; the knack is making sure that your writing lines up with it.&lt;/p&gt;
&lt;p&gt;When I write I try to write for myself‚Äîa developer, interested in a thing. That could be a new technology, an in-depth explanation, a random musing on life, or anything else. Would I like to read the thing I‚Äôve read? Does it avoid the pitfalls that plague the soulless bland crap that some companies churn out, stick an emoji on, and call developer marketing?&lt;/p&gt;
&lt;p&gt;There are three key dimensions that it‚Äôs useful to consider here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;clarity&lt;/li&gt;
&lt;li&gt;personality (also called voice)&lt;/li&gt;
&lt;li&gt;uniformity of content.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can roughly overlay these dimensions across the range of written materials that we might write:&lt;/p&gt;
&lt;img src=&#34;https://rmoff.net/images/2023/07/01.svg&#34; width=600/&gt;
&lt;p&gt;Things aren‚Äôt always so simple, and for some platforms in particular there‚Äôs quite a range:&lt;/p&gt;
&lt;img src=&#34;https://rmoff.net/images/2023/07/02.svg&#34; width=600/&gt;
&lt;p&gt;What do these different dimensions mean in practice? Let‚Äôs explore that.&lt;/p&gt;
&lt;h4 id=&#34;clarity-is-key&#34;&gt;Clarity is Key&lt;/h4&gt;
&lt;p&gt;The first of these dimensions is pretty straightforward and shouldn‚Äôt really vary. Whatever you write, for whomever you write it, &lt;strong&gt;it has to be clear&lt;/strong&gt;. Writing clearly means everything from sentence construction and paragraph breaks through to the structure of your article. It can be surprisingly hard to do but is crucial if you want to write material that people will &lt;em&gt;want&lt;/em&gt; to read.&lt;/p&gt;
&lt;p&gt;One neat trick when it comes to clarity is to remember that &lt;em&gt;what you leave out&lt;/em&gt; is as important as what you leave in. This is going to be very context-specific. Documentation, by definition, should be comprehensive. A blog, on the other hand, might want to get to the point sooner and just provide a link to background material for the reader should they want it. Less is often more, as they say.&lt;/p&gt;
&lt;p&gt;Some types of writing are going to have greater scope for individuality than others, but all have the potential to at least be accessible and clear. For example, just because you‚Äôre writing documentation doesn‚Äôt give you a pass to copy and paste the requirements doc in all its generic and obscure complexity. Write documentation that you as a developer would like to read. It can be complex and precise, yet still accessible.&lt;/p&gt;
&lt;h4 id=&#34;personality-and-voice&#34;&gt;Personality and Voice&lt;/h4&gt;
&lt;p&gt;Should the &amp;lsquo;voice&amp;rsquo; of the author be allowed to come through in the writing?&lt;/p&gt;
&lt;p&gt;This is very much a sliding scale. I‚Äôve jotted down &lt;em&gt;some&lt;/em&gt; of the characteristics you might associate with either extreme of the scale. This is not to say that by definition you‚Äôd put cuss words into a blog so as to convey your voice‚Äîbut as an example of something that you might see at that end of the spectrum and definitely not at the other.&lt;/p&gt;
&lt;img src=&#34;https://rmoff.net/images/2023/07/03.svg&#34; height=300/&gt;
&lt;p&gt;How you decide where to pitch your voice on this scale will come down to your preference, audience, and general area and discipline. If you spend much time on Twitter you‚Äôll notice that InfoSec Twitter is different from DevOps Twitter, which is different again from DataEng Twitter. Each has its own cliques and customs, and also a varying range to which an author‚Äôs voice shines through in published writing.&lt;/p&gt;
&lt;p&gt;You‚Äôll generally find that generally writing mediums such as a project report to stakeholders or product documentation requires a neutral voice. That‚Äôs not to say &lt;em&gt;boring&lt;/em&gt;, but it is to say that a certain uniformity is required. In the case of a project report, the message mustn‚Äôt be obscured by colloquialisms and the such. And can you imagine the cognitive dissonance if a set of documentation were written by multiple writers each looking to stamp their personality on the pages?&lt;/p&gt;
&lt;p&gt;When we get to things like blogs and other types of writing we &lt;em&gt;deliberately&lt;/em&gt; want to include some personality. How much is up to you to calibrate with your audience and yourself. There is a ‚ÄúGoldilocks‚Äù zone here‚Äîenough personality and genuine voice coming through to convince the reader that they are reading something that was written by someone who is actually interested and informed on the matter, but not so much that it gets in the way of the content.&lt;/p&gt;
&lt;h4 id=&#34;uniformity-and-standardisation&#34;&gt;Uniformity and Standardisation&lt;/h4&gt;
&lt;p&gt;This has a strong relationship with personality and voice but relates a lot more to the structure and content of the material&lt;/p&gt;
&lt;img src=&#34;https://rmoff.net/images/2023/07/04.svg&#34; height=300/&gt;
&lt;p&gt;Using the example of blogs, you‚Äôll find that blogs for a company or project are going to have a strong focus on the consistency of messaging and structure. There‚Äôll be an introduction, there‚Äôll be context; it‚Äôll be comprehensive.&lt;/p&gt;
&lt;p&gt;Compare that to a personal blog that may sometimes be not much more than the gutterings of a developer wanting to log an error message and solution for future Googlers. They &lt;em&gt;might&lt;/em&gt; flesh it out into a longer article, but that‚Äôs not necessary for it still to have value.&lt;/p&gt;
&lt;h4 id=&#34;a-holistic-view&#34;&gt;A Holistic View&lt;/h4&gt;
&lt;p&gt;It may seem like there‚Äôs going to be a linear relationship between the two dimensions. As we decrease the amount of personality coming through in an author‚Äôs writings, we‚Äôre also going to move towards a much more standardised set of writing.&lt;/p&gt;
&lt;p&gt;I‚Äôd suggest that it‚Äôs not always the case.&lt;/p&gt;
&lt;p&gt;A startup may value personality much more over standardisation, perhaps only really dropping the voice when it comes to something like documentation (and even then, perhaps not entirely).&lt;/p&gt;
&lt;img src=&#34;https://rmoff.net/images/2023/07/05.svg&#34; height=300/&gt;
&lt;p&gt;At the other end of the scale, some companies‚Äîusually large corporations‚Äîhave the habit of squeezing the last inch of life out of any kind of writing, making the relationship a much different one.&lt;/p&gt;
&lt;p&gt;Here there‚Äôs little voice even where you might hope to find it, and that rapidly drops off into nothing very soon after:&lt;/p&gt;
&lt;img src=&#34;https://rmoff.net/images/2023/07/06.svg&#34; height=300/&gt;
&lt;p&gt;The wildcard within this is the social media teams of large companies who &lt;em&gt;are&lt;/em&gt; given the remit to be &lt;code&gt;Funny&lt;/code&gt; and &lt;code&gt;Engaging&lt;/code&gt;, but this is usually outside the scope of developer writing and more into the field of &lt;a href=&#34;https://www.boredpanda.com/sassiest-responses-from-companies&#34;&gt;condiments and fast food chains&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;structuring-your-blog-writing&#34;&gt;Structuring your Blog Writing&lt;/h2&gt;
&lt;p&gt;Like a favourite pair of jeans that‚Äôs well-worn, comfy, and slightly saggy round the arse, I have a go-to structure for writing. Come to think of it, I use it for lots of conference talks too. It looks like this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Tell them what you‚Äôre going to tell them&lt;/li&gt;
&lt;li&gt;Tell them&lt;/li&gt;
&lt;li&gt;Tell them what you told them&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;What this looks like in practice is something along these lines:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;An intro&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;What is this thing, and why should the reader &lt;del&gt;give af&lt;/del&gt; be interested?&lt;/p&gt;
&lt;p&gt;This could be a brief explanation of why I am interested in it, or why you would want to read my take on it. The key thing is you‚Äôre relating to your audience here. Not everyone wants to read everything you write, and that‚Äôs ok.&lt;/p&gt;
&lt;p&gt;Let people self-select out (or in, hopefully) at this stage, but make it nice and easy. For example, if you‚Äôre writing about data engineering, make it clear to the appdev crowd that they should move on as there‚Äôs nothing to see here (or stick around and learn something new, but as a visitor, not the target audience).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;The article itself&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;A recap&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Make sure you don‚Äôt just finish your article with a figurative mic drop‚Äîtie up it nicely with a bow (a üôáüèª or a üéÄ, either works).&lt;/p&gt;
&lt;p&gt;This is where marketing would like to introduce you to the acronym CTA (Call To Action) üòâ. As an author you can decide how or if to weave that into your narrative.&lt;/p&gt;
&lt;p&gt;Either way, you‚Äôre going to summarise what you just did and give people something to &lt;em&gt;do&lt;/em&gt; with it next. Are there code samples they can go and run or inspect? A new service to sign up for? A video to watch? Or just a general life reflection upon which to ponder.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;-the-physical-act-of-writing-jfdi--&#34;&gt;‚úçüèª The Physical Act of Writing: JFDI ;-)&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/07/07.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;At the risk of repeating the &lt;a href=&#34;https://knowyourmeme.com/memes/how-to-draw-an-owl&#34;&gt;owl meme&lt;/a&gt; I would give the following advice: just start writing!&lt;/p&gt;
&lt;p&gt;I don‚Äôt mean just go write an article. I mean start writing &lt;strong&gt;something&lt;/strong&gt;, &lt;strong&gt;&lt;em&gt;anything.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Some notes, some snippets, some whole paragraphs. It might even look like this&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/07/08.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;The point is you now have &lt;em&gt;something&lt;/em&gt;. The sections and threads of a story start to fall out as you write more. What starts as one section perhaps becomes two as you realise there are individual elements to tease out.&lt;/p&gt;
&lt;p&gt;Iterate, iterate, and then iterate some more.&lt;/p&gt;
&lt;p&gt;That random link you made a note of, where does it fit in what you want to say? Is it pushing the need for a new section or tangent, or is it actually not so relevant and you can park it? Not sure? Well just leave it there and think about it again on the next pass round.&lt;/p&gt;
&lt;p&gt;I‚Äôve recently found that using a &lt;a href=&#34;https://en.wikipedia.org/wiki/Pomodoro_Technique&#34;&gt;Pomodoro timer&lt;/a&gt; is an effective way of getting me to focus, and to take a break. Instead of staring at a screen, descending into a pit of despair at the stagnation of an article, you spend a chunk of time and then step away. Perhaps you come back to it after the break or maybe wait longer. Like many problems in life, things resolve themselves given time to marinade in the recesses of one‚Äôs brain. That paragraph that just wouldn‚Äôt write itself will come spilling out of your eager fingers onto the keyboard. The section you thought you‚Äôd &lt;em&gt;nailed&lt;/em&gt;‚Äîturns out you didn‚Äôt and it needs a rewrite. But all these things come with time and iteration through the text.&lt;/p&gt;
&lt;h2 id=&#34;find-a-really-good-reviewer-and-copyeditor&#34;&gt;Find a really good reviewer and copyeditor&lt;/h2&gt;
&lt;p&gt;You might think you‚Äôre good at writing. You‚Äôre probably not &lt;em&gt;that&lt;/em&gt; good at writing that the eye of an excellent copyeditor won‚Äôt improve it, nor the tactful input of a good reviewer enhance it.&lt;/p&gt;
&lt;p&gt;Good copyeditors will respect the voice that‚Äôs present in your writing and work to preserve it whilst improving the clarity and grammatical accuracy of what you‚Äôve written.&lt;/p&gt;
&lt;p&gt;Good reviewers will grok what you‚Äôre saying and help distil and mould it into a better shape.&lt;/p&gt;
&lt;h2 id=&#34;tools&#34;&gt;Tools&lt;/h2&gt;
&lt;p&gt;Ah, the meta-blog post about tooling. Each to their own, but here‚Äôs my stack:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://obsidian.md/&#34;&gt;Obsidian&lt;/a&gt; for authoring&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cleanshot.com/&#34;&gt;CleanShot X&lt;/a&gt; for screen grabs and markup&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.grammarly.com/&#34;&gt;Grammarly&lt;/a&gt; for proofreading (and please, for the sak of your readers, profread, noone wnats to red a baydly writen blog)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rmoff.net/categories/hugo/&#34;&gt;Hugo and GitHub Pages&lt;/a&gt; for publishing and hosting&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;resources&#34;&gt;Resources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;A &lt;a href=&#34;https://github.com/sixhobbits/technical-writing/blob/master/resources.md&#34;&gt;useful list of resources&lt;/a&gt; from &lt;a href=&#34;https://twitter.com/sixhobbits&#34;&gt;Gareth Dwyer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;üìß An email-based course called &lt;a href=&#34;https://bloggingfordevs.com/&#34;&gt;Blogging for Devs&lt;/a&gt;. It‚Äôs quite focussed on the mechanics of a blogging but has some useful nuggets - and it‚Äôs free&lt;/li&gt;
&lt;li&gt;üìï&lt;a href=&#34;https://pragprog.com/titles/actb2/technical-blogging-second-edition/&#34;&gt;Technical Blogging&lt;/a&gt;, by &lt;a href=&#34;https://antoniocangiano.com/&#34;&gt;Antonio Cangiano&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=kOnZovTFTHc&#34;&gt;Avoiding Anti-patterns in Technical Communication&lt;/a&gt; - good conference talk from &lt;a href=&#34;https://www.linkedin.com/in/sophwats/&#34;&gt;Sophie Watson&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;A nice blog from &lt;a href=&#34;https://www.linkedin.com/in/kudmitry/&#34;&gt;Dmitry Kudryavtsev&lt;/a&gt; on &lt;a href=&#34;https://www.yieldcode.blog/post/why-engineers-should-write&#34;&gt;Why engineers should focus on writing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://developers.google.com/tech-writing&#34;&gt;Technical Writing Courses - Google Developers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;footnote-_what_-should-i-write&#34;&gt;Footnote: &lt;em&gt;What&lt;/em&gt; Should I Write?&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;We‚Äôve covered the why and the how - but what about the what?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;What to write will often come from the ‚ÄúWhy‚Äù above, but let‚Äôs imagine that the creative juices aren‚Äôt flowing and you still really want to get a blog written.&lt;/p&gt;
&lt;p&gt;A really excellent place for ideas is the community around the thing you want to write about. Go and lurk (or even better, join in) at StackOverflow, Twitter, Slack, Discord‚Ä¶wherever the community is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What questions do people repeatedly ask?&lt;/li&gt;
&lt;li&gt;What are the anti-patterns and misunderstandings that you see?&lt;/li&gt;
&lt;li&gt;What are the new trends?&lt;/li&gt;
&lt;li&gt;What cool things can you do with &lt;code&gt;$THING&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In short, if it would be interesting to me then I would write about it.&lt;/p&gt;
&lt;p&gt;Make sure to also watch &lt;a href=&#34;https://www.youtube.com/watch?v=vtIzMaLkCaM&#34;&gt;this lecture&lt;/a&gt; in which the concept of &lt;em&gt;value&lt;/em&gt; and &lt;em&gt;ideas&lt;/em&gt; is discussed. tl;dr if you aren‚Äôt writing about something interesting to the reader, it has no value, regardless of its value to you.&lt;/p&gt;
&lt;h3 id=&#34;what-not-to-write&#34;&gt;What Not to Write?&lt;/h3&gt;
&lt;p&gt;This is a &lt;em&gt;very&lt;/em&gt; personal preference. I‚Äôm not keen at all on growth-driven blogging styles. You know the sort: listicles, SEO bait, etc. It‚Äôs low-grade, developers see through it, and it tarnishes the blogger‚Äôs image IMHO. That said, if you write a good blog, there‚Äôs no reason not to structure it such (‚Äú&lt;em&gt;Top Five Tips for Successful Developer Writing&lt;/em&gt;‚Äù) but put the horse before the cart, not the other way around.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;recap&#34;&gt;Recap&lt;/h2&gt;
&lt;p&gt;To summarise this whole article, bear in mind that these two statements are not mutually exclusive:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Write for yourself. Work out what &lt;em&gt;you&lt;/em&gt; would like to read, and write it.&lt;/li&gt;
&lt;li&gt;Think of the reader and what value you‚Äôre providing to them in your writing.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;That‚Äôs because as a developer writing for developers, you &lt;strong&gt;are&lt;/strong&gt; the reader.&lt;/p&gt;
&lt;p&gt;Oh, and did you watch &lt;a href=&#34;https://www.youtube.com/watch?v=vtIzMaLkCaM&#34;&gt;Larry McEnerney‚Äôs lecture&lt;/a&gt; yet? üòä&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>