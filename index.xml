<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>rmoff&#39;s random ramblings</title>
    <link>https://rmoff.net/</link>
    <description>Recent content on rmoff&#39;s random ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>2023-10-02</lastBuildDate>
    
        <atom:link href="https://rmoff.net/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Learning Apache Flink S01E02: What *is* Flink?</title>
      <link>https://rmoff.net/2023/10/02/learning-apache-flink-s01e02-what-is-flink/</link>
      <pubDate>2023-10-02</pubDate>
      
      <guid>https://rmoff.net/2023/10/02/learning-apache-flink-s01e02-what-is-flink/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2023/10/t_IMG_5412.webp" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;p&gt;My &lt;a href=&#34;https://rmoff.net/2023/09/29/learning-apache-flink-s01e01-where-do-i-start/&#34;&gt;journey&lt;/a&gt; with &lt;a href=&#34;https://flink.apache.org&#34;&gt;Apache Flink&lt;/a&gt; begins with an overview of &lt;em&gt;what Flink actually is&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;What better place to start than the &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.17/#apache-flink-documentation&#34;&gt;Apache Flink website itself&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Apache Flink&lt;/strong&gt; is a framework and distributed processing engine for stateful computations over &lt;em&gt;unbounded&lt;/em&gt; and &lt;em&gt;bounded&lt;/em&gt; data streams. Flink has been designed to run in &lt;em&gt;all common cluster environments&lt;/em&gt;, perform computations at &lt;em&gt;in-memory&lt;/em&gt; speed and at &lt;em&gt;any scale&lt;/em&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/10/lafs01e02.webp&#34; alt=&#34;An image of a squirrel making notes with a big pile of books and papers behind him&#34;&gt;&lt;/p&gt;
&lt;p&gt;In this post, I&amp;rsquo;m going to summarise my current—possibly naïve—understanding of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#so-what-is-flink&#34;&gt;What Flink is&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#use-cases&#34;&gt;What Flink is used for&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#users-of-flink&#34;&gt;Who uses Flink&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#how-do-you-run-flink&#34;&gt;How do you run Flink&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-flink-community&#34;&gt;Where to find the Flink community&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;so-what-is-flink&#34;&gt;So: What is Flink?&lt;/h2&gt;
&lt;p&gt;I found a couple of &lt;a href=&#34;https://www.dataengineeringpodcast.com/apache-flink-with-fabian-hueske-episode-57&#34;&gt;excellent&lt;/a&gt; &lt;a href=&#34;https://overcast.fm/+BAj84H3884&#34;&gt;podcasts&lt;/a&gt; from &lt;a href=&#34;https://www.linkedin.com/in/fhueske/&#34;&gt;Fabian Heuske&lt;/a&gt; and my &lt;a href=&#34;https://decodable.co/&#34;&gt;Decodable&lt;/a&gt; colleague &lt;a href=&#34;https://www.linkedin.com/in/metzgerrobert/?originalSubdomain=de&#34;&gt;Robert Metzger&lt;/a&gt; respectively that gave some really useful background on the project:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Flink started life as a research project in 2011, called &lt;a href=&#34;https://scholar.google.com/citations?view_op=view_citation&amp;amp;hl=en&amp;amp;user=Q1LJyvQAAAAJ&amp;amp;citation_for_view=Q1LJyvQAAAAJ:_FxGoFyzp5QC&#34;&gt;&lt;em&gt;Stratosphere&lt;/em&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;It was donated to &lt;a href=&#34;https://www.apache.org/&#34;&gt;Apache Software Foundation&lt;/a&gt; in 2014.&lt;/li&gt;
&lt;li&gt;Version 1.0 released 2016, latest version is &lt;a href=&#34;https://flink.apache.org/downloads/#apache-flink-1171&#34;&gt;1.17&lt;/a&gt; .&lt;/li&gt;
&lt;li&gt;Whilst it was originally designed for batch, it always used streaming principles, making its move into stream processing a logical one&lt;/li&gt;
&lt;li&gt;Hadoop revolutionised the distributed processing of data at scale, but was &amp;ldquo;dumb&amp;rdquo;. Flink aimed to use some of the principles whilst bringing in important learnings from the RDBMS world that had been missed in Hadoop&lt;/li&gt;
&lt;li&gt;JVM-based. &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-master/docs/dev/table/sql/overview/&#34;&gt;SQL&lt;/a&gt; and &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-master/docs/dev/python/overview/&#34;&gt;PyFlink&lt;/a&gt; added in recent years.&lt;/li&gt;
&lt;li&gt;Flink is a Distributed system. &lt;a href=&#34;https://overcast.fm/+H1YOnxO3I/05:50&#34;&gt;Each&lt;/a&gt; worker stores state.&lt;/li&gt;
&lt;li&gt;It &lt;a href=&#34;https://overcast.fm/+H1YOnxO3I/23:29&#34;&gt;supports&lt;/a&gt; exactly once state guarantee with checkpointing across workers that stores the state and metadata of input sources (e.g. Kafka topics offsets) all on a distributed filesystem (e.g. S3)&lt;/li&gt;
&lt;li&gt;Event time processing. &lt;a href=&#34;https://overcast.fm/+H1YOnxO3I/21:42&#34;&gt;Uses&lt;/a&gt; watermarks (same as Google data flow), which enable you to trade off between completeness and latency.&lt;/li&gt;
&lt;li&gt;🤯 Everything is a stream; it&amp;rsquo;s just some streams are bounded, whilst others are unbounded.
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;Wait, What? Everything is a Stream?&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;From my background with Apache Kafka and the &lt;a href=&#34;https://www.michael-noll.com/blog/2018/04/05/of-stream-and-tables-in-kafka-and-stream-processing-part1/&#34;&gt;stream-table duality&lt;/a&gt;, this source-agnostic framing of events is different, and I can&amp;rsquo;t wait to explore it further. I&amp;rsquo;m interested to see if it&amp;rsquo;s just a matter of semantics, or if there is something fundamentally different in how Flink reasons about streams of events vs state for given keys.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;uses--users-of-flink&#34;&gt;Uses &amp;amp; Users of Flink&lt;/h2&gt;
&lt;h3 id=&#34;use-cases&#34;&gt;Use Cases&lt;/h3&gt;
&lt;p&gt;The documentation for Flink lays out &lt;a href=&#34;https://flink.apache.org/use-cases/&#34;&gt;three distinct use cases&lt;/a&gt; for Flink. Under each are linked several examples, mostly from the Flink Forward conference.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://flink.apache.org/use-cases/#event-driven-applications-a-nameeventdrivenappsa&#34;&gt;&lt;strong&gt;Event-driven Applications&lt;/strong&gt;&lt;/a&gt;, e.g.
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=Do7C4UJyWCM/&#34;&gt;Fraud detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=rJNH5WhWAj4/&#34;&gt;Anomaly detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=_yHds9SvMfE/&#34;&gt;Rule-based alerting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jobs.zalando.com/tech/blog/complex-event-generation-for-business-process-monitoring-using-apache-flink/&#34;&gt;Business process monitoring&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=0cJ565r2FVI/&#34;&gt;Web application (social network)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://flink.apache.org/use-cases/#data-analytics-applicationsa-nameanalyticsa&#34;&gt;&lt;strong&gt;Data Analytics Applications&lt;/strong&gt;&lt;/a&gt;, e.g.
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=izYsMQWeUbE/&#34;&gt;Quality monitoring of Telco networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=17tUR4TsvpM/&#34;&gt;Analysis of product updates &amp;amp; experiment evaluation&lt;/a&gt; &lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://eng.uber.com/athenax/&#34;&gt;Ad-hoc analysis of live data&lt;/a&gt; &lt;/li&gt;
&lt;li&gt;Large-scale graph analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://flink.apache.org/use-cases/#data-pipeline-applications-a-namepipelinesa&#34;&gt;&lt;strong&gt;Data Pipeline Applications&lt;/strong&gt;&lt;/a&gt;, e.g.
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://ververica.com/blog/blink-flink-alibaba-search&#34;&gt;Real-time search index building&lt;/a&gt; &lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jobs.zalando.com/tech/blog/apache-showdown-flink-vs.-spark/&#34;&gt;Continuous ETL&lt;/a&gt;  (a.k.a. &amp;ldquo;Streaming ETL&amp;rdquo;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;One thing that&amp;rsquo;s interesting about the linked examples is that they are all from 6-7 years ago. One can look at this two ways. Put positively, it demonstrates what a long history and proof of success Flink has when it comes to experience in stream processing. Being snarky, one would cast it in the light that Flink is a technology of the past, on its way out with the Hadoops of this world.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;d strongly reject the latter view. You may say that is obvious given that I now work for a company offering &lt;a href=&#34;https://decodable.co/&#34;&gt;a managed Flink service&lt;/a&gt; 😉. But this in itself is a point to counter the snark. There are multiple companies &lt;em&gt;launching&lt;/em&gt; Flink as a service—including companies which already had stream processing offerings based on other technology. Flink is a well-established technology with a strong &lt;a href=&#34;https://flink.apache.org/roadmap/&#34;&gt;roadmap&lt;/a&gt; and a &lt;a href=&#34;https://flink.apache.org/roadmap/#scenarios-we-focus-on&#34;&gt;modern and cloud-native vision&lt;/a&gt; for its future direction.&lt;/p&gt;
&lt;h3 id=&#34;users-of-flink&#34;&gt;Users of Flink&lt;/h3&gt;
&lt;p&gt;Whilst the rise of managed Flink services is one proof-point demonstrating Flink&amp;rsquo;s popularity, the other irrefutable one is its &lt;em&gt;continued use&lt;/em&gt; in a wide range of companies and use cases (and not just those from 6-7 years ago). A quick look through the back issues of &lt;a href=&#34;https://www.dataengineeringweekly.com/&#34;&gt;Data Engineering Weekly&lt;/a&gt; and past sessions of &lt;a href=&#34;https://www.flink-forward.org/events&#34;&gt;Flink Forward&lt;/a&gt; and other conferences demonstrates this.&lt;/p&gt;
&lt;p&gt;Users with &lt;strong&gt;recent&lt;/strong&gt; (in the last ~two years) published use cases include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://alibaba-cloud.medium.com/four-billion-records-per-second-f8eeabce934d&#34;&gt;Alibaba Cloud&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.flink-forward.org/sf-2022/conference-program#alexa--be-quiet---end-to-end-near-real-time-model-building-and-evaluation-in-amazon-alexa&#34;&gt;Amazon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.infoq.com/presentations/apache-iceberg-streaming/&#34;&gt;Apple&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=-wSbb4JSuZU&#34;&gt;Booking.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/capital-one-tech/exploring-apache-flink-aws-kda-realtime-data-streaming-7201ed4ed197&#34;&gt;Capital One&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://doordash.engineering/2021/07/14/open-source-search-indexing/&#34;&gt;DoorDash&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.flink-forward.org/seattle-2023/agenda#model-inference-in-flink-sql-using-a-custom-http-connector&#34;&gt;ING Bank&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://tech.instacart.com/building-a-flink-self-serve-platform-on-kubernetes-at-scale-c11ef19aef10&#34;&gt;Instacart&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.flink-forward.org/seattle-2023/agenda#quality-scale-with-flink&#34;&gt;JP MorganChase&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.slideshare.net/FlinkForward/building-a-fully-managed-stream-processing-platform-on-flink-at-scale-for-linkedin-252866883&#34;&gt;LinkedIn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://eng.lyft.com/wheres-my-data-a-unique-encounter-with-flink-streaming-s-kinesis-connector-6da3b11b164a&#34;&gt;Lyft&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://netflixtechblog.com/data-mesh-a-data-movement-and-processing-platform-netflix-1288bcab2873&#34;&gt;Netflix&lt;/a&gt; (&lt;a href=&#34;https://netflixtechblog.com/keystone-real-time-stream-processing-platform-a3ee651812a&#34;&gt;ad&lt;/a&gt; &lt;a href=&#34;https://www.google.com/search?q=site:netflixtechblog.com+flink&#34;&gt;infinitum&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/pinterest-engineering/lessons-from-debugging-a-tricky-direct-memory-leak-f638c722d9f2&#34;&gt;Pintrest&lt;/a&gt; (this &lt;a href=&#34;https://medium.com/pinterest-engineering/unified-flink-source-at-pinterest-streaming-data-processing-c9d4e89f2ed6&#34;&gt;older article&lt;/a&gt; lists more of their use cases)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.flink-forward.org/seattle-2023/agenda#protecting-reddit-users-at-scale-with-flink-stateful-functions&#34;&gt;Reddit&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://shopify.engineering/optimizing-apache-flink-applications-tips&#34;&gt;Shopify&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://speakerdeck.com/jeffchao/flink-forward-2022-squirreling-away-640-dollars-billion-how-stripe-leverages-flink-for-change-data-capture&#34;&gt;Stripe&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.flink-forward.org/seattle-2023/agenda#self-service-data-ingestion-platform-at-tiktok--powering--foryoupage-for--b--users&#34;&gt;TikTok&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.uber.com/en-GB/blog/real-time-exactly-once-ad-event-processing/&#34;&gt;Uber&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://vinted.engineering/2023/09/25/search-indexing-pipeline/&#34;&gt;Vinted&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;See also the Powered By Flink &lt;a href=&#34;https://flink.apache.org/powered-by/&#34;&gt;highlights&lt;/a&gt; and &lt;a href=&#34;https://cwiki.apache.org/confluence/display/FLINK/Powered+by+Flink&#34;&gt;complete list&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;how-do-you-run-flink&#34;&gt;How do you run Flink?&lt;/h2&gt;
&lt;h3 id=&#34;self-managed&#34;&gt;Self-Managed&lt;/h3&gt;
&lt;p&gt;Flink is a distributed system, which means that you don&amp;rsquo;t just buy one great big box and scale it up and up for capacity. Instead, you deploy it across multiple instances for both scalability and fault-tolerance.&lt;/p&gt;
&lt;p&gt;The Flink documentation has a clear set of instructions for running Flink using the &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/resource-providers/standalone/overview/&#34;&gt;binaries directly&lt;/a&gt;, under &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/resource-providers/standalone/docker/&#34;&gt;Docker&lt;/a&gt;, and with &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/resource-providers/native_kubernetes/&#34;&gt;Kubernetes&lt;/a&gt;. Betraying its Big Data history, is also still supports &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/resource-providers/yarn/&#34;&gt;YARN&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;managed-service&#34;&gt;Managed Service&lt;/h3&gt;
&lt;p&gt;Did I mention yet that &lt;a href=&#34;https://decodable.co/&#34;&gt;Decodable&lt;/a&gt; offers a fully-managed Apache Flink service? :-D&lt;/p&gt;
&lt;p&gt;You can find a list of other vendors that offer Apache Flink as a managed service in &lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/overview/#vendor-solutions&#34;&gt;the Flink documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;the-flink-community&#34;&gt;The Flink Community&lt;/h2&gt;
&lt;p&gt;Just like any healthy open-source project, there is a good community around Flink. Per the Apache motto:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If it didn’t happen on a mailing list, it didn’t happen.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The &lt;a href=&#34;https://flink.apache.org/community/&#34;&gt;community&lt;/a&gt; page on the Flink site lists numerous mailing lists. &lt;code&gt;news@&lt;/code&gt; and &lt;code&gt;community@&lt;/code&gt; are both pretty stagnant, but &lt;a href=&#34;https://lists.apache.org/list.html?user@flink.apache.org&#34;&gt;users@&lt;/a&gt; is well-used with half a dozen posts per day. If you&amp;rsquo;re contributing to Flink (rather than just using it) you&amp;rsquo;ll want the &lt;code&gt;dev@&lt;/code&gt; list too.&lt;/p&gt;
&lt;p&gt;Alongside the mailing lists, there is a &lt;a href=&#34;https://join.slack.com/t/apache-flink/shared_invite/zt-22mklt3r5-89MjX41gqHsBk81ZoTDqXg&#34;&gt;Slack group&lt;/a&gt; with 3k members. It has a good layout of channels, and a handful of messages per day&lt;/p&gt;
&lt;p&gt;You&amp;rsquo;ll also find a steady stream of Flink questions and answers on &lt;a href=&#34;https://stackoverflow.com/questions/tagged/apache-flink&#34;&gt;StackOverflow&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;whats-next-for-flink&#34;&gt;What&amp;rsquo;s next for Flink?&lt;/h2&gt;
&lt;p&gt;There&amp;rsquo;s a &lt;a href=&#34;https://flink.apache.org/roadmap/&#34;&gt;comprehensive and well-maintained roadmap&lt;/a&gt; for Flink. Changes are made through FLIPs (&lt;em&gt;&lt;strong&gt;FL&lt;/strong&gt;ink &lt;strong&gt;I&lt;/strong&gt;mprovement &lt;strong&gt;P&lt;/strong&gt;roposals&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;As well as what&amp;rsquo;s coming there&amp;rsquo;s also a clear list of &lt;a href=&#34;https://flink.apache.org/roadmap/#feature-radar&#34;&gt;features that are being phased out&lt;/a&gt;. This level of insight into the project is really useful for a newbie—given how long Flink has been around (aeons, in internet years) there is going to be a lot of material published that is out of date and this chart will hopefully be a quick way to navigate that.&lt;/p&gt;
&lt;p&gt;The roadmap page is notable for not only a list of planned features but also the &lt;a href=&#34;https://flink.apache.org/roadmap/#scenarios-we-focus-on&#34;&gt;general strategy&lt;/a&gt; (which should help inform users as to whether their use cases are within sensible bounds) and even something close to my own heart: &lt;a href=&#34;https://flink.apache.org/roadmap/#developer-experience&#34;&gt;developer experience&lt;/a&gt;. One particularly interesting bit that caught my eye is the idea of built-in dynamic table storage, described in &lt;a href=&#34;https://cwiki.apache.org/confluence/display/FLINK/FLIP-188%3A+Introduce+Built-in+Dynamic+Table+Storage&#34;&gt;FLIP-188&lt;/a&gt; and—if I understand correctly—spun out into its own Apache Incubator project, &lt;a href=&#34;https://paimon.apache.org/&#34;&gt;Apache Paimon&lt;/a&gt;. Paimon describes itself as a &amp;ldquo;&lt;em&gt;Streaming data lake platform&lt;/em&gt;&amp;rdquo; and is definitely on my list to go and check out particularly after &lt;a href=&#34;https://rmoff.net/2022/09/14/data-engineering-in-2022-storage-and-access/&#34;&gt;my work last year on mapping out the data engineering landscape&lt;/a&gt; as at first glance I&amp;rsquo;m not sure where it fits.&lt;/p&gt;
&lt;h2 id=&#34;flink-resources&#34;&gt;Flink Resources&lt;/h2&gt;
&lt;p&gt;The &lt;a href=&#34;https://flink.apache.org&#34;&gt;Apache Flink project website&lt;/a&gt; itself is an excellent resource. Especially when compared to some other Apache projects (&lt;em&gt;cough&lt;/em&gt;), it&amp;rsquo;s extremely well laid out, thoughtfully organised, and easy to use.&lt;/p&gt;
&lt;p&gt;Some other good places for Flink information include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;a href=&#34;https://www.flink-forward.org/&#34;&gt;Flink Forward&lt;/a&gt; conference (&lt;a href=&#34;https://www.flink-forward.org/events&#34;&gt;previous events&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Podcasts
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://overcast.fm/itunes1193040557/data-engineering-podcast&#34;&gt;Stateful, Distributed Stream Processing on Flink with Fabian Hueske&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://overcast.fm/+BAj84H3884&#34;&gt;Inside Apache Flink: A Conversation with Robert Metzger&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://overcast.fm/+BAj87Wiuo4&#34;&gt;Diving Deep into Apache Flink with Robert Metzger&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cse.google.com/cse?cx=010150859881542981030:hqhxyxpwtc4&amp;amp;ie=UTF-8&amp;amp;q=Apache+Flink+&amp;amp;sa=Search&#34;&gt;Apache Flink presentations on SpeakerDeck&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Learning Apache Flink S01E01: Where Do I Start?</title>
      <link>https://rmoff.net/2023/09/29/learning-apache-flink-s01e01-where-do-i-start/</link>
      <pubDate>2023-09-29</pubDate>
      
      <guid>https://rmoff.net/2023/09/29/learning-apache-flink-s01e01-where-do-i-start/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2023/09/t_IMG_5443.webp" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;p&gt;Like a fortunate child on Christmas Day, I&amp;rsquo;ve got a brand new toy! A brand new—to me—open-source technology to unwrap, learn, and perhaps even aspire to master elements of within.&lt;/p&gt;
&lt;p&gt;I &lt;a href=&#34;https://rmoff.net/2023/09/21/an-itch-that-just-has-to-be-scratched-or-why-am-i-joining-decodable&#34;&gt;joined Decodable&lt;/a&gt; two weeks ago, and since &lt;a href=&#34;https://decodable.co/&#34;&gt;Decodable&lt;/a&gt; is built on top of &lt;a href=&#34;https://flink.apache.org&#34;&gt;Apache Flink&lt;/a&gt; it seems like a great time to learn it. After six years learning Apache Kafka and hearing about this &amp;ldquo;Flink&amp;rdquo; thing but—for better or worse—never investigating it, I now have the perfect opportunity to do so.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/09/20230929134244.webp&#34; alt=&#34;An image of a squirrel at a laptop looking at a map, preparing to navigate the wonderful world of Apache Flink&#34;&gt;&lt;/p&gt;
&lt;p&gt;Just like the aforementioned kid with a new toy, what else would I do except run around (figuratively) with wild excitement, clicking on all the Apache Flink links and demos and tutorials and presentations and videos that I could find! And then I realised I should take somewhat of a more measured approach to my learning, and started to map out the different areas.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/09/learningflink.webp&#34; alt=&#34;A mindmap of the areas of Apache Flink about which I want to learn&#34;&gt;&lt;/p&gt;
&lt;p&gt;Breaking this out into sub-topics gives me nice little nuggets to start exploring (and blogging about, of course!). These include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What &lt;em&gt;is&lt;/em&gt; Flink (high level)
&lt;ul&gt;
&lt;li&gt;Uses &amp;amp; Users&lt;/li&gt;
&lt;li&gt;How do you run Flink&lt;/li&gt;
&lt;li&gt;Who can use Flink?
&lt;ul&gt;
&lt;li&gt;Java nerds only, or &lt;del&gt;normal&lt;/del&gt; non-Java folk too? 😜&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Resources&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Flink Architecture, Concepts, and Components&lt;/li&gt;
&lt;li&gt;Learn some Flink!&lt;/li&gt;
&lt;li&gt;Where does Flink sit in relation to other software in this space?
&lt;ul&gt;
&lt;li&gt;A mental map for me, not a holy war of streaming projects&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Some of these are going to be fairly self-contained (what &lt;em&gt;is&lt;/em&gt; Flink) whilst others (learning Flink) are going to be a multi-year journey :)&lt;/p&gt;</description>
    </item>
    <item>
      <title>An Itch That Just Has to Be Scratched… (Or, Why Am I Joining Decodable?)</title>
      <link>https://rmoff.net/2023/09/21/an-itch-that-just-has-to-be-scratched-or-why-am-i-joining-decodable/</link>
      <pubDate>2023-09-21</pubDate>
      
      <guid>https://rmoff.net/2023/09/21/an-itch-that-just-has-to-be-scratched-or-why-am-i-joining-decodable/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2023/09/t_IMG_8746.jpeg" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;p&gt;This week I joined &lt;a href=&#34;https://decodable.co&#34;&gt;Decodable&lt;/a&gt;. I&amp;rsquo;m grateful to my former colleagues at Treeverse for allowing me to &lt;a href=&#34;https://rmoff.net/2022/12/09/looking-forwards-and-looking-backwards/&#34;&gt;join them&lt;/a&gt; on the journey with &lt;a href=&#34;https://lakefs.io&#34;&gt;lakeFS&lt;/a&gt; - but something about the streaming world was too strong to resist 😁.&lt;/p&gt;
&lt;p&gt;I spent several years previously at Confluent bringing my data engineer&amp;rsquo;s view of the world to help &lt;a href=&#34;https://rmoff.net/categories/kafka-connect/&#34;&gt;advocate&lt;/a&gt; &lt;a href=&#34;http://youtube.com/rmoff&#34;&gt;for&lt;/a&gt; what was being built within Confluent as &lt;a href=&#34;https://ksqldb.io/&#34;&gt;ksqlDB&lt;/a&gt;—and the broader Apache Kafka community in &lt;a href=&#34;https://kafka.apache.org/documentation.html#connect&#34;&gt;Kafka Connect&lt;/a&gt;—as a coherent platform on which analytics and data integration solutions could be built.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/09/just-when-i-thought-i-was-out-they-pull-me-back-in.gif&#34; alt=&#34;Just when I thought I was out / They Pull Me Back In - Al Pacino - The Godfather&#34;&gt;&lt;/p&gt;
&lt;p&gt;Turns out, stream processing was only really just getting started. In the last 12-18 months a veritable plethora of stream processing projects and companies have shown up, demonstrating that there is not only demand for it but also different approaches to take too.&lt;/p&gt;
&lt;p&gt;The advent of real-time data stores such as &lt;a href=&#34;https://druid.apache.org/&#34;&gt;Apache Druid&lt;/a&gt;, &lt;a href=&#34;https://pinot.apache.org/&#34;&gt;Apache Pinot&lt;/a&gt;, and &lt;a href=&#34;https://clickhouse.com/&#34;&gt;Clickhouse&lt;/a&gt; further complicates the picture (or makes it more interesting, depending on your view). How much do you serve from your operational application, your streams, or your dedicated realtime store? What&amp;rsquo;s driving the need for the data, and what kind of access patterns do you have?&lt;/p&gt;
&lt;p&gt;In short, I have unfinished business with streaming.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/09/notdone-got.gif&#34; alt=&#34;I Am Not Finished! - Yara Greyjoy - Game of Thrones&#34;&gt;&lt;/p&gt;
&lt;p&gt;Unsuprising really, since event streams &lt;em&gt;are&lt;/em&gt; unbounded 🤓 &lt;code&gt;&amp;lt;groan/&amp;gt;&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;abl-always-be-learning&#34;&gt;A.B.L. (Always Be Learning)&lt;/h2&gt;
&lt;p&gt;One of the many things that excites me about joining Decodable is the opportunity to dive in and learn &lt;a href=&#34;https://flink.apache.org/&#34;&gt;Apache Flink&lt;/a&gt;. I&amp;rsquo;m planning to blog my journey with it (similar to how I did as &lt;a href=&#34;https://rmoff.net/2020/06/25/learning-golang-some-rough-notes-s01e00/&#34;&gt;a complete n00b going into Go&lt;/a&gt;), so if you have any burning questions about it already then make sure to &lt;a href=&#34;https://twitter.com/rmoff/&#34;&gt;drop me&lt;/a&gt; &lt;a href=&#34;https://www.linkedin.com/in/robinmoffatt&#34;&gt;a line&lt;/a&gt; and I&amp;rsquo;ll be happy to use it as an excuse to go and find out the answer. And find out the answer I shall, because one of the &lt;em&gt;other&lt;/em&gt; many reasons that I&amp;rsquo;m so excited about Decodable is my colleagues here:&lt;/p&gt;
&lt;h2 id=&#34;never-be-the-smartest-in-the-room&#34;&gt;Never Be The Smartest in the Room&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Well, there&amp;rsquo;s never been any danger of that at any of my previous gigs—I&amp;rsquo;ve been fortunate to work with some excellent people—and the same holds true for Decodable&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;One of the things that really sealed the deal for me during the interview process was just how damn smart the folk were. Not in a &amp;ldquo;&lt;em&gt;I ask you stupidly pointless question to highlight how smart I am, you wriggle for an answer that I&amp;rsquo;ll not really listen to, rinse &amp;amp; repeat&lt;/em&gt;&amp;rdquo; kind of way. But in a focussed and probing and inquisitive way, with true dialogue and listening. That&amp;rsquo;s the kind of stuff you can&amp;rsquo;t LeetCode for, and is a hugely positive indicator.&lt;/p&gt;
&lt;p&gt;As well as being lovely people to chat to and sharp as a sharp thing that&amp;rsquo;s just been sharpened, there&amp;rsquo;s some extensive and deep knowledge about the stream processing world in general and the projects which Decodable uses. These include folk such as &lt;a href=&#34;https://www.linkedin.com/in/esammer/&#34;&gt;Eric Sammer&lt;/a&gt;, &lt;a href=&#34;https://www.linkedin.com/in/sharonxr/&#34;&gt;Sharon Xie&lt;/a&gt;, Flink PMC Chair &lt;a href=&#34;https://home.apache.org/phonebook.html?uid=rmetzger&#34;&gt;Robert Metzger&lt;/a&gt;, and former lead on the &lt;a href=&#34;https://debezium.io/&#34;&gt;Debezium&lt;/a&gt; project &lt;a href=&#34;https://www.morling.dev/&#34;&gt;Gunnar Morling&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;what-will-i-be-doing-at-decodable&#34;&gt;What Will I Be Doing at Decodable?&lt;/h2&gt;
&lt;p&gt;Who knows?! That&amp;rsquo;s the fun part of joining a 30-person startup 😉.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/09/IMG_5699.jpeg&#34; alt=&#34;Conference badge that reads &amp;amp;ldquo;Robin Moffatt: Principal Shitposter and Meme Artist&amp;amp;rdquo;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Srsly tho: my starting point for this answer is my blog from earlier this year &lt;a href=&#34;https://rmoff.net/2023/05/23/what-does-this-devex-engineer-do/&#34;&gt;&lt;em&gt;What Does This DevEx Engineer Do?&lt;/em&gt;&lt;/a&gt;. But very shortly after that my answer is: getting stuck in and helping build a really awesome streaming platform. Friction logs, blogs, &lt;del&gt;shitposting&lt;/del&gt;, community, docs, making videos…whatever needs doing to make the experience for developers the very best 🏆.&lt;/p&gt;
&lt;h2 id=&#34;stream-processing---weve-only-just-got-started&#34;&gt;Stream Processing - We&amp;rsquo;ve Only Just Got Started&lt;/h2&gt;
&lt;p&gt;So, time for me to get back into stream processing land. I&amp;rsquo;ll save you the fluff and gumpf about the business value of stream processing, the use cases, all the evils and perils of batch, yada yada. If you know, you know. And if you don&amp;rsquo;t, well, join me for the ride 🙃.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/09/saddle-up-partner-dumb-and-dumber.gif&#34; alt=&#34;Saddle up, partner! Jim Carrey - Dumb &amp;amp; Dumber&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Blog Writing for Developers</title>
      <link>https://rmoff.net/2023/07/19/blog-writing-for-developers/</link>
      <pubDate>2023-07-19</pubDate>
      
      <guid>https://rmoff.net/2023/07/19/blog-writing-for-developers/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2023/07/t_IMG_3731.jpeg" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;p&gt;Writing is one of the most powerful forms of communication, and it’s useful in a multitude of roles and contexts. As a &lt;a href=&#34;https://rmoff.net&#34;&gt;blog-writing&lt;/a&gt;, &lt;a href=&#34;https://github.com/treeverse/lakeFS/pulls?q=is%3Apr+label%3Adocs+author%3Armoff+&#34;&gt;documentation-authoring&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/rmoff/status/1587382202781913089&#34;&gt;twitter-shitposting&lt;/a&gt; DevEx engineer I spend a lot of my time writing. Recently, someone paid me a very nice compliment about a blog I’d written and asked how they could learn to write like me and what resources I’d recommend.&lt;/p&gt;
&lt;p&gt;Never one to miss a chance to write and share something, here’s my response to this :)&lt;/p&gt;
&lt;p&gt;To begin with I want to cover briefly the motivations behind writing.&lt;/p&gt;
&lt;h2 id=&#34;why-do-i-write&#34;&gt;Why Do &lt;strong&gt;I&lt;/strong&gt; Write?&lt;/h2&gt;
&lt;p&gt;Firstly, I like &lt;strong&gt;to share information&lt;/strong&gt;. That could be a new &lt;a href=&#34;https://rmoff.net/2021/03/04/quick-profiling-of-data-in-apache-kafka-using-kafkacat-and-visidata/&#34;&gt;tool&lt;/a&gt; or &lt;a href=&#34;https://lakefs.io/blog/data-engineering-patterns-write-audit-publish/&#34;&gt;technique&lt;/a&gt; that I’ve learnt, &lt;a href=&#34;https://rmoff.net/2020/09/30/setting-key-value-when-piping-from-jq-to-kafkacat/&#34;&gt;a clever trick&lt;/a&gt; I’ve discovered, or sometimes away from the technical and into the realms of &lt;a href=&#34;https://rmoff.net/2019/02/09/travelling-for-work-with-kids-at-home/&#34;&gt;life pondering&lt;/a&gt; and &lt;a href=&#34;https://rmoff.net/2023/05/23/what-does-this-devex-engineer-do/&#34;&gt;navel gazing&lt;/a&gt;. In the case of this very blog, it’s to share my thoughts on something that interests me. I could have written some notes and sent them directly back to the person who asked the original question, but if it was useful to them it’s hopefully useful to others—so therefore it’s worth writing up and publishing.&lt;/p&gt;
&lt;p&gt;The second reason that I’ll write is &lt;strong&gt;to learn about something&lt;/strong&gt;. It’s one thing to hand-wave one’s way through a presentation. It’s another to commit pen to paper (well, bytes to disk) and &lt;a href=&#34;https://rmoff.net/2018/08/02/kafka-listeners-explained/&#34;&gt;explain something&lt;/a&gt;. Quite often I’ll realise that there’s a gap—or gaps—in my knowledge that I need to explore first before I can properly write about something, and that’s the very reason that I do it.&lt;/p&gt;
&lt;p&gt;There are several pleasant side-effects from writing too. Anything in the public domain (such as your blog, but also open-source project documentation, etc) helps establish your credibility in an area and awareness by others of you. We may never reach the stratospheric heights of someone such as Kelsey Hightower, who has wowed a generation of developers with their &lt;a href=&#34;https://youtu.be/HlAXp0-M6SY?t=718&#34;&gt;Tetris-playing skills&lt;/a&gt;, but being known as &lt;em&gt;that guy&lt;/em&gt; who wrote a really useful blog that helped others is still a really nice feeling :)&lt;/p&gt;
&lt;h2 id=&#34;how-do-i-write-for-developers&#34;&gt;HOW do I Write for Developers?&lt;/h2&gt;
&lt;h3 id=&#34;-stop-watch-this-first-&#34;&gt;🛑 STOP! Watch This First 🎥&lt;/h3&gt;
&lt;p&gt;Go and watch this excellent lecture called &lt;a href=&#34;https://www.youtube.com/watch?v=vtIzMaLkCaM&#34;&gt;The Craft of Writing Effectively&lt;/a&gt;. It’s given by Larry McEnerney who is the Director of the University of Chicago’s Writing Program and knows a thing or two about writing. There are direct parallels between his observations on how and why academics communicate, and communication between developers.&lt;/p&gt;
&lt;p&gt;👉🏻 I’ve seen it recommended several times but to my embarrassment, the length put me off—but I wish it hadn’t as it’s superb.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If you’d rather listen instead of watch you can use &lt;a href=&#34;https://github.com/yt-dlp/yt-dlp&#34;&gt;&lt;code&gt;yt-dlp&lt;/code&gt;&lt;/a&gt; to download it as audio (&lt;code&gt;--extract-audio --audio-format mp3&lt;/code&gt;).&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;so-how-do-i-write-for-developers&#34;&gt;So, how do I write for developers?&lt;/h3&gt;
&lt;p&gt;Each writer will have their own approach to writing, and it will vary based on the audience and purpose too. A report for publication in an academic journey will have a different structure to a shitpost on Twitter. A blog aimed at developers will read very differently from the documentation from the depths of a product manual. Each medium and audience is valid; the knack is making sure that your writing lines up with it.&lt;/p&gt;
&lt;p&gt;When I write I try to write for myself—a developer, interested in a thing. That could be a new technology, an in-depth explanation, a random musing on life, or anything else. Would I like to read the thing I’ve read? Does it avoid the pitfalls that plague the soulless bland crap that some companies churn out, stick an emoji on, and call developer marketing?&lt;/p&gt;
&lt;p&gt;There are three key dimensions that it’s useful to consider here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;clarity&lt;/li&gt;
&lt;li&gt;personality (also called voice)&lt;/li&gt;
&lt;li&gt;uniformity of content.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can roughly overlay these dimensions across the range of written materials that we might write:&lt;/p&gt;
&lt;img src=&#34;https://rmoff.net/images/2023/07/01.svg&#34; width=600/&gt;
&lt;p&gt;Things aren’t always so simple, and for some platforms in particular there’s quite a range:&lt;/p&gt;
&lt;img src=&#34;https://rmoff.net/images/2023/07/02.svg&#34; width=600/&gt;
&lt;p&gt;What do these different dimensions mean in practice? Let’s explore that.&lt;/p&gt;
&lt;h4 id=&#34;clarity-is-key&#34;&gt;Clarity is Key&lt;/h4&gt;
&lt;p&gt;The first of these dimensions is pretty straightforward and shouldn’t really vary. Whatever you write, for whomever you write it, &lt;strong&gt;it has to be clear&lt;/strong&gt;. Writing clearly means everything from sentence construction and paragraph breaks through to the structure of your article. It can be surprisingly hard to do but is crucial if you want to write material that people will &lt;em&gt;want&lt;/em&gt; to read.&lt;/p&gt;
&lt;p&gt;One neat trick when it comes to clarity is to remember that &lt;em&gt;what you leave out&lt;/em&gt; is as important as what you leave in. This is going to be very context-specific. Documentation, by definition, should be comprehensive. A blog, on the other hand, might want to get to the point sooner and just provide a link to background material for the reader should they want it. Less is often more, as they say.&lt;/p&gt;
&lt;p&gt;Some types of writing are going to have greater scope for individuality than others, but all have the potential to at least be accessible and clear. For example, just because you’re writing documentation doesn’t give you a pass to copy and paste the requirements doc in all its generic and obscure complexity. Write documentation that you as a developer would like to read. It can be complex and precise, yet still accessible.&lt;/p&gt;
&lt;h4 id=&#34;personality-and-voice&#34;&gt;Personality and Voice&lt;/h4&gt;
&lt;p&gt;Should the &amp;lsquo;voice&amp;rsquo; of the author be allowed to come through in the writing?&lt;/p&gt;
&lt;p&gt;This is very much a sliding scale. I’ve jotted down &lt;em&gt;some&lt;/em&gt; of the characteristics you might associate with either extreme of the scale. This is not to say that by definition you’d put cuss words into a blog so as to convey your voice—but as an example of something that you might see at that end of the spectrum and definitely not at the other.&lt;/p&gt;
&lt;img src=&#34;https://rmoff.net/images/2023/07/03.svg&#34; height=300/&gt;
&lt;p&gt;How you decide where to pitch your voice on this scale will come down to your preference, audience, and general area and discipline. If you spend much time on Twitter you’ll notice that InfoSec Twitter is different from DevOps Twitter, which is different again from DataEng Twitter. Each has its own cliques and customs, and also a varying range to which an author’s voice shines through in published writing.&lt;/p&gt;
&lt;p&gt;You’ll generally find that generally writing mediums such as a project report to stakeholders or product documentation requires a neutral voice. That’s not to say &lt;em&gt;boring&lt;/em&gt;, but it is to say that a certain uniformity is required. In the case of a project report, the message mustn’t be obscured by colloquialisms and the such. And can you imagine the cognitive dissonance if a set of documentation were written by multiple writers each looking to stamp their personality on the pages?&lt;/p&gt;
&lt;p&gt;When we get to things like blogs and other types of writing we &lt;em&gt;deliberately&lt;/em&gt; want to include some personality. How much is up to you to calibrate with your audience and yourself. There is a “Goldilocks” zone here—enough personality and genuine voice coming through to convince the reader that they are reading something that was written by someone who is actually interested and informed on the matter, but not so much that it gets in the way of the content.&lt;/p&gt;
&lt;h4 id=&#34;uniformity-and-standardisation&#34;&gt;Uniformity and Standardisation&lt;/h4&gt;
&lt;p&gt;This has a strong relationship with personality and voice but relates a lot more to the structure and content of the material&lt;/p&gt;
&lt;img src=&#34;https://rmoff.net/images/2023/07/04.svg&#34; height=300/&gt;
&lt;p&gt;Using the example of blogs, you’ll find that blogs for a company or project are going to have a strong focus on the consistency of messaging and structure. There’ll be an introduction, there’ll be context; it’ll be comprehensive.&lt;/p&gt;
&lt;p&gt;Compare that to a personal blog that may sometimes be not much more than the gutterings of a developer wanting to log an error message and solution for future Googlers. They &lt;em&gt;might&lt;/em&gt; flesh it out into a longer article, but that’s not necessary for it still to have value.&lt;/p&gt;
&lt;h4 id=&#34;a-holistic-view&#34;&gt;A Holistic View&lt;/h4&gt;
&lt;p&gt;It may seem like there’s going to be a linear relationship between the two dimensions. As we decrease the amount of personality coming through in an author’s writings, we’re also going to move towards a much more standardised set of writing.&lt;/p&gt;
&lt;p&gt;I’d suggest that it’s not always the case.&lt;/p&gt;
&lt;p&gt;A startup may value personality much more over standardisation, perhaps only really dropping the voice when it comes to something like documentation (and even then, perhaps not entirely).&lt;/p&gt;
&lt;img src=&#34;https://rmoff.net/images/2023/07/05.svg&#34; height=300/&gt;
&lt;p&gt;At the other end of the scale, some companies—usually large corporations—have the habit of squeezing the last inch of life out of any kind of writing, making the relationship a much different one.&lt;/p&gt;
&lt;p&gt;Here there’s little voice even where you might hope to find it, and that rapidly drops off into nothing very soon after:&lt;/p&gt;
&lt;img src=&#34;https://rmoff.net/images/2023/07/06.svg&#34; height=300/&gt;
&lt;p&gt;The wildcard within this is the social media teams of large companies who &lt;em&gt;are&lt;/em&gt; given the remit to be &lt;code&gt;Funny&lt;/code&gt; and &lt;code&gt;Engaging&lt;/code&gt;, but this is usually outside the scope of developer writing and more into the field of &lt;a href=&#34;https://www.boredpanda.com/sassiest-responses-from-companies&#34;&gt;condiments and fast food chains&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;structuring-your-blog-writing&#34;&gt;Structuring your Blog Writing&lt;/h2&gt;
&lt;p&gt;Like a favourite pair of jeans that’s well-worn, comfy, and slightly saggy round the arse, I have a go-to structure for writing. Come to think of it, I use it for lots of conference talks too. It looks like this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Tell them what you’re going to tell them&lt;/li&gt;
&lt;li&gt;Tell them&lt;/li&gt;
&lt;li&gt;Tell them what you told them&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;What this looks like in practice is something along these lines:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;An intro&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;What is this thing, and why should the reader &lt;del&gt;give af&lt;/del&gt; be interested?&lt;/p&gt;
&lt;p&gt;This could be a brief explanation of why I am interested in it, or why you would want to read my take on it. The key thing is you’re relating to your audience here. Not everyone wants to read everything you write, and that’s ok.&lt;/p&gt;
&lt;p&gt;Let people self-select out (or in, hopefully) at this stage, but make it nice and easy. For example, if you’re writing about data engineering, make it clear to the appdev crowd that they should move on as there’s nothing to see here (or stick around and learn something new, but as a visitor, not the target audience).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;The article itself&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;A recap&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Make sure you don’t just finish your article with a figurative mic drop—tie up it nicely with a bow (a 🙇🏻 or a 🎀, either works).&lt;/p&gt;
&lt;p&gt;This is where marketing would like to introduce you to the acronym CTA (Call To Action) 😉. As an author you can decide how or if to weave that into your narrative.&lt;/p&gt;
&lt;p&gt;Either way, you’re going to summarise what you just did and give people something to &lt;em&gt;do&lt;/em&gt; with it next. Are there code samples they can go and run or inspect? A new service to sign up for? A video to watch? Or just a general life reflection upon which to ponder.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;-the-physical-act-of-writing-jfdi--&#34;&gt;✍🏻 The Physical Act of Writing: JFDI ;-)&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/07/07.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;At the risk of repeating the &lt;a href=&#34;https://knowyourmeme.com/memes/how-to-draw-an-owl&#34;&gt;owl meme&lt;/a&gt; I would give the following advice: just start writing!&lt;/p&gt;
&lt;p&gt;I don’t mean just go write an article. I mean start writing &lt;strong&gt;something&lt;/strong&gt;, &lt;strong&gt;&lt;em&gt;anything.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Some notes, some snippets, some whole paragraphs. It might even look like this&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/07/08.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;The point is you now have &lt;em&gt;something&lt;/em&gt;. The sections and threads of a story start to fall out as you write more. What starts as one section perhaps becomes two as you realise there are individual elements to tease out.&lt;/p&gt;
&lt;p&gt;Iterate, iterate, and then iterate some more.&lt;/p&gt;
&lt;p&gt;That random link you made a note of, where does it fit in what you want to say? Is it pushing the need for a new section or tangent, or is it actually not so relevant and you can park it? Not sure? Well just leave it there and think about it again on the next pass round.&lt;/p&gt;
&lt;p&gt;I’ve recently found that using a &lt;a href=&#34;https://en.wikipedia.org/wiki/Pomodoro_Technique&#34;&gt;Pomodoro timer&lt;/a&gt; is an effective way of getting me to focus, and to take a break. Instead of staring at a screen, descending into a pit of despair at the stagnation of an article, you spend a chunk of time and then step away. Perhaps you come back to it after the break or maybe wait longer. Like many problems in life, things resolve themselves given time to marinade in the recesses of one’s brain. That paragraph that just wouldn’t write itself will come spilling out of your eager fingers onto the keyboard. The section you thought you’d &lt;em&gt;nailed&lt;/em&gt;—turns out you didn’t and it needs a rewrite. But all these things come with time and iteration through the text.&lt;/p&gt;
&lt;h2 id=&#34;find-a-really-good-reviewer-and-copyeditor&#34;&gt;Find a really good reviewer and copyeditor&lt;/h2&gt;
&lt;p&gt;You might think you’re good at writing. You’re probably not &lt;em&gt;that&lt;/em&gt; good at writing that the eye of an excellent copyeditor won’t improve it, nor the tactful input of a good reviewer enhance it.&lt;/p&gt;
&lt;p&gt;Good copyeditors will respect the voice that’s present in your writing and work to preserve it whilst improving the clarity and grammatical accuracy of what you’ve written.&lt;/p&gt;
&lt;p&gt;Good reviewers will grok what you’re saying and help distil and mould it into a better shape.&lt;/p&gt;
&lt;h2 id=&#34;tools&#34;&gt;Tools&lt;/h2&gt;
&lt;p&gt;Ah, the meta-blog post about tooling. Each to their own, but here’s my stack:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://obsidian.md/&#34;&gt;Obsidian&lt;/a&gt; for authoring&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cleanshot.com/&#34;&gt;CleanShot X&lt;/a&gt; for screen grabs and markup&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.grammarly.com/&#34;&gt;Grammarly&lt;/a&gt; for proofreading (and please, for the sak of your readers, profread, noone wnats to red a baydly writen blog)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rmoff.net/categories/hugo/&#34;&gt;Hugo and GitHub Pages&lt;/a&gt; for publishing and hosting&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;resources&#34;&gt;Resources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;A &lt;a href=&#34;https://github.com/sixhobbits/technical-writing/blob/master/resources.md&#34;&gt;useful list of resources&lt;/a&gt; from &lt;a href=&#34;https://twitter.com/sixhobbits&#34;&gt;Gareth Dwyer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;📧 An email-based course called &lt;a href=&#34;https://bloggingfordevs.com/&#34;&gt;Blogging for Devs&lt;/a&gt;. It’s quite focussed on the mechanics of a blogging but has some useful nuggets - and it’s free&lt;/li&gt;
&lt;li&gt;📕&lt;a href=&#34;https://pragprog.com/titles/actb2/technical-blogging-second-edition/&#34;&gt;Technical Blogging&lt;/a&gt;, by &lt;a href=&#34;https://antoniocangiano.com/&#34;&gt;Antonio Cangiano&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=kOnZovTFTHc&#34;&gt;Avoiding Anti-patterns in Technical Communication&lt;/a&gt; - good conference talk from &lt;a href=&#34;https://www.linkedin.com/in/sophwats/&#34;&gt;Sophie Watson&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;A nice blog from &lt;a href=&#34;https://www.linkedin.com/in/kudmitry/&#34;&gt;Dmitry Kudryavtsev&lt;/a&gt; on &lt;a href=&#34;https://www.yieldcode.blog/post/why-engineers-should-write&#34;&gt;Why engineers should focus on writing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://developers.google.com/tech-writing&#34;&gt;Technical Writing Courses - Google Developers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;footnote-_what_-should-i-write&#34;&gt;Footnote: &lt;em&gt;What&lt;/em&gt; Should I Write?&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;We’ve covered the why and the how - but what about the what?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;What to write will often come from the “Why” above, but let’s imagine that the creative juices aren’t flowing and you still really want to get a blog written.&lt;/p&gt;
&lt;p&gt;A really excellent place for ideas is the community around the thing you want to write about. Go and lurk (or even better, join in) at StackOverflow, Twitter, Slack, Discord…wherever the community is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What questions do people repeatedly ask?&lt;/li&gt;
&lt;li&gt;What are the anti-patterns and misunderstandings that you see?&lt;/li&gt;
&lt;li&gt;What are the new trends?&lt;/li&gt;
&lt;li&gt;What cool things can you do with &lt;code&gt;$THING&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In short, if it would be interesting to me then I would write about it.&lt;/p&gt;
&lt;p&gt;Make sure to also watch &lt;a href=&#34;https://www.youtube.com/watch?v=vtIzMaLkCaM&#34;&gt;this lecture&lt;/a&gt; in which the concept of &lt;em&gt;value&lt;/em&gt; and &lt;em&gt;ideas&lt;/em&gt; is discussed. tl;dr if you aren’t writing about something interesting to the reader, it has no value, regardless of its value to you.&lt;/p&gt;
&lt;h3 id=&#34;what-not-to-write&#34;&gt;What Not to Write?&lt;/h3&gt;
&lt;p&gt;This is a &lt;em&gt;very&lt;/em&gt; personal preference. I’m not keen at all on growth-driven blogging styles. You know the sort: listicles, SEO bait, etc. It’s low-grade, developers see through it, and it tarnishes the blogger’s image IMHO. That said, if you write a good blog, there’s no reason not to structure it such (“&lt;em&gt;Top Five Tips for Successful Developer Writing&lt;/em&gt;”) but put the horse before the cart, not the other way around.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;recap&#34;&gt;Recap&lt;/h2&gt;
&lt;p&gt;To summarise this whole article, bear in mind that these two statements are not mutually exclusive:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Write for yourself. Work out what &lt;em&gt;you&lt;/em&gt; would like to read, and write it.&lt;/li&gt;
&lt;li&gt;Think of the reader and what value you’re providing to them in your writing.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;That’s because as a developer writing for developers, you &lt;strong&gt;are&lt;/strong&gt; the reader.&lt;/p&gt;
&lt;p&gt;Oh, and did you watch &lt;a href=&#34;https://www.youtube.com/watch?v=vtIzMaLkCaM&#34;&gt;Larry McEnerney’s lecture&lt;/a&gt; yet? 😊&lt;/p&gt;</description>
    </item>
    <item>
      <title>What Does This DevEx Engineer Do?</title>
      <link>https://rmoff.net/2023/05/23/what-does-this-devex-engineer-do/</link>
      <pubDate>2023-05-23</pubDate>
      
      <guid>https://rmoff.net/2023/05/23/what-does-this-devex-engineer-do/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2023/05/t_IMG_2342.jpeg" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;p&gt;&lt;em&gt;This was originally titled more broadly &amp;ldquo;What Does &lt;em&gt;A&lt;/em&gt; DevEx Engineer Do&amp;rdquo;, but that made it into a far too tedious and long-winding etymological exploration of the discipline. Instead, I&amp;rsquo;m going to tell you what this particular instantiation of the entity does 😄&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;lets-define-devex-first&#34;&gt;Let&amp;rsquo;s Define DevEx first…&lt;/h2&gt;
&lt;p&gt;Developer Experience (a.k.a. DevEx, DevX) is fundamentally about making the experience for developers a good, nay, positively joyful, one.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s about removing the &amp;ldquo;&lt;em&gt;if you just read the first five chapters of the manual then you can use this … calculator&lt;/em&gt;&amp;rdquo; and instead making software behave as one would instinctively expect it to.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s pre-populating fields that can be pre-populated, opening APIs that can be opened, removing barriers and lifting developers up.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s about shipping that MVP but with the sharp edges rounded off and plotting a happy path for users so that the cringe-worthy mission statement of companies that &amp;ldquo;we build software that people love&amp;rdquo; can actually seem credible.&lt;/p&gt;
&lt;p&gt;In a crowded market-place where alternative software is a click away making your software not just functional but also damned easy and enjoyable to use is vital. Developers are no longer chained to their workstations, doomed to use whatever piece of crap the IT director bought on the golf course from some salesman looking to hit their quarterly target.&lt;/p&gt;
&lt;p&gt;Developers are empowered to use the software that not only works but which gets the job done efficiently, painlessly, and is easy to use. Don&amp;rsquo;t confuse &lt;em&gt;easy&lt;/em&gt; with &lt;em&gt;simple&lt;/em&gt;—complicated software can have a great developer experience - and simple software can unfortuntely also have a bloody awful developer experience.&lt;/p&gt;
&lt;h2 id=&#34;but-hang-on-i-thought-devex-was-differentthing&#34;&gt;But Hang On, I thought DevEx Was… &lt;code&gt;$DifferentThing&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Developer Experience (DevEx, also DevX) has taken on a similar-but-dual meaning in the last year or two. Both relate to developers and their experience, but one&amp;rsquo;s audience is developers &lt;em&gt;within&lt;/em&gt; a company, and the other&amp;rsquo;s &lt;em&gt;outside&lt;/em&gt; the company.&lt;/p&gt;
&lt;p&gt;My familiarity with DevEx is based on the latter - working to improve the experience of developers external to the company, and specifically, those to whom the company is building and hopefully selling a product. Just like the broader discipline of Developer Relations as a whole—of which this version of DevEx is a part—there is no selling to be done here. DevRel, DevEx, and whatever other term you come up with, do not sell. Period. They educate, inform, and entertain the developer base, with a view to the developer then having such a great time with the software that they subsequently decide to open their cheque books and buy the software of their own volition.&lt;/p&gt;
&lt;p&gt;The other DevEx which I&amp;rsquo;ve noticed more and more of recently is that serving the developers within a company. A good example of this angle is the wonderfully-named &lt;a href=&#34;https://www.container-solutions.com/wtf-is-devex&#34;&gt;WTF is DevEx&lt;/a&gt; from Container Solutions. Microsoft have &lt;a href=&#34;https://microsoft.github.io/code-with-engineering-playbook/developer-experience/&#34;&gt;a good page on DevEx&lt;/a&gt;, and the &lt;a href=&#34;https://www.developerexperience.us/&#34;&gt;DevX Community&lt;/a&gt; has sprung up to provide a place for DevX practitioners to support each other.&lt;/p&gt;
&lt;h2 id=&#34;ok-so-were-talking-about-the-devrel-y-devex&#34;&gt;OK, so we&amp;rsquo;re talking about the DevRel-y DevEx&lt;/h2&gt;
&lt;p&gt;Both kinds of DevX are important, and there is &lt;em&gt;huge&lt;/em&gt; overlap between them - but there are some significant differences. DevX done under the DevRel banner will often include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Content creation&lt;/li&gt;
&lt;li&gt;Documentation&lt;/li&gt;
&lt;li&gt;Community interaction&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In a nutshell, it&amp;rsquo;s activities that enhance the &lt;em&gt;experience&lt;/em&gt; of a &lt;em&gt;developer&lt;/em&gt; not only when they&amp;rsquo;re just using software, but on their entire journey with it - from becoming aware of it, trying it, learning it, and so on.&lt;/p&gt;
&lt;h2 id=&#34;so-what-does-this-devex-engineer-do&#34;&gt;So… What Does &lt;em&gt;This&lt;/em&gt; DevEx Engineer Do?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Write &lt;a href=&#34;https://rmoff.net//2018/08/02/kafka-listeners-explained/&#34;&gt;deeply technical&lt;/a&gt; and &lt;a href=&#34;https://www.confluent.io/blog/streaming-etl-and-analytics-for-real-time-location-tracking/&#34;&gt;engaging blog posts&lt;/a&gt;, along with more &lt;a href=&#34;https://rmoff.net/2022/09/14/stretching-my-legs-in-the-data-engineering-ecosystem-in-2022/&#34;&gt;analytical ones&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Build best-of-breed &lt;a href=&#34;https://docs.lakefs.io/quickstart&#34;&gt;Quickstarts&lt;/a&gt; and &lt;a href=&#34;https://rmoff.net/2020/03/11/streaming-wi-fi-trace-data-from-raspberry-pi-to-apache-kafka-with-confluent-cloud/&#34;&gt;fun&lt;/a&gt; &lt;a href=&#34;https://github.com/confluentinc/demo-scene/tree/master/mqtt-tracker&#34;&gt;demos&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/treeverse/lakeFS/issues?q=is%3Aissue+author%3Armoff+DX&#34;&gt;Advocate for&lt;/a&gt; and &lt;a href=&#34;https://github.com/treeverse/lakeFS/pull/5313&#34;&gt;Fix&lt;/a&gt; DX in the product&lt;/li&gt;
&lt;li&gt;Record and produce &lt;a href=&#34;https://rmoff.net/2021/02/17/ksqldb-howto-a-mini-video-series/&#34;&gt;video explainers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Teaching &lt;a href=&#34;https://rmoff.net/2020/06/25/learning-golang-some-rough-notes-s01e00/&#34;&gt;by learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Engage with the online community wherever Developers are found&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/rmoff/status/1587382202781913089&#34;&gt;Shitposting&lt;/a&gt;, &lt;a href=&#34;https://www.linkedin.com/posts/robinmoffatt_choosing-open-wisely-snowflake-blog-activity-6973309528628973568-gjOJ?utm_source=share&amp;amp;utm_medium=member_desktop&#34;&gt;Shitposting&lt;/a&gt;, and &lt;a href=&#34;https://twitter.com/rmoff/status/1448230290657251338&#34;&gt;Memes&lt;/a&gt; (and more &lt;a href=&#34;https://twitter.com/rmoff/status/1641113617662722064&#34;&gt;shitposting&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Manage and develop &lt;a href=&#34;https://forum.confluent.io/t/why-yacp-yet-another-community-platform/54&#34;&gt;community platforms&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Author &lt;a href=&#34;https://github.com/treeverse/lakeFS/pulls?q=is%3Apr+author%3Armoff+label%3Adocs&#34;&gt;docs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Maintain and improve &lt;a href=&#34;https://rmoff.net/2023/04/20/building-better-docs-automating-jekyll-builds-and-link-checking-for-prs/&#34;&gt;Docs platform&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;isnt-this-the-same-as-developer-advocacy&#34;&gt;Isn&amp;rsquo;t this the same as Developer Advocacy?&lt;/h3&gt;
&lt;p&gt;To an extent, yes. I&amp;rsquo;m not interested in a discussion about job titles really, short to say that most people assume a Developer Advocate travels and does conference talks with other activities fitting around it. For me a DevX Engineer is more focussed on the building and writing, than speaking.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Authoring Wordpress blogs in Markdown (with Google Docs for review)</title>
      <link>https://rmoff.net/2023/05/03/authoring-wordpress-blogs-in-markdown-with-google-docs-for-review/</link>
      <pubDate>2023-05-03</pubDate>
      
      <guid>https://rmoff.net/2023/05/03/authoring-wordpress-blogs-in-markdown-with-google-docs-for-review/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2023/05/t_IMG_2565.jpeg" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;p&gt;Wordpress still, to an extent, rules the blogging world. Its longevity is testament to…something about it ;) However, it&amp;rsquo;s not my favourite platform in which to write a blog by a long way. It doesn&amp;rsquo;t support Markdown to the extent that I want. Yes, I&amp;rsquo;ve tried the plugins; no, they didn&amp;rsquo;t do what I needed.&lt;/p&gt;
&lt;p&gt;I like to write all my content in a structured format - ideally &lt;a href=&#34;https://asciidoc.org/&#34;&gt;Asciidoc&lt;/a&gt;, but &lt;a href=&#34;https://rmoff.net/2017/09/12/what-is-markdown-and-why-is-it-awesome/&#34;&gt;I&amp;rsquo;ll settle for Markdown too&lt;/a&gt;. Here&amp;rsquo;s how I stayed [almost] sane whilst composing a blog in Markdown, reviewing it in Google Docs, and then publishing it in Wordpress in a non-lossy way.&lt;/p&gt;
&lt;h1 id=&#34;author&#34;&gt;Author&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;Write your blog in Markdown. &lt;em&gt;Perhaps this approach will work with Asciidoc too, since pandoc also works with it - I&amp;rsquo;ve just not tried it.&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;review&#34;&gt;Review&lt;/h1&gt;
&lt;p&gt;Google Docs is still the best way that I&amp;rsquo;ve found to collaboratively review a blog. It&amp;rsquo;s accessible to technical and less-technical users alike.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ll get your Markdown into GDocs via a &lt;code&gt;.docx&lt;/code&gt; export/import.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;pandoc&lt;/code&gt; to convert the Markdown to &lt;code&gt;.docx&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pandoc Securing&lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;\ &lt;/span&gt;lakeFS&lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;\ &lt;/span&gt;with&lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;\ &lt;/span&gt;Role-Based&lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;\ &lt;/span&gt;Access&lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;\ &lt;/span&gt;Control&lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;\ \(&lt;/span&gt;RBAC&lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;\)&lt;/span&gt;.md &lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;&lt;/span&gt;       -o ~/Downloads/blog.docx   
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Import the &lt;code&gt;.docx&lt;/code&gt; file to Google Docs&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Save GDoc as native Google Doc, share with comment access&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Review / Copyedit&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make edits, accept proposed changes, etc directly in GDocs.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;If you&amp;rsquo;re using Asciidoc, see this related blog that I wrote on &lt;a href=&#34;https://rmoff.net/2020/04/16/converting-from-asciidoc-to-google-docs-and-ms-word/&#34;&gt;Converting from AsciiDoc to Google Docs and MS Word&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;h1 id=&#34;publish&#34;&gt;Publish&lt;/h1&gt;
&lt;p&gt;At this point the Google Doc is ready to publish. However, Google Docs doesn&amp;rsquo;t have a concept of code blocks (and other formatting such as figure captions) that your Markdown has. We don&amp;rsquo;t want lose these in a straightforward copy and paste into Wordpress&amp;rsquo; WYSIWYG editor directly&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/05/1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;import-the-changed-gdoc-with-edits-back-into-markdown&#34;&gt;Import the changed GDoc with edits back into Markdown&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Export the copy edited &amp;amp; reviewed &lt;a href=&#34;https://workspace.google.com/marketplace/app/docs_to_markdown/700168918607?ref=iain-broome&#34;&gt;GDoc back to Markdown using a Chrome plugin&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Do a diff and import changes back to original Markdown document (so that code blocks &amp;amp; language are not lost)
&lt;img src=&#34;https://rmoff.net/images/2023/05/CleanShot%202023-03-17%20at%2006.39.02@2x.png&#34; alt=&#34;|700&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;publish-the-markdown-to-wordpress&#34;&gt;Publish the Markdown to Wordpress&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Convert the markdown to HTML.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;cd &amp;#34;/Users/rmoff/my_blogs/&amp;#34;
pandoc &amp;#34;Here&amp;#39;s Something Diff-erent - lakeFS adds support for diff of Delta tables.md&amp;#34; \
    -o ~/Downloads/blog.html \
    --wrap=none \
    --no-highlight \
    --extract-media=/Users/rmoff/Downloads/
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--no-highlight&lt;/code&gt; is important to stop the HTML being generated with syntax highlighting - we want to keep the pure code block intact and let WP doing its highlighting instead.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;extract-media&lt;/code&gt; path does not support &lt;code&gt;~&lt;/code&gt; and a relative path is from the working directory in which the command is executed.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In Wordpress, create a new post.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;From the top-right dropdown menu select &lt;strong&gt;Code editor&lt;/strong&gt; (⇧⌥⌘M) to view the raw HTML. Copy and paste the HTML that pandoc generated into Wordpress.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/05/Pasted%20image%2020230317104543.png&#34; alt=&#34;|300&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Upload all the images needed to the WordPress Media Library. Look at the resulting URL prefix (e.g. &lt;code&gt;https://lakefs.io/wp-content/uploads/2023/03/&lt;/code&gt;) and search and replace all the image paths in the source HTML as needed.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;You will need to amend &lt;code&gt;%20&lt;/code&gt; in the URL for &lt;code&gt;-&lt;/code&gt; for files with spaces in&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;At this point the code should render OK, but without syntax highlighting&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/05/Pasted%20image%2020230317105230.png&#34; alt=&#34;|500&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To add in the syntax highlighting:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Search and replace in the raw HTML to replace:  &lt;code&gt;&amp;lt;pre class=&amp;quot;bash&amp;quot;&amp;gt;&amp;lt;code&amp;gt;&lt;/code&gt; with &lt;code&gt;&amp;lt;pre class=&amp;quot;bash&amp;quot;&amp;gt;&amp;lt;code lang=&amp;quot;bash&amp;quot; class=&amp;quot;language-bash&amp;quot;&amp;gt;&lt;/code&gt;. You can do this in your favourite text editor, or use this little bash snippet:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sed -i &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;.bak&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;s/&amp;lt;pre class=&amp;#34;\(.*\)&amp;#34;&amp;gt;&amp;lt;code&amp;gt;/&amp;lt;pre class=&amp;#34;\1&amp;#34;&amp;gt;&amp;lt;code lang=&amp;#34;\1&amp;#34; class=&amp;#34;language-\1&amp;#34;&amp;gt;/&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;&lt;/span&gt;    ~/Downloads/blog.html
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Copy and paste the HTML into the blog&amp;rsquo;s code editor afresh&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Use this one weird trick…&lt;/strong&gt; switch back to the visual editor, put the cursor in the editor box, and click the &lt;strong&gt;Convert to blocks&lt;/strong&gt; option that appears&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/05/CleanShot%202023-03-17%20at%2011.01.58@2x.png&#34; alt=&#34;|400&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you click in one of the code blocks you&amp;rsquo;ll see that it&amp;rsquo;s picked up the language, and when you preview the blog it should highlight its syntax correctly
&lt;img src=&#34;https://rmoff.net/images/2023/05/CleanShot%202023-03-17%20at%2011.04.18@2x.png&#34; alt=&#34;|400&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2023/05/CleanShot%202023-03-17%20at%2011.11.29@2x.png&#34; alt=&#34;|500&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;</description>
    </item>
    <item>
      <title>Building Better Docs - Automating Jekyll Builds and Link Checking for PRs</title>
      <link>https://rmoff.net/2023/04/20/building-better-docs-automating-jekyll-builds-and-link-checking-for-prs/</link>
      <pubDate>2023-04-20</pubDate>
      
      <guid>https://rmoff.net/2023/04/20/building-better-docs-automating-jekyll-builds-and-link-checking-for-prs/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2023/04/t_IMG_9850.jpeg" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;p&gt;One of the most important ways that a project can help its developers is providing them good documentation. Actually, scratch that. &lt;em&gt;Great&lt;/em&gt; documentation.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/04/Pasted%20image%2020230419164830.png&#34; alt=&#34;Kathy Sierra - If you want them to RTFM, make a better FM&#34;&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href=&#34;https://docs.lakefs.io/&#34;&gt;lakeFS documentation&lt;/a&gt; is built as a static site using &lt;a href=&#34;https://jekyllrb.com/&#34;&gt;Jekyll&lt;/a&gt; and the &lt;a href=&#34;https://just-the-docs.github.io/just-the-docs/&#34;&gt;Just the Docs&lt;/a&gt; theme, hosted on &lt;a href=&#34;https://pages.github.com/&#34;&gt;GitHub Pages&lt;/a&gt;. The documentation itself is stored on GitHub, and &lt;em&gt;any&lt;/em&gt; changes to it go through a PR review process.&lt;/p&gt;
&lt;p&gt;There were two points of friction that I wanted to fix to make it easily and quicker to improve the docs:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The local build process for docs was not instantaneous, meaning that &lt;em&gt;contributors&lt;/em&gt; would either just not test their changes (&amp;quot;&lt;em&gt;it&amp;rsquo;s just a small docs change&amp;quot;&lt;/em&gt;, amiright?), or would diligently test them and wasting literally minutes between each build (if you&amp;rsquo;ve any tips to fix this &lt;a href=&#34;https://github.com/treeverse/lakeFS/issues/5404&#34;&gt;let me know&lt;/a&gt;!). On top of this, reviewers of PRs would need to clone the repo and build the docs site to be able to review the changes properly…so very tedious&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/04/zzzzzzz-gif.gif&#34; alt=&#34;BORING&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There were broken links, and no automated checking on incoming Pull Requests (PRs) that a change didn&amp;rsquo;t break things further.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;github-actions-are-magic&#34;&gt;GitHub Actions are MAGIC&lt;/h2&gt;
&lt;p&gt;If you&amp;rsquo;re already using GitHub PRs then using &lt;a href=&#34;https://docs.github.com/en/actions&#34;&gt;Actions&lt;/a&gt; fits in with the workflow beautifully. Actions are defined per-repository and can be triggered by, amongst other things, a new PR. Actions can do lots of things including building and testing your code itself. The two actions I set up do the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Build the docs site from the code in the PR, and deploy it as a static site hosted temporarily on surge.sh&lt;/li&gt;
&lt;li&gt;Run a link checker on the whole site, and if broken links are found fail the job ❌ and log the problems&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You can see the action definition &lt;a href=&#34;https://github.com/treeverse/lakeFS/blob/master/.github/workflows/docs-pr.yaml&#34;&gt;here&lt;/a&gt; - feel free to take it and customise it for your own use! Below I explain a bit more about how each works.&lt;/p&gt;
&lt;h2 id=&#34;triggering-the-action&#34;&gt;Triggering the Action&lt;/h2&gt;
&lt;p&gt;The action is triggered by any PR to &lt;code&gt;master&lt;/code&gt; branch and touching files under &lt;code&gt;/docs&lt;/code&gt; (there&amp;rsquo;s no point rebuilding the docs site if it&amp;rsquo;s only code in the repo that changed and not docs)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;on&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;pull_request&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;paths&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;docs/**&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;branches&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;      &lt;/span&gt;- master&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;build-the-docs-site&#34;&gt;Build the docs site&lt;/h2&gt;
&lt;p&gt;The action runs as a single job covering both purposes (preview deploy, and link checker). I guess it could be split and the build run twice. The job is executed on a container (defined in the &lt;code&gt;runs-on: ubuntu-20.04&lt;/code&gt; step) that lives for the duration of the job.&lt;/p&gt;
&lt;p&gt;The build itself is just as it is in the live docs deployment, running Jekyll&amp;rsquo;s &lt;code&gt;build&lt;/code&gt; command against the &lt;code&gt;docs&lt;/code&gt; folder of the repo and writing the static site to a &lt;code&gt;_site&lt;/code&gt; path on the container.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;name&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;Build latest&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;	&lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;id&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;build-latest&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;	&lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;working-directory&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;docs&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;	&lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;run&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;bundle exec jekyll build --config _config.yml -d _site/ --verbose&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;deploy-a-preview-of-docs-changes&#34;&gt;Deploy a Preview of Docs Changes&lt;/h2&gt;
&lt;p&gt;Before deploying the preview the action some shell script which overlays on each page of the docs site a label to show that it&amp;rsquo;s a preview build, and linking back to the PR from which it was generated:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/04/CleanShot_2023-04-19_at_17.47.05.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;I wish I could claim credit for the code, but it was all the handiwork of chatGPT (pretty cool, right!). This updates the HTML files in place.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;name&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;Overlay PR message on each page&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;	&lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;working-directory&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;docs/_site&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;	&lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;run&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;|&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;	  &lt;/span&gt;PR_URL=${{ github.event.pull_request.html_url }}&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;	  &lt;/span&gt;PR_NUMBER=${{ github.event.pull_request.number }}&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;	  &lt;/span&gt;html_files=$(find . -name &amp;#39;*.html&amp;#39;)&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;	  &lt;/span&gt;for file in $html_files; do&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;		&lt;/span&gt;sed -i -e &amp;#34;s|\(.*\)\(&amp;lt;/body&amp;gt;\)|&amp;lt;div style=\&amp;#34;position: fixed; top: 5px; left: 5px; padding: 3px; background-color:&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#408080;font-style:italic&#34;&gt;#e8ac07; font-weight: bold; z-index: 9999; box-shadow: 0 0 10px rgba(0,0,0,0.5);\&amp;#34;&amp;gt;ℹ️ This is a preview of PR &amp;lt;a href=\&amp;#34;$PR_URL\&amp;#34; style=\&amp;#34;color: black;\&amp;#34;&amp;gt;#$PR_NUMBER&amp;lt;/a&amp;gt;&amp;lt;/div&amp;gt;\n\1\2|&amp;#34; $file&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;	  &lt;/span&gt;done&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The next step then uses a &lt;a href=&#34;https://github.com/afc163/surge-preview&#34;&gt;pre-built Action&lt;/a&gt; to deploy a given folder to &lt;a href=&#34;https://surge.sh/&#34;&gt;surge.sh&lt;/a&gt; (a static site hosting service which provides a free plan that&amp;rsquo;s perfect for this use). You can read more about setting up surge.sh &lt;a href=&#34;https://rmoff.net/2022/04/06/using-github-actions-to-build-automagic-hugo-previews-of-draft-articles/#_setting_up_an_account_on_surge_sh&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The action also updates the PR itself with the link to the preview, so the submitter and reviewer both can easily see the impact of the PR on the docs site.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/04/CleanShot_2023-04-19_at_17.51.29.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;checking-for-broken-links&#34;&gt;Checking for Broken Links&lt;/h2&gt;
&lt;p&gt;This requires a single step in the job to invoke the link checking tool &lt;a href=&#34;https://lychee.cli.rs/&#34;&gt;lychee&lt;/a&gt; using the supplied &lt;a href=&#34;https://github.com/lycheeverse/lychee-action&#34;&gt;GitHub Action&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The root of the built docs site (&lt;code&gt;docs/_site&lt;/code&gt; ) is supplied as the first argument, along with an exclusion file of pages and URLs to not check. I added to this things like URLs in the documentation that referred to sample instances of the lakeFS server (e.g. http://127.0.0.1:8000 is indeed a link, but not a link that we want to check because it&amp;rsquo;s not going to be valid). Some other external sites also needed adding to the ignore file as they appeared to block the automated checking and caused false positives.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;name&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;Check links&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;	&lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;id&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;lychee&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;	&lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;uses&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;lycheeverse/lychee-action@v1.6.1&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;	&lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;with&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;	  &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;args&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;docs/_site --no-progress --exclude-file=docs/.lycheeignore&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;	  &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;fail&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;	  &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;jobSummary&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;	  &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;format&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;markdown&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;	&lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;env&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;	  &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;GITHUB_TOKEN&lt;/span&gt;:&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;${{secrets.GITHUB_TOKEN}}&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If any broken links are found the Action logs these in a very readable and useful way:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/04/CleanShot_2023-04-19_at_17.58.16.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;go-and-try-it-out&#34;&gt;Go and try it out&lt;/h2&gt;
&lt;p&gt;The GitHub Action configuration that I used is &lt;a href=&#34;https://github.com/treeverse/lakeFS/blob/master/.github/workflows/docs-pr.yaml&#34;&gt;here&lt;/a&gt;. Give it a try, and let me know any other cool tricks you have for keeping documentation in tip-top shape :)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Using Delta from pySpark - `java.lang.ClassNotFoundException: delta.DefaultSource`</title>
      <link>https://rmoff.net/2023/04/05/using-delta-from-pyspark-java.lang.classnotfoundexception-delta.defaultsource/</link>
      <pubDate>2023-04-05</pubDate>
      
      <guid>https://rmoff.net/2023/04/05/using-delta-from-pyspark-java.lang.classnotfoundexception-delta.defaultsource/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2023/04/t_IMG_2117.jpeg" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;p&gt;No great insights in this post, just something for folk who Google this error after me and don&amp;rsquo;t want to waste three hours chasing their tails… 😄&lt;/p&gt;
&lt;p&gt;I wanted to use Delta Lake with &lt;a href=&#34;https://spark.apache.org/docs/latest/api/python/&#34;&gt;PySpark&lt;/a&gt; from within a Jupyter Notebook. Easy, right? Not if you&amp;rsquo;re like me and perhaps are new to it and rely on copy and paste of snippets you find across the internet to start with.&lt;/p&gt;
&lt;p&gt;Whatever I tried, I kept hitting this error:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Py4JJavaError: An error occurred while calling o45.save.
: java.lang.ClassNotFoundException: 
Failed to find data source: delta.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;In short, the problem was that I was creating both a &lt;code&gt;SparkSession&lt;/code&gt; &lt;em&gt;and&lt;/em&gt; a &lt;code&gt;SparkContext&lt;/code&gt;&lt;/strong&gt;. I honestly don&amp;rsquo;t understand enough about Spark to tell you why this causes the error, but through a lot of painful trial and error I can tell you that it does. &lt;em&gt;Someone more knowledgable than me can perhaps tell me (&lt;a href=&#34;mailto:robin@rmoff.net&#34;&gt;email&lt;/a&gt; / &lt;a href=&#34;https://twitter.com/rmoff/&#34;&gt;twitter&lt;/a&gt; / &lt;a href=&#34;https://data-folks.masto.host/@rmoff&#34;&gt;mastodon&lt;/a&gt;) why this is and if what I&amp;rsquo;ve ended up with is the right code&lt;/em&gt;. &lt;strong&gt;UPDATE: Damon Cortesi explained it to me :) See &lt;a href=&#34;#why-did-it-do-what-it-did&#34;&gt;below&lt;/a&gt; for details.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;re the salient points of the Jupyter notebook:&lt;/p&gt;
&lt;h2 id=&#34;versions-and-stuff&#34;&gt;Versions and stuff&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;sys&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;Kernel:&amp;#34;&lt;/span&gt;, sys&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;executable)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;Python version:&amp;#34;&lt;/span&gt;, sys&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;version)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;pyspark&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;PySpark version:&amp;#34;&lt;/span&gt;, pyspark&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;__version__)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Kernel: /opt/conda/bin/python
Python version: 3.9.7 | packaged by conda-forge | (default, Oct 10 2021, 15:08:54)
[GCC 9.4.0]
PySpark version: 3.2.0
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;this-worked&#34;&gt;This worked&lt;/h2&gt;
&lt;h3 id=&#34;initialise-spark-with-delta-lake-config&#34;&gt;Initialise Spark with Delta Lake config&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;pyspark.context&lt;/span&gt; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; SparkContext
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;pyspark&lt;/span&gt; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; SparkFiles
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;pyspark.sql.session&lt;/span&gt; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; SparkSession
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;spark &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; (
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    SparkSession&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;builder&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;master(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;local[*]&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;config(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;spark.jars.packages&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;io.delta:delta-core_2.12:2.0.0&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;config(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;spark.sql.extensions&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;io.delta.sql.DeltaSparkSessionExtension&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;config(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;spark.sql.catalog.spark_catalog&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;org.apache.spark.sql.delta.catalog.DeltaCatalog&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;config(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;spark.delta.logStore.class&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;org.apache.spark.sql.delta.storage.S3SingleDriverLogStore&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;getOrCreate()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;test-delta&#34;&gt;Test delta&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;data &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; spark&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;range(&lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;5&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;data&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;write&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;format(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;delta&amp;#34;&lt;/span&gt;)&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;save(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;/tmp/delta-table2&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; spark&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;read&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;format(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;delta&amp;#34;&lt;/span&gt;)&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;load(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;/tmp/delta-table2&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;show()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;+---+
| id|
+---+
|  2|
|  1|
|  4|
|  3|
|  0|
+---+
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;this-didnt-work&#34;&gt;This didn&amp;rsquo;t work&lt;/h2&gt;
&lt;h3 id=&#34;initialise-spark-with-delta-lake-config-1&#34;&gt;Initialise Spark with Delta Lake config&lt;/h3&gt;
&lt;p&gt;(notice line 5 sets the &lt;code&gt;SparkContext&lt;/code&gt;, unlike the example above)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;pyspark.context&lt;/span&gt; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; SparkContext
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;pyspark&lt;/span&gt; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; SparkFiles
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;pyspark.sql.session&lt;/span&gt; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; SparkSession
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sc &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; SparkContext(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;local[*]&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;spark &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; (
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    SparkSession&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;builder&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;master(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;local[*]&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;config(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;spark.jars.packages&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;io.delta:delta-core_2.12:2.0.0&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;config(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;spark.sql.extensions&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;io.delta.sql.DeltaSparkSessionExtension&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;config(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;spark.sql.catalog.spark_catalog&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;org.apache.spark.sql.delta.catalog.DeltaCatalog&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;config(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;spark.delta.logStore.class&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;org.apache.spark.sql.delta.storage.S3SingleDriverLogStore&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;getOrCreate()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)        
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;test-delta-1&#34;&gt;Test delta&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;data &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; spark&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;range(&lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#666&#34;&gt;5&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;data&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;write&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;format(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;delta&amp;#34;&lt;/span&gt;)&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;save(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;/tmp/delta-table&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;---------------------------------------------------------------------------

Py4JJavaError                             Traceback (most recent call last)

/tmp/ipykernel_983/939553335.py in &amp;lt;module&amp;gt;
      1 data = spark.range(0, 5)
----&amp;gt; 2 data.write.format(&amp;quot;delta&amp;quot;).save(&amp;quot;/tmp/delta-table&amp;quot;)


/usr/local/spark/python/pyspark/sql/readwriter.py in save(self, path, format, mode, partitionBy, **options)
    738             self._jwrite.save()
    739         else:
--&amp;gt; 740             self._jwrite.save(path)
    741 
    742     @since(1.4)


/usr/local/spark/python/lib/py4j-0.10.9.2-src.zip/py4j/java_gateway.py in __call__(self, *args)
   1307 
   1308         answer = self.gateway_client.send_command(command)
-&amp;gt; 1309         return_value = get_return_value(
   1310             answer, self.gateway_client, self.target_id, self.name)
   1311 


/usr/local/spark/python/pyspark/sql/utils.py in deco(*a, **kw)
    109     def deco(*a, **kw):
    110         try:
--&amp;gt; 111             return f(*a, **kw)
    112         except py4j.protocol.Py4JJavaError as e:
    113             converted = convert_exception(e.java_exception)


/usr/local/spark/python/lib/py4j-0.10.9.2-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name)
    324             value = OUTPUT_CONVERTER[type](answer[2:], gateway_client)
    325             if answer[1] == REFERENCE_TYPE:
--&amp;gt; 326                 raise Py4JJavaError(
    327                     &amp;quot;An error occurred while calling {0}{1}{2}.\n&amp;quot;.
    328                     format(target_id, &amp;quot;.&amp;quot;, name), value)


Py4JJavaError: An error occurred while calling o45.save.
: java.lang.ClassNotFoundException: 
Failed to find data source: delta. Please find packages at
http://spark.apache.org/third-party-projects.html
       
	at org.apache.spark.sql.errors.QueryExecutionErrors$.failedToFindDataSourceError(QueryExecutionErrors.scala:443)
	at org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:670)
	at org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:720)
	at org.apache.spark.sql.DataFrameWriter.lookupV2Provider(DataFrameWriter.scala:852)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:256)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.lang.ClassNotFoundException: delta.DefaultSource
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:476)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:589)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)
	at org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:656)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:656)
	at scala.util.Failure.orElse(Try.scala:224)
	at org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:656)
	... 16 more
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;notebook-log&#34;&gt;Notebook Log&lt;/h2&gt;
&lt;p&gt;I did notice in the notebook that in the version I ran without setting &lt;code&gt;SparkContext&lt;/code&gt; the Delta library was downloaded:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
:: loading settings :: url = jar:file:/usr/local/spark-3.2.0-bin-hadoop3.2/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /home/jovyan/.ivy2/cache
The jars for the packages stored in: /home/jovyan/.ivy2/jars
io.delta#delta-core_2.12 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-86ca6813-f39f-472c-b6a2-dfe988ab0404;1.0
    confs: [default]
    found io.delta#delta-core_2.12;2.0.0 in central
    found io.delta#delta-storage;2.0.0 in central
    found org.antlr#antlr4-runtime;4.8 in central
    found org.codehaus.jackson#jackson-core-asl;1.9.13 in central
:: resolution report :: resolve 94ms :: artifacts dl 4ms
    :: modules in use:
    io.delta#delta-core_2.12;2.0.0 from central in [default]
    io.delta#delta-storage;2.0.0 from central in [default]
    org.antlr#antlr4-runtime;4.8 from central in [default]
    org.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]
    ---------------------------------------------------------------------
    |                  |            modules            ||   artifacts   |
    |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
    ---------------------------------------------------------------------
    |      default     |   4   |   0   |   0   |   0   ||   4   |   0   |
    ---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-86ca6813-f39f-472c-b6a2-dfe988ab0404
    confs: [default]
    0 artifacts copied, 4 already retrieved (0kB/3ms)
23/04/05 16:29:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark&amp;#39;s default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to &amp;#34;WARN&amp;#34;.
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;whilst the version that did set &lt;code&gt;SparkContext&lt;/code&gt; didn&amp;rsquo;t.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
Using Spark&amp;#39;s default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to &amp;#34;WARN&amp;#34;.
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
23/04/05 16:30:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/04/05 16:30:36 WARN Utils: Service &amp;#39;SparkUI&amp;#39; could not bind on port 4040. Attempting port 4041.
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;why-did-it-do-what-it-did&#34;&gt;Why Did It Do What It Did?&lt;/h2&gt;
&lt;p&gt;Courtesy of &lt;a href=&#34;https://www.linkedin.com/feed/update/urn:li:activity:7049423288099319809?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7049423288099319809%2C7049433950406021120%29&amp;amp;dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287049433950406021120%2Curn%3Ali%3Aactivity%3A7049423288099319809%29&#34;&gt;Damon Cortesi&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In the example that doesn&amp;rsquo;t work, you explicitly create a &lt;code&gt;SparkContext&lt;/code&gt; first with &lt;code&gt;sc = SparkContext(&#39;local[*]&#39;)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;When you use &lt;code&gt;SparkSession.builder&lt;/code&gt;&amp;hellip;&lt;code&gt;getOrCreate()&lt;/code&gt;, it reuses the &lt;code&gt;SparkContext&lt;/code&gt; you already created. You should be able to see this by running &lt;code&gt;spark.sparkContext&lt;/code&gt;. That &lt;code&gt;SparkContext&lt;/code&gt; unfortunately doesn&amp;rsquo;t have the config variables you specified and, based on some reason I don&amp;rsquo;t totally understand, the config variables you specify later are not updated. I&amp;rsquo;m guessing this is because &lt;code&gt;SparkContext&lt;/code&gt; spins up a JVM and some options (like &lt;code&gt;spark.jars.packages&lt;/code&gt;) would need to be specified before you spin up the JVM.&lt;/p&gt;
&lt;p&gt;In the example that works, it doesn&amp;rsquo;t have a &lt;code&gt;SparkContext&lt;/code&gt; to reuse, so it creates a one using the config you provided.&lt;/p&gt;
&lt;p&gt;😅 I love Spark! /s&lt;/p&gt;
&lt;p&gt;This post does a pretty good job of explaining what&amp;rsquo;s going on: &lt;a href=&#34;https://medium.com/@achilleus/spark-session-10d0d66d1d24&#34;&gt;A tale of Spark Session and Spark Context&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;proving-it-to-myself&#34;&gt;Proving It To Myself&lt;/h2&gt;
&lt;p&gt;Damon&amp;rsquo;s explanation and the linked blog were good, so to close the loop I wanted to prove to myself that I could reproduce this explanation locally. Here&amp;rsquo;s &lt;a href=&#34;https://gist.github.com/rmoff/1d86204b559f8ffce83be4b3206b1fa0&#34;&gt;the notebook itself if you want to try it&lt;/a&gt; and reproduced here too:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;sys&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;pyspark&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;Kernel:&amp;#34;&lt;/span&gt;, sys&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;executable)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;Python version:&amp;#34;&lt;/span&gt;, sys&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;version)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;PySpark version:&amp;#34;&lt;/span&gt;, pyspark&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;__version__)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Kernel: /opt/conda/bin/python
Python version: 3.9.7 | packaged by conda-forge | (default, Oct 10 2021, 15:08:54) 
[GCC 9.4.0]
PySpark version: 3.2.0
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;spark-context-and-session---no-config-to-pick-up&#34;&gt;Spark Context and Session - no config to pick up&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;pyspark.context&lt;/span&gt; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; SparkContext
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;pyspark&lt;/span&gt; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; SparkFiles
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;pyspark.sql.session&lt;/span&gt; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; SparkSession
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sc &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; SparkContext(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;local&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;spark &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; SparkSession(sc)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;spark&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;sparkContext&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;getConf()&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;getAll()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[(&#39;spark.master&#39;, &#39;local&#39;),
 (&#39;spark.app.startTime&#39;, &#39;1680720996903&#39;),
 (&#39;spark.executor.id&#39;, &#39;driver&#39;),
 (&#39;spark.app.name&#39;, &#39;pyspark-shell&#39;),
 (&#39;spark.driver.extraJavaOptions&#39;,
  &#39;-Dio.netty.tryReflectionSetAccessible=true&#39;),
 (&#39;spark.driver.port&#39;, &#39;33339&#39;),
 (&#39;spark.driver.host&#39;, &#39;358d949974bd&#39;),
 (&#39;spark.rdd.compress&#39;, &#39;True&#39;),
 (&#39;spark.serializer.objectStreamReset&#39;, &#39;100&#39;),
 (&#39;spark.app.id&#39;, &#39;local-1680720997412&#39;),
 (&#39;spark.submit.pyFiles&#39;, &#39;&#39;),
 (&#39;spark.submit.deployMode&#39;, &#39;client&#39;),
 (&#39;spark.executor.extraJavaOptions&#39;,
  &#39;-Dio.netty.tryReflectionSetAccessible=true&#39;),
 (&#39;spark.ui.showConsoleProgress&#39;, &#39;true&#39;)]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Now restart the kernel&lt;/em&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;no-explicit-spark-context---picks-up-config-as-expected&#34;&gt;No explicit Spark Context - picks up config as expected&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;pyspark.context&lt;/span&gt; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; SparkContext
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;pyspark&lt;/span&gt; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; SparkFiles
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;pyspark.sql.session&lt;/span&gt; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; SparkSession
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;spark &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; (
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    SparkSession&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;builder&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;master(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;local[*]&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;config(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;spark.jars.packages&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;io.delta:delta-core_2.12:2.2.0&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;config(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;spark.sql.extensions&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;io.delta.sql.DeltaSparkSessionExtension&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;config(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;spark.sql.catalog.spark_catalog&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;org.apache.spark.sql.delta.catalog.DeltaCatalog&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;getOrCreate()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)        
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;spark&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;sparkContext&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;getConf()&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;getAll()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[(&#39;spark.repl.local.jars&#39;,
  &#39;file:///home/jovyan/.ivy2/jars/io.delta_delta-core_2.12-2.2.0.jar,file:///home/jovyan/.ivy2/jars/io.delta_delta-storage-2.2.0.jar,file:///home/jovyan/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar&#39;),
 (&#39;spark.app.id&#39;, &#39;local-1680721007128&#39;),
 (&#39;spark.app.startTime&#39;, &#39;1680721006667&#39;),
 (&#39;spark.files&#39;,
  &#39;file:///home/jovyan/.ivy2/jars/io.delta_delta-core_2.12-2.2.0.jar,file:///home/jovyan/.ivy2/jars/io.delta_delta-storage-2.2.0.jar,file:///home/jovyan/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar&#39;),
 (&#39;spark.app.initial.file.urls&#39;,
  &#39;file:///home/jovyan/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar,file:///home/jovyan/.ivy2/jars/io.delta_delta-core_2.12-2.2.0.jar,file:///home/jovyan/.ivy2/jars/io.delta_delta-storage-2.2.0.jar&#39;),
 (&#39;spark.executor.id&#39;, &#39;driver&#39;),
 (&#39;spark.app.name&#39;, &#39;pyspark-shell&#39;),
 (&#39;spark.driver.extraJavaOptions&#39;,
  &#39;-Dio.netty.tryReflectionSetAccessible=true&#39;),
 (&#39;spark.app.initial.jar.urls&#39;,
  &#39;spark://358d949974bd:41145/jars/io.delta_delta-core_2.12-2.2.0.jar,spark://358d949974bd:41145/jars/io.delta_delta-storage-2.2.0.jar,spark://358d949974bd:41145/jars/org.antlr_antlr4-runtime-4.8.jar&#39;),
 (&#39;spark.jars.packages&#39;, &#39;io.delta:delta-core_2.12:2.2.0&#39;),
 (&#39;spark.driver.host&#39;, &#39;358d949974bd&#39;),
 (&#39;spark.sql.warehouse.dir&#39;, &#39;file:/home/jovyan/spark-warehouse&#39;),
 (&#39;spark.sql.extensions&#39;, &#39;io.delta.sql.DeltaSparkSessionExtension&#39;),
 (&#39;spark.rdd.compress&#39;, &#39;True&#39;),
 (&#39;spark.submit.pyFiles&#39;,
  &#39;/home/jovyan/.ivy2/jars/io.delta_delta-core_2.12-2.2.0.jar,/home/jovyan/.ivy2/jars/io.delta_delta-storage-2.2.0.jar,/home/jovyan/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar&#39;),
 (&#39;spark.driver.port&#39;, &#39;41145&#39;),
 (&#39;spark.jars&#39;,
  &#39;file:///home/jovyan/.ivy2/jars/io.delta_delta-core_2.12-2.2.0.jar,file:///home/jovyan/.ivy2/jars/io.delta_delta-storage-2.2.0.jar,file:///home/jovyan/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar&#39;),
 (&#39;spark.serializer.objectStreamReset&#39;, &#39;100&#39;),
 (&#39;spark.master&#39;, &#39;local[*]&#39;),
 (&#39;spark.submit.deployMode&#39;, &#39;client&#39;),
 (&#39;spark.executor.extraJavaOptions&#39;,
  &#39;-Dio.netty.tryReflectionSetAccessible=true&#39;),
 (&#39;spark.ui.showConsoleProgress&#39;, &#39;true&#39;),
 (&#39;spark.sql.catalog.spark_catalog&#39;,
  &#39;org.apache.spark.sql.delta.catalog.DeltaCatalog&#39;)]
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Now restart the kernel&lt;/em&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;existing-spark-context-with-attempted-config-for-the-session-&#34;&gt;Existing Spark Context with attempted config for the Session 💀&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;SparkContext gets implictly reused by the Spark Session and so config is ignored&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;pyspark.context&lt;/span&gt; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; SparkContext
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;pyspark&lt;/span&gt; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; SparkFiles
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;pyspark.sql.session&lt;/span&gt; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; SparkSession
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sc &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; SparkContext(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;local&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;spark &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; (
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    SparkSession&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;builder&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;master(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;local[*]&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;config(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;spark.jars.packages&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;io.delta:delta-core_2.12:2.2.0&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;config(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;spark.sql.extensions&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;io.delta.sql.DeltaSparkSessionExtension&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;config(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;spark.sql.catalog.spark_catalog&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;org.apache.spark.sql.delta.catalog.DeltaCatalog&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;getOrCreate()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)        
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;spark&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;sparkContext&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;getConf()&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;getAll()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[(&#39;spark.master&#39;, &#39;local&#39;),
 (&#39;spark.app.startTime&#39;, &#39;1680721019537&#39;),
 (&#39;spark.executor.id&#39;, &#39;driver&#39;),
 (&#39;spark.app.name&#39;, &#39;pyspark-shell&#39;),
 (&#39;spark.app.id&#39;, &#39;local-1680721020036&#39;),
 (&#39;spark.driver.extraJavaOptions&#39;,
  &#39;-Dio.netty.tryReflectionSetAccessible=true&#39;),
 (&#39;spark.driver.host&#39;, &#39;358d949974bd&#39;),
 (&#39;spark.sql.warehouse.dir&#39;, &#39;file:/home/jovyan/spark-warehouse&#39;),
 (&#39;spark.rdd.compress&#39;, &#39;True&#39;),
 (&#39;spark.serializer.objectStreamReset&#39;, &#39;100&#39;),
 (&#39;spark.submit.pyFiles&#39;, &#39;&#39;),
 (&#39;spark.driver.port&#39;, &#39;46397&#39;),
 (&#39;spark.submit.deployMode&#39;, &#39;client&#39;),
 (&#39;spark.executor.extraJavaOptions&#39;,
  &#39;-Dio.netty.tryReflectionSetAccessible=true&#39;),
 (&#39;spark.ui.showConsoleProgress&#39;, &#39;true&#39;)]
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>Quickly Convert CSV to Parquet with DuckDB</title>
      <link>https://rmoff.net/2023/03/14/quickly-convert-csv-to-parquet-with-duckdb/</link>
      <pubDate>2023-03-14</pubDate>
      
      <guid>https://rmoff.net/2023/03/14/quickly-convert-csv-to-parquet-with-duckdb/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2023/03/t_IMG_1672.jpeg" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;p&gt;Here&amp;rsquo;s a neat little trick you can use with &lt;a href=&#34;https://duckdb.org/&#34;&gt;DuckDB&lt;/a&gt; to convert a CSV file into a Parquet file:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;COPY&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;(&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;SELECT&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;	    &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;FROM&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;read_csv(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;~/data/source.csv&amp;#39;&lt;/span&gt;,AUTO_DETECT&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;TRUE&lt;/span&gt;))&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;TO&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;~/data/target.parquet&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;(FORMAT&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;PARQUET&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;CODEC&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;ZSTD&amp;#39;&lt;/span&gt;);&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You can modify the schema too if you want, selecting specific fields and renaming them too if you want:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;COPY&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;(&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;SELECT&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;col1,&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;col2,&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;col3&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;AS&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;foo&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;	    &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;FROM&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;read_csv(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;~/data/source.csv&amp;#39;&lt;/span&gt;,AUTO_DETECT&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;TRUE&lt;/span&gt;))&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;TO&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;~/data/target.parquet&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;(FORMAT&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;PARQUET&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;CODEC&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;ZSTD&amp;#39;&lt;/span&gt;);&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Read more on the DuckDB &lt;a href=&#34;https://duckdb.org/docs/data/csv/overview&#34;&gt;CSV&lt;/a&gt; and &lt;a href=&#34;https://duckdb.org/docs/data/parquet/overview&#34;&gt;Parquet&lt;/a&gt; docs pages.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Making the move from Alfred to Raycast</title>
      <link>https://rmoff.net/2023/03/03/making-the-move-from-alfred-to-raycast/</link>
      <pubDate>2023-03-03</pubDate>
      
      <guid>https://rmoff.net/2023/03/03/making-the-move-from-alfred-to-raycast/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2023/03/t_DSCF8412.jpeg" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;p&gt;It all started with a tweet.&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Raycast is blowing my mind. It&amp;#39;s the 20% of macOS I didn&amp;#39;t realize was missing. It&amp;#39;s everything I wanted Alfred to be. It&amp;#39;s clearly made by people obsessed with nailing the details. It&amp;#39;s been 2 days and I can&amp;#39;t remember how I used my computer before it.&lt;/p&gt;&amp;mdash; dcj.eth (@dcwj) &lt;a href=&#34;https://twitter.com/dcwj/status/1623373904612888588?ref_src=twsrc%5Etfw&#34;&gt;February 8, 2023&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;p&gt;You see, &lt;a href=&#34;https://rmoff.net/2021/07/29/why-i-use-alfred-app-and-maybe-you-should-too/&#34;&gt;I have a soft spot for Alfred&lt;/a&gt; so this piqued my interest on two fronts. First, &lt;em&gt;how dare anyone say anything about this great tool&lt;/em&gt;. Second…what if I&amp;rsquo;m missing out?&lt;/p&gt;
&lt;p&gt;The subsequent short thread only drew me in further&lt;/p&gt;


&lt;p&gt;🔥 Not gonna lie…this bit stung:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;idc keep using Alfred if you can’t be bothered to try new things&amp;gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;And so here we are. And I&amp;rsquo;m rather glad that we are.&lt;/p&gt;
&lt;h2 id=&#34;stressing-my-alfred-fanboi-credentials&#34;&gt;Stressing my Alfred fanboi credentials&lt;/h2&gt;
&lt;p&gt;Before we get into things, let me say this. I&amp;rsquo;ve used Alfred since almost as long as I&amp;rsquo;ve been using Macs, becoming a powerpack subscriber back in 2012 with v1. Alfred would be one of the first applications I&amp;rsquo;d install on any new Mac. Using a Mac without Alfred installed felt like trying to tie my shoelaces with one hand behind my back, and wearing a thick glove on the other.&lt;/p&gt;
&lt;p&gt;But…time moves on.&lt;/p&gt;
&lt;h2 id=&#34;what-is-raycast&#34;&gt;What is Raycast?&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.raycast.com/&#34;&gt;Raycast&lt;/a&gt; is a launcher, kinda like Spotlight that comes built into macOS. To say that is to understate things somewhat significantly. It&amp;rsquo;s an all-singing and all-dancing productivity tool for your Mac that you really should try out.&lt;/p&gt;
&lt;h2 id=&#34;introducing-raycast-the-newish-kid-on-the-block&#34;&gt;Introducing Raycast, the new(ish) kid on the block.&lt;/h2&gt;
&lt;p&gt;Raycast is like Alfred, but better. Sorry Alfred. Whatever Alfred can do, Raycast can do, and usually better, in a simpler and more intuitive user interface.&lt;/p&gt;
&lt;p&gt;Almost everything in Raycast is driven through its menu system which has been brilliantly thought out, along with a fantastic ecosystem of extensions accessed through the built-in &amp;ldquo;store&amp;rdquo;.&lt;/p&gt;
&lt;h2 id=&#34;a-superb-user-experience&#34;&gt;A Superb User Experience&lt;/h2&gt;
&lt;p&gt;The user interface of Raycast has been superbly thought out to make it joyfully simple and straightforward, but also richly featured for more advanced uses when you need it - without the need to context switch.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s say we&amp;rsquo;ve launched the GitHub extension to interact with our PRs etc.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/03/Pasted%20image%2020230303224304.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;We hit enter to select &lt;code&gt;My Pull Requests&lt;/code&gt;. The next screen has the same UI as all others in Raycast:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/03/Pasted_Image_03_03_2023__22_44.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;the-store-&#34;&gt;The Store 🛒&lt;/h2&gt;
&lt;p&gt;Alfred was Alfred. You can have the car in any colour so long as it&amp;rsquo;s black. Well, there are &lt;a href=&#34;https://www.alfredapp.com/workflows/&#34;&gt;workflows&lt;/a&gt; but I need to go to a web page to browse and read and … gosh it&amp;rsquo;s just not as simple as pressing &lt;code&gt;Cmd-Space&lt;/code&gt;, typing &lt;code&gt;Store&lt;/code&gt; (or the first couple of characters), and then searching for whatever you want.&lt;/p&gt;
&lt;p&gt;Interested in &lt;del&gt;losing all your money on a ponzi scheme&lt;/del&gt; crypto? Let&amp;rsquo;s see what Raycast has for that:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Cmd-Space to launch&lt;/li&gt;
&lt;li&gt;Start to type &lt;code&gt;store&lt;/code&gt; and hit enter&lt;/li&gt;
&lt;li&gt;Start to type &lt;code&gt;Crypto&lt;/code&gt; and hit enter&lt;/li&gt;
&lt;li&gt;Pick an extension and hit enter&lt;/li&gt;
&lt;li&gt;Press enter to launch the extension&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/03/Kapture%202023-03-03%20at%2022.37.23.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;This is all without your hands leaving the keyboard, which I think is probably where the power of Raycast comes in. It soon becomes part of your muscle-memory.&lt;/p&gt;
&lt;p&gt;Raycast becomes the platform for a potentially vast ecosystem of plugins. It&amp;rsquo;s the kitchen utensils for making whatever nice meal you&amp;rsquo;d like, instead of the pre-packaged ready meal you bought from the supermarket. That ready meal might be really nice, but you get what you get and nothing more. The half-assed metaphor breaks down because of course you &lt;em&gt;can&lt;/em&gt; extend Alfred. It just never felt like it was designed from the outset to be used that way.&lt;/p&gt;
&lt;h2 id=&#34;searching-for-files&#34;&gt;Searching for files&lt;/h2&gt;
&lt;p&gt;Searching for files is fairly basic table-stakes for a laucher app like this. But Raycast does it with style and aplomb. Each file can be directly dragged to a target application (useful when working with images, uploading PDFs, etc), as well as handled with a multitude of actions from the Cmd-K menu. These include copying the path of the file to the clipboard, opening it in an application of your choosing, or even deleting it. All of these options are available at your finger tips without needing to go anywhere near your touchpad or mouse.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/03/Pasted%20image%2020230303231855.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;clipboard-history&#34;&gt;Clipboard History&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;This one weird trick&lt;/em&gt; … will make you &lt;em&gt;so&lt;/em&gt; much more productive. Using a clipboard manager lets you access things you&amp;rsquo;ve copied to the clipboard previously, not just the most recent one. Alfred does that, plenty of other app do that… but Raycast potentially does it the best of all of them.&lt;/p&gt;
&lt;p&gt;You get your text, obviously, but also your images. You get the metadata for each item, and you can filter by type.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/03/Pasted%20image%2020230303225558.png&#34; alt=&#34;&#34;&gt;
You can drag and drop from the clipboard history onto a file prompt or into an application.&lt;/p&gt;
&lt;p&gt;&lt;video autoplay=&#34;true&#34; loop=&#34;true&#34; width=800 src=&#34;https://rmoff.net/images/2023/03/Kapture 2023-03-03 at 22.57.46.mp4&#34;&gt;&lt;/video&gt;&lt;/p&gt;
&lt;h2 id=&#34;emojis&#34;&gt;Emojis&lt;/h2&gt;
&lt;p&gt;Who doesn&amp;rsquo;t like a good emoji? The emoji plugin in Raycast is just much smarter and less clunky than the &lt;a href=&#34;https://github.com/mr-pennyworth/alfred-fastest-emoji#fastest-emoji-search-famos&#34;&gt;Alfred workflow which I was using before&lt;/a&gt;.
&lt;img src=&#34;https://rmoff.net/images/2023/03/CleanShot%202023-02-13%20at%2011.29.45.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;alfred-was-first-now-raycasts-coming-for-you-too&#34;&gt;Alfred was first, now Raycast&amp;rsquo;s coming for you too…&lt;/h2&gt;
&lt;p&gt;Because Raycast has such a good framework for extensions and each command within an extension can have a hotkey bound to it there are other apps that Raycast can actually replace. One example is &lt;a href=&#34;https://manytricks.com/moom/&#34;&gt;Moom&lt;/a&gt;. Previously a favourite of mine for getting control of a cluttered workspace by resizing windows based on a hotkey press, this is now just done by the Window Management extension which is built in to Raycast.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/03/Pasted%20image%2020230303230601.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;quicklinks&#34;&gt;Quicklinks&lt;/h2&gt;
&lt;p&gt;Similar to the search engines you can define in Chrome, Quicklinks in Chrome lets you take a URL with a pattern for a search term and make it into a command accessible from the launcher at any time. Here&amp;rsquo;s an example for being able to search LinkedIn without first opening your web browser.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create Quicklink (which itself is accessed through the Raycast menu)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/03/CleanShot%202023-02-14%20at%2009.28.51.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Define the Quicklink based on the URL syntax of a LinkedIn search page URL &lt;code&gt;https://www.linkedin.com/search/results/all/?keywords={Query}&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/03/CleanShot%202023-02-14%20at%2009.29.38.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Now you can enter the name of the quicklink (or partial) and search to your heart&amp;rsquo;s content:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/03/CleanShot%202023-02-14%20at%2009.30.10.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;switch-windows-with-filtering&#34;&gt;Switch windows with filtering&lt;/h2&gt;
&lt;p&gt;Like command-tab but without all the annoyance of a mouse 🤯&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/03/Raycast%202023-02-14%20at%2011.29.23.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;alfred-snippets---raycast-snippets--easy-peasy&#34;&gt;Alfred snippets -&amp;gt; Raycast snippets = easy peasy&lt;/h2&gt;
&lt;p&gt;Along with clipboard history, &lt;em&gt;snippets&lt;/em&gt; are a fantastic productivity tool. Whether auto-expanding your email address when you type &lt;code&gt;ep&lt;/code&gt;, entering the current timestamp, or even pasting your resume, it just speeds things up. The good news is that Raycast supports snippets, and &lt;a href=&#34;https://xavd.id/&#34;&gt;David Brownman&lt;/a&gt; wrote a nice tutorial on &lt;a href=&#34;https://xavd.id/blog/post/migrating-alfred-snippets-to-raycast/&#34;&gt;how to migrate your Alfred snippets to Raycast&lt;/a&gt;. Just make sure that each snippet has a name otherwise the import will fail. It&amp;rsquo;s fine to give it a dummy name - but it can&amp;rsquo;t be blank.&lt;/p&gt;
&lt;h2 id=&#34;github-extension&#34;&gt;GitHub extension&lt;/h2&gt;
&lt;p&gt;Think of all the tasks that you do on your computer each day. Many of those will have a Raycast extension that you can use to make it quicker and easier to get things done. Here&amp;rsquo;s an example with the GitHub extension to merge &lt;a href=&#34;https://github.com/rmoff/rmoff-blog/pull/34&#34;&gt;the PR&lt;/a&gt; to publish this blog :)&lt;/p&gt;
&lt;p&gt;&lt;video autoplay=&#34;true&#34; loop=&#34;true&#34; width=800 src=&#34;https://rmoff.net/images/2023/03/gh.mp4&#34;&gt;&lt;/video&gt;&lt;/p&gt;
&lt;h2 id=&#34;sorry-but-the-time-has-come&#34;&gt;Sorry, but the time has come.&lt;/h2&gt;
&lt;p&gt;It &lt;em&gt;is&lt;/em&gt; you, not me. Raycast does everything Alfred did, but better.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2023/03/Kapture%202023-02-27%20at%2022.04.04%201.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>