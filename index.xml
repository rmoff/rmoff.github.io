<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>rmoff&#39;s random ramblings</title>
    <link>https://rmoff.net/</link>
    <description>Recent content on rmoff&#39;s random ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>2022-09-16</lastBuildDate>
    
        <atom:link href="https://rmoff.net/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Data Engineering in 2022: Exploring LakeFS with Jupyter and PySpark</title>
      <link>https://rmoff.net/2022/09/16/data-engineering-in-2022-exploring-lakefs-with-jupyter-and-pyspark/</link>
      <pubDate>2022-09-16</pubDate>
      
      <guid>https://rmoff.net/2022/09/16/data-engineering-in-2022-exploring-lakefs-with-jupyter-and-pyspark/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2022/09/t_DSCF8265.jpeg" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;p&gt;With my &lt;a href=&#34;https://rmoff.net/2022/09/14/stretching-my-legs-in-the-data-engineering-ecosystem-in-2022/&#34;&gt;foray&lt;/a&gt; into the current world of data engineering I wanted to get my hands dirty with some of the tools and technologies I&amp;rsquo;d been reading about. The vehicle for this was trying to understand more about LakeFS, but along the way dabbling with PySpark and S3 (MinIO) too.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;d forgotten how amazingly useful notebooks are. It&amp;rsquo;s &lt;a href=&#34;https://www.rittmanmead.com/blog/2016/12/etl-offload-with-spark-and-amazon-emr-part-2-code-development-with-notebooks-and-docker/&#34;&gt;six years since I wrote about them last&lt;/a&gt; (and the last time I tried my hand at PySpark). This blog is basically the notebook, with some more annotations.&lt;/p&gt;
&lt;p&gt;If you want to run it yourself you can &lt;a href=&#34;https://rmoff.net/images/2022/09/lakefs.ipynb&#34;&gt;download the notebook&lt;/a&gt; and run it on the &lt;a href=&#34;https://github.com/treeverse/lakeFS/tree/master/deployments/compose&#34;&gt;Everything Bagel&lt;/a&gt; Docker Compose environment from LakeFS.&lt;/p&gt;
&lt;h2 id=&#34;tldr&#34;&gt;tl;dr&lt;/h2&gt;
&lt;p&gt;With LakeFS you can branch and merge your data just as you would with your code. You can work on a copy of your main dataset to test new code without worrying about overwriting it. You can test destructive changes without committing them until you&amp;rsquo;re sure they work.&lt;/p&gt;
&lt;p&gt;See more thoughts on it &lt;a href=&#34;https://rmoff.net/2022/09/14/data-engineering-in-2022-storage-and-access/#_git_for_data_with_lakefs&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;I wanted to understand and see for myself how LakeFS brings the concept of git to data, and what it looks like in practice.&lt;/p&gt;
&lt;p&gt;I start off with a &lt;code&gt;main&lt;/code&gt; branch and write some data to it (as a Parquet file).&lt;/p&gt;
&lt;p&gt;From there I create two branches, in which I&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Add some more rows of data&lt;/li&gt;
&lt;li&gt;Delete some columns from the existing data&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Along the way I compare how LakeFS reports the files (acting as a S3 proxy), and what&amp;rsquo;s happening in the actual S3 storage underneath. The latter&amp;rsquo;s interesting because LakeFS does &amp;ldquo;copy on write&amp;rdquo;, whereby data&amp;rsquo;s not duplicated until it needs to be written (i.e. when, and only when, it changes). This CoW approach is great for storage efficiency, and a solid reason why you&amp;rsquo;d be looking at something like LakeFS instead of simply actually duplicating data on S3 when you want to test something.&lt;/p&gt;
&lt;h2 id=&#34;set-up-connections&#34;&gt;Set up connections&lt;/h2&gt;
&lt;h3 id=&#34;s3&#34;&gt;S3&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Connection is configured &lt;a href=&#34;https://github.com/treeverse/lakeFS/blob/master/deployments/compose/etc/hive-site.xml#L51-L62&#34;&gt;here&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;boto3&lt;/span&gt;

s3 &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; boto3&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;resource(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;s3&amp;#39;&lt;/span&gt;,
                  endpoint_url&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;http://minio:9000/&amp;#39;&lt;/span&gt;,
                  aws_access_key_id&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;minioadmin&amp;#39;&lt;/span&gt;,
                  aws_secret_access_key&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;minioadmin&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;lakefs&#34;&gt;LakeFS&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;lakefs_client&lt;/span&gt;
&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;lakefs_client&lt;/span&gt; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; models
&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;lakefs_client.client&lt;/span&gt; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; LakeFSClient
&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;lakefs_client.api&lt;/span&gt; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; branches_api
&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;lakefs_client.api&lt;/span&gt; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; commits_api

&lt;span style=&#34;color:#408080;font-style:italic&#34;&gt;# lakeFS credentials and endpoint&lt;/span&gt;
configuration &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; lakefs_client&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Configuration()
configuration&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;username &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;AKIAIOSFODNN7EXAMPLE&amp;#39;&lt;/span&gt;
configuration&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;password &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY&amp;#39;&lt;/span&gt;
configuration&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;host &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;http://lakefs:8000&amp;#39;&lt;/span&gt;

client &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; LakeFSClient(configuration)
api_client &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; lakefs_client&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;ApiClient(configuration)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;spark&#34;&gt;Spark&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;pyspark.context&lt;/span&gt; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; SparkContext
&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;pyspark&lt;/span&gt; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; SparkFiles
&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;pyspark.sql.session&lt;/span&gt; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; SparkSession
sc &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; SparkContext(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;local&amp;#39;&lt;/span&gt;)
spark &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; SparkSession(sc)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;list-the-current-branches-in-the-repository&#34;&gt;List the current branches in the repository&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://pydocs.lakefs.io/docs/BranchesApi.html#list_branches&#34;&gt;https://pydocs.lakefs.io/docs/BranchesApi.html#list_branches&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;repo&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;example&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;for&lt;/span&gt; b &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;in&lt;/span&gt; client&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;branches&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;list_branches(repo)&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;results:
    display(b&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;id)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&#39;main&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;load-and-write-some-data-to-the-main-branch&#34;&gt;Load and write some data to the main branch&lt;/h2&gt;
&lt;p&gt;To start with we take a random parquet data file that I found on github, load it, and write it to S3 on the main branch of the repository.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;url&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;https://github.com/Teradata/kylo/blob/master/samples/sample-data/parquet/userdata1.parquet?raw=true&amp;#39;&lt;/span&gt;
sc&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;addFile(url)
df &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; spark&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;read&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;parquet(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;file://&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt; SparkFiles&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;get(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;userdata1.parquet&amp;#34;&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Inspect the data:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;display(df&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;count())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;1000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What does the data look like?&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;df&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;show(n&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;,vertical&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;True&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;-RECORD 0--------------------------------
 registration_dttm | 2016-02-03 07:55:29 
 id                | 1                   
 first_name        | Amanda              
 last_name         | Jordan              
 email             | ajordan0@com.com    
 gender            | Female              
 ip_address        | 1.197.201.2         
 cc                | 6759521864920116    
 country           | Indonesia           
 birthdate         | 3/8/1971            
 salary            | 49756.53            
 title             | Internal Auditor    
 comments          | 1E+02               
only showing top 1 row
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;write-data-to-s3&#34;&gt;Write data to S3&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;branch&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;main&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;df&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;write&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;mode(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;overwrite&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;parquet(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;s3a://&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;repo&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;branch&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;/demo/users&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;exploring-lakefs&#34;&gt;Exploring LakeFS&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s see how LakeFS handles and see the file that we&amp;rsquo;ve just written, and then how to commit it to the branch.&lt;/p&gt;
&lt;h3 id=&#34;the-data-as-seen-from-lakefs&#34;&gt;The data as seen from LakeFS&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://pydocs.lakefs.io/docs/ObjectsApi.html#list_objects&#34;&gt;https://pydocs.lakefs.io/docs/ObjectsApi.html#list_objects&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Note the &lt;code&gt;physical_address&lt;/code&gt; and its match in the S3 output in the next step&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;client&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;objects&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;list_objects(repo,branch)&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;results
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[{&#39;checksum&#39;: &#39;d41d8cd98f00b204e9800998ecf8427e&#39;,
  &#39;content_type&#39;: &#39;application/octet-stream&#39;,
  &#39;mtime&#39;: 1663316305,
  &#39;path&#39;: &#39;demo/users/_SUCCESS&#39;,
  &#39;path_type&#39;: &#39;object&#39;,
  &#39;physical_address&#39;: &#39;s3://example/5e91c0a09d3a4415abd33bc460662e18&#39;,
  &#39;size_bytes&#39;: 0},
 {&#39;checksum&#39;: &#39;addfab49d691a5d4a18ae0b127a792a0&#39;,
  &#39;content_type&#39;: &#39;application/octet-stream&#39;,
  &#39;mtime&#39;: 1663316304,
  &#39;path&#39;: &#39;demo/users/part-00000-142e4126-aaec-477c-bbcf-c1dd68011369-c000.snappy.parquet&#39;,
  &#39;path_type&#39;: &#39;object&#39;,
  &#39;physical_address&#39;: &#39;s3://example/2895bba44b5b4f5199bf58d80144a9de&#39;,
  &#39;size_bytes&#39;: 78869}]
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;the-data-as-seen-from-s3&#34;&gt;The data as seen from S3&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;for&lt;/span&gt; o &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;in&lt;/span&gt; s3&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Bucket(repo)&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;objects&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;all():
    &lt;span style=&#34;color:#008000&#34;&gt;print&lt;/span&gt;(o&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;last_modified, o&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;key, o&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;size)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;2022-09-16 08:18:24.769000+00:00 1984e4e69777452fb03800bd4c6b1b05 0
2022-09-16 08:18:23.607000+00:00 2895bba44b5b4f5199bf58d80144a9de 78869
2022-09-16 08:18:22.900000+00:00 49ad588d52b942c9b682f271f228cb9c 0
2022-09-16 08:18:25.034000+00:00 5e91c0a09d3a4415abd33bc460662e18 0
2022-09-16 08:18:24.277000+00:00 c4cae27b7c0a46beb14f79347d77c29d 0
2022-09-16 08:17:18.615000+00:00 dummy 70
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;list-diff-of-branch-in-lakefs-this-is-kinda-like-a-git-status&#34;&gt;List diff of branch in LakeFS (this is kinda like a &lt;code&gt;git status&lt;/code&gt;)&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://pydocs.lakefs.io/docs/BranchesApi.html#diff_branch&#34;&gt;https://pydocs.lakefs.io/docs/BranchesApi.html#diff_branch&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note that the files show &lt;strong&gt;&lt;code&gt;&#39;type&#39;: &#39;added&#39;&lt;/code&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;api_instance &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; branches_api&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;BranchesApi(api_client)

api_response &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; api_instance&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;diff_branch(repo, branch)
&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;if&lt;/span&gt; api_response&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;pagination&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;results&lt;span style=&#34;color:#666&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;:
    display(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;Nothing to commit&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;else&lt;/span&gt;:
    &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;for&lt;/span&gt; r &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;in&lt;/span&gt; api_response&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;results:
        display(r)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;{&#39;path&#39;: &#39;demo/users/_SUCCESS&#39;,
 &#39;path_type&#39;: &#39;object&#39;,
 &#39;size_bytes&#39;: 78869,
 &#39;type&#39;: &#39;added&#39;}



{&#39;path&#39;: &#39;demo/users/part-00000-142e4126-aaec-477c-bbcf-c1dd68011369-c000.snappy.parquet&#39;,
 &#39;path_type&#39;: &#39;object&#39;,
 &#39;size_bytes&#39;: 78869,
 &#39;type&#39;: &#39;added&#39;}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;commit-the-new-file-in-main&#34;&gt;Commit the new file in &lt;code&gt;main&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://pydocs.lakefs.io/docs/CommitsApi.html#commit&#34;&gt;https://pydocs.lakefs.io/docs/CommitsApi.html#commit&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;lakefs_client.api&lt;/span&gt; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; commits_api
&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;lakefs_client.model.commit&lt;/span&gt; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; Commit
&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;lakefs_client.model.commit_creation&lt;/span&gt; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; CommitCreation

api_instance &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; commits_api&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;CommitsApi(api_client)
commit_creation &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; CommitCreation(
    message&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;Everything Bagel - commit users data (original)&amp;#34;&lt;/span&gt;,
    metadata&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;{
        &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;foo&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;bar&amp;#34;&lt;/span&gt;,
    }
) 

api_instance&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;commit(repo, branch, commit_creation)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;{&#39;committer&#39;: &#39;docker&#39;,
 &#39;creation_date&#39;: 1663316414,
 &#39;id&#39;: &#39;de2ae0f24961f65bf7b525d983b3dbc869ce49a0dea43529920743154ce0ddd0&#39;,
 &#39;message&#39;: &#39;Everything Bagel - commit users data (original)&#39;,
 &#39;meta_range_id&#39;: &#39;&#39;,
 &#39;metadata&#39;: {&#39;foo&#39;: &#39;bar&#39;},
 &#39;parents&#39;: [&#39;a3bfc3317b697cb671665ea44b05b4009a06404c95c56a705fe638a824f1c04e&#39;]}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;list-branch-status-again---nothing-returned-means-that-there-is-nothing-uncommitted&#34;&gt;List branch status again - nothing returned means that there is nothing uncommitted&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;api_instance &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; branches_api&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;BranchesApi(api_client)

api_response &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; api_instance&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;diff_branch(repo, branch)
&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;if&lt;/span&gt; api_response&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;pagination&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;results&lt;span style=&#34;color:#666&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;:
    display(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;Nothing to commit&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;else&lt;/span&gt;:
    &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;for&lt;/span&gt; r &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;in&lt;/span&gt; api_response&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;results:
        display(r)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&#39;Nothing to commit&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Similar to a &lt;code&gt;git status&lt;/code&gt; showing &lt;code&gt;Your branch is up to date with &#39;main&#39;&lt;/code&gt; / &lt;code&gt;nothing to commit, working tree clean&lt;/code&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;branching-to-test-new-code&#34;&gt;Branching to test new code&lt;/h2&gt;
&lt;p&gt;Now that we&amp;rsquo;ve got our main branch set up, let&amp;rsquo;s explore what we can do with. Imagine we have a couple of things that we&amp;rsquo;re working on and want to try out without touching the main dataset (at least until we know that they work).&lt;/p&gt;
&lt;p&gt;First we&amp;rsquo;ll test adding new data, and create a branch on which to try it.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://pydocs.lakefs.io/docs/BranchesApi.html#create_branch&#34;&gt;https://pydocs.lakefs.io/docs/BranchesApi.html#create_branch&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Note that at this point there&amp;rsquo;s no additional object created on the object store&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;branch&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;add_more_user_data&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;lakefs_client.model.branch_creation&lt;/span&gt; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; BranchCreation

api_instance &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; branches_api&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;BranchesApi(api_client)
branch_creation &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; BranchCreation(
    name&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;branch,
    source&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;main&amp;#34;&lt;/span&gt;,
) 

api_response &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; api_instance&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;create_branch(repo, branch_creation)
display(api_response)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&#39;de2ae0f24961f65bf7b525d983b3dbc869ce49a0dea43529920743154ce0ddd0&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;list-the-current-branches-in-the-example-repository&#34;&gt;List the current branches in the &lt;code&gt;example&lt;/code&gt; repository&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://pydocs.lakefs.io/docs/BranchesApi.html#list_branches&#34;&gt;https://pydocs.lakefs.io/docs/BranchesApi.html#list_branches&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;for&lt;/span&gt; b &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;in&lt;/span&gt; client&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;branches&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;list_branches(repo)&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;results:
    display(b&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;id)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&#39;add_more_user_data&#39;
&#39;main&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;read-the-existing-data&#34;&gt;Read the existing data&lt;/h3&gt;
&lt;p&gt;Note that we&amp;rsquo;re reading from the new branch, and see the data that was committed to &lt;code&gt;main&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;xform_df &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; spark&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;read&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;parquet(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;s3a://&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;repo&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;branch&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;/demo/users&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;How many rows of data?&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;display(xform_df&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;count())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;1000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What does the data look like?&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;xform_df&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;show(n&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;,vertical&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;True&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;-RECORD 0--------------------------------
 registration_dttm | 2016-02-03 07:55:29 
 id                | 1                   
 first_name        | Amanda              
 last_name         | Jordan              
 email             | ajordan0@com.com    
 gender            | Female              
 ip_address        | 1.197.201.2         
 cc                | 6759521864920116    
 country           | Indonesia           
 birthdate         | 3/8/1971            
 salary            | 49756.53            
 title             | Internal Auditor    
 comments          | 1E+02               
only showing top 1 row
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;add-some-new-data&#34;&gt;Add some new data&lt;/h3&gt;
&lt;p&gt;We&amp;rsquo;ll download another file from the same source as originally. It&amp;rsquo;s &lt;code&gt;userdata2&lt;/code&gt; this time, instead of the &lt;code&gt;userdata1&lt;/code&gt; used above.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;url&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;https://github.com/Teradata/kylo/blob/master/samples/sample-data/parquet/userdata2.parquet?raw=true&amp;#39;&lt;/span&gt;
sc&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;addFile(url)
df &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; spark&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;read&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;parquet(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;file://&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt; SparkFiles&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;get(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;userdata2.parquet&amp;#34;&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Look at the new data:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;df&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;show(n&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;,vertical&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;True&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;-RECORD 0---------------------------------
 registration_dttm | 2016-02-03 13:36:39  
 id                | 1                    
 first_name        | Donald               
 last_name         | Lewis                
 email             | dlewis0@clickbank... 
 gender            | Male                 
 ip_address        | 102.22.124.20        
 cc                |                      
 country           | Indonesia            
 birthdate         | 7/9/1972             
 salary            | 140249.37            
 title             | Senior Financial ... 
 comments          |                      
only showing top 1 row
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;write-the-data-to-the-branch-and-commit-it&#34;&gt;Write the data (to the branch) and commit it&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;df&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;write&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;mode(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;append&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;parquet(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;s3a://&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;repo&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;branch&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;/demo/users&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;LakeFS sees that there is an uncommited change&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;api_instance &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; branches_api&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;BranchesApi(api_client)

api_response &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; api_instance&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;diff_branch(repo, branch)
&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;if&lt;/span&gt; api_response&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;pagination&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;results&lt;span style=&#34;color:#666&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;:
    display(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;Nothing to commit&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;else&lt;/span&gt;:
    &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;for&lt;/span&gt; r &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;in&lt;/span&gt; api_response&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;results:
        display(r)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;{&#39;path&#39;: &#39;demo/users/part-00000-b90910aa-58a0-42af-84ec-8ec557c56850-c000.snappy.parquet&#39;,
 &#39;path_type&#39;: &#39;object&#39;,
 &#39;size_bytes&#39;: 78729,
 &#39;type&#39;: &#39;added&#39;}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Commit it&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;lakefs_client.api&lt;/span&gt; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; commits_api
&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;lakefs_client.model.commit&lt;/span&gt; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; Commit
&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;lakefs_client.model.commit_creation&lt;/span&gt; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; CommitCreation

api_instance &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; commits_api&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;CommitsApi(api_client)
commit_creation &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; CommitCreation(
    message&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;Everything Bagel - add more user data&amp;#34;&lt;/span&gt;,
    metadata&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;{
        &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;foo&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;bar&amp;#34;&lt;/span&gt;,
    }
) 

api_instance&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;commit(repo, branch, commit_creation)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;{&#39;committer&#39;: &#39;docker&#39;,
 &#39;creation_date&#39;: 1663316722,
 &#39;id&#39;: &#39;9d7f809d1733ee0f48d89fd6d5d1d915aaf79200e10f26e997db1437b3414794&#39;,
 &#39;message&#39;: &#39;Everything Bagel - add more user data&#39;,
 &#39;meta_range_id&#39;: &#39;&#39;,
 &#39;metadata&#39;: {&#39;foo&#39;: &#39;bar&#39;},
 &#39;parents&#39;: [&#39;de2ae0f24961f65bf7b525d983b3dbc869ce49a0dea43529920743154ce0ddd0&#39;]}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;status-check-hows-the-data-look-from-each-branch&#34;&gt;Status check: how&amp;rsquo;s the data look from each branch?&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s re-read the &lt;code&gt;main&lt;/code&gt; and &lt;code&gt;add_more_user_data&lt;/code&gt; branches and count the rows in each&lt;/p&gt;
&lt;p&gt;Original branch (&lt;code&gt;main&lt;/code&gt;):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;add_more_user_data &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; spark&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;read&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;parquet(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;s3a://&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;repo&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;/main/demo/users&amp;#39;&lt;/span&gt;)
display(add_more_user_data&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;count())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;1000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;New branch (&lt;code&gt;add_more_user_data&lt;/code&gt;):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;add_more_user_data &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; spark&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;read&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;parquet(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;s3a://&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;repo&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;/add_more_user_data/demo/users&amp;#39;&lt;/span&gt;)
display(add_more_user_data&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;count())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;2000
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;look-at-the-view-in-lakefs&#34;&gt;Look at the view in LakeFS&lt;/h3&gt;
&lt;h4 id=&#34;main&#34;&gt;&lt;code&gt;main&lt;/code&gt;&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;client&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;objects&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;list_objects(repo,&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;main&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;results
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[{&#39;checksum&#39;: &#39;d41d8cd98f00b204e9800998ecf8427e&#39;,
  &#39;content_type&#39;: &#39;application/octet-stream&#39;,
  &#39;mtime&#39;: 1663316305,
  &#39;path&#39;: &#39;demo/users/_SUCCESS&#39;,
  &#39;path_type&#39;: &#39;object&#39;,
  &#39;physical_address&#39;: &#39;s3://example/5e91c0a09d3a4415abd33bc460662e18&#39;,
  &#39;size_bytes&#39;: 0},
 {&#39;checksum&#39;: &#39;addfab49d691a5d4a18ae0b127a792a0&#39;,
  &#39;content_type&#39;: &#39;application/octet-stream&#39;,
  &#39;mtime&#39;: 1663316304,
  &#39;path&#39;: &#39;demo/users/part-00000-142e4126-aaec-477c-bbcf-c1dd68011369-c000.snappy.parquet&#39;,
  &#39;path_type&#39;: &#39;object&#39;,
  &#39;physical_address&#39;: &#39;s3://example/2895bba44b5b4f5199bf58d80144a9de&#39;,
  &#39;size_bytes&#39;: 78869}]
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;add_more_user_data&#34;&gt;&lt;code&gt;add_more_user_data&lt;/code&gt;&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;client&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;objects&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;list_objects(repo,&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;add_more_user_data&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;results
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[{&#39;checksum&#39;: &#39;d41d8cd98f00b204e9800998ecf8427e&#39;,
  &#39;content_type&#39;: &#39;application/octet-stream&#39;,
  &#39;mtime&#39;: 1663316556,
  &#39;path&#39;: &#39;demo/users/_SUCCESS&#39;,
  &#39;path_type&#39;: &#39;object&#39;,
  &#39;physical_address&#39;: &#39;s3://example/8acafaeee021459ba6cc29cfb35bb06b&#39;,
  &#39;size_bytes&#39;: 0},
 {&#39;checksum&#39;: &#39;addfab49d691a5d4a18ae0b127a792a0&#39;,
  &#39;content_type&#39;: &#39;application/octet-stream&#39;,
  &#39;mtime&#39;: 1663316304,
  &#39;path&#39;: &#39;demo/users/part-00000-142e4126-aaec-477c-bbcf-c1dd68011369-c000.snappy.parquet&#39;,
  &#39;path_type&#39;: &#39;object&#39;,
  &#39;physical_address&#39;: &#39;s3://example/2895bba44b5b4f5199bf58d80144a9de&#39;,
  &#39;size_bytes&#39;: 78869},
 {&#39;checksum&#39;: &#39;90bee97b5d4bf0675f2684664e5993dc&#39;,
  &#39;content_type&#39;: &#39;application/octet-stream&#39;,
  &#39;mtime&#39;: 1663316555,
  &#39;path&#39;: &#39;demo/users/part-00000-b90910aa-58a0-42af-84ec-8ec557c56850-c000.snappy.parquet&#39;,
  &#39;path_type&#39;: &#39;object&#39;,
  &#39;physical_address&#39;: &#39;s3://example/ece3333dd6bd4d6d9ffab3d53fd4e6b2&#39;,
  &#39;size_bytes&#39;: 78729}]
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;the-data-as-seen-from-s3-1&#34;&gt;The data as seen from S3&lt;/h3&gt;
&lt;p&gt;Note that there are just two 78k files; there is no duplication of data shared by branches.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;for&lt;/span&gt; o &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;in&lt;/span&gt; s3&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;Bucket(repo)&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;objects&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;all():
    &lt;span style=&#34;color:#008000&#34;&gt;print&lt;/span&gt;(o&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;last_modified, o&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;key, o&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;size)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;2022-09-16 08:18:24.769000+00:00 1984e4e69777452fb03800bd4c6b1b05 0
2022-09-16 08:18:23.607000+00:00 2895bba44b5b4f5199bf58d80144a9de 78869
2022-09-16 08:22:35.628000+00:00 31d780e5af4140e895a7c3779fac985d 0
2022-09-16 08:22:36.105000+00:00 3aec1fd8560f43aaa8667d0b2d3a70be 0
2022-09-16 08:18:22.900000+00:00 49ad588d52b942c9b682f271f228cb9c 0
2022-09-16 08:18:25.034000+00:00 5e91c0a09d3a4415abd33bc460662e18 0
2022-09-16 08:22:36.360000+00:00 8acafaeee021459ba6cc29cfb35bb06b 0
2022-09-16 08:25:22.454000+00:00 _lakefs/1ddeab3bef4929b69d52e44b94048f47fe17269821ccdf3ba6701c43d691fb34 1239
2022-09-16 08:20:14.890000+00:00 _lakefs/6f2ea862d75cb1a2cdb4a3a76969c2bb134c51538c74c0d144b781ed12165b83 1390
2022-09-16 08:20:14.903000+00:00 _lakefs/ae52ce4551b3d0fd1eb49a8568f4a65db007f222953dd2770d55e0f13c4aaeb9 1239
2022-09-16 08:25:22.447000+00:00 _lakefs/dedf8f514dcf0bb4184e9ebd55ceddcfafc9fb9fd02888566a0ad2052cfb7c12 1609
2022-09-16 08:22:34.689000+00:00 b3cf0d04badd411da874a6448eead32f 0
2022-09-16 08:18:24.277000+00:00 c4cae27b7c0a46beb14f79347d77c29d 0
2022-09-16 08:17:18.615000+00:00 dummy 70
2022-09-16 08:22:35.017000+00:00 ece3333dd6bd4d6d9ffab3d53fd4e6b2 78729
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;creating-another-new-branch&#34;&gt;Creating another new branch&lt;/h2&gt;
&lt;p&gt;We&amp;rsquo;ve not merged the new user data back into main yet, but in parallel we decide we want to test removing personally identifiable information (PII) from the data that we do have already. We can create another branch to do this.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;branch&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;remove_pii&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#00f;font-weight:bold&#34;&gt;lakefs_client.model.branch_creation&lt;/span&gt; &lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;import&lt;/span&gt; BranchCreation

api_instance &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; branches_api&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;BranchesApi(api_client)
branch_creation &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; BranchCreation(
    name&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;branch,
    source&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;main&amp;#34;&lt;/span&gt;,
) 

api_response &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; api_instance&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;create_branch(repo, branch_creation)
display(api_response)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&#39;de2ae0f24961f65bf7b525d983b3dbc869ce49a0dea43529920743154ce0ddd0&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First off we&amp;rsquo;ll confirm that the data in this new branch matches what&amp;rsquo;s in main (a row count alone will suffice for a quick check):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;xform_df &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; spark&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;read&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;parquet(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;s3a://&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;repo&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;branch&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;/demo/users&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;display(xform_df&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;count())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;1000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Note that this shows 1000 per &lt;code&gt;main&lt;/code&gt;, and not 2000 per the &lt;code&gt;add_more_user_data&lt;/code&gt; branch above since this has not been merged to &lt;code&gt;main&lt;/code&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;transform-the-data&#34;&gt;Transform the data&lt;/h3&gt;
&lt;p&gt;Now we&amp;rsquo;ll use &lt;code&gt;.drop()&lt;/code&gt; to remove sensitive fields from the data.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;df2&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;xform_df&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;drop(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;ip_address&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;birthdate&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;salary&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;email&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;cache()
df2&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;show(n&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;,vertical&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;True&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;-RECORD 0--------------------------------
 registration_dttm | 2016-02-03 07:55:29 
 id                | 1                   
 first_name        | Amanda              
 last_name         | Jordan              
 gender            | Female              
 cc                | 6759521864920116    
 country           | Indonesia           
 title             | Internal Auditor    
 comments          | 1E+02               
only showing top 1 row
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;write-data-back-to-the-branch&#34;&gt;Write data back to the branch&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;df2&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;write&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;mode(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;overwrite&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;parquet(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;s3a://&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;repo&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;branch&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;/demo/users&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;commit-changes&#34;&gt;Commit changes&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;api_instance &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; commits_api&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;CommitsApi(api_client)
commit_creation &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; CommitCreation(
    message&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#34;Remove PII&amp;#34;&lt;/span&gt;,
) 

api_instance&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;commit(repo, branch, commit_creation)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;{&#39;committer&#39;: &#39;docker&#39;,
 &#39;creation_date&#39;: 1663322293,
 &#39;id&#39;: &#39;12718ce62f97df78beb1d49dcd4c5528a1977d2af1b220f22012f8305e72f768&#39;,
 &#39;message&#39;: &#39;Remove PII&#39;,
 &#39;meta_range_id&#39;: &#39;&#39;,
 &#39;metadata&#39;: {},
 &#39;parents&#39;: [&#39;de2ae0f24961f65bf7b525d983b3dbc869ce49a0dea43529920743154ce0ddd0&#39;]}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;-reading-and-writing-the-same-data-back&#34;&gt; Reading and writing the same data back&lt;/h3&gt;
&lt;p&gt;If you try to read and then write the data from the same place you&amp;rsquo;ll get an error like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Caused by: java.io.FileNotFoundException: 
No such file or directory: s3a://example/remove_pii/demo/users/part-00000-7a0bbe79-a3e2-4355-984e-bd8b950a4e0c-c000.snappy.parquet
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;One &lt;a href=&#34;https://stackoverflow.com/a/65330116/350613&#34;&gt;solution&lt;/a&gt; is to use &lt;code&gt;.cache()&lt;/code&gt;. Alternatively (and probably better, is to read the data from a different path - the reference point from which the branch was created)&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Thanks to Barak Amar on the LakeFS Slack for helping me with this.&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;re-read-all-branches-and-inspect-data-for-isolation&#34;&gt;Re-read all branches and inspect data for isolation&lt;/h3&gt;
&lt;p&gt;Here&amp;rsquo;s the original branch (&lt;code&gt;main&lt;/code&gt;), with 1k records and full set of fields:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;main &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; spark&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;read&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;parquet(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;s3a://&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;repo&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;/main/demo/users&amp;#39;&lt;/span&gt;)
display(main&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;count())
main&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;show(n&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;,vertical&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;True&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;1000


-RECORD 0--------------------------------
 registration_dttm | 2016-02-03 07:55:29 
 id                | 1                   
 first_name        | Amanda              
 last_name         | Jordan              
 email             | ajordan0@com.com    
 gender            | Female              
 ip_address        | 1.197.201.2         
 cc                | 6759521864920116    
 country           | Indonesia           
 birthdate         | 3/8/1971            
 salary            | 49756.53            
 title             | Internal Auditor    
 comments          | 1E+02               
only showing top 1 row
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The branch to which we added more data still has that data (as we&amp;rsquo;d expect; we&amp;rsquo;ve not touched it):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;add_more_user_data &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; spark&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;read&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;parquet(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;s3a://&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;repo&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;/add_more_user_data/demo/users&amp;#39;&lt;/span&gt;)
display(add_more_user_data&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;count())
add_more_user_data&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;show(n&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;,vertical&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;True&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;2000


-RECORD 0--------------------------------
 registration_dttm | 2016-02-03 07:55:29 
 id                | 1                   
 first_name        | Amanda              
 last_name         | Jordan              
 email             | ajordan0@com.com    
 gender            | Female              
 ip_address        | 1.197.201.2         
 cc                | 6759521864920116    
 country           | Indonesia           
 birthdate         | 3/8/1971            
 salary            | 49756.53            
 title             | Internal Auditor    
 comments          | 1E+02               
only showing top 1 row
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And our new branch for removing PII is showing the correct data too:  (&lt;code&gt;remove_pii&lt;/code&gt;):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;remove_pii &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; spark&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;read&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;parquet(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;s3a://&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;repo&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;/remove_pii/demo/users&amp;#39;&lt;/span&gt;)
display(remove_pii&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;count())
remove_pii&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;show(n&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;,vertical&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;True&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;1000


-RECORD 0--------------------------------
 registration_dttm | 2016-02-03 07:55:29 
 id                | 1                   
 first_name        | Amanda              
 last_name         | Jordan              
 gender            | Female              
 cc                | 6759521864920116    
 country           | Indonesia           
 title             | Internal Auditor    
 comments          | 1E+02               
only showing top 1 row
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;merge-remove_pii-into-main&#34;&gt;Merge &lt;code&gt;remove_pii&lt;/code&gt; into &lt;code&gt;main&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Since we&amp;rsquo;re happy with the data transform work, we&amp;rsquo;ll merge the result into main.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;client&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;refs&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;merge_into_branch(repository&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;repo, source_ref&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;remove_pii&amp;#39;&lt;/span&gt;, destination_branch&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;main&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;{&#39;reference&#39;: &#39;bb4564d3811586db5db202e8553fa5bfc4c5a235c4d8b8ec22ab62f7ab43b34c&#39;,
 &#39;summary&#39;: {&#39;added&#39;: 0, &#39;changed&#39;: 0, &#39;conflict&#39;: 0, &#39;removed&#39;: 0}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now if we read the data from the original branch (&lt;code&gt;main&lt;/code&gt;), we can see that it&amp;rsquo;s what we merged in, as expected:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;main &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; spark&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;read&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;parquet(&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;s3a://&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;repo&lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;/main/demo/users&amp;#39;&lt;/span&gt;)
display(main&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;count())
main&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;show(n&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;,vertical&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#008000;font-weight:bold&#34;&gt;True&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;1000


-RECORD 0--------------------------------
 registration_dttm | 2016-02-03 07:55:29 
 id                | 1                   
 first_name        | Amanda              
 last_name         | Jordan              
 gender            | Female              
 cc                | 6759521864920116    
 country           | Indonesia           
 title             | Internal Auditor    
 comments          | 1E+02               
only showing top 1 row
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;data-engineering-in-2022&#34;&gt;Data Engineering in 2022&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://rmoff.net/2022/09/14/stretching-my-legs-in-the-data-engineering-ecosystem-in-2022/&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rmoff.net/2022/09/14/data-engineering-in-2022-storage-and-access/&#34;&gt;Storage and Access&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Query &amp;amp; Transformation Engines [TODO]&lt;/li&gt;
&lt;li&gt;ETL/ELT tools &amp;amp; Orchestration [TODO]&lt;/li&gt;
&lt;li&gt;Architectures &amp;amp; Terminology [TODO]&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rmoff.net/2022/09/14/data-engineering-resources/&#34;&gt;Resources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Data Engineering: Resources</title>
      <link>https://rmoff.net/2022/09/14/data-engineering-resources/</link>
      <pubDate>2022-09-14</pubDate>
      
      <guid>https://rmoff.net/2022/09/14/data-engineering-resources/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2022/09/t_DSCF7583.jpeg" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;As Ive been reading and exploring the current world of data engineering Ive been adding links to my &lt;a href=&#34;https://raindrop.io/rmoff/data-engineering-23335742&#34;&gt;Raindrop.io collection&lt;/a&gt;, so check that out. In addition, below are some specific resources that Id recommend.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_articles&#34;&gt;Articles&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.getdbt.com/blog/future-of-the-modern-data-stack/&#34;&gt;Tristan Handy - The Modern Data Stack: Past, Present, and Future&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://medium.com/free-code-camp/the-rise-of-the-data-engineer-91be18f1e603&#34;&gt;Maxime Beauchemin - The Rise of the Data Engineer&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_newsletters&#34;&gt;Newsletters&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://benn.substack.com/&#34;&gt;benn.substack | Benn Stancil | Substack&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://davidsj.substack.com/&#34;&gt;davidj.substack | David Jayatillake | Substack&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.dataengineeringweekly.com/&#34;&gt;Data Engineering Weekly | Ananth Packkildurai | Substack&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_podcasts&#34;&gt;Podcasts&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The main podcast that I listen to in this area is the &lt;a href=&#34;https://www.dataengineeringpodcast.com/&#34;&gt;Data Engineering Podcast&lt;/a&gt;. Here are some ones Ive particularly enjoyed:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.dataengineeringpodcast.com/joe-reis-flips-the-script-episode-307/&#34;&gt;Joe Reis Flips The Script And Interviews Tobias Macey About The Data Engineering Podcast&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Implementations&lt;/p&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.dataengineeringpodcast.com/riskified-data-platform-journey-episode-306/&#34;&gt;Charting the Path of Riskifieds Data Platform Journey&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.dataengineeringpodcast.com/segment-customer-analytics-episode-72/&#34;&gt;Customer Analytics At Scale With Segment&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.dataengineeringpodcast.com/snuba-event-data-warehouse-episode-108/&#34;&gt;Building A Real Time Event Data Warehouse For Sentry&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.dataengineeringpodcast.com/shopify-data-warehouse-with-dbt-episode-171/&#34;&gt;How Shopify Is Building Their Production Data Warehouse Using DBT&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.dataengineeringpodcast.com/yotpo-data-platform-architecture-episode-285/&#34;&gt;Evolving And Scaling The Data Platform at Yotpo&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.dataengineeringpodcast.com/data-lake-platform-design-srivatsan-sridharan-episode-289/&#34;&gt;Insights And Advice On Building A Data Lake Platform From Someone Who Learned The Hard Way&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.dataengineeringpodcast.com/shadow-it-data-analytics-episode-121/&#34;&gt;Shining A Light on Shadow IT In Data And Analytics&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Technology&lt;/p&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.dataengineeringpodcast.com/dbt-data-analytics-episode-81/&#34;&gt;Build Your Data Analytics Like An Engineer With DBT&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.dataengineeringpodcast.com/hudi-streaming-data-lake-episode-209/&#34;&gt;Charting A Path For Streaming Data To Fill Your Data Lake With Hudi&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.dataengineeringpodcast.com/lakefs-data-lake-versioning-episode-157/&#34;&gt;Add Version Control To Your Data Lake With LakeFS&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;hr/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_data_engineering_in_2022&#34;&gt;Data Engineering in 2022&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://rmoff.net/2022/09/14/stretching-my-legs-in-the-data-engineering-ecosystem-in-2022/&#34;&gt;Introduction&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://rmoff.net/2022/09/14/data-engineering-in-2022-storage-and-access/&#34;&gt;Storage and Access&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://rmoff.net/2022/09/16/data-engineering-in-2022-exploring-lakefs-with-jupyter-and-pyspark/&#34;&gt;Exploring LakeFS with Jupyter and PySpark&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Query &amp;amp; Transformation Engines [TODO]&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ETL/ELT tools &amp;amp; Orchestration [TODO]&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Architectures &amp;amp; Terminology [TODO]&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
    </item>
    <item>
      <title>Data Engineering in 2022: Storage and Access</title>
      <link>https://rmoff.net/2022/09/14/data-engineering-in-2022-storage-and-access/</link>
      <pubDate>2022-09-14</pubDate>
      
      <guid>https://rmoff.net/2022/09/14/data-engineering-in-2022-storage-and-access/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2022/09/t_IMG_5037.jpeg" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In this article I look at where we store our analytical data, how we organise it, and how we enable access to it. Im considering here potentially large volumes of data for access throughout an organisation. Im not looking at data stores that are used for specific purposes (caches, low-latency analytics, graph etc).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The article is &lt;a href=&#34;https://rmoff.net/2022/09/14/stretching-my-legs-in-the-data-engineering-ecosystem-in-2022/&#34;&gt;part of a series&lt;/a&gt; in which I explore the world of data engineering in 2022 and how it has changed from when I started my career in data warehousing 20+ years ago. Read the &lt;a href=&#34;https://rmoff.net/2022/09/14/stretching-my-legs-in-the-data-engineering-ecosystem-in-2022/&#34;&gt;introduction&lt;/a&gt; for more context and background.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_storing_and_accessing_your_data_pt_1_burn_it_all_down&#34;&gt;Storing and Accessing Your Data pt 1:  Burn It All Down&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In the beginning was the word, and the word was an expensive relational datawarehouse that wasnt flexible or scalable enough for the cool kids in Silicon Valley.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Then came Hadoop and scalability was won, at the vast cost of usability. You literally had to write your own Java code to move data around and transform it. You needed to serialise and deserialise the data yourself, and could store whatever you wanted - it didnt have to be structured. This was sold as a benefit&amp;#34;Schema on Read&amp;#34; they said, &amp;#34;Itll be a good idea&amp;#34;, they said. &lt;em&gt;&amp;#34;Oh bugger, wheres my schema&amp;#34;&lt;/em&gt;, they said when they came to use it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Through the virtues of open source a fantastic ecosystem grew particularly around the &lt;a href=&#34;https://apache.org&#34;&gt;Apache Software Foundation&lt;/a&gt; and we got such wonderfully named projects as &lt;a href=&#34;https://sqoop.apache.org/&#34;&gt;Sqoop&lt;/a&gt;, &lt;a href=&#34;https://oozie.apache.org/&#34;&gt;Oozie&lt;/a&gt;, &lt;a href=&#34;https://pig.apache.org/&#34;&gt;Pig&lt;/a&gt;, and &lt;a href=&#34;https://flume.apache.org/&#34;&gt;Flume&lt;/a&gt; emerged. &lt;a href=&#34;https://hive.apache.org/&#34;&gt;Hive&lt;/a&gt; brought with it the familiar and comforting bosom of SQL and table structures but with limited functionality (including no &lt;code&gt;DELETE&lt;/code&gt; or &lt;code&gt;UPDATE&lt;/code&gt; at first) and performance.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Over the years things improved, with &lt;a href=&#34;https://spark.apache.org/&#34;&gt;Spark&lt;/a&gt; replacing &lt;a href=&#34;https://hadoop.apache.org/&#34;&gt;MapReduce&lt;/a&gt; and enabling a generation of Python coders to get into the big data lark too, along with &lt;a href=&#34;https://spark.apache.org/sql/&#34;&gt;SQL&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Amongst all of this pioneering work and technology was the assumption that the resting place for analytical data was &lt;a href=&#34;https://hadoop.apache.org/&#34;&gt;HDFS&lt;/a&gt;. Other stores like &lt;a href=&#34;https://hbase.apache.org/&#34;&gt;HBase&lt;/a&gt; existed for special purposes, but the general weve-got-a-bunch-of-data-in-this-org-and-need-to-collect-it destination was HDFS. Because &amp;#34;general dumping ground&amp;#34; wasnt sexy enough for the marketing folk it became sold as a &amp;#34;Data Lake&amp;#34; with all the associated puns and awful cliches (fishing for data, data swamp, etc etc etc).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The general pitch around the data lake was to collect all the data, structured and unstructured (&lt;em&gt;or structured that youve made unstructured by chucking away its schema when you loaded it&lt;/em&gt;), and then &lt;del&gt;wait for the data lake fairy to conjure magical value out of the pile of data youve dumped there&lt;/del&gt; make the raw data available for teams in the company to process and use for their particular purposes. This may have been direct querying of the data in place, or processing it and landing it in another data store for serving (for example, aggregated and structured for optimal query access in an RDBMS or columnar data store).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Accessing the data in HDFS was done with Hive and other tools including &lt;a href=&#34;https://impala.apache.org/&#34;&gt;Impala&lt;/a&gt;, &lt;a href=&#34;https://drill.apache.org/&#34;&gt;Drill&lt;/a&gt;, and &lt;a href=&#34;https://prestodb.io/&#34;&gt;Presto&lt;/a&gt;. All had their pros and cons particularly in early releases, often with limitations around performance and management of the data.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;All of this was built around the closely-intertwined &lt;a href=&#34;https://hadoop.apache.org/&#34;&gt;Hadoop&lt;/a&gt; platform, whether self-managed on-premises including with deployments from Cloudera, MapR, and Hortonworks, or with a cloud provider such as AWS and its &lt;a href=&#34;https://aws.amazon.com/emr/&#34;&gt;EMR&lt;/a&gt; service.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This was pretty much the state of the Big Data world (as it was called then) as &lt;a href=&#34;https://www.rittmanmead.com/blog/2016/12/etl-offload-with-spark-and-amazon-emr-part-5/&#34;&gt;I last saw it&lt;/a&gt; before getting distracted by the world of stream processing - fragmented, more difficult to use, less functionality than an RDBMS for analytics, and evolving rapidly.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_storing_and_accessing_your_data_pt_2_and_then_rebuild_it_&#34;&gt;Storing and Accessing Your Data pt 2: and Then Rebuild It &lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Coming back to this after my attention being elsewhere for a few years means that I have the slightly uninformed but helpfully simplistic view of things. What the relational data warehouses used to do (bar scale, arguably), we are now approaching something roughly like parity again with a stack of tools that have stabilised and matured in large, with a layer on top thats still being figured out.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Underpinning it all is the core idea of separation of storage and compute. Instead of one box (the traditional RDBMS), we have two. This is important for two vital reasons:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Its a lot &lt;strong&gt;cheaper&lt;/strong&gt; to just store data and then only pay for compute when you want to use it.&lt;/p&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The alternative is that you couple the two together which is what weve generally always done and is seen in every RDBMS, like Oracle, DB2, etc etc. With the coupled approach you have a server with disks and CPUs and youre paying for the CPUs whether theyre doing anything or not, and when you need more storage and have filled the disk bays you need to buy (and license, hi Oracle) another server (with CPUs etc).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The added element here is that you have to provision your capacity for your &lt;strong&gt;peak&lt;/strong&gt; workload, which means over-provisioning and capacity sat idle potentially for much of the time depending on your business and data workload patterns.&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If your data is held in an &lt;strong&gt;open format&lt;/strong&gt; on a storage platform that has &lt;strong&gt;open APIs&lt;/strong&gt; then multiple tools can use it as they want to.&lt;/p&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Contrast this to putting your data in SQL Server (not to pick on Oracle all the time), and any tool that wants to use it has to do so through SQL Server. If a new tool comes along that does particular processing really really well and your data is sat in an RDBMS then you have to migrate that data off the RDBMS first, or query it in place.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Given the &lt;a href=&#34;https://en.wikipedia.org/wiki/Cambrian_explosion&#34;&gt;Cambrian explosion&lt;/a&gt; thats been happening in the world of software and showing no signs of abating, setting ourselves up for compatibilty and future evolution of software choices seems like the smart move.&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;HDFS and Hive gave us this separation, right? Well, it did, but with a &lt;a href=&#34;https://youtu.be/nWwQMlrjhy0?t=734&#34;&gt;long list of problems and limitations for Hive&lt;/a&gt;. These include poor perfomance, a lack of support for transactions, point-in-time querying, streaming updates, and more. In addition, HDFS has nowadays been overtaken by S3 as the object store of choice with APIs supported by numerous non-S3 platforms, both Cloud based (e.g. &lt;a href=&#34;https://cloud.google.com/storage/docs/interoperability&#34;&gt;Googles Cloud Storage (GCS)&lt;/a&gt;, and &lt;a href=&#34;https://developers.cloudflare.com/r2/platform/s3-compatibility/api/&#34;&gt;Cloudflares R2&lt;/a&gt;) and on-premises (e.g. &lt;a href=&#34;https://min.io/&#34;&gt;Minio&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;So if its not HDFS and Hive, whats the current state and future of analytics data storage &amp;amp; access looking like?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_data_lake_table_formats_data_lakehouses&#34;&gt;Data Lake Table Formats &amp;amp; Data Lakehouses&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;So, full disclosure first:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Confession: Until last week I honestly thought &amp;quot;data lakehouse&amp;quot; was some god-awful marketing bollocks and nothing more. &lt;br&gt;Embarrassed to find out there&amp;#39;s actually a rather interesting paper from last year describing the concept in detail: &lt;a href=&#34;https://t.co/XEI0zGSXBl&#34;&gt;https://t.co/XEI0zGSXBl&lt;/a&gt;&lt;/p&gt;&amp;mdash; Robin Moffatt  (@rmoff) &lt;a href=&#34;https://twitter.com/rmoff/status/1565747777992359938?ref_src=twsrc%5Etfw&#34;&gt;September 2, 2022&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;You can read the &lt;a href=&#34;https://www.cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf&#34;&gt;Lakehouse paper&lt;/a&gt; (and &lt;a href=&#34;https://www.databricks.com/wp-content/uploads/2020/08/p975-armbrust.pdf&#34;&gt;more detailed one&lt;/a&gt;) and decide for yourself &lt;a href=&#34;https://twitter.com/gwenshap/status/1565771009902256129&#34;&gt;its virtues&lt;/a&gt;, but I found it a useful description of a pattern that several technologies are adopting, not just &lt;a href=&#34;https://www.databricks.com/product/data-lakehouse&#34;&gt;Databricks and their Delta Lake implementation of the Lakehouse&lt;/a&gt;. &lt;em&gt;Ill admit, the name gratesand I miss the Hadoop days of fun names .&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In short, the &amp;#34;Lakehouse&amp;#34; concept is where data is stored on object store (the Data Lake) with a layer above it providing a &amp;#34;table format&amp;#34; through which data can be read and written in a structured way, supporting updates and deletes to the data, as well as queried in an efficient way. The Lakehouse is the whole; the &lt;strong&gt;table format&lt;/strong&gt; is the specific layer of technology that implements the access on the data in your Data Lake.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;img-lakehouse&#34; class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;a class=&#34;image&#34; href=&#34;https://www.cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2022/09/lakehouse_dl01.png&#34; alt=&#34;Diagram of the evolution of the Lakehouse from Databricks&#34;/&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Whether you go for the &lt;strong&gt;Lakehouse&lt;/strong&gt; term (Databricks would like you to, and &lt;a href=&#34;https://www.snowflake.com/guides/what-data-lakehouse&#34;&gt;Snowflake&lt;/a&gt; are onboard too, and maybe even &lt;a href=&#34;https://www.oracle.com/uk/data-lakehouse/what-is-data-lakehouse/&#34;&gt;Oracle&lt;/a&gt;) or just the &lt;strong&gt;Data Lake plus Table Format&lt;/strong&gt;, its a really interesting idea. The bit that really catches my attention is that it enables a common table structure to be defined and accessed by a variety of compute engines - meaning that in both querying and processing (ETL/ELT) the data can be structured and manipulated in the way in which you would in an RDBMS.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;There are three table formats available:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://hudi.apache.org/&#34;&gt;Apache Hudi&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://iceberg.apache.org&#34;&gt;Apache Iceberg&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://delta.io&#34;&gt;Delta Lake&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;All of them enable the things that wed have taken for granted a decade ago including rich metadata, transactional access, `UPDATE`s, `DELETE`s, and ACID compliance, along with performant access when querying the data.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Both Hudi and Delta Lake have a similar conceptual diagram which illustrates things well. Note the plethora of query engines and integrations that each support.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2022/09/hudi_dl01.png&#34; alt=&#34;Apache Hudi and Delta Lake conceptual diagrams&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;(image credits: &lt;a href=&#34;https://hudi.apache.org/&#34;&gt;Apache Hudi&lt;/a&gt; / &lt;a href=&#34;https://delta.io&#34;&gt;Delta Lake&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_managed_data_lakehouses&#34;&gt;Managed Data Lakehouses&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;You can run run your own, or use used hosted versions including&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.onehouse.ai/&#34;&gt;Onehouse&lt;/a&gt; (Apache Hudi)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://tabular.io/&#34;&gt;Tabular&lt;/a&gt; (Apache Iceberg)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.databricks.com/&#34;&gt;Databricks&lt;/a&gt; (Delta Lake)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;GCP&lt;/strong&gt;&amp;#39;s &lt;a href=&#34;https://cloud.google.com/blog/products/data-analytics/unify-data-lakes-and-warehouses-with-biglake-now-generally-available&#34;&gt;BigLake&lt;/a&gt; (Iceberg?)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;Azure&lt;/strong&gt; have a close partnership with Databricks, so the only major cloud provider missing from this list is &lt;strong&gt;AWS&lt;/strong&gt;. They have &lt;a href=&#34;https://aws.amazon.com/lake-formation/&#34;&gt;Lake Formation&lt;/a&gt; and &lt;a href=&#34;https://docs.aws.amazon.com/lake-formation/latest/dg/governed-tables.html&#34;&gt;Governed Tables&lt;/a&gt; which looks similar on the surface but Ive not dug into in detail (and Governed Tables arent even mentioned on AWS&amp;#39; &lt;a href=&#34;https://aws.amazon.com/blogs/big-data/build-a-lake-house-architecture-on-aws/&#34;&gt;Build a Lakehouse Architecture on AWS&lt;/a&gt; blog).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;Snowflake&lt;/strong&gt; recently added support for &lt;a href=&#34;https://www.snowflake.com/blog/iceberg-tables-powering-open-standards-with-snowflake-innovations/&#34;&gt;Iceberg tables&lt;/a&gt; (complementing the existing &lt;a href=&#34;https://docs.snowflake.com/en/user-guide/tables-external-intro.html#delta-lake-support&#34;&gt;support for Delta Lake external tables&lt;/a&gt;), and are &lt;a href=&#34;https://www.snowflake.com/blog/5-reasons-apache-iceberg/&#34;&gt;backing Iceberg&lt;/a&gt;  presumably in part to try and hamper Databricks&amp;#39; Delta Lake (see also their snarky comments about &amp;#34;&lt;em&gt;Iceberg includes features that are &lt;strong&gt;paid in other table formats&lt;/strong&gt;&lt;/em&gt;&amp;#34;, &amp;#34;&lt;em&gt;The Iceberg project is &lt;strong&gt;well-run&lt;/strong&gt; open source&lt;/em&gt;&amp;#34; etc, taking a shot at the fact that Delta Lake has paid options, and the majority of committers are from Databricks).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.dremio.com/&#34;&gt;&lt;strong&gt;Dremio&lt;/strong&gt;&lt;/a&gt; are also in this space as one of the companies working on &lt;a href=&#34;https://arrow.apache.org/&#34;&gt;Apache Arrow&lt;/a&gt; and providing a fast query engine built on it called Dremio Sonar. Ive yet to get my head around their offering, but it looks like on-premises platform as well as hosted, with support for Apache Iceberg and Delta Lake. Theyve got a rich set of resources in their &lt;a href=&#34;https://www.dremio.com/subsurface/&#34;&gt;Subsurface&lt;/a&gt; resource area.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;Oracle&lt;/strong&gt; being Oracle are not ones to miss up the chance to jump on a buzzword or marketing bandwagon. Their version of the Lakehouse however looks to be to stick their Autonomous Data Warehouse (its self driving! self healing!) on top of a data lake - kinda like Snowflake have done, but without the open table format support of Apache Iceberg. The huge downside to this is that without the open table format theres zero interoperability with other query &amp;amp; processing engines - something Oracle are presumably not in a rush to enable.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_storage_formats&#34;&gt;Storage Formats&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Regardless of which &lt;em&gt;table format&lt;/em&gt; you implement, you still store your data in a format appropriate for its use - and that format is separate from the table format (confused yet? you might be). Different table formats support different storage formats but in general youll see various open formats used:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Probably something like &lt;a href=&#34;https://avro.apache.org/&#34;&gt;Avro&lt;/a&gt; for structure data thats still to be processed&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A columnar format such as &lt;a href=&#34;https://parquet.apache.org/&#34;&gt;Parquet&lt;/a&gt; or &lt;a href=&#34;https://orc.apache.org/&#34;&gt;Orc&lt;/a&gt; for data thats going to be queried&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It could also just be JSON (hell, use CSV if you really must)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Regardless of the format, the data is stored on storage with an open API (or at least one which is widely supported by most tools) - S3 becomes the de facto choice here.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_reading_more_about_table_formats_lakehouses&#34;&gt;Reading more about Table Formats &amp;amp; Lakehouses&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Here are some good explanations, deep-dives, and comparison posts covering the three formats:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://dacort.dev/posts/modern-data-lake-storage-layers/&#34;&gt;An Introduction to Modern Data Lake Storage Layers&lt;/a&gt; - &lt;a href=&#34;https://twitter.com/dacort&#34;&gt;Damon Cortesi&lt;/a&gt; (AWS)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Comparison of Data Lake Table Formats &lt;a href=&#34;https://www.dremio.com/subsurface/comparison-of-data-lake-table-formats-iceberg-hudi-and-delta-lake/&#34;&gt;blog&lt;/a&gt; / &lt;a href=&#34;https://www.dremio.com/subsurface/subsurface-meetup-comparison-of-data-lakehouse-table-formats/&#34;&gt;video&lt;/a&gt; - &lt;a href=&#34;https://twitter.com/AMdatalakehouse&#34;&gt;Alex Merced&lt;/a&gt; (Dremio)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.onehouse.ai/blog/apache-hudi-vs-delta-lake-vs-apache-iceberg-lakehouse-feature-comparison&#34;&gt;Apache Hudi vs Delta Lake vs Apache Iceberg - Lakehouse Feature Comparison&lt;/a&gt; - &lt;a href=&#34;https://www.linkedin.com/in/lakehouse/&#34;&gt;Kyle Weller&lt;/a&gt; (Onehouse)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://lakefs.io/hudi-iceberg-and-delta-lake-data-lake-table-formats-compared/&#34;&gt;Hudi, Iceberg and Delta Lake: Data Lake Table Formats Compared&lt;/a&gt; - &lt;a href=&#34;https://www.linkedin.com/in/paulsingman/&#34;&gt;Paul Singman&lt;/a&gt; (LakeFS)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_a_note_about_open_formats&#34;&gt;A Note About Open Formats&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Whether were talking data lakes, Lakehouses, or other ways of storing data, open formats are important. A closed-format vendor will tell you that its just the &amp;#34;vendor lockin bogeyman man&amp;#34; pitch and how often do you re-platform anyway. I would reframe it away from this and suggest that just as with tools such as Apache Kafka, an open format enables you to keep your data in a neutral place, accessible by many different tools and technologies. Why do so many support it? Because its open!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In a technology landscape which has not stopped moving at this pace for several years now and probably wont for many more, the alternative to an open format is betting big on a closed platform and hoping that nothing better comes along in the envisaged lifetime of the data platform. Open formats give you the flexibility to hedge your bets, to evaluate newer tools and technologies as they come along, and to not be beholden to a particular vendor or technology if it falls behind what you need.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In previous times the use of an open format may have been moot given the dearth of alternatives when it came to processing the datanever mind the fact that the storage of data was usually coupled to the compute making it even more irrelevant. Nowadays there are multiple &amp;#34;big hitters&amp;#34; in each processing category with a dozen other options nibbling at their feet. Using a open format gives you the freedom to trial whichever ones you want to.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Just a tip to vendors: thats great if youre embracing open formats, but check your hubris if you start to brag about it whilst simultaneously throwing FUD at open source. &lt;a href=&#34;https://www.linkedin.com/posts/robinmoffatt_choosing-open-wisely-snowflake-blog-activity-6973309528628973568-gjOJ?utm_source=share&amp;amp;utm_medium=member_desktop&#34;&gt;Just sayin&amp;#39;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_git_for_data_with_lakefs&#34;&gt;&lt;code&gt;git&lt;/code&gt; For Data with LakeFS&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Leaving aside table formats and lakehouses for the momentand coming back to the big picture of how we store and access data nowadaysone idea thats caught my attention is that of being able to apply git-like semantics &lt;strong&gt;to the data itself&lt;/strong&gt;. Heres a copy of &lt;a href=&#34;https://twitter.com/rmoff/status/1567829714865102853&#34;&gt;a recent Twitter thread that I wrote&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;hr/&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Having &lt;a href=&#34;https://www.youtube.com/watch?v=uixZ7NcGoeE&#34;&gt;watched @gwenshap and @ozkatz100 talk about &amp;#34;git for data&amp;#34;&lt;/a&gt; I would definitely say is a serious idea.
However to the point at the end of the video, RTFMit took reading &lt;a href=&#34;https://docs.lakefs.io/using_lakefs/data-devenv.html&#34;&gt;page from the docs&lt;/a&gt; and some other pages subsequently to really grok the concept in practice.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Where I struggled at first with the git analogy alone was that data changes, and I couldnt see how branch/merge fitted into that outside of the idea of branching for throwaway testing alone. The &lt;a href=&#34;https://www.youtube.com/watch?v=uixZ7NcGoeE&amp;amp;t=1401s&#34;&gt;1PB accidental deletion example&lt;/a&gt; was useful for illustrating the latter point for sure.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;But then reading &lt;a href=&#34;https://docs.lakefs.io/understand/roadmap.html#improved-streaming-support-for-apache-kafka&#34;&gt;this page&lt;/a&gt; made me realise that I was thinking about the whole thing from a streaming PoVwhen actually the idea of running a batch against a branch with a hook to validate and then merge is a freakin awesome idea&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;(As the roadmap issue notes, doing this for streaming data is conceptually possible but more complex to implement.)&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Im also still trying to think through the implications of &lt;a href=&#34;https://docs.lakefs.io/understand/model.html#merge&#34;&gt;merging one branch into another&lt;/a&gt; in which there are changes; can data really be treated the same as code in that sense, or could one end up with inconsistent data sets?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Lastly, having been reading up on table formats, Id be interested to dig into quite how much LakeFS works already with them vs roadmap alone (the docs are not entirely consistent on this point)but with both in place it sounds like a fantastic place for data eng to be heading.&lt;/p&gt;
&lt;/div&gt;
&lt;hr/&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The &amp;#34;git for data&amp;#34; pitch is a great way to articulate things, but it also shifted my brain off some of the central uses. For code, &lt;code&gt;git&lt;/code&gt; is an integral part of the development process but once it hits Production &lt;code&gt;git&lt;/code&gt; steps back from an active role. However, in the case of LakeFS some of their most exciting use cases are &lt;em&gt;as part of the Production data process&lt;/em&gt;. &lt;a href=&#34;https://docs.lakefs.io/understand/roadmap.html#improved-streaming-support-for-apache-kafka&#34;&gt;The docs&lt;/a&gt; have several examples which I think are just great:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;When your batch pipeline runs, it does so against a branch of the data. Before merging that branch back into trunk, a hook can be configured to do various data quality checks (just as youd configure hooks in GitHub etc to check for code quality, test suites, etc etc). This could be things like checking for PII slipping through, or simply &amp;#34;did we process the approximate number of records that we would expect&amp;#34;. If that kind of check fails because the source datas gone bad or failed up stream then you potentially save yourself a ton of unpicking that youd have to do if its updated directly in the Production data lake.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;As above, the batch pipeline creates a new branch when it runs, and when (or if) it completes successfully and merges that back into the trunk, that merge can have attached to it a bunch of metadata to do with the pipeline execution. What version of the code was it running, what version of the underlying frameworks on which it executed, and so on. Invaluable for tracing particular problems at a later date.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;I kicked the tyres on LakeFS and wrote about it &lt;a href=&#34;https://rmoff.net/2022/09/16/data-engineering-in-2022-exploring-lakefs-with-jupyter-and-pyspark/&#34;&gt;here&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;hr/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_data_engineering_in_2022&#34;&gt;Data Engineering in 2022&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://rmoff.net/2022/09/14/stretching-my-legs-in-the-data-engineering-ecosystem-in-2022/&#34;&gt;Introduction&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://rmoff.net/2022/09/16/data-engineering-in-2022-exploring-lakefs-with-jupyter-and-pyspark/&#34;&gt;Exploring LakeFS with Jupyter and PySpark&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Query &amp;amp; Transformation Engines [TODO]&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ETL/ELT tools &amp;amp; Orchestration [TODO]&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Architectures &amp;amp; Terminology [TODO]&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://rmoff.net/2022/09/14/data-engineering-resources/&#34;&gt;Resources&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
    </item>
    <item>
      <title>Stretching my Legs in the Data Engineering Ecosystem in 2022</title>
      <link>https://rmoff.net/2022/09/14/stretching-my-legs-in-the-data-engineering-ecosystem-in-2022/</link>
      <pubDate>2022-09-14</pubDate>
      
      <guid>https://rmoff.net/2022/09/14/stretching-my-legs-in-the-data-engineering-ecosystem-in-2022/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2022/09/IMG_7557.jpeg" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;For the past 5.5 years Ive been head-down in the exciting area of stream processing and events, and I realised recently that the world of data and analytics that I worked in up to 2017 which was changing significantly back then (Big Data, yall!) has evolved and, dare I say it, matured somewhat - and Ive not necessarily kept up with it. In this series of posts you can follow along as I start to reacquaint myself with where its got to these days.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_background&#34;&gt;Background&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Twenty years ago (TWENTY) I took my first job from university using my  Music degree tobuild data warehouses. I was lucky to get a place on a graduate scheme at a well-established retailer with an excellent training programme. I got taught COBOL, DB2, TSO, and all that fun stuff. I even remember my TSO handle - TSO954. Weird huh. From there I continued in the data space, via a stint as a DBA on production OLTP systems, and into more data warehousing and analytics with Oracle in 2010.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;From the mid 2010s I became aware of the Big Data ecosystem emerging, primarily around Apache Hadoop and Cloudera (anyone remember &lt;a href=&#34;https://twitter.com/kestelyn/status/322407722261819392&#34;&gt;&lt;em&gt;Data Is The New Bacon&lt;/em&gt;&lt;/a&gt;?). All the things Id been used to doing with analytical data suddenly became really difficult. Query some data? Write Java code. Update some data? Haha nope. Use SQL? hah, welcome to this alpha release that probably doesnt work. And BTW, if you didnt know it before, now you truly know the meaning of JAR hell.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Snark aside, I spent some time &lt;a href=&#34;https://www.rittmanmead.com/blog/2016/12/etl-offload-with-spark-and-amazon-emr-part-5/&#34;&gt;looking at some of the tools&lt;/a&gt; and building out examples of its use in 2016, before moving jobs into my current role at Confluent.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;At Confluent Ive been working with Apache Kafka and diving deep into the world of stream processing, including building streaming data pipelines. When I took on the role of chair of the &lt;a href=&#34;https://www.confluent.io/en-gb/blog/introducing-current-2022-program-committee/&#34;&gt;program committee for Current 22&lt;/a&gt; part of the remit was to help source and build a program that included elements across the broader data landscape than Kafka alone. In doing this, I realised quite how much had changed in recent years, and gave me an itch to try and make some sense of it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Herewith that itch being scratched&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;
&lt;/p&gt;&lt;div class=&#34;tenor-gif-embed&#34; data-postid=&#34;15016547&#34; data-share-method=&#34;host&#34; data-aspect-ratio=&#34;1&#34; data-width=&#34;100%&#34;&gt;&lt;a href=&#34;https://tenor.com/view/happy-scratch-head-cat-gif-15016547&#34;&gt;Happy Scratch Head GIF&lt;/a&gt;from &lt;a href=&#34;https://tenor.com/search/happy-gifs&#34;&gt;Happy GIFs&lt;/a&gt;&lt;/div&gt; &lt;script type=&#34;text/javascript&#34; async=&#34;&#34; src=&#34;https://tenor.com/embed.js&#34;&gt;&lt;/script&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_how_it_started&#34;&gt;How It Started&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Its hard to write a piece like this without invoking &lt;a href=&#34;https://www.youtube.com/watch?v=ue7wM0QC5LE&#34;&gt;The Four Yorkshiremen&lt;/a&gt; at some point, so Ill get it out of the way now. But &lt;del&gt;back in my day&lt;/del&gt; my starting point for what is nowadays called &lt;code&gt;&amp;lt;Data|Analytics&amp;gt; Engineering&lt;/code&gt; is what pretty much everyonebar the real cool kids in silicon valleywas doing back in the early 2010s (and the previous ~decades before that):&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Find a source system - probably just one, or maybe two. Almost certainly a mainframe, Oracle, flat files.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ETL/ELT the data into a target Data Warehouse or Data Mart, probably with a star or snowflake schema&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Build dashboards on the data&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2022/09/simpledw.png&#34; alt=&#34;Source DB  DW  Dashboard&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;It was maybe not as neat as this, with various elements of &amp;#34;shadow IT&amp;#34; springing up to circumvent real [or perceived] limitations - but at least you knew what you&lt;/em&gt; should &lt;em&gt;be doing and aspiring for&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Extracts were usually once a day. Operational Data Stores were becoming a bit trendy then along with &amp;#39;micro-batch&amp;#39; extracts which meant data coming maybe more frequently, e.g. 5-10 minutes&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Tools were the traditional ETL lot (Informatica, Data Stage, etc), with Oracles Data Integrator (ne Sunopsis) bringing the concept of ELT in which instead of buying servers (e.g. Informatica) to run the Transform, you took advantage of the target databases ability to crunch data by loading the data into the database in one set of tables, transform it there, and load it into another set of tables. Nowadays &lt;a href=&#34;https://twitter.com/esammer/status/1567547892927442944&#34;&gt;ELT is not such a clear-cut concept&lt;/a&gt; (for non-obvious reasons)&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Data modeling was an important part, as was the separation of logical and physical at both the ELT stage (ODI) and reporting (e.g. OBIEEs semantic layer).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Source control in analytics was something that the hipsters did. Emailing around files and using &lt;code&gt;CODE_FILE_V01&lt;/code&gt;, &lt;code&gt;CODE_FILE_V02&lt;/code&gt;, &lt;code&gt;CODE_FILE_PROD_RELESE!_V3&lt;/code&gt; was seen as perfectly acceptable and sufficient. Even if you wanted to, it was often &lt;a href=&#34;https://www.rittmanmead.com/blog/2015/01/concurrent-rpd-development-in-obiee/&#34;&gt;difficult&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Data Warehouses tended to live on dedicated platforms including Teradata, Netezza, as well as the big RDBMSs such as Oracle, DB2, and SQL Server.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Scaling was mostly vertical (buy a bigger box, put in more CPUs). Oracles Exadata was an engineered system and launched with the promise of magical performance improvements with a combination of hardware and software fairy dust to make everything go quick.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The idea of building around open source software was not a commonplace idea for most companies of any size, and Cloud was in the early phases of the hype cycle.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Analytics work was centralised around the BI (Business Information) or MIS (Management Information Systems) teams, or going back a bit further the DSS (Decision Support System) team. Source systems owners would grudgingly allow an extract from their systems, with domain model specifics often left to the analytics team to figure out.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_how_its_going&#34;&gt;How Its Going&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;First, a HUGE caveat: whereas the above is written based on my experience as a &amp;#34;practitioner&amp;#34; (I was actually doing and building this stuff), what comes next is my&lt;/em&gt; perception &lt;em&gt;from conversations, my Twitter bubble, etc. I would be deeply pleased to be corrected on any skew in what I write.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Where to start?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The use of data has changed. The technology to do so has changed. The general technical competence and willingness to interact with IT systems has changed.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Data is no longer used just to print out on a report on a Monday morning. Data is used throughout companies to inform and automate processes, as described by Jay Kreps in his article &lt;a href=&#34;https://www.confluent.io/blog/every-company-is-becoming-software/&#34;&gt;Every Company is Becoming &lt;del&gt;a&lt;/del&gt; Software &lt;del&gt;Company&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Handling of data is done by many teams, not just one. In the new world of the Data Mesh even source system owners are supposed to get in on the game and publish their data as a data product. Outside of IT, other departments in a company are staffed by a new generation of &amp;#34;technology native&amp;#34; employees - those who grew up with the internet and computers as just as much a part of their worlds as television and the telephone. Rather than commissioning a long project from the IT department theyre as likely to self-serve their requirements, either building something themselves or using a credit card to sign up for one of the thousands of SaaS platforms.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The data engineering world has realisedif not fully acceptedthat software engineering practices including testing, CI/CD, etc are important - see &lt;a href=&#34;https://www.youtube.com/watch?v=uixZ7NcGoeE&amp;amp;t=450s&#34;&gt;this interesting discussion&lt;/a&gt; on the &amp;#34;shift left&amp;#34; of data engineering.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Hardware is not limited to what you can procure and provision in your data center through a regimented and standardised central process, but whatever you can imagine (and afford) in the Cloud. Laptops themselves are so powerful that much processing can just be done locally. And the fact that its laptops is notable - now anyone can work anywhere. The desktop machine in the office is becoming an anachronistic idea except for specialised roles such as video processing. That mobility in its adds considerations to how technology serves us too.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Both &lt;a href=&#34;https://seattledataguy.substack.com/&#34;&gt;SeattleDataGuy&lt;/a&gt; in his article &lt;a href=&#34;https://seattledataguy.substack.com/p/the-baseline-datastack-going-beyond&#34;&gt;The Baseline Data Stack&lt;/a&gt; and &lt;a href=&#34;https://www.linkedin.com/in/jamesdensmore/&#34;&gt;James Densmore&lt;/a&gt; in his book &lt;a href=&#34;https://www.oreilly.com/library/view/data-pipelines-pocket/9781492087823/&#34;&gt;Data Pipelines Pocket Reference&lt;/a&gt; describe a basic approach to moving data into a place from which it can be analysed. Build a pipeline to do a batch extract of data from the source system into a target store from which it can be worked on. No streaming, no fancy tooling - just good ole&amp;#39; ETL. Same as we saw above, right?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;
&lt;/p&gt;&lt;div class=&#34;tenor-gif-embed&#34; data-postid=&#34;23108779&#34; data-share-method=&#34;host&#34; data-aspect-ratio=&#34;1&#34; data-width=&#34;50%&#34;&gt;&lt;a href=&#34;https://tenor.com/view/sir-im-confused-butters-stotch-south-park-s15e6-city-sushi-gif-23108779&#34;&gt;Sir Im Confused Butters Stotch GIF&lt;/a&gt;from &lt;a href=&#34;https://tenor.com/search/sir+im+confused-gifs&#34;&gt;Sir Im Confused GIFs&lt;/a&gt;&lt;/div&gt; &lt;script type=&#34;text/javascript&#34; async=&#34;&#34; src=&#34;https://tenor.com/embed.js&#34;&gt;&lt;/script&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Well not really. Because instead of one or two sources, there are probably dozens if not hundreds. Instead of one central data warehouse there will be numerous data stores. And rather than just a set of static reports to print out for a Monday morning, the data is being used in every corner of the business on every device and platform you can imagine.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_all_change_please&#34;&gt;All Change, Please&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The world of software has been blown apart, driven in my opinion by the internet, Cloud, and open source.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://archive.org/download/X09-51175/preview.jpg&#34; alt=&#34;Microsoft SQL Server 2000 CD&#34; width=&#34;500&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Never mind placing an order for software and waiting for the installation media to arrive. The world of software is at our disposal and just a download link away. With Docker you can spin up and try a dozen data stores in a day and pick the one that suits you best. Cloud gives you the ability to provision capacity on which to run whatever youd like (IaaS), or as is widely the case provision the software itself (SaaS). They host it, they support it, they tune it - all you do it use it. Companies no longer have to choose simply between paying IBM for a mainframe license or Microsoft for a Windows licence, but whether to pay at all. Linux went from being a niche geek interest to the foundation on which a huge number of critical systems run. Oracle is still a dominant player in the RDBMS world but youre no longer an oddity if you propose to use Postgres instead.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;And speaking of a dozen data stores, nowadays there are stores specialised for every purpose. NoSQL, oldSQL, someSQL, NewSQL and everywhere in between. Graph, relational, and document. AWS in particular has leant into this, mirroring whats available to run yourself in their plethora of SaaS offerings in the data space.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_job_titles&#34;&gt;Job Titles&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In terms of job titles, back in the day you were often a &lt;em&gt;programmer&lt;/em&gt;, a &lt;em&gt;datawarehouse specialist&lt;/em&gt;, a &lt;em&gt;BI analyst&lt;/em&gt;, and all and many titles in between. Nowadays you have people who get the actual value out of the data that pays for all of this to happen, and they might still be called Analysts of one flavour or another but more often Data Scientists. This overlaps and bleeds into the ML world too. For a few years the people who got the data for the analysts to work with were &lt;a href=&#34;https://medium.com/free-code-camp/the-rise-of-the-data-engineer-91be18f1e603&#34;&gt;&lt;strong&gt;Data Engineers&lt;/strong&gt;&lt;/a&gt; (modelling the Software Engineers that &amp;#34;programmers&amp;#34; of old had become). It seems to me that this label has split further, with Data Engineering being the discipline of getting the data out of the source, building the pipelines to get it into some kind of staging area (e.g. data lake). From here the &lt;a href=&#34;https://benn.substack.com/p/why-do-people-want-to-be-analytics&#34;&gt;&lt;strong&gt;Analytics Engineers&lt;/strong&gt;&lt;/a&gt; take over, cleansing and perhaps restructuring it into a form and schema that is accessible and performant for the required use.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_where_to_start&#34;&gt;Where to Start?&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;So there is a &lt;strong&gt;lot&lt;/strong&gt; to cover, even if I were to just summarise across all of it. There are &lt;strong&gt;seventy seven&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;sub-categeries&lt;/em&gt;&lt;/strong&gt; alone in Matt Turcks useful survey of the landscape (&lt;a href=&#34;http://46eybw2v1nh52oe80d3bi91u-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/2020-Data-and-AI-Landscape-Matt-Turck-at-FirstMark-v1.pdf&#34;&gt;pdf&lt;/a&gt; / &lt;a href=&#34;http://dfkoz.com/ai-data-landscape/&#34;&gt;source data&lt;/a&gt; / &lt;a href=&#34;https://mattturck.com/data2020/&#34;&gt;article&lt;/a&gt;)and thats from 2 years ago  (lakeFS published something similar for &lt;a href=&#34;https://lakefs.io/the-state-of-data-engineering-2022/&#34;&gt;2022&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;What Im going to do is dig into some of the particular areas that have caught my eye, which is generally those closest related to the developments in the specific area of my interest - data engineering for analytics purposes. Even then Im sure Ill miss a huge swath of relevant content.&lt;/p&gt;
&lt;/div&gt;
&lt;hr/&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://rmoff.net/2022/09/14/data-engineering-in-2022-storage-and-access/&#34;&gt;Storage and Access&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://rmoff.net/2022/09/16/data-engineering-in-2022-exploring-lakefs-with-jupyter-and-pyspark/&#34;&gt;Exploring LakeFS with Jupyter and PySpark&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Query &amp;amp; Transformation Engines [TODO]&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ETL/ELT tools &amp;amp; Orchestration [TODO]&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Architectures &amp;amp; Terminology [TODO]&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://rmoff.net/2022/09/14/data-engineering-resources/&#34;&gt;Resources&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_footnote_so_what&#34;&gt;Footnote: &lt;em&gt;So What?&lt;/em&gt;&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;You may be wondering what is even the purpose of this blog? Theres no &amp;#34;call to action&amp;#34;, no great insight. And thats fine - this is just my notes for myself, and if theyre of interest to anyone else then they are welcome to peruse them :)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
    </item>
    <item>
      <title>Customising the fields shown in Airtable&#39;s Calendar .ics export</title>
      <link>https://rmoff.net/2022/09/12/customising-the-fields-shown-in-airtables-calendar-.ics-export/</link>
      <pubDate>2022-09-12</pubDate>
      
      <guid>https://rmoff.net/2022/09/12/customising-the-fields-shown-in-airtables-calendar-.ics-export/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2022/09/t_DSCF8251.jpeg" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://airtable.com&#34;&gt;Airtable&lt;/a&gt; is a rather wonderful tool. It powers &lt;a href=&#34;https://rmoff.net/2022/08/31/inside-the-sausage-factory-how-we-built-the-program-for-current-2022/&#34;&gt;the program creation backend process&lt;/a&gt; for Kafka Summit and Current. It does, however, have a few frustrating limitations - often where it feels like a feature was built on a Friday afternoon and they didnt get chance to finish it before knocking off to head to the pub.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_the_problem&#34;&gt;The Problem&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;One of these limitations is that the &lt;a href=&#34;https://support.airtable.com/docs/integrating-airtable-with-external-calendar-applications&#34;&gt;&lt;code&gt;.ics&lt;/code&gt; calendar sharing&lt;/a&gt; will only use the primary field of the table. Which means that a view that looks nice in Airtable:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2022/09/airtable01.png&#34; alt=&#34;Calendar view in Airtable with full details&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;will look like crap in your calendar application:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2022/09/airtable02.png&#34; alt=&#34;Fantastical showing record IDs&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Youd think that the &lt;strong&gt;labels&lt;/strong&gt; configured in the Calendar view:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2022/09/airtable03.png&#34; alt=&#34;Airtable calendar label config&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;would apply to the &lt;code&gt;.ics&lt;/code&gt; but apparently not. Airtable support confirmed that the primary field is all thats shown, and that this is a limitation.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_the_solution_kinda&#34;&gt;The Solution (kinda)&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This isnt a perfect solution because it wont automagically update as new records are added (&lt;em&gt;UPDATE: see note below on how to do this!&lt;/em&gt;). However, if you have a static set of records, or are content to do additional manual work when you add any, then it may still be useful for you.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;olist arabic&#34;&gt;
&lt;ol class=&#34;arabic&#34;&gt;
&lt;li&gt;
&lt;p&gt;Create a new table called &lt;code&gt;Calendar&lt;/code&gt; (or whatever you want)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Delete the columns that are created, and rename the primary field to something that represents the record that will be on the calendar. Since Im using it to represent sessions at a conference Im going to call it &lt;code&gt;Session&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2022/09/airtable04.png&#34; alt=&#34;New table&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Add a new field to the table, set it as a &lt;strong&gt;Link to another record&lt;/strong&gt; and select the source table which holds the records you want on the calendar.&lt;/p&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;When prompted, add the additional fields that you will want to use in the calendar:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Start date/time&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;End date/time (optional)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;All the fields you want to use in the label&lt;/p&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2022/09/airtable05.png&#34; alt=&#34;Add the link field&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;You should have a table that looks something like this:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2022/09/airtable06.png&#34; alt=&#34;Empty table with all the necessary fields&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Now the cludgy bit (and if theres a way to automate it, please do let me know!). Over in the source table, youll see a new column has been added for the link field to your new table (mines called &lt;code&gt;Calendar&lt;/code&gt; and so is the link field)&lt;/p&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2022/09/airtable07.png&#34; alt=&#34;Link field added to the source table&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Click on the &lt;strong&gt;header of the primary field of your source table&lt;/strong&gt; to select all the cells, and copy them to the clipboard (Cmd-C on the Mac).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2022/09/airtable08.png&#34; alt=&#34;Copying the primary field values&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Now click on the header of the new link field and paste from the clipboard (Cmd-V on the Mac).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2022/09/airtable09.png&#34; alt=&#34;Pasting the primary field values into the link field&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;When you go to your new table youll see it populated with records matching those in the source.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2022/09/airtable10.png&#34; alt=&#34;The new records in the link table&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Now to customise the primary field so that it displays the values that you want it to. Change the field type to &lt;strong&gt;Formula&lt;/strong&gt; and set the formula to a concatenation of the fields required&lt;/p&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2022/09/airtable11.png&#34; alt=&#34;Setting the primary field formula&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2022/09/airtable12.png&#34; alt=&#34;Resulting primary field values&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Now the process is as normal - create a Calendar view and set the start/end dates from the lookup fields included in your table:&lt;/p&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2022/09/airtable13.png&#34; alt=&#34;Setting the calendar start/end date fields&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The calendar will show using the primary field value by default (you dont need to customise the labels now):&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2022/09/airtable14.png&#34; alt=&#34;Calendar view showing records&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;And with the &lt;code&gt;.ics&lt;/code&gt; share link created
image::/images/2022/09/airtable15.png[.ics share link]&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;it renders exactly as we want it in our external calendar app:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2022/09/airtable16.png&#34; alt=&#34;External calendar view&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&#34;admonitionblock note&#34;&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td class=&#34;icon&#34;&gt;
&lt;i class=&#34;fa icon-note&#34; title=&#34;Note&#34;&gt;&lt;/i&gt;
&lt;/td&gt;
&lt;td class=&#34;content&#34;&gt;
If you add new records to the source table you need to make sure that the link field has the primary field value set in it, otherwise the Calendar table that weve created wont get an entry for it.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_update_airtables_support_is_awesome&#34;&gt;Update: AirTables Support is Awesome &lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;How cool is this? I shared my blog with AirTable support and they made a video showing how to close the loop on this and automate adding records to the Calendar table from the main one! Check it out:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/mEYl42Rhizs&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_bonus_points_fixing_the_time_zones_in_airtable_calendar&#34;&gt;Bonus Points: Fixing the Time Zones in Airtable Calendar&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Another hack here, but I honestly cant make head nor tail of the logic used in the date/time fields and time zones. In the absence of a way to set the time zone, Ive resorted to creating a derived field in the &lt;code&gt;Calendar&lt;/code&gt; table above and a formula to shift the time as necessary:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;rouge highlight&#34; style=&#34;background-color: #f8f8f8&#34;&gt;&lt;code data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;background-color: #f8f8f8&#34;&gt;DATEADD&lt;/span&gt;&lt;span style=&#34;background-color: #f8f8f8&#34;&gt;({&lt;/span&gt;&lt;span style=&#34;color: #000000;font-weight: bold&#34;&gt;Start&lt;/span&gt; &lt;span style=&#34;background-color: #f8f8f8&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #000000;font-weight: bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;background-color: #f8f8f8&#34;&gt;session_link&lt;/span&gt;&lt;span style=&#34;background-color: #f8f8f8&#34;&gt;)},&lt;/span&gt;&lt;span style=&#34;color: #009999&#34;&gt;5&lt;/span&gt;&lt;span style=&#34;background-color: #f8f8f8&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color: #d14&#34;&gt;&amp;#39;hours&amp;#39;&lt;/span&gt;&lt;span style=&#34;background-color: #f8f8f8&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2022/09/airtable17.png&#34; alt=&#34;Changing the time zone in an Airtable field&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;You can then reconfigure the Calendar view to use the new field with the fixed time zone:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2022/09/airtable18.png&#34; alt=&#34;Using the new fixed TZ field in Airtable calendar view&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
    </item>
    <item>
      <title>Inside the Sausage Factory: How we Built the Program for Current 2022</title>
      <link>https://rmoff.net/2022/08/31/inside-the-sausage-factory-how-we-built-the-program-for-current-2022/</link>
      <pubDate>2022-08-31</pubDate>
      
      <guid>https://rmoff.net/2022/08/31/inside-the-sausage-factory-how-we-built-the-program-for-current-2022/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2022/08/t_DSCF7575.jpeg" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;If youve ever been to a conference, particularly as a speaker whose submitted a paper that may or may not have been accepted, you might wonder quite how conferences choose the talks that get accepted.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I had the privilege of chairing the program committee for Current and Kafka Summit this year and curating the final program for both. Heres a glimpse behind the curtains of how we built the program for Current 2022. It was originally posted as a &lt;a href=&#34;https://twitter.com/rmoff/status/1549410161688813569&#34;&gt;thread on Twitter&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;For a conference about data, youd rightly expect that we use data when evaluating sessions and building the program for Kafka Summit and Current 2022. It starts with the &lt;a href=&#34;https://www.confluent.io/en-gb/blog/introducing-current-2022-program-committee/&#34;&gt;31 person program committee&lt;/a&gt; reviewing all the submissions to the &lt;a href=&#34;https://www.confluent.io/en-gb/blog/how-to-be-a-speaker-at-current-2022-the-next-kafka-summit/&#34;&gt;Call for Speakers&lt;/a&gt; in a tool called &lt;a href=&#34;https://sessionize.com&#34;&gt;Sessionize&lt;/a&gt; which uses the &lt;a href=&#34;https://en.wikipedia.org/wiki/Elo_rating_system&#34;&gt;Elo rating system&lt;/a&gt; for its magic.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The output from the session reviews is a single score for each talk, which along with a ton of metadata gets loaded into &lt;a href=&#34;https://airtable.com/&#34;&gt;Airtable&lt;/a&gt;. The review score then forms the basis for the first pass of building the program. Some talks are obviously great  whilst others are obviously not&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2022/08/1FYCQRYLWYAUS-iU.png&#34; alt=&#34;A top rated score&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2022/08/2FYCQR2cXoAED5dU.png&#34; alt=&#34;A bottom rated score&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;a id=&#34;passes&#34;&gt;&lt;/a&gt;
This is just the beginning of the process. If we built a program on abstract score alone it probably wouldnt be a very balanced program. There are many more factors to take into account.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://rmoff.net/images/2022/08/3FYCQjotXgAAzty-.png&#34; alt=&#34;List of the six passes that the program content goes through&#34;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;One of the things that the program committee does to help counteract the somewhat blunt &amp;#34;Average Rating&amp;#34; is provide comments for many of the submissions, which provides extra colour and context for the rating:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2022/08/comments.png&#34; alt=&#34;Some comments from the program committee about an abstract&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;You can read an analysis of some of the patterns I saw in the comments in &lt;a href=&#34;https://rmoff.net/2022/07/20/how-to-write-a-good-tech-conference-abstract-learn-from-the-mistakes-of-others/&#34;&gt;another article&lt;/a&gt; I wrote recently.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Another bit of data that I thought would be interesting to compare was the speaker ratings for the previous Kafka Summit with the abstract ratings for the same sessions. How correlated is the abstract rating with the resulting talk delivery?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;First up, a huge caveat. Speaker rating data is definitely sketchy at best. For Kafka Summit its collected through an app (that not everyone will have installed), not everyone leaves a rating, probably people who feel most strongly will take the time to leave a rating&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;and thats before you take into account the fact that a single number cant convey the full gamut of opinions a person may have (the same goes for abstract scores, BTW). Perhaps you couldnt hear the speaker and rate them down because of it (even though thats the AVs fault). Maybe the slides were crap but delivery great, or the delivery great but the content poor. Or maybe you had a sore head from the party the night before, or its nearly lunchtime and youre impatient for the session to finish.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;All these reasons and more contribute to the speaker score being a pretty crude measure. But a measure it is nonetheless, so lets take a look at it.
For Kafka Summit London the very best-rated sessions (top 10%) were all good picks based on the abstract score too&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2022/08/4FYCS9S8WAAAQH4V.png&#34; alt=&#34;4FYCS9S8WAAAQH4V&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;So does a top-rated abstract mean that youre going to get an excellent talk? Well, no, no it doesnt. Even excusing a few outliers and data burps, its pretty clear that a great abstract is no guarantee of a great talk.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2022/08/5FYCTKGKWYAA3Lms.png&#34; alt=&#34;5FYCTKGKWYAA3Lms&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;What about if we invert this? Are there bad abstracts that end up being great talks? Well, &lt;strong&gt;the data here is already biased for what arehopefullygoing to be good talks&lt;/strong&gt; (because why would you build a conference program from abstracts that were crap?).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Of the six abstracts with review scores below the median, three tanked (speaker score in bottom quartile or even bottom 10%)  but one beat the median speaker score and two were in the top quartile!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2022/08/6FYCUIDAWYAA5R09.png&#34; alt=&#34;6FYCUIDAWYAA5R09&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;What conclusions are there to draw from this? Firstly, the abstract isnt &lt;strong&gt;everything&lt;/strong&gt;. But does that mean you can put in a crap abstract and expect to be accepted because it might turn out to be a diamond in the rough? NO! 
Per the above data, the &lt;strong&gt;really bad&lt;/strong&gt; abstracts (bottom quartile) just dont get accepted. Period&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Make sure you put your best work into a good abstract because it gives you the best fighting chance. &lt;a href=&#34;https://rmoff.net/2020/01/16/how-to-win-or-at-least-not-suck-at-the-conference-abstract-submission-game/&#34;&gt;This blog&lt;/a&gt; and &lt;a href=&#34;https://rmoff.net/2022/07/20/how-to-write-a-good-tech-conference-abstract-learn-from-the-mistakes-of-others/&#34;&gt;this one&lt;/a&gt; gives you some advice, as does &lt;a href=&#34;https://developer.confluent.io/podcast/tips-for-writing-abstracts-and-speaking-at-conferences/&#34;&gt;this podcast&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;If we dont pick abstracts based on score alone, then what else factors into that? The &lt;a href=&#34;#passes&#34;&gt;screenshot earlier&lt;/a&gt; in the thread gives you some clues. For example, is the subject relevant to the audience at the conference? Is there a good representation of different technologies?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Make sure you come along to &lt;a href=&#34;https://2022.currentevent.io/&#34;&gt;Current 2022&lt;/a&gt; to see what you make of the program that weve got for you tickets are on sale now.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;(oh, and do all the speakers and future program committee a favour and &lt;strong&gt;always&lt;/strong&gt; leave session ratings for any conference youre at if you can )&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    <item>
      <title> Writing an abstract for a lightning talk </title>
      <link>https://rmoff.net/2022/08/31/%EF%B8%8F-writing-an-abstract-for-a-lightning-talk-%EF%B8%8F/</link>
      <pubDate>2022-08-31</pubDate>
      
      <guid>https://rmoff.net/2022/08/31/%EF%B8%8F-writing-an-abstract-for-a-lightning-talk-%EF%B8%8F/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2022/08/t_IMG_8372.jpeg" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;(&lt;a href=&#34;https://twitter.com/rmoff/status/1544257707049467905&#34;&gt;src&lt;/a&gt;)&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Lightning talks are generally 5-10 minutes. As the name implies - they are quick!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;A good lightning talk is not just your breakout talk condensed into a shorter time frame. You cant simply deliver the same material faster, or the same material at a higher level, or the same material with a few bits left out&lt;/p&gt;
&lt;/div&gt;
&lt;hr/&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;A good lightning talk has been specifically conceived of as a &lt;strong&gt;lightning talk&lt;/strong&gt;. Lets say its a ten minute talk. You get on stage, clear your throat, thank everyone for coming. Youre a minute in.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;You probably set the scene, explain why youre there, make a lame joke about conference coffee. Two minutes in. Eight to go.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;You have time to make one or two &lt;strong&gt;at most&lt;/strong&gt; salient points that you want the audience to walk away with at the end&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The whole tell people what youre going to tell them / tell it to them / tell them what you told themthats ok by me, its tried and tested - and so lets give a minute for &amp;#34;what youll tell them&amp;#34;, and a couple of minutes for &amp;#34;what you told them&amp;#34; recap&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Now were down to five minutes. FIVE MINUTES to actually tell the audience something useful. Thats &lt;strong&gt;plenty of time&lt;/strong&gt; if youve thought long and hard about what that useful nugget or two of info is. But its not going to materialise out of a breakout session abstract.&lt;/p&gt;
&lt;/div&gt;
&lt;hr/&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Think of your &amp;#34;elevator pitch&amp;#34; about the thing you want to talk about, and then flesh it out &lt;em&gt;just a tad&lt;/em&gt;. Thats your lightning talk there. Dont start with a long talk and cut it down. Start with the interesting nub of an idea and build around it &lt;em&gt;just a little bit&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Now you need to write your abstract.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Your abstract should mirror your talk: snappy, interesting, to the point, and engaging.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;If your abstract for a lighting talk takes longer to read and grok than the talk itself, youre maybe doing it wrong. Your abstract should set the scene, make it &lt;strong&gt;crystal clear&lt;/strong&gt; what the one or two things that youre going to deliver in your talk are, and then wrap up. Thats all.
You need to be specific.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&amp;#34;&lt;em&gt;Im going to talk about our project&lt;/em&gt;&amp;#34; is not specific.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&amp;#34;&lt;em&gt;Ill explain why we opted to deploy Kafka Connect in distributed mode rather than standalone&lt;/em&gt;&amp;#34; is specific.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Your abstract is your pitch; your abstract is the way the program committee will judge if your talk is likely to be any good. If your abstract is vague, waffly, boring, turgid, etc - the program committee are likely to assume that your talk will be too&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;
&lt;/p&gt;&lt;div class=&#34;tenor-gif-embed&#34; data-postid=&#34;10978886&#34; data-share-method=&#34;host&#34; data-aspect-ratio=&#34;1.85799&#34; data-width=&#34;100%&#34;&gt;&lt;a href=&#34;https://tenor.com/view/boring-bored-yawn-ali-g-gif-10978886&#34;&gt;Boring Bored GIF&lt;/a&gt;from &lt;a href=&#34;https://tenor.com/search/boring-gifs&#34;&gt;Boring GIFs&lt;/a&gt;&lt;/div&gt; &lt;script type=&#34;text/javascript&#34; async=&#34;&#34; src=&#34;https://tenor.com/embed.js&#34;&gt;&lt;/script&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;hr/&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Lightning talks can be out of the context of a larger project. Taking the example above - deploying Kafka Connect distributed vs standalone. Whether you did or didnt in your project, a lightning talk is a great way to share a cool tidbit of information youve learnt.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Found a cool way to run Kafka Connect in a Docker container thats not so well known? Good lightning talk idea.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Got a really cool code pattern for checking that messages are delivered? Good lightning talk idea.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Come up with a good workflow for debugging a Kafka client request in-flight thatll be useful for others? Good lightning talk idea.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Written a neat open-source tool thatll make Kafka SREs&amp;#39; lives easier and want to show it off? Good lightning talk idea.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;(Why open-source? Well, showing off a tool youve written that no-one outside your org can actually use is a bit like taking your cool toy to school and boasting about it and then saying &amp;#34; &lt;code&gt;ner ner ner you cant use it&lt;/code&gt; &amp;#34; to anyone who asks for a go)&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;
&lt;/p&gt;&lt;div class=&#34;tenor-gif-embed&#34; data-postid=&#34;13142173&#34; data-share-method=&#34;host&#34; data-aspect-ratio=&#34;2.40385&#34; data-width=&#34;100%&#34;&gt;&lt;a href=&#34;https://tenor.com/view/zach-galifinakis-hangover-hangover-alan-alan-hairflip-gif-13142173&#34;&gt;Zach Galifinakis Hangover GIF&lt;/a&gt;from &lt;a href=&#34;https://tenor.com/search/zach+galifinakis-gifs&#34;&gt;Zach Galifinakis GIFs&lt;/a&gt;&lt;/div&gt; &lt;script type=&#34;text/javascript&#34; async=&#34;&#34; src=&#34;https://tenor.com/embed.js&#34;&gt;&lt;/script&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;A good lightning talk is &lt;strong&gt;harder&lt;/strong&gt; to do than a breakout session in some ways. You have to be more disciplined in your delivery, you dont have the luxury of time to settle into it - by the time youve done that its time to wrap up. This means that the program committee will be looking for abstracts that suggest the speaker is capable of delivering a good lightning talk - not just a breakout session delivered at speed.&lt;/p&gt;
&lt;/div&gt;
&lt;hr/&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;What does a good lightning talk look like?&lt;/strong&gt; For me, the canonical example has to be this legendary one from &lt;a href=&#34;https://twitter.com/garybernhardt&#34;&gt;@garybernhardt&lt;/a&gt; - &lt;a href=&#34;https://www.destroyallsoftware.com/talks/wat&#34;&gt;WAT&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;
&lt;a target=&#34;_blank&#34; href=&#34;https://www.destroyallsoftware.com/talks/wat&#34;&gt;&lt;img src=&#34;https://www.destroyallsoftware.com/assets/posters/talks/wat.poster-4f5425901c10ffeaceb61f82e25dc40b9212aadf078cead0dc6ffe40696e2bec.png&#34; alt=&#34;screencap of WAT opening slide&#34;/&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    <item>
      <title>How to Write a Good Tech Conference Abstract - Learn from the Mistakes of Others</title>
      <link>https://rmoff.net/2022/07/20/how-to-write-a-good-tech-conference-abstract-learn-from-the-mistakes-of-others/</link>
      <pubDate>2022-07-20</pubDate>
      
      <guid>https://rmoff.net/2022/07/20/how-to-write-a-good-tech-conference-abstract-learn-from-the-mistakes-of-others/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2022/07/IMG_6823.jpeg" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Building the program for any conference is not an easy task. There will always be a speaker disappointed that their talk didnt get inor perhaps an audience who are disappointed that a particular talk &lt;em&gt;did&lt;/em&gt; get in. As the chair of the &lt;a href=&#34;https://www.confluent.io/en-gb/blog/introducing-current-2022-program-committee/&#34;&gt;program committee&lt;/a&gt; for &lt;a href=&#34;https://2022.currentevent.io/&#34;&gt;Current 22&lt;/a&gt; one of the things that Ive found really useful in building out the program this time round are the comments that the program committee left against submissions as they reviewed them.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;There were some common patterns I saw, and I thought it would be useful to share these here. Perhaps youre an aspiring conference speaker looking to understand what mistakes to avoid. Maybe youre an existing speaker whose abstracts dont get accepted as often as youd like. Or perhaps youre just curious as to what goes on behind the curtains :)&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Here are some of the headline mistakes that Ive seen made, along with the quoted comments from the program committee when they reviewed the abstract in question&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_a_good_title_is_not_enough&#34;&gt;A Good Title is Not Enough&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;best thing is the title.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;want to like this, but we need more in the abstract; cannot pick a session by title alone&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt; TIP: Fancy titles alone dont suffice. Your abstract needs to back up the title and be clear about what youre going to deliver in the talk.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_smart_is_fine_but_not_at_the_expense_of_your_abstract&#34;&gt;Smart is Fine, but Not at the Expense of Your Abstract&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Unclear what it is about. Speakers got lost in the nice allegory, completely missing the actual core content.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Cute, but no detail as to why this talk would be interesting, what the basis for the talk is, technology involved, etc.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Fun theming but theyve missed out the detail&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt; TIP: Making your abstract jump out by giving it a good theme or story can be a winning formula  but only if coupled with a solid background and explanation too. Think of the clever stuff as the icing on the cake. No-one wants to eat the whole bowl of icing itself.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_the_program_committee_are_rooting_for_you_to_succeed_but_a_bad_abstract_is_a_bad_abstract&#34;&gt;The Program Committee Are Rooting for You to Succeed - but a Bad Abstract Is a Bad Abstract&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Too sparse. Its a pity though, the speaker writes cool blog posts usually.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Knowing the speakers Im sure they have some interesting tech to share, but from the abstract I just cant tell what&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This talk could have been so amazing, but I have no idea what its going to cover&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt; TIP: The program committee dont like rejecting talks. Almost all of them are conference speakers themselves. They &lt;em&gt;want&lt;/em&gt; to accept your talk. But if the abstract is badly written, if its not clear what value your talk will bring, then its not going to get accepted.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_your_clever_title_might_actually_not_be_so_clever&#34;&gt;Your Clever Title Might Actually Not Be so Clever &lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I would not feel comfortable attending a talk with a suggestive title.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;the title creeps me out&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Is the titles reference appropriate for a tech conference?&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;If accepted, I recommend we re-title the talk to avoid negative wording&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt; TIP: Be conscious of your titles negative meanings and/or cultural resonances. A good example would be &amp;#34;&lt;em&gt;Make &amp;lt;x&amp;gt; Great Again&lt;/em&gt;&amp;#34; which was a popular pattern for titles on the conference circuit in previous years. Basing your talk title on the &lt;a href=&#34;https://en.wikipedia.org/wiki/Make_America_Great_Again#Use_by_Donald_Trump&#34;&gt;campaign slogan of a controversial politician&lt;/a&gt; might alienate some of your audience.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Another example would be &amp;#34;From Zero to Hero&amp;#34;-esque titles (of which &lt;a href=&#34;https://talks.rmoff.net/Itynf7&#34;&gt;Ive been guilty&lt;/a&gt; in the past). Some people may feel that referring to people new to a subject as &amp;#34;zeros&amp;#34; (and experts as &amp;#34;heros&amp;#34;) doesnt necessarily help propogate the kind of respectful community wed like.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_you_might_think_you_dont_need_to_write_much_of_an_abstract_but_the_program_committee_will_disagree&#34;&gt;You Might Think You Dont Need to Write Much of an Abstract, but the Program Committee Will Disagree&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;not enough information to accept&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Abstracts quite thin. Its a shame because I know speaker has some strong opinions on this topic and Im curious about what they are. :-(&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Will the talk be similarly thin on detail?&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Too thin. A pity though, speaker is doing good stuff.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Not enough detail in the abstract&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Thats just not enough for an abstract. Which is sad, because Im sure speaker has interesting things to tell. Really needs more detail to get me to bite.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Super vague. Vague, vague, vague.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt; TIP: &lt;strong&gt;You&lt;/strong&gt; might know what youre going to talk about but the program committee are not telepathic! Writing a good abstract isnt always easy, but submitting something half-finished is not likely to get you accepted to the conference.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_help_the_program_committee_and_they_will_help_you_hinder_them_and_they_might_not&#34;&gt;Help the Program Committee and They Will Help You. Hinder Them, and They Might Not!&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;huge text wall. hard to digest also the way its written.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This isnt very well written. Can we start with line breaks and then work out what each paragraph is trying to achieve?&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Very unclear abstract. Hard to read (use line breaks!). Next time start from the point of the audience - what will they gain from this talk? Why would it be interesting to them?&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt; TIP: The program committee for a conference will usually have &lt;em&gt;hundreds&lt;/em&gt; of abstracts to review. Do them a favour and put them in a good mood by making your abstract well formatted and easy to read. Paragraph breaks, punctuation, and a sensible length (3-4 paragraphs max, usually) all help.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_make_your_abstract_intelligible&#34;&gt;Make Your Abstract Intelligible&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I may not be the sharpest knife in the drawer, but Ive read through this a few times and still cant quite make out what the talk is about.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This is really jumbled. I can just about figure out what the talks going to be about, but an attendee shouldnt have to.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Ive read an abstract a few times. and I still dont understand what this talk is about&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt; TIP: Dont make people have to play detective and make assumptions about what your talk is about. As with the point about abstracts that are too brief, abstracts that are toowellabstract will also struggle. The program committee needs to have a clear picture of what your talk is about, what youll cover, what the audience will learn from it.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_sometimes_you_just_cant_win_lolsob&#34;&gt;Sometimes You Just Cant Win &lt;code&gt;:lolsob:&lt;/code&gt;&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The scope feels too narrow[]&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;this looks like a nicely focused topic []&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;(these comments were left by two reviewers for the very same abstract)&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt; TIP: Perhaps youve written the best abstract in the world, and still got your talk rejected. Dont be disheartened. Conference speaking is a numbers game and even the seasoned professionals who do this &lt;em&gt;for a living&lt;/em&gt; will get plenty of rejections (FWIW my success rate is around 34%).&lt;/p&gt;
&lt;/div&gt;
&lt;hr/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_more_abstract_writing_advice&#34;&gt;More Abstract Writing Advice&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;For more advice on writing a good abstract, check out &lt;a href=&#34;https://rmoff.net/2020/01/16/how-to-win-or-at-least-not-suck-at-the-conference-abstract-submission-game/&#34;&gt;this article&lt;/a&gt; that I wrote, and &lt;a href=&#34;https://developer.confluent.io/podcast/tips-for-writing-abstracts-and-speaking-at-conferences/&#34;&gt;this podcast&lt;/a&gt; that I recorded with my colleague and fellow program committee member &lt;a href=&#34;https://twitter.com/krisajenkins&#34;&gt;Kris Jenkins&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
    </item>
    <item>
      <title>Remote-First Developer Advocacy</title>
      <link>https://rmoff.net/2022/04/07/remote-first-developer-advocacy/</link>
      <pubDate>2022-04-07</pubDate>
      
      <guid>https://rmoff.net/2022/04/07/remote-first-developer-advocacy/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2022/04/IMG_4948.jpeg" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Im convinced that a developer advocate &lt;em&gt;can&lt;/em&gt; be effective remotely. As a profession, weve all spent two years figuring out how to do just that. Some of it worked out great. Some of it, less so.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I &lt;a href=&#34;https://rmoff.net/2022/04/07/hanging-up-my-boarding-passes-and-jetlagfor-now/&#34;&gt;made the decision&lt;/a&gt; during COVID to stop travelling as part of my role as a developer advocate. In this article, I talk about my experience with different areas of advocacy done remotely.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_virtual_conferences&#34;&gt;Virtual Conferences&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt; bleugh. nah . nope .&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;This is the obvious one: do what you did before (conferences) but from home&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Ive &lt;a href=&#34;https://rmoff.net/2020/12/03/life-as-a-developer-advocate-nine-months-into-a-pandemic/#_virtual_conferences_as_a_speaker&#34;&gt;written&lt;/a&gt; &lt;a href=&#34;https://rmoff.net/2020/03/13/are-tech-conferences-dead/&#34;&gt;before&lt;/a&gt; about virtual conferences, so I shant rehash it here. Short to say, as a speaker, Ive had my fill of talking to a faceless webcam, and Im pretty sure as attendees most people are quite content to watch a video on YouTube at a later date than attending an online event that is almost, but not quite, entirely unlike an actual conference.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;A few managed to put on good virtual conferences. The folk over at Container Solutions hosted &lt;a href=&#34;https://rmoff.net/2020/03/13/are-tech-conferences-dead/#_software_circus&#34;&gt;Software Circus&lt;/a&gt; which was a good example of a virtual conference done well. But by and large, virtual conferences were and are a dispiriting affair for all involved.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_video_youtube&#34;&gt;Video (YouTube)&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;Just as the vacuum cleaner is known by most as a Hoover, the same for video platforms on which we disseminate material for developers. Its YouTube, and theres no point beating around that bush. TikTok et al are a different beast, and Im not considering those here.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Many developer advocates, &lt;a href=&#34;http://youtube.com/rmoff&#34;&gt;myself included&lt;/a&gt;, took to YouTube at the beginning of the pandemic. It was an obvious outlet - if we couldnt be on stage, then damnit, wed get ourselves in front of a camera.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;My experience with YouTube started from knowing nothing about it, nothing about making videos, nada. After a while (&lt;em&gt;and with some great advice along the way from my friends and former colleagues &lt;a href=&#34;https://twitter.com/gAmUssA&#34;&gt;@gAmUssA&lt;/a&gt; &lt;a href=&#34;https://twitter.com/tlberglund&#34;&gt;@tlberglund&lt;/a&gt;&lt;/em&gt;) I got to the point of being able to make a passingly competent amateur YouTube video. I really enjoyed itand I reached a bunch of developers in the process!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2022/04/2022-04-07_22-18-51.png&#34; alt=&#34;2022 04 07 22 18 51&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;There have been one hundred and sixty five THOUSAND views of my videos, adding up to 14.2k hours (over 1.6 YEARS) watched :-) That is not to sound conceited, but to emphasise the point that if someone like mewith a face made for radio and video editing skills to matchcan reach developers in that way, then any developer advocate can.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Another neat thing about YouTube is that it has a long tail for anything still relevant. You can see that the views per month goes up and up until the last time I published a videobut they dont go down after that and just plateauthat is, there are still around 8 thousand views of my videos per month, even now.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2022/04/FOESNmcXEAIOGFG.jpeg&#34; alt=&#34;FOESNmcXEAIOGFG&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I made many of these videos months (if not years) ago, but theyre still getting thousands of views. Its true to an extent for any content published onlinebut YouTubes automagic algorithm I think must do more to boost continued traffic to it than would be got by, say, a blog sitting on a dusty corner of the internet.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;One of the patterns that I found most successful and rewarding as an author was to pair a blog with a video. Id research the subject, write up a demo script, record it, and then publish all of it. That way folk who like video can watch video, and those who prefer to read and/or want to try out the code shown can also do so. I used &lt;a href=&#34;https://github.com/confluentinc/demo-scene/tree/master/kafka-connect-single-message-transforms&#34;&gt;GitHub&lt;/a&gt; to host all the code samples. You can see the published results &lt;a href=&#34;https://rmoff.net/2021/02/17/ksqldb-howto-a-mini-video-series/&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2022/04/FOETklcX0AAjp-B.jpeg&#34; alt=&#34;FOETklcX0AAjp B&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I also learnt plenty about recording and editing video. Screenflow did the job well and its learning curve was ok for time invested. A decent camera and lighting helps too&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;https://rmoff.net/images/2022/04/2022-04-07_22-33-17.png&#34; alt=&#34;2022 04 07 22 33 17&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;You can read more about my YouTube journey in &lt;a href=&#34;https://talks.rmoff.net/rgvKMl&#34;&gt;this short talk&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Just as some developer advocates will focus on conference speaking and have their keynotes down to a T, many will focus on video nowadays. As a result, it would not be unusual to expect a developer advocate to not only be comfortable on presenting on screen, but also producing and editing such a video.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_blogging&#34;&gt;Blogging&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Blogging was always there for us when we were off the road, and its still here for us now. Whilst some developers learn through watching (like with YouTube, above), others learn through reading. A well-written blog can be the kind of material with a long, long tail. It can &lt;a href=&#34;https://rmoff.net/2018/03/06/why-do-we-need-streaming-etl/&#34;&gt;promote an idea&lt;/a&gt;, it can &lt;a href=&#34;https://rmoff.net/2021/02/26/loading-delimited-data-into-kafka-quick-dirty-but-effective/&#34;&gt;solve a specific problem&lt;/a&gt;, or &lt;a href=&#34;https://rmoff.net/2019/12/18/detecting-and-analysing-ssh-attacks-with-ksqldb/&#34;&gt;illustrate a fun idea&lt;/a&gt;. Ive &lt;a href=&#34;https://rnm1978.wordpress.com/2009/03/&#34;&gt;always loved blog writing&lt;/a&gt;, and still do.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_meeting_developers_where_they_are_online&#34;&gt;Meeting developers where they are online&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;If youre not at conferences, meetups, or customer site visits, how do you know what developers are doing? How can you advocate &lt;em&gt;for&lt;/em&gt; developers and not just &lt;em&gt;to&lt;/em&gt; them? The value of a developer advocate to an organisation is not just the outbound advocacy but the inbound. The bug reports, the &amp;#34;&lt;em&gt;this damn sharp edge catches me out every time&lt;/em&gt;&amp;#34;, the &amp;#34;&lt;em&gt;I was trying to build this thing with your product&lt;/em&gt;&amp;#34; stories. If youre face to face with developers you cant help but have these conversations. If youre not travelling, then you have to find that elsewhere.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Thankfully in this day and age, the internet is pretty much ubiquitous amongst developers. Getting answers from StackOverflow is second nature to many. Taking to Twitter to chat and &lt;a href=&#34;https://twitter.com/rmoff/status/1448230290657251338&#34;&gt;shitpost&lt;/a&gt; is standard. And amongst the shitposting and noise are golden nuggets of information. Conversations to spark up. Ideas to pursue.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Something Ive done whilst at Confluent is help launch a &lt;a href=&#34;https://forum.confluent.io/&#34;&gt;Discourse-based forum&lt;/a&gt; to complement the existing Slack workspace that we have. With these two platforms I can listen to and help potentially tens of thousands of developers.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;As well as on our community platforms, Ive had a lot of great interactions on &lt;a href=&#34;https://stackoverflow.com/questions/tagged/apache-kafka&#34;&gt;StackOverflow&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/search?q=apachekafka&#34;&gt;Twitter&lt;/a&gt;, and &lt;a href=&#34;https://www.reddit.com/r/apachekafka/&#34;&gt;Reddit&lt;/a&gt;. Find out where your communities hang out, and go &lt;strong&gt;to&lt;/strong&gt; them. A community platform that you curate and run is a nice space thats familar and important to have, but remember that developers may not take the time to look for &lt;strong&gt;your&lt;/strong&gt; platform. General tech platforms like StackOverflow (and appropriate subreddits) are where devs also head, and if you dont participate in those then youre ignoring part of your audience.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I see several concrete results and benefits from interacting with the online community:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;olist arabic&#34;&gt;
&lt;ol class=&#34;arabic&#34;&gt;
&lt;li&gt;
&lt;p&gt;Enriching and strengthening the community by helping answer questions, model good behaviour, welcoming new users.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Developing an online reputation as a person who is helpful and hopefully to be trusted, and not as a shill who only talks &lt;em&gt;at&lt;/em&gt; developers. When my name is subsequently seen on a blog or video Im &lt;em&gt;that guy&lt;/em&gt; who already helped them.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Get ideas for blog posts and talks. Some of my most popular material started life as this. My favourite is an &lt;a href=&#34;https://talks.rmoff.net/qrgjuz/all-at-sea-with-streams-using-kafka-to-detect-patterns-in-the-behaviour-of-ships&#34;&gt;entire conference talk&lt;/a&gt; sparked by interest in a single fascinating question that someone asked on our Slack group.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Spot opportunity for product and documentation feedback. Sometimes this is just logging a ticket; oftentimes its arranging an introduction between the community member and the relevant product manager or engineer related to the issue being discussed.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_developer_experience&#34;&gt;Developer Experience&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The team Im part of is called &lt;code&gt;DevX&lt;/code&gt;, or Developer Experience. It broadly encompasses all the usual DevRel areas youd expect, but its name also suggests a crucial part of what a developer advocate can provide. Just as the interface on a web app will be designed and refined by the UX (User Experience) team, a developers interactions with software, its APIs, and its documentation falls broadly under the &amp;#34;Developer Experience&amp;#34;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Developer Advocates are well placed to be a key resource for improving developer experience, because they &lt;strong&gt;are&lt;/strong&gt; developers, and part of their job is communicating. A good developer advocate should be able to not only identify a friction point but articulate how a developer would expect it to behave, and communicate clearly how to do this. That could be an API in the software, an error message, a tutorial, or anything else that developers interface with.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This in particular has been a large part of my role in recent months, with a focus on &lt;a href=&#34;https://developer.confluent.io&#34;&gt;Confluent Developer&lt;/a&gt; - helping make it a resource that &lt;strong&gt;developers&lt;/strong&gt; want to use.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_conferences&#34;&gt;Conferences&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Not speaking at them, but helping organise them. Just as a developer advocate represents the voice of the developer back to departments, including product and engineering, they can also speak well for developers when it comes to organising conferences and selecting their programs.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Ive had the honour this year of chairing the &lt;a href=&#34;https://www.kafka-summit.org/events/kafka-summit-london-2022/&#34;&gt;Kafka Summit London 2022&lt;/a&gt; program committee, and it has been hugely rewarding. Being able to influence the program and help draw in talks from the community has been great, and I cant wait for the conference itself later this month. And yes, Ill be travelling to that :)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_building_stuff_the_devxdevrel_engineer_role&#34;&gt;Building stuff (the DevX/DevRel Engineer role)&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In recent times Ive noticed an increase in the &lt;code&gt;Engineer&lt;/code&gt; job title in the DevRel space (&lt;code&gt;DevEx Engineer&lt;/code&gt; for example), and it usefully captures a huge part of what some DevRel folk do. Behind many brilliant talks lies some great code that enabled that demo. Supporting many a successful implementation of your product may be a library or set of hacks.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Creating demos, writing the &amp;#34;sticky tape&amp;#34; scripts and examplesthese are great examples of DevRel engineering. In many cases it will be the person doing the talk that wrote the demo, that spun out script from another talk into its own github repo. But there are plenty of cases where the engineer and advocate can work collaboratively for efficiency and scale.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_soare_you_saying_that_travel_is_redundant_in_developer_advocacy&#34;&gt;SoAre You Saying That Travel Is Redundant in Developer Advocacy?&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Dont be ridiculous :-P&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Humans crave face-to-face interactions. Virtual conferences will &lt;em&gt;never&lt;/em&gt; come close to replicating that. The in-person conference will always be a thing, and developer advocates can play an important role in bringing new technologies and ideas to developers at these conferencesand feeding back conversations and ideas from them to their company.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;My thesis is that you dont &lt;strong&gt;have&lt;/strong&gt; to travel. It is &lt;em&gt;not&lt;/em&gt; that you &lt;em&gt;shouldnt&lt;/em&gt; travel.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This is also on a personal level. Can I, as a developer advocate having &lt;a href=&#34;https://rmoff.net/2022/04/07/hanging-up-my-boarding-passes-and-jetlagfor-now/&#34;&gt;chosen to stop travelling&lt;/a&gt;, still be effective? Yes, I think so. Can a companys entire DevRel efforts be done virtually as effectively as they might be with a proportion of travel involved? I would say not.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_resources&#34;&gt;Resources&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://twitter.com/flyless_dev&#34;&gt;flyless.dev&lt;/a&gt; came about around the same time as the COVID lockdowns, with the premise of basically this article - as developer advocates, can we fly less? Do we really need to get on an aeroplane to go to a conference?&lt;/p&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Its a really friendly community, and they have a great &lt;a href=&#34;https://discord.com/invite/FWauQ9Vj&#34;&gt;Discord server&lt;/a&gt; on which there are weekly gatherings. You can also find a few &lt;a href=&#34;https://www.youtube.com/channel/UCBKQHEoNoTJ4CxpW5shqRvA&#34;&gt;recordings of earlier meetups&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;A++++ would recommend.&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ricardo Ferreira wrote a good article about creating &lt;a href=&#34;https://riferrei.com/how-to-create-more-effective-developer-content/&#34;&gt;effective developer content&lt;/a&gt;, which is very relevant in this context.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
    </item>
    <item>
      <title>Hanging up my Boarding Passes and Jetlagfor now</title>
      <link>https://rmoff.net/2022/04/07/hanging-up-my-boarding-passes-and-jetlagfor-now/</link>
      <pubDate>2022-04-07</pubDate>
      
      <guid>https://rmoff.net/2022/04/07/hanging-up-my-boarding-passes-and-jetlagfor-now/</guid>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://rmoff.net/images/2022/04/IMG_8109.jpeg" medium="image" type="image/jpg" width="100" height="100" />
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I recently started writing an abstract for a conference later this year and realised that Im not even sure if I want to do it. Not the conferenceits a great onebut just the whole up on stage doing a talk thing. I cant work out if this is just nerves from the amount of time off the stage, or something more fundamental to deal with.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I know many Developer Advocates have been chomping at the bit to get back to proper conference speaking since COVID hit, so perhaps Im on my own going through this kind of thought process?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The weird thing is that when I get the time-hop photos of past conferences pop up on my phone, I get a proper kick of nostalgia and feel like Ive missed it like crazy - but now I come to think about actually doing it again, Im just not quite sure. Do I actually want to go back to what I was doing before?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;And then the scary thing about acknowledging that I would be doing something different is that I realise that being a Developer Advocate on stage, online, gave me an inherent sense of self-worth. I was being helpful; people liked my talks, and I was helping them. Quantifying if youre succeeding in other roles isnt always so easy.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This post has been in my drafts folder for several months now, and its time to get it into shape and publish it. Its a mixture of a navel-gazing diary entry and a blog about life as a developer advocate.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_some_serious_self_reflection&#34;&gt;Some serious self-reflection&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;COVID was a bastard. It still is, albeit less so in terms of the number of people that its killing. But what it did give me was space to reflect on my job as a Developer Advocate, and specifically its impact on my home life. I wrote about it in depth &lt;a href=&#34;https://rmoff.net/2020/12/03/life-as-a-developer-advocate-nine-months-into-a-pandemic/&#34;&gt;previously&lt;/a&gt; and sixteen months later stand by everything I wrote, if not more so.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;If I had to tl;dr my thoughts back then into one paragraph, it would be &lt;a href=&#34;https://rmoff.net/2020/12/03/life-as-a-developer-advocate-nine-months-into-a-pandemic/#_being_honest&#34;&gt;this one&lt;/a&gt;. And of that, the most crucial point thenand nowwas this assertion:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The kids are used to me travelling; its fine.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;As I noted when I wrote this, my kids were &lt;em&gt;used to it&lt;/em&gt;, but that is &lt;strong&gt;not to say it was fine, at all&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I am truly thankful for the opportunity that not travelling afforded me to appreciate what it would mean to my relationship with my family to be at home all the time.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I try to avoid having regrets, but I am somewhat sad to think of the years that I was around less and missed out, particularly on time with my children. &amp;#34;&lt;em&gt;You dont get that time with them again&lt;/em&gt;&amp;#34; is an oft-repeated phrase, but it is true in every sense. The nuance thats often missed from that expression is that its easy to convince oneself that since one is spending &lt;em&gt;some&lt;/em&gt; time then that counts as &amp;#34;&lt;em&gt;that time&lt;/em&gt;&amp;#34;. But it doesnt. Being around 70% of the time is a world of difference from being around 100% of the time.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I made this point &lt;a href=&#34;https://rmoff.net/2020/12/03/life-as-a-developer-advocate-nine-months-into-a-pandemic/#_the_whole_is_less_than_the_sum_of_the_parts&#34;&gt;before&lt;/a&gt;, but if youre away 30% of the time, that doesnt mean you simply step back in to the same remaining 70% of home life that you would do were you around all the time. Being away fundamentally alters your standing and relationship in the family. Im not saying it changes it &lt;em&gt;negatively&lt;/em&gt; per se - but just that it alters it. Youre not the person who comes home from the office (or emerges from the home study) every evening for tea, to chat about the day, how was school, what funny toilet joke did your kids hear. Youre the person who &lt;em&gt;might&lt;/em&gt; be there, who &lt;em&gt;might&lt;/em&gt; be around to share a story with or who &lt;em&gt;might&lt;/em&gt; instead be on the end of a FaceTime call, probably running through an airport or on a weird timezone.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;All families are different. All relationships are different. But I have found being off the road truly wonderful. My relationship with my children is much closer.  Life is more stable. More solid.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_so_what_now&#34;&gt;So what now?&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;Im not going to be travelling again as part of my job&lt;/strong&gt;. To be precise: Ill travel &lt;em&gt;now and then&lt;/em&gt;, but not as a central part of my role. Im still going to be a Developer Advocate at Confluent. Im just going to be doing it from home.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Honestly? Thats a little bit scary. Getting on an aeroplane or train to go to a conference &lt;em&gt;was what I did for my job&lt;/em&gt;. Everything else fitted in around that. But the fundamental truth is that I want to be at home to be an integral part of my kids&amp;#39; lives growing up.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I do recognise that some people would &lt;em&gt;love&lt;/em&gt; to be at home but &lt;em&gt;have&lt;/em&gt; to be on the road, and I acknowledge the privilege of my situation of being able to &lt;em&gt;choose&lt;/em&gt; not to travel. I also appreciate the willingness of my employer to support me in that choice.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;So what now&lt;/strong&gt;? Can I even call myself a Developer Advocate once my airline status has dropped from platinum, my conference swag wardrobe has faded into threads in the wash, and I occassionally join the gibbering masses flailing around at security whilst the practised professionals tut quietly behind me?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Read my &lt;a href=&#34;https://rmoff.net/2022/04/07/remote-first-developer-advocacy/&#34;&gt;next post&lt;/a&gt; to see what I think that it means to be a Developer Advocate and not travel.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
    </item>
    
  </channel>
</rss>