<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8" />

  
  <title>Streaming data from Kafka into Elasticsearch</title>

  
  
  <link href="//cdn.jsdelivr.net" rel="dns-prefetch">
  <link href="//cdnjs.cloudflare.com" rel="dns-prefetch">
  <link href="//at.alicdn.com" rel="dns-prefetch">
  <link href="//fonts.googleapis.com" rel="dns-prefetch">
  <link href="//fonts.gstatic.com" rel="dns-prefetch">
  
  
  
  
  

  

  
  <meta name="author" content="Robin Moffatt">
  <meta name="description" content="This article is part of a series exploring Streaming ETL in practice. You can read about setting up the ingest of realtime events from a standard Oracle platform, and building streaming ETL using KSQL.
This post shows how we take data streaming in from an Oracle transactional system into Kafka, and simply stream it onwards into Elasticsearch. This is a common pattern, for enabling rapid search or analytics against data held in systems elsewhere.">

  
  
    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="@gohugoio">
    <meta name="twitter:title" content="Streaming data from Kafka into Elasticsearch">
    <meta name="twitter:description" content="This article is part of a series exploring Streaming ETL in practice. You can read about setting up the ingest of realtime events from a standard Oracle platform, and building streaming ETL using KSQL.
This post shows how we take data streaming in from an Oracle transactional system into Kafka, and simply stream it onwards into Elasticsearch. This is a common pattern, for enabling rapid search or analytics against data held in systems elsewhere.">
    <meta name="twitter:image" content="/images/avatar.jpg">
  

  
  <meta property="og:type" content="article">
  <meta property="og:title" content="Streaming data from Kafka into Elasticsearch">
  <meta property="og:description" content="This article is part of a series exploring Streaming ETL in practice. You can read about setting up the ingest of realtime events from a standard Oracle platform, and building streaming ETL using KSQL.
This post shows how we take data streaming in from an Oracle transactional system into Kafka, and simply stream it onwards into Elasticsearch. This is a common pattern, for enabling rapid search or analytics against data held in systems elsewhere.">
  <meta property="og:url" content="https://rmoff.github.io/post/streaming-data-from-kafka-into-elasticsearch/">
  <meta property="og:image" content="/images/avatar.jpg">




<meta name="generator" content="Hugo 0.52">


<link rel="canonical" href="https://rmoff.github.io/post/streaming-data-from-kafka-into-elasticsearch/">

<meta name="renderer" content="webkit">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="format-detection" content="telephone=no,email=no,adress=no">
<meta http-equiv="Cache-Control" content="no-transform">


<meta name="robots" content="index,follow">
<meta name="referrer" content="origin-when-cross-origin">







<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="apple-mobile-web-app-title" content="rmoff.net">
<meta name="msapplication-tooltip" content="rmoff.net">
<meta name='msapplication-navbutton-color' content="#5fbf5e">
<meta name="msapplication-TileColor" content="#5fbf5e">
<meta name="msapplication-TileImage" content="/images/tile-image-windows.png">
<link rel="icon" href="/images/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
<link rel="icon" sizes="192x192" href="/images/touch-icon-android.png">
<link rel="apple-touch-icon" href="/images/touch-icon-apple.png">


<link rel="preload" href="/styles/main.min.css" as="style">
<link rel="preload" href="https://fonts.googleapis.com/css?family=Lobster" as="style">
<link rel="preload" href="/images/avatar.jpg" as="image">
<link rel="preload" href="/images/grey-prism.svg" as="image">


<style>
  body {
    background: rgb(244, 243, 241) url('/images/grey-prism.svg') repeat fixed;
  }
</style>
<link rel="stylesheet" href="/styles/main.min.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lobster">


<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.2/dist/medium-zoom.min.js"></script>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/video.js@7.3.0/dist/video-js.min.css">



  
  
<!--[if lte IE 8]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/videojs-ie8@1.1.2/dist/videojs-ie8.min.js"></script>
<![endif]-->

<!--[if lte IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/eligrey-classlist-js-polyfill@1.2.20180112/classList.min.js"></script>
<![endif]-->


<script src="https://cdn.jsdelivr.net/npm/smooth-scroll@14.2.1/dist/smooth-scroll.polyfills.min.js"></script>


</head>
  <body>
    
    <div class="suspension">
      <a title="Go to top" class="to-top is-hide"><span class="icon icon-up"></span></a>
      
        
      
    </div>
    
    
  <header class="site-header">
  <img class="avatar" src="/images/avatar.jpg" alt="Avatar">
  
  <h2 class="title">rmoff.net</h2>
  
  <p class="subtitle"></p>
  <button class="menu-toggle" type="button">
    <span class="icon icon-menu"></span>
  </button>
  <nav class="site-menu collapsed">
    <h2 class="offscreen">Main Menu</h2>
    <ul class="menu-list">
      
      
      
      
    </ul>
  </nav>
  <nav class="social-menu collapsed">
    <h2 class="offscreen">Social Networks</h2>
    <ul class="social-list"></ul>
  </nav>
</header>

  <section class="main post-detail">
    <header class="post-header">
      <h1 class="post-title">Streaming data from Kafka into Elasticsearch</h1>
      <p class="post-meta">@Robin Moffatt · Mar 6, 2018 · 2 min read</p>
    </header>
    <article class="post-content"><p><em>This article is part of a series exploring Streaming ETL in practice. You can read about <a href="https://rmoff.net/2018/02/01/howto-oracle-goldengate-apache-kafka-schema-registry-swingbench/">setting up the ingest of realtime events from a standard Oracle platform</a>, and <a href="https://www.confluent.io/blog/ksql-in-action-real-time-streaming-etl-from-oracle-transactional-data">building streaming ETL using KSQL</a>.</em></p>

<hr />

<p>This post shows how we take data streaming in from an Oracle transactional system into Kafka, and simply stream it onwards into Elasticsearch. This is a common pattern, for enabling rapid search or analytics against data held in systems elsewhere.</p>

<p>We&rsquo;ll use Kafka Connect to stream the Avro topics directly into Elasticsearch. Because we&rsquo;re using Avro and the schema registry all of our Elasticsearch mappings will be created automagically and with the correct datatypes. You can read more about using Kafka Connect to build pipelines in an earlier blog series here: <a href="https://www.confluent.io/blog/simplest-useful-kafka-connect-data-pipeline-world-thereabouts-part-1/">1</a> <a href="https://www.confluent.io/blog/blogthe-simplest-useful-kafka-connect-data-pipeline-in-the-world-or-thereabouts-part-2/">2</a> <a href="https://www.confluent.io/blog/simplest-useful-kafka-connect-data-pipeline-world-thereabouts-part-3/">3</a>.</p>

<p><img src="/content/images/2018/02/connectsrwin.png" alt="" /></p>

<p>Create the Connect sink configuration file—note that we&rsquo;re using Single Message Transforms (SMT) to set Timestamp datatype for <code>op_ts</code> and <code>current_ts</code>. We&rsquo;re doing this to get around a limitation in the current release of GoldenGate in which date/timestamps are simply passed as strings. In order for Elasticsearch to work seamlessly, we want the Kafka Connect sink to pass the datatype as a timestamp—which using the SMT will enable.</p>

<p>Write <a href="https://gist.github.com/rmoff/975707be38b452f79347cde065b2322b">this</a> to <code>/home/oracle/es-sink-soe-all.json</code></p>

<p>Load the sink:</p>

<pre><code>confluent load es-sink-soe-all -d /home/oracle/es-sink-soe-all.json
</code></pre>

<p>Check status:</p>

<pre><code>confluent status connectors|  jq '.[]'|  xargs -I{connector} confluent status {connector}|  jq -c -M '[.name,.connector.state,.tasks[].state]|join(&quot;:|:&quot;)'|  column -s : -t|  sed 's/\&quot;//g'|  sort
</code></pre>

<p>If it&rsquo;s <code>FAILED</code> then check the Connect log:</p>

<pre><code>confluent log connect
</code></pre>

<p>Check Elasticsearch doc count:</p>

<pre><code>curl -s &quot;http://localhost:9200/soe.warehouses/_search&quot; | jq '.hits.total'
1000
</code></pre>

<p>From here, with the data now in Elasticsearch, you can go and build Kibana dashboards to your heart&rsquo;s content.</p>

<p><img src="/content/images/2018/02/ogg01.png" alt="" /></p>

<p><img src="/content/images/2018/02/ogg02.png" alt="" /></p>

<p>Here&rsquo;s a very simple one of median/max Order values and counts over time, along with a histogram plot showing the distribution of order values.</p>

<p><img src="/content/images/2018/02/oggkib01.png" alt="" /></p>

<p>Remember that this is based on data streaming through from our source transactional system, with two particular benefits:</p>

<ol>
<li>We&rsquo;ve not had to modify the source application at all to provide this data</li>
<li>It&rsquo;s extremely low latency, giving us a near-realtime analytics view of our data</li>
</ol>

<hr />

<p><em>To read more about this, and see the awesome KSQL in action, head over to the <a href="https://www.confluent.io/blog/">Confluent blog</a></em></p>
</article>
    <footer class="post-footer">
      
      <ul class="post-tags">
        
          <li><a href="/tags/kafka-connect"><span class="tag">Kafka Connect</span></a></li>
        
          <li><a href="/tags/elasticsearch"><span class="tag">Elasticsearch</span></a></li>
        
          <li><a href="/tags/kafka"><span class="tag">Kafka</span></a></li>
        
          <li><a href="/tags/oracle"><span class="tag">Oracle</span></a></li>
        
          <li><a href="/tags/streaming-etl"><span class="tag">Streaming Etl</span></a></li>
        
      </ul>
      
      <p class="post-copyright">
        This post was published <strong>283</strong> days ago, content in the post may be inaccurate, even wrong now, please take risk yourself.
      </p>
    </footer>
    
      
    
  </section>
  


<footer class="site-footer">
  <p>© 2017-2018 rmoff.net</p>
  <p>Powered by <a href="https://gohugo.io/" target="_blank">Hugo</a> with theme <a href="https://github.com/laozhu/hugo-nuo" target="_blank">Nuo</a>.</p>
  
</footer>



<script async src="https://cdn.jsdelivr.net/npm/video.js@7.3.0/dist/video.min.js"></script>




<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      displayMath: [['$$','$$'], ['\\[','\\]']],
      processEscapes: true,
      processEnvironments: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      TeX: { equationNumbers: { autoNumber: "AMS" },
      extensions: ["AMSmath.js", "AMSsymbols.js"] }
    },
  });
</script>
<script type="text/x-mathjax-config">
  // Fix <code> tags after MathJax finishes running. This is a
  // hack to overcome a shortcoming of Markdown. Discussion at
  // https://github.com/mojombo/jekyll/issues/199
  MathJax.Hub.Queue(() => {
    MathJax.Hub.getAllJax().map(v => v.SourceElement().parentNode.className += ' has-jax');
  });
</script>



<script src="/scripts/index.min.js"></script>








  </body>
</html>
