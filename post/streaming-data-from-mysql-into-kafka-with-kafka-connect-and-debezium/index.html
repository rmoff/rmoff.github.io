<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8" />

  
  <title>Streaming Data from MySQL into Kafka with Kafka Connect and Debezium</title>

  
  
  <link href="//cdn.jsdelivr.net" rel="dns-prefetch">
  <link href="//cdnjs.cloudflare.com" rel="dns-prefetch">
  <link href="//at.alicdn.com" rel="dns-prefetch">
  <link href="//fonts.googleapis.com" rel="dns-prefetch">
  <link href="//fonts.gstatic.com" rel="dns-prefetch">
  
  
  
  
  

  

  
  <meta name="author" content="Robin Moffatt">
  <meta name="description" content="Debezium is a CDC tool that can stream changes from MySQL, MongoDB, and PostgreSQL into Kafka, using Kafka Connect. In this article we&amp;rsquo;ll see how to set it up and examine the format of the data. A subsequent article will show using this realtime stream of data from a RDBMS and join it to data originating from other sources, using KSQL.
The software versions used here are:
 Confluent Platform 4.">

  
  
    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="@gohugoio">
    <meta name="twitter:title" content="Streaming Data from MySQL into Kafka with Kafka Connect and Debezium">
    <meta name="twitter:description" content="Debezium is a CDC tool that can stream changes from MySQL, MongoDB, and PostgreSQL into Kafka, using Kafka Connect. In this article we&amp;rsquo;ll see how to set it up and examine the format of the data. A subsequent article will show using this realtime stream of data from a RDBMS and join it to data originating from other sources, using KSQL.
The software versions used here are:
 Confluent Platform 4.">
    <meta name="twitter:image" content="/images/avatar.jpg">
  

  
  <meta property="og:type" content="article">
  <meta property="og:title" content="Streaming Data from MySQL into Kafka with Kafka Connect and Debezium">
  <meta property="og:description" content="Debezium is a CDC tool that can stream changes from MySQL, MongoDB, and PostgreSQL into Kafka, using Kafka Connect. In this article we&amp;rsquo;ll see how to set it up and examine the format of the data. A subsequent article will show using this realtime stream of data from a RDBMS and join it to data originating from other sources, using KSQL.
The software versions used here are:
 Confluent Platform 4.">
  <meta property="og:url" content="https://rmoff.github.io/post/streaming-data-from-mysql-into-kafka-with-kafka-connect-and-debezium/">
  <meta property="og:image" content="/images/avatar.jpg">




<meta name="generator" content="Hugo 0.52">


<link rel="canonical" href="https://rmoff.github.io/post/streaming-data-from-mysql-into-kafka-with-kafka-connect-and-debezium/">

<meta name="renderer" content="webkit">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="format-detection" content="telephone=no,email=no,adress=no">
<meta http-equiv="Cache-Control" content="no-transform">


<meta name="robots" content="index,follow">
<meta name="referrer" content="origin-when-cross-origin">







<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="apple-mobile-web-app-title" content="rmoff.net">
<meta name="msapplication-tooltip" content="rmoff.net">
<meta name='msapplication-navbutton-color' content="#5fbf5e">
<meta name="msapplication-TileColor" content="#5fbf5e">
<meta name="msapplication-TileImage" content="/images/tile-image-windows.png">
<link rel="icon" href="/images/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
<link rel="icon" sizes="192x192" href="/images/touch-icon-android.png">
<link rel="apple-touch-icon" href="/images/touch-icon-apple.png">


<link rel="preload" href="/styles/main.min.css" as="style">
<link rel="preload" href="https://fonts.googleapis.com/css?family=Lobster" as="style">
<link rel="preload" href="/images/avatar.jpg" as="image">
<link rel="preload" href="/images/grey-prism.svg" as="image">


<style>
  body {
    background: rgb(244, 243, 241) url('/images/grey-prism.svg') repeat fixed;
  }
</style>
<link rel="stylesheet" href="/styles/main.min.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lobster">


<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.2/dist/medium-zoom.min.js"></script>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/video.js@7.3.0/dist/video-js.min.css">



  
  
<!--[if lte IE 8]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/videojs-ie8@1.1.2/dist/videojs-ie8.min.js"></script>
<![endif]-->

<!--[if lte IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/eligrey-classlist-js-polyfill@1.2.20180112/classList.min.js"></script>
<![endif]-->


<script src="https://cdn.jsdelivr.net/npm/smooth-scroll@14.2.1/dist/smooth-scroll.polyfills.min.js"></script>


</head>
  <body>
    
    <div class="suspension">
      <a title="Go to top" class="to-top is-hide"><span class="icon icon-up"></span></a>
      
        
      
    </div>
    
    
  <header class="site-header">
  <img class="avatar" src="/images/avatar.jpg" alt="Avatar">
  
  <h2 class="title">rmoff.net</h2>
  
  <p class="subtitle"></p>
  <button class="menu-toggle" type="button">
    <span class="icon icon-menu"></span>
  </button>
  <nav class="site-menu collapsed">
    <h2 class="offscreen">Main Menu</h2>
    <ul class="menu-list">
      
      
      
      
    </ul>
  </nav>
  <nav class="social-menu collapsed">
    <h2 class="offscreen">Social Networks</h2>
    <ul class="social-list"></ul>
  </nav>
</header>

  <section class="main post-detail">
    <header class="post-header">
      <h1 class="post-title">Streaming Data from MySQL into Kafka with Kafka Connect and Debezium</h1>
      <p class="post-meta">@Robin Moffatt · Mar 24, 2018 · 6 min read</p>
    </header>
    <article class="post-content">

<p><a href="http://debezium.io/">Debezium</a> is a CDC tool that can stream changes from MySQL, MongoDB, and PostgreSQL into Kafka, using Kafka Connect. In this article we&rsquo;ll see how to set it up and examine the format of the data. A subsequent article will show using this realtime stream of data from a RDBMS and join it to data originating from other sources, using KSQL.</p>

<p>The software versions used here are:</p>

<ul>
<li>Confluent Platform 4.0</li>
<li>Debezium 0.7.2</li>
<li>MySQL 5.7.19 with <a href="https://dev.mysql.com/doc/sakila/en/sakila-installation.html">Sakila sample database</a> installed</li>
</ul>

<h2 id="install-debezium">Install Debezium</h2>

<p>To use it, you need the relevant JAR for the source system (e.g. MySQL), and make that JAR available to Kafka Connect. Here we&rsquo;ll set it up for MySQL.</p>

<p>Download <code>debezium-connector-mysql-0.7.2-plugin.tar.gz</code> jar from <a href="https://repo1.maven.org/maven2/io/debezium/debezium-connector-mysql/">https://repo1.maven.org/maven2/io/debezium/debezium-connector-mysql/</a></p>

<p>Unpack the <code>.tar.gz</code> into its own folder, for example <code>/u01/plugins</code> so that you have:</p>

<pre><code>/u01/plugins/debezium-connector-mysql/mysql-binlog-connector-java-0.13.0.jar
/u01/plugins/debezium-connector-mysql/debezium-core-0.7.2.jar
/u01/plugins/debezium-connector-mysql/mysql-binlog-connector-java-0.13.0.jar
/u01/plugins/debezium-connector-mysql/mysql-connector-java-5.1.40.jar
/u01/plugins/debezium-connector-mysql/debezium-connector-mysql-0.7.2.jar
</code></pre>

<p>Now configure Kafka Connect to pick up the Debezium plugin, by updating the Kafka Connect worker config.</p>

<p>Edit <code>./etc/kafka/connect-distributed.properties</code> and append to <code>plugin.path</code> the value for the <em>folder containing the Debezium JAR</em>. For example:</p>

<pre><code>plugin.path=share/java,/u01/plugins/
</code></pre>

<p><code>plugin.path</code> is based on this expected structure: <img src="/content/images/2018/03/KafkaConnect_pluginpath.png" alt="" /></p>

<h2 id="mysql-config">MySQL config</h2>

<p>Debezium uses MySQL&rsquo;s binlog facility to extract events, and you need to configure MySQL to enable it. Here is the bare-basics necessary to get this working - fine for demo purposes, but not a substitute for an actual MySQL DBA doing this properly :)</p>

<p>Doc: <a href="https://dev.mysql.com/doc/refman/5.7/en/server-configuration.html">Server Config reference</a></p>

<p>Check current state of binlog replication:</p>

<pre><code>$ mysqladmin variables -uroot|grep log_bin
| log_bin                                                  | OFF
[...]
</code></pre>

<p>Enable binlog <a href="http://debezium.io/docs/connectors/mysql/#enabling-the-binlog">per the doc</a>. On the Mac I&rsquo;d installed MySQL with homebrew, and enabled binlog by creating the following file at <code>/usr/local/opt/mysql/my.cnf</code></p>

<pre><code>[mysqld]
server-id         = 42
log_bin           = mysql-bin
binlog_format     = row
binlog_row_image  = full
expire_logs_days  = 10
</code></pre>

<p>I restarted <code>mysqld</code> with:</p>

<pre><code>brew services restart mysql
</code></pre>

<p>and verified that binlog was now enabled:</p>

<pre><code>$ mysqladmin variables -uroot|grep log_bin
| log_bin                                                  | ON
[...]
</code></pre>

<p>Create user with required permissions;</p>

<pre><code>$ mysql -uroot

mysql&gt; GRANT SELECT, RELOAD, SHOW DATABASES, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'debezium' IDENTIFIED BY 'dbz';
</code></pre>

<h2 id="kafka-connect-setup">Kafka Connect setup</h2>

<p>Load the connector configuration into Kafka Connect using the REST API:</p>

<pre><code>curl -i -X POST -H &quot;Accept:application/json&quot; \
    -H  &quot;Content-Type:application/json&quot; http://localhost:8083/connectors/ \
    -d '{
      &quot;name&quot;: &quot;mysql-connector&quot;,
      &quot;config&quot;: {
            &quot;connector.class&quot;: &quot;io.debezium.connector.mysql.MySqlConnector&quot;,
            &quot;database.hostname&quot;: &quot;localhost&quot;,
            &quot;database.port&quot;: &quot;3306&quot;,
            &quot;database.user&quot;: &quot;debezium&quot;,
            &quot;database.password&quot;: &quot;dbz&quot;,
            &quot;database.server.id&quot;: &quot;42&quot;,
            &quot;database.server.name&quot;: &quot;demo&quot;,
            &quot;database.history.kafka.bootstrap.servers&quot;: &quot;localhost:9092&quot;,
            &quot;database.history.kafka.topic&quot;: &quot;dbhistory.demo&quot; ,
            &quot;include.schema.changes&quot;: &quot;true&quot;
       }
    }'
</code></pre>

<p>Now check that the connector is running successfully:</p>

<pre><code>curl -s &quot;http://localhost:8083/connectors&quot; | jq '.[]' | \
xargs -I{connector_name} curl -s &quot;http://localhost:8083/connectors/&quot;{connector_name}&quot;/status&quot; | \
jq -c -M '[.name,.connector.state,.tasks[].state] | \
join(&quot;:|:&quot;)'| column -s : -t| sed 's/\&quot;//g'| sort

mysql-connector  |  RUNNING  |  RUNNING
</code></pre>

<p>If it&rsquo;s <code>FAILED</code> then check the Connect Worker log for errors - often this will be down to mistakes with the plugin&rsquo;s JAR path or availability, so check that carefully.</p>

<p>Assuming it&rsquo;s <code>RUNNING</code>, you should see in the Connect Worker logs something like this, indicating that Debezium has successfully pulled data from MySQL:</p>

<pre><code>[2018-02-09 15:27:40,268] INFO Starting snapshot for jdbc:mysql://localhost:3306/?useInformationSchema=true&amp;nullCatalogMeansCurrent=false&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8&amp;characterSetResults=UTF-8&amp;zeroDateTimeBehavior=convertToNull with user 'debezium' (io.debezium.connector.mysql.SnapshotReader:220)
[...]
[2018-02-09 15:27:57,297] INFO Step 8: scanned 97354 rows in 24 tables in 00:00:15.617 (io.debezium.connector.mysql.SnapshotReader:579)
[2018-02-09 15:27:57,297] INFO Step 9: committing transaction (io.debezium.connector.mysql.SnapshotReader:611)
[2018-02-09 15:27:57,299] INFO Completed snapshot in 00:00:17.032 (io.debezium.connector.mysql.SnapshotReader:661)
</code></pre>

<h2 id="inspect-the-mysql-data-in-kafka">Inspect the MySQL data in Kafka</h2>

<p>Use <code>kafka-topics</code> to see all the topics created by Debezium:</p>

<pre><code>kafka-topics --zookeeper localhost:2181 --list
</code></pre>

<p>Each <strong>table</strong> in the database becomes one <strong>topic</strong> in Kafka. You&rsquo;ll see that the topic name is in the format of <code>database.schema.table</code>:</p>

<pre><code>fullfillment.sakila.actor
fullfillment.sakila.address
fullfillment.sakila.category
[...]
</code></pre>

<p>Now let&rsquo;s look at the messages. Each <strong>table row</strong> becomes a <strong>message</strong> on a kafka topic.</p>

<p>Run the Avro Console consumer:  (using the excellent <a href="https://stedolan.github.io/jq/">jq</a> for easy formatting of the JSON)</p>

<pre><code>./bin/kafka-avro-console-consumer \
--bootstrap-server localhost:9092 \
--property schema.registry.url=http://localhost:8081 \
--topic fullfillment.sakila.customer \
--from-beginning | jq '.'
</code></pre>

<p>This will show the current contents of the topic. Leave the above command running, and in a separate window make a change to the table in MySQL, for example, an update:</p>

<pre><code>mysql&gt; UPDATE CUSTOMER SET FIRST_NAME='Rick' WHERE CUSTOMER_ID=603;
</code></pre>

<p>In the Kafka consumer you&rsquo;ll see the change record come through pretty much instantaneously.</p>

<script src="https://asciinema.org/a/vzt7YhIBHdcuYz9Zp4UsYPuaS.js" id="asciicast-vzt7YhIBHdcuYz9Zp4UsYPuaS" async></script>

<p>The records from Debezium look like this:</p>

<pre><code>{
  &quot;before&quot;: null,
  &quot;after&quot;: {
    &quot;fullfillment.sakila.rental.Value&quot;: {
      &quot;rental_id&quot;: 13346,
      &quot;rental_date&quot;: 1124483301000,
      &quot;inventory_id&quot;: 4541,
      &quot;customer_id&quot;: 131,
      &quot;return_date&quot;: {
        &quot;long&quot;: 1125188901000
      },
      &quot;staff_id&quot;: 2,
      &quot;last_update&quot;: &quot;2006-02-15T21:30:53Z&quot;
    }
  },
  &quot;source&quot;: {
    &quot;name&quot;: &quot;fullfillment&quot;,
    &quot;server_id&quot;: 0,
    &quot;ts_sec&quot;: 0,
    &quot;gtid&quot;: null,
    &quot;file&quot;: &quot;mysql-bin.000002&quot;,
    &quot;pos&quot;: 832,
    &quot;row&quot;: 0,
    &quot;snapshot&quot;: {
      &quot;boolean&quot;: true
    },
    &quot;thread&quot;: null,
    &quot;db&quot;: {
      &quot;string&quot;: &quot;sakila&quot;
    },
    &quot;table&quot;: {
      &quot;string&quot;: &quot;rental&quot;
    }
  },
  &quot;op&quot;: &quot;c&quot;,
  &quot;ts_ms&quot;: {
    &quot;long&quot;: 1518190060267
  }
}
</code></pre>

<p>Note the structure of the messages - you get an <code>before</code> and <code>after</code> view of the record, plus a bunch of metadata (<code>source</code>, <code>op</code>, <code>ts_ms</code>). Depending on what you&rsquo;re using the CDC events for, you&rsquo;ll want to retain some or all of this structure.</p>

<h2 id="event-message-flattening-with-single-message-transform">Event Message Flattening with Single Message Transform</h2>

<p>For simply streaming into Kafka the <em>current</em> state of the record, it can be useful to take just the <code>after</code> section of the message. Kafka Connect includes functionality called Single Message Transform (SMT). As the name suggests, it enables you to transform single messages! You can read more about it and examples of its usage <a href="https://www.confluent.io/blog/simplest-useful-kafka-connect-data-pipeline-world-thereabouts-part-3/">here</a>. As well as the <a href="http://kafka.apache.org/documentation.html#connect_transforms">Transforms that ship with Apache Kafka</a>, you can write your own using the <a href="https://kafka.apache.org/10/javadoc/org/apache/kafka/connect/transforms/Transformation.html">documented API</a>. This is exactly what the Debezium project have done, shipping their own SMT as part of it, providing an easy way to <a href="http://debezium.io/docs/configuration/event-flattening/">flatten the events that Debezium emits</a>.</p>

<p>Using SMT you can amend the message inbound/outbound from Kafka to show just the new record:</p>

<pre><code>{
  &quot;c1&quot;: {
    &quot;int&quot;: 100
  },
  &quot;c2&quot;: {
    &quot;string&quot;: &quot;wibble&quot;
  },
  &quot;create_ts&quot;: &quot;2018-01-23T22:47:09Z&quot;,
  &quot;update_ts&quot;: &quot;2018-02-09T15:35:48Z&quot;
}
</code></pre>

<p>instead of the full change:</p>

<pre><code>{
  &quot;before&quot;: {
    &quot;fullfillment.demo.foobar.Value&quot;: {
      &quot;c1&quot;: {
        &quot;int&quot;: 100
      },
      &quot;c2&quot;: {
        &quot;string&quot;: &quot;bar&quot;
      },
      &quot;create_ts&quot;: &quot;2018-01-23T22:47:09Z&quot;,
      &quot;update_ts&quot;: &quot;2018-01-23T22:47:09Z&quot;
    }
  },
  &quot;after&quot;: {
    &quot;fullfillment.demo.foobar.Value&quot;: {
      &quot;c1&quot;: {
        &quot;int&quot;: 100
      },
      &quot;c2&quot;: {
        &quot;string&quot;: &quot;wibble&quot;
      },
      &quot;create_ts&quot;: &quot;2018-01-23T22:47:09Z&quot;,
      &quot;update_ts&quot;: &quot;2018-02-09T15:35:48Z&quot;
    }
  },
  &quot;source&quot;: {
    &quot;name&quot;: &quot;fullfillment&quot;,
    &quot;server_id&quot;: 42,
    &quot;ts_sec&quot;: 1518190548,
    &quot;gtid&quot;: null,
    &quot;file&quot;: &quot;mysql-bin.000002&quot;,
    &quot;pos&quot;: 1025,
    &quot;row&quot;: 3,
    &quot;snapshot&quot;: null,
    &quot;thread&quot;: {
      &quot;long&quot;: 11
    },
    &quot;db&quot;: {
      &quot;string&quot;: &quot;demo&quot;
    },
    &quot;table&quot;: {
      &quot;string&quot;: &quot;foobar&quot;
    }
  },
  &quot;op&quot;: &quot;u&quot;,
  &quot;ts_ms&quot;: {
    &quot;long&quot;: 1518190548539
  }
}
</code></pre>

<p>SMT can also be used to modify the target topic (which unmodified is <code>server.database.table</code>), using the <code>RegexRouter</code> transform.</p>

<p>With these two SMT included, this is how our configuration looks now:</p>

<pre><code>{
  &quot;name&quot;: &quot;mysql-connector-flattened&quot;,
  &quot;config&quot;: {
    &quot;connector.class&quot;: &quot;io.debezium.connector.mysql.MySqlConnector&quot;,
    &quot;database.hostname&quot;: &quot;localhost&quot;,
    &quot;database.port&quot;: &quot;3306&quot;,
    &quot;database.user&quot;: &quot;debezium&quot;,
    &quot;database.password&quot;: &quot;dbz&quot;,
    &quot;database.server.id&quot;: &quot;42&quot;,
    &quot;database.server.name&quot;: &quot;fullfillment&quot;,
    &quot;database.history.kafka.bootstrap.servers&quot;: &quot;localhost:9092&quot;,
    &quot;database.history.kafka.topic&quot;: &quot;dbhistory.fullfillment&quot; ,
    &quot;include.schema.changes&quot;: &quot;true&quot; ,
    &quot;transforms&quot;: &quot;unwrap,changetopic&quot;,
    &quot;transforms.unwrap.type&quot;: &quot;io.debezium.transforms.UnwrapFromEnvelope&quot;,
    &quot;transforms.changetopic.type&quot;:&quot;org.apache.kafka.connect.transforms.RegexRouter&quot;,
    &quot;transforms.changetopic.regex&quot;:&quot;(.*)&quot;,
    &quot;transforms.changetopic.replacement&quot;:&quot;$1-smt&quot;
  }
}
</code></pre>

<hr />

<p>To see how streaming events from a RDBMS such as MySQL into Kafka can be even more powerful when combined with KSQL for stream processing check out <a href="https://www.confluent.io/blog/ksql-in-action-enriching-csv-events-with-data-from-rdbms-into-AWS/">KSQL in Action: Enriching CSV Events with Data from RDBMS into AWS</a>.</p>
</article>
    <footer class="post-footer">
      
      <ul class="post-tags">
        
          <li><a href="/tags/debezium"><span class="tag">Debezium</span></a></li>
        
          <li><a href="/tags/kafka"><span class="tag">Kafka</span></a></li>
        
          <li><a href="/tags/kafka-connect"><span class="tag">Kafka Connect</span></a></li>
        
          <li><a href="/tags/mysql"><span class="tag">Mysql</span></a></li>
        
      </ul>
      
      <p class="post-copyright">
        This post was published <strong>266</strong> days ago, content in the post may be inaccurate, even wrong now, please take risk yourself.
      </p>
    </footer>
    
      
    
  </section>
  


<footer class="site-footer">
  <p>© 2017-2018 rmoff.net</p>
  <p>Powered by <a href="https://gohugo.io/" target="_blank">Hugo</a> with theme <a href="https://github.com/laozhu/hugo-nuo" target="_blank">Nuo</a>.</p>
  
</footer>



<script async src="https://cdn.jsdelivr.net/npm/video.js@7.3.0/dist/video.min.js"></script>




<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      displayMath: [['$$','$$'], ['\\[','\\]']],
      processEscapes: true,
      processEnvironments: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      TeX: { equationNumbers: { autoNumber: "AMS" },
      extensions: ["AMSmath.js", "AMSsymbols.js"] }
    },
  });
</script>
<script type="text/x-mathjax-config">
  // Fix <code> tags after MathJax finishes running. This is a
  // hack to overcome a shortcoming of Markdown. Discussion at
  // https://github.com/mojombo/jekyll/issues/199
  MathJax.Hub.Queue(() => {
    MathJax.Hub.getAllJax().map(v => v.SourceElement().parentNode.className += ' has-jax');
  });
</script>



<script src="/scripts/index.min.js"></script>








  </body>
</html>
