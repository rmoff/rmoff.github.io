<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8" />

  
  <title>Monitoring Logstash Ingest Rates with InfluxDB and Grafana</title>

  
  
  <link href="//cdn.jsdelivr.net" rel="dns-prefetch">
  <link href="//cdnjs.cloudflare.com" rel="dns-prefetch">
  <link href="//at.alicdn.com" rel="dns-prefetch">
  <link href="//fonts.googleapis.com" rel="dns-prefetch">
  <link href="//fonts.gstatic.com" rel="dns-prefetch">
  
  
  
  
  

  

  
  <meta name="author" content="Robin Moffatt">
  <meta name="description" content="In this article I&amp;rsquo;m going to show you how to easily monitor the rate at which Logstash is ingesting data, as well as in future articles the rate at which Elasticsearch is indexing it. It&amp;rsquo;s a nice little touch to add to any project involving Logstash, and it&amp;rsquo;s easy to do.
Logstash is powerful tool for data ingest, processing, and distribution. It originated as simply the pipe to slurp at log files and put them into Elasticsearch, but has evolved into a whole bunch more.">

  
  
    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="@gohugoio">
    <meta name="twitter:title" content="Monitoring Logstash Ingest Rates with InfluxDB and Grafana">
    <meta name="twitter:description" content="In this article I&amp;rsquo;m going to show you how to easily monitor the rate at which Logstash is ingesting data, as well as in future articles the rate at which Elasticsearch is indexing it. It&amp;rsquo;s a nice little touch to add to any project involving Logstash, and it&amp;rsquo;s easy to do.
Logstash is powerful tool for data ingest, processing, and distribution. It originated as simply the pipe to slurp at log files and put them into Elasticsearch, but has evolved into a whole bunch more.">
    <meta name="twitter:image" content="/images/avatar.jpg">
  

  
  <meta property="og:type" content="article">
  <meta property="og:title" content="Monitoring Logstash Ingest Rates with InfluxDB and Grafana">
  <meta property="og:description" content="In this article I&amp;rsquo;m going to show you how to easily monitor the rate at which Logstash is ingesting data, as well as in future articles the rate at which Elasticsearch is indexing it. It&amp;rsquo;s a nice little touch to add to any project involving Logstash, and it&amp;rsquo;s easy to do.
Logstash is powerful tool for data ingest, processing, and distribution. It originated as simply the pipe to slurp at log files and put them into Elasticsearch, but has evolved into a whole bunch more.">
  <meta property="og:url" content="https://rmoff.github.io/post/monitoring-logstash-ingest-rates-with-influxdb-and-grafana/">
  <meta property="og:image" content="/images/avatar.jpg">




<meta name="generator" content="Hugo 0.52">


<link rel="canonical" href="https://rmoff.github.io/post/monitoring-logstash-ingest-rates-with-influxdb-and-grafana/">

<meta name="renderer" content="webkit">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="format-detection" content="telephone=no,email=no,adress=no">
<meta http-equiv="Cache-Control" content="no-transform">


<meta name="robots" content="index,follow">
<meta name="referrer" content="origin-when-cross-origin">







<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="apple-mobile-web-app-title" content="rmoff.net">
<meta name="msapplication-tooltip" content="rmoff.net">
<meta name='msapplication-navbutton-color' content="#5fbf5e">
<meta name="msapplication-TileColor" content="#5fbf5e">
<meta name="msapplication-TileImage" content="/images/tile-image-windows.png">
<link rel="icon" href="/images/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
<link rel="icon" sizes="192x192" href="/images/touch-icon-android.png">
<link rel="apple-touch-icon" href="/images/touch-icon-apple.png">


<link rel="preload" href="/styles/main.min.css" as="style">
<link rel="preload" href="https://fonts.googleapis.com/css?family=Lobster" as="style">
<link rel="preload" href="/images/avatar.jpg" as="image">
<link rel="preload" href="/images/grey-prism.svg" as="image">


<style>
  body {
    background: rgb(244, 243, 241) url('/images/grey-prism.svg') repeat fixed;
  }
</style>
<link rel="stylesheet" href="/styles/main.min.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lobster">


<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.2/dist/medium-zoom.min.js"></script>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/video.js@7.3.0/dist/video-js.min.css">



  
  
<!--[if lte IE 8]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/videojs-ie8@1.1.2/dist/videojs-ie8.min.js"></script>
<![endif]-->

<!--[if lte IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/eligrey-classlist-js-polyfill@1.2.20180112/classList.min.js"></script>
<![endif]-->


<script src="https://cdn.jsdelivr.net/npm/smooth-scroll@14.2.1/dist/smooth-scroll.polyfills.min.js"></script>


</head>
  <body>
    
    <div class="suspension">
      <a title="Go to top" class="to-top is-hide"><span class="icon icon-up"></span></a>
      
        
      
    </div>
    
    
  <header class="site-header">
  <img class="avatar" src="/images/avatar.jpg" alt="Avatar">
  
  <h2 class="title">rmoff.net</h2>
  
  <p class="subtitle"></p>
  <button class="menu-toggle" type="button">
    <span class="icon icon-menu"></span>
  </button>
  <nav class="site-menu collapsed">
    <h2 class="offscreen">Main Menu</h2>
    <ul class="menu-list">
      
      
      
      
    </ul>
  </nav>
  <nav class="social-menu collapsed">
    <h2 class="offscreen">Social Networks</h2>
    <ul class="social-list"></ul>
  </nav>
</header>

  <section class="main post-detail">
    <header class="post-header">
      <h1 class="post-title">Monitoring Logstash Ingest Rates with InfluxDB and Grafana</h1>
      <p class="post-meta">@Robin Moffatt · May 12, 2016 · 8 min read</p>
    </header>
    <article class="post-content">

<p>In this article I&rsquo;m going to show you how to easily monitor the rate at which Logstash is ingesting data, as well as in future articles the rate at which Elasticsearch is indexing it. It&rsquo;s a nice little touch to add to any project involving Logstash, and it&rsquo;s easy to do.</p>

<p>Logstash is powerful tool for data ingest, processing, and distribution. It originated as simply the pipe to slurp at log files and put them into Elasticsearch, but has evolved into a whole bunch more. With connectors to JDBC and Kafka, as well as many other <a href="https://www.elastic.co/guide/en/logstash/current/input-plugins.html">input</a> and <a href="https://www.elastic.co/guide/en/logstash/current/output-plugins.html">output</a> options (not to mention the <a href="https://www.elastic.co/guide/en/logstash/current/filter-plugins.html">filtering</a> possibilities), it really is a great bit of software to use. I&rsquo;ve used it over the years with <a href="http://www.rittmanmead.com/2014/10/monitoring-obiee-with-elasticsearch-logstash-and-kibana/">OBIEE</a>, as well as more recently to <a href="https://www.elastic.co/blog/visualising-oracle-performance-data-with-the-elastic-stack">pull data from Oracle</a>, and even <a href="http://rmoff.net/2016/03/24/my-latest-irc-client-kibana/">IRC</a>. Another great set of tools is <a href="http://influxdb.com">InfluxDB</a> and <a href="http://grafana.org">Grafana</a>, which for me really round off the standalone Elastic platform (previously known as ELK - Elasticsearch, Logstash, and Kibana). What InfluxDB and Grafana give is a powerful dedicated time series database and flexible time series-based dashboarding tool respectively. A topic for another day is the Elasticsearch vs InfluxDB overlap, and Kibana vs Grafana - but for now, just take it as read that it&rsquo;s horses for course, right tool for the right job, etc.</p>

<p>Let&rsquo;s get started&hellip;</p>

<h2 id="pre-requisites">Pre-Requisites</h2>

<p>I&rsquo;m not going to cover setup &amp; install here - I&rsquo;m assuming that you&rsquo;ve got Logstash &gt;=2.3.1, InfluxDB &gt;= 0.12, Grafana &gt;= 2.6 running. In this example it&rsquo;s all running on a single node, localhost, default ports for everything. The only non-standard configuration is that I&rsquo;ve <a href="https://github.com/influxdata/influxdb/blob/master/services/graphite/README.md">enabled the <strong>graphite</strong> listener in InfluxDB</a>.</p>

<h2 id="overview">Overview</h2>

<p>We&rsquo;ll get Logstash to send event rates over to InfluxDB, from where we&rsquo;ll visualise it in Grafana.</p>

<p>The example I&rsquo;m using it based on pulling some data in from a Kafka topic (similar to the <a href="http://rmoff.net/2016/04/12/decoupling-the-data-pipeline-with-kafka-a-very-simple-real-life-example/">pattern described here</a>) and indexing it into Elasticsearch. I can start and stop my Logstash configuration when I want, and it picks up from where it left off in consuming the data from Kafka.</p>

<h2 id="logstash-instrumentation">Logstash Instrumentation</h2>

<p>First job is to get Logstash to track, and then output, the rate at which it&rsquo;s processing events. One row read from a log, one message pulled from Kafka - each is one &ldquo;event&rdquo;.</p>

<p>We&rsquo;ll use the <strong><a href="https://www.elastic.co/guide/en/logstash/current/plugins-filters-metrics.html">metric</a></strong> filter to do this. In the <strong>filter</strong> stanza of my Logstash configuration, I add:</p>

<pre><code class="language-ruby">filter {
    # Any other filter code here
    # [...]
    #
    # Add events per second metric
    metrics {
        meter =&gt; &quot;events&quot;
        add_tag =&gt; &quot;metric&quot;
    }
}
</code></pre>

<p>and then to get it written over to InfluxDB, via the graphite protocol, I amend my <strong>output</strong> stanza to split out the events based on tag - metrics go to Influx (and stdout for debug), everything else to Elasticsearch as before:</p>

<pre><code class="language-ruby">output {
    if &quot;metric&quot; in [tags] {
        stdout {
            codec =&gt; line {
            format =&gt; &quot;Events per second ingest rate (1/5/15 min avg): %{[events][rate_1m]} | %{[events][rate_5m]} | %{[events][rate_15m]}&quot;
            }
        }
        graphite {
            host =&gt; &quot;localhost&quot;
            metrics_format =&gt; &quot;logstash.*&quot;
            include_metrics =&gt; [ &quot;events.*&quot; ]
            fields_are_metrics =&gt; true
        }
    } else {
        # Output configuration as before,
        # to Elasticsearch or wherever
        # [...]
    }
}
</code></pre>

<p>Fire up your Logstash agent (the new <code>--auto-reload</code> parameter I&rsquo;ve found great for development stuff like this):</p>

<pre><code>bin/logstash --auto-reload --config logstash-twitter-kafka.conf
</code></pre>

<p>And, aside from any other stdout that your script is writing, you&rsquo;ll now see the 1/5/15 minute moving averages for events per second being processed:</p>

<pre><code>Events per second ingest rate (1/5/15 min avg): 2.0609812156329577 | 2.327820782492659 | 2.3756847177898033
</code></pre>

<p>But &hellip; that stdout is just debug, remember? Where we really want it is over in InfluxDB, so we can build some lovely charts against it.</p>

<h2 id="checking-the-data-in-influxdb">Checking the data in InfluxDB</h2>

<p>You can use the <a href="https://docs.influxdata.com/influxdb/v0.12/tools/web_admin/">InfluxDB GUI</a> for this, or the <a href="https://docs.influxdata.com/influxdb/v0.12/tools/shell/">command line</a>. Here I&rsquo;ll use the command line.</p>

<p>Launch the client</p>

<pre><code>$ influx
Visit https://enterprise.influxdata.com to register for updates, InfluxDB server management, and monitoring.
Connected to http://localhost:8086 version 0.12.1
InfluxDB shell 0.12.1
</code></pre>

<p>Switch to the <code>graphite</code> database (used by default for graphite protocol data; can be changed in the influxDB configuration)</p>

<pre><code>&gt; use graphite
Using database graphite
</code></pre>

<p>List the series that exist so far:</p>

<pre><code>&gt; show measurements
name: measurements
------------------
name
logstash.events.count
logstash.events.rate_15m
logstash.events.rate_1m
logstash.events.rate_5m
</code></pre>

<p>Show a sample of the data:</p>

<pre><code>&gt; select * from /logstash.events.rate_1m/ limit 5
name: logstash.events.rate_1m
-----------------------------
time                    value
1463044923000000000     0
1463044928000000000     16.8
1463044933000000000     15.472737282846767
1463044938000000000     14.379525569777279
1463044943000000000     14.379525569777279
</code></pre>

<p>The time value is epoch microseconds. For more information on the InfluxDB query language, <a href="https://docs.influxdata.com/influxdb/v0.12/query_language/data_exploration/">see here</a>.</p>

<p>So, we&rsquo;ve instrumented Logstash configuration to generate and send the data, we&rsquo;ve validated that InfluxDB is getting the data &hellip; now let&rsquo;s graph the data!</p>

<h2 id="charting-it-in-grafana">Charting it in Grafana</h2>

<p>In Grafana I&rsquo;ve added a datasource pointing to my InfluxDB, and then headed over to my dashboard. When done in real life, this kind of chart makes a lot of sense alongside other &ldquo;health check&rdquo; visualisations, enabling you to see not only what the data coming into the system is telling you, but also the status of that data flow. There&rsquo;s nothing worse than thinking &ldquo;hey cool, no errors&rdquo; when the reason there&rsquo;s no errors is that all the errors are backed up in the pipeline and not even making it into your monitoring system &hellip;</p>

<p>So here&rsquo;s the basic chart:</p>

<p><img src="/content/images/2016/05/lsir01.png" alt="" /></p>

<p>I&rsquo;ve added a title, and values to the legend. Other than that, dead simple.</p>

<p>Let&rsquo;s make it easier to see, at a glance, if things are bad (<a href="https://www.youtube.com/watch?v=Uh7l8dx-h8M">m&rsquo;kay</a>) or not:</p>

<p><img src="/content/images/2016/05/lsir02-1.png" alt="" /></p>

<p>Here I&rsquo;ve added a Singlestat panel. A very important thing to change from the default option if you&rsquo;re using it in this way, to show the current value - is to make sure you set it to that - current:</p>

<p><img src="/content/images/2016/05/lsir03.png" alt="" /></p>

<p>If you don&rsquo;t do this, you get the average across all values, which typically of less use.</p>

<p>The Singlestat panel also supports thresholds, so you can be alerted visually if the ingest rate is less than you&rsquo;d want. Here it&rsquo;s up to you to know what rate you would expect. In this screenshot it&rsquo;s going to show green above 10, amber above 5, and red below 5:</p>

<p><img src="/content/images/2016/05/lsir04.png" alt="" /></p>

<p>In actuality, my ingest rate is pretty modest, at around 0.5 per second, so I&rsquo;ve set my thresholds at 0.1 and 0.5. Anything below 0.5 I want to be aware of, anything below 0.1 and it suggests there&rsquo;s a problem. Let&rsquo;s see how that pans out.</p>

<p>To start with, everything&rsquo;s good. Rate is above 0.5, and we&rsquo;re ticking along nicely:</p>

<p><img src="/content/images/2016/05/lsir05.png" alt="" /></p>

<p>For some reason, the ingest rate slows - could be my source, could be the pipeline - but I want to be aware. The Singlestat colour highlights this for me, since it&rsquo;s below the threshold of 0.5 that I set:</p>

<p><img src="/content/images/2016/05/lsir06.png" alt="" /></p>

<p>Now, let&rsquo;s cut the pipeline and see what happens. We should get a nice big red alert background.</p>

<p><img src="/content/images/2016/05/lsir07.png" alt="" /></p>

<p>Oh. Not what we wanted. Even though the chart clearly shows there&rsquo;s been no data for ten minutes, the Singlestat is showing a current ingest rate of 0.4 (and in amber, not red), and if you look closely the &ldquo;Current&rdquo; value on the legend shows the same.</p>

<p>This is where we need to get a bit deeper into Grafana. If you look closely at the Metrics configuration for both the Graph and Singlestat, you&rsquo;ll see that by default &ldquo;fill&rdquo; is set to null.</p>

<p><img src="/content/images/2016/05/lsir08.png" alt="" /></p>

<p>This is a time series chart, where time moves on whether you like it or not &ndash; and whether you have data or not. Grafana by default will &lsquo;fill&rsquo; any gaps with null. Null is most definitely <strong>not</strong> zero &ndash; it&rsquo;s null, it&rsquo;s an absence of data, it&rsquo;s &ldquo;we don&rsquo;t know&rdquo;. So when we ask Grafana to use &ldquo;current&rdquo; value (in the legend, in the singlestat), it ends up using the &ldquo;last known&rdquo; value of the data - which for our purposes is stale and basically wrong.</p>

<p>So in this case, we&rsquo;re going to deliberately conflate &ldquo;no ingest rate from Logstash&rdquo; with &ldquo;Logstash isn&rsquo;t ingesting data&rdquo;. Technically, this could be untrue at times, but it&rsquo;s close enough for me. So now we will tell Grafana to use <strong>zero</strong> if it doesn&rsquo;t find any data for a given time period.</p>

<p><img src="/content/images/2016/05/lsir09.png" alt="" /></p>

<p>You&rsquo;ll notice the graph&rsquo;s rendering different now, because Grafana&rsquo;s plotting it at a resolution higher than we&rsquo;re sending data. Logstash emits the event data every five seconds or so, and Grafana&rsquo;s plotting at every second - so it&rsquo;s marking the chart as zero for every four of each five seconds. To solution to this is to set the time group by to <strong>at least five seconds</strong>:</p>

<p><img src="/content/images/2016/05/lsir10.png" alt="" /></p>

<p>Applying the same Metric configuration (fill=zero, group by &gt;=5s) to the Singlestat panel gives us a much better result now. When there&rsquo;s no data, we get a big fat red zero making it nice and clear that there&rsquo;s a problem.</p>

<p><img src="/content/images/2016/05/lsir11.png" alt="" /></p>

<p>For the final touch, let&rsquo;s give an indication on the chart of the threshold levels we&rsquo;re using for the Singlestat, using the <strong>Thresholds</strong> option:</p>

<p><img src="/content/images/2016/05/lsir12.png" alt="" /></p>

<p>This shows itself on the chart as a coloured background for each threshold level used:</p>

<p><img src="/content/images/2016/05/lsir13.png" alt="" /></p>

<p><em>(From this we can see probably 0.5 is too high a threshold since the data seems to usually fall within that range - and there&rsquo;s nothing worse than a permanent &ldquo;warning&rdquo; that just becomes background noise.)</em></p>

<p>So there you go - nice monitoring of Logstash ingest rates, using InfluxDB and Grafana. Stick around to see how we can do a similar thing for monitoring Elasticsearch, and even the data within it too&hellip;</p>
</article>
    <footer class="post-footer">
      
      <ul class="post-tags">
        
          <li><a href="/tags/influxdb"><span class="tag">Influxdb</span></a></li>
        
          <li><a href="/tags/grafana"><span class="tag">Grafana</span></a></li>
        
          <li><a href="/tags/logstash"><span class="tag">Logstash</span></a></li>
        
          <li><a href="/tags/graphite"><span class="tag">Graphite</span></a></li>
        
          <li><a href="/tags/monitoring"><span class="tag">Monitoring</span></a></li>
        
          <li><a href="/tags/ingest"><span class="tag">Ingest</span></a></li>
        
      </ul>
      
      <p class="post-copyright">
        This post was published <strong>947</strong> days ago, content in the post may be inaccurate, even wrong now, please take risk yourself.
      </p>
    </footer>
    
      
    
  </section>
  


<footer class="site-footer">
  <p>© 2017-2018 rmoff.net</p>
  <p>Powered by <a href="https://gohugo.io/" target="_blank">Hugo</a> with theme <a href="https://github.com/laozhu/hugo-nuo" target="_blank">Nuo</a>.</p>
  
</footer>



<script async src="https://cdn.jsdelivr.net/npm/video.js@7.3.0/dist/video.min.js"></script>




<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      displayMath: [['$$','$$'], ['\\[','\\]']],
      processEscapes: true,
      processEnvironments: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      TeX: { equationNumbers: { autoNumber: "AMS" },
      extensions: ["AMSmath.js", "AMSsymbols.js"] }
    },
  });
</script>
<script type="text/x-mathjax-config">
  // Fix <code> tags after MathJax finishes running. This is a
  // hack to overcome a shortcoming of Markdown. Discussion at
  // https://github.com/mojombo/jekyll/issues/199
  MathJax.Hub.Queue(() => {
    MathJax.Hub.getAllJax().map(v => v.SourceElement().parentNode.className += ' has-jax');
  });
</script>



<script src="/scripts/index.min.js"></script>








  </body>
</html>
