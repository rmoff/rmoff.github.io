<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8" />

  
  <title>
  Posts
   | rmoff.net
</title>

  
  
  <link href="//cdn.jsdelivr.net" rel="dns-prefetch">
  <link href="//cdnjs.cloudflare.com" rel="dns-prefetch">
  <link href="//at.alicdn.com" rel="dns-prefetch">
  <link href="//fonts.googleapis.com" rel="dns-prefetch">
  <link href="//fonts.gstatic.com" rel="dns-prefetch">
  <link href="///disqus.com" rel="dns-prefetch">
  <link href="//c.disquscdn.com" rel="dns-prefetch">
  
  
  

  

  
  
  

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="@gohugoio">
  <meta name="twitter:title" content="rmoff.net">
  
  <meta name="twitter:image" content="/images/avatar.jpg">

  
  <meta property="og:type" content="website">
  <meta property="og:title" content="rmoff.net">
  
  <meta property="og:url" content="https://rmoff.github.io/post/">
  <meta property="og:image" content="/images/avatar.jpg">




<meta name="generator" content="Hugo 0.52">


<link rel="canonical" href="https://rmoff.github.io/post/">
<link rel="alternate" type="application/rss+xml" href="https://rmoff.github.io/post/index.xml" title="rmoff.net">

<meta name="renderer" content="webkit">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="format-detection" content="telephone=no,email=no,adress=no">
<meta http-equiv="Cache-Control" content="no-transform">


<meta name="robots" content="index,follow">
<meta name="referrer" content="origin-when-cross-origin">







<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="apple-mobile-web-app-title" content="rmoff.net">
<meta name="msapplication-tooltip" content="rmoff.net">
<meta name='msapplication-navbutton-color' content="#5fbf5e">
<meta name="msapplication-TileColor" content="#5fbf5e">
<meta name="msapplication-TileImage" content="/images/tile-image-windows.png">
<link rel="icon" href="/images/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
<link rel="icon" sizes="192x192" href="/images/touch-icon-android.png">
<link rel="apple-touch-icon" href="/images/touch-icon-apple.png">


<link rel="preload" href="/styles/main.min.css" as="style">
<link rel="preload" href="https://fonts.googleapis.com/css?family=Lobster" as="style">
<link rel="preload" href="/images/avatar.jpg" as="image">
<link rel="preload" href="/images/grey-prism.svg" as="image">


<style>
  body {
    background: rgb(244, 243, 241) url('/images/grey-prism.svg') repeat fixed;
  }
</style>
<link rel="stylesheet" href="/styles/main.min.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lobster">


<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.2/dist/medium-zoom.min.js"></script>





  
  
<!--[if lte IE 8]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/videojs-ie8@1.1.2/dist/videojs-ie8.min.js"></script>
<![endif]-->

<!--[if lte IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/eligrey-classlist-js-polyfill@1.2.20180112/classList.min.js"></script>
<![endif]-->


<script src="https://cdn.jsdelivr.net/npm/smooth-scroll@14.2.1/dist/smooth-scroll.polyfills.min.js"></script>


</head>
  <body>
    
    <div class="suspension">
      <a title="Go to top" class="to-top is-hide"><span class="icon icon-up"></span></a>
      
    </div>
    
    
  <header class="site-header">
  <img class="avatar" src="/images/avatar.jpg" alt="Avatar">
  
  <h2 class="title">rmoff.net</h2>
  
  <p class="subtitle"></p>
  <button class="menu-toggle" type="button">
    <span class="icon icon-menu"></span>
  </button>
  <nav class="site-menu collapsed">
    <h2 class="offscreen">Main Menu</h2>
    <ul class="menu-list">
      
      
      
      
        <li class="menu-item
            
            
            ">
            <a href="/about-me/">about me</a>
          </li>
      
        <li class="menu-item
            
            
            ">
            <a href="/presentations/">presentations</a>
          </li>
      
    </ul>
  </nav>
  <nav class="social-menu collapsed">
    <h2 class="offscreen">Social Networks</h2>
    <ul class="social-list"></ul>
  </nav>
</header>

  <section class="main post-list">
    <header class="list-header offscreen">
      <h2 class="list-label">Posts List</h2>
    </header>
    
    
      
        <article class="post-entry">
  <header class="post-header">
    <h3 class="post-title"><a href="https://rmoff.github.io/2016/12/02/kafka-avro-console-producer-error-registering-avro-schema-io.confluent.kafka.schemaregistry.client.rest.exceptions.restclientexception/" class="post-link">kafka-avro-console-producer - Error registering Avro schema / io.confluent.kafka.schemaregistry.client.rest.exceptions.RestClientException</a></h3>
    <p class="post-meta">@Robin Moffatt · Dec 2, 2016 · 1 min read</p>
  </header>
  
  <p class="post-summary">By default, the kafka-avro-console-producer will assume that the schema registry is on port 8081, and happily connect to it. Unfortunately, this can lead to some weird errors if another process happens to be listening on port 8081 already!
[oracle@bigdatalite tmp]$ kafka-avro-console-producer \ &gt; --broker-list localhost:9092 --topic kudu_test \ &gt; --property value.schema=&#39;{&#34;type&#34;:&#34;record&#34;,&#34;name&#34;:&#34;myrecord&#34;,&#34;fields&#34;:[{&#34;name&#34;:&#34;id&#34;,&#34;type&#34;:&#34;int&#34;},{&#34;name&#34;:&#34;random_field&#34;, &#34;type&#34;: &#34;string&#34;}]}&#39; {&#34;id&#34;: 999, &#34;random_field&#34;: &#34;foo&#34;} org.apache.kafka.common.errors.SerializationException: Error registering Avro schema: {&#34;type&#34;:&#34;record&#34;,&#34;name&#34;:&#34;myrecord&#34;,&#34;fields&#34;:[{&#34;name&#34;:&#34;id&#34;,&#34;type&#34;:&#34;int&#34;},{&#34;name&#34;:&#34;random_field&#34;,&#34;type&#34;:&#34;string&#34;}]} Caused by: io.confluent.kafka.schemaregistry.client.rest.exceptions.RestClientException: Unexpected character (&#39;&lt;&#39; (code 60)): expected a valid value (number, String, array, object, &#39;true&#39;, &#39;false&#39; or &#39;null&#39;) at [Source: sun.</p>
  <footer class="post-footer">
    <a class="read-more" href="https://rmoff.github.io/2016/12/02/kafka-avro-console-producer-error-registering-avro-schema-io.confluent.kafka.schemaregistry.client.rest.exceptions.restclientexception/">Read More →</a>
  </footer>
</article>

      
        <article class="post-entry">
  <header class="post-header">
    <h3 class="post-title"><a href="https://rmoff.github.io/2016/11/29/oracle-goldengate-kafka-connect-failed-to-serialize-avro-data/" class="post-link">Oracle GoldenGate -&gt; Kafka Connect - &#34;Failed to serialize Avro data&#34;</a></h3>
    <p class="post-meta">@Robin Moffatt · Nov 29, 2016 · 2 min read</p>
  </header>
  
  <p class="post-summary">tl;dr Make sure that key.converter.schema.registry.url and value.converter.schema.registry.url are specified, and that there are no trailing whitespaces.
I’ve been building on previous work I’ve done with Oracle GoldenGate and Kafka Connect, looking at how to have the change records from the Oracle database come through to Kafka in Avro format rather than the default JSON that the sample configuration gives.
Simply changing the Kafka Connect OGG configuration file (confluent.properties) from
value.converter=org.apache.kafka.connect.json.JsonConverter key.</p>
  <footer class="post-footer">
    <a class="read-more" href="https://rmoff.github.io/2016/11/29/oracle-goldengate-kafka-connect-failed-to-serialize-avro-data/">Read More →</a>
  </footer>
</article>

      
        <article class="post-entry">
  <header class="post-header">
    <h3 class="post-title"><a href="https://rmoff.github.io/2016/11/24/kafka-connect-java.lang.incompatibleclasschangeerror/" class="post-link">Kafka Connect - java.lang.IncompatibleClassChangeError</a></h3>
    <p class="post-meta">@Robin Moffatt · Nov 24, 2016 · 1 min read</p>
  </header>
  
  <p class="post-summary">I hit this error running Kafka Connect HDFS connector from Confluent Platform v3.1.1 on BigDataLite 4.6:
[oracle@bigdatalite ~]$ connect-standalone /etc/schema-registry/connect-avro-standalone.properties /etc/kafka-connect-hdfs/quickstart-hdfs.properties [...] Exception in thread &#34;main&#34; java.lang.IncompatibleClassChangeError: Implementing class at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:763) at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) at java.net.URLClassLoader.defineClass(URLClassLoader.java:467) at java.net.URLClassLoader.access$100(URLClassLoader.java:73) at java.net.URLClassLoader$1.run(URLClassLoader.java:368) at java.net.URLClassLoader$1.run(URLClassLoader.java:362) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:361) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:763)  The fix was to unset the CLASSPATH first:
unset CLASSPATH  </p>
  <footer class="post-footer">
    <a class="read-more" href="https://rmoff.github.io/2016/11/24/kafka-connect-java.lang.incompatibleclasschangeerror/">Read More →</a>
  </footer>
</article>

      
        <article class="post-entry">
  <header class="post-header">
    <h3 class="post-title"><a href="https://rmoff.github.io/2016/10/14/boto-s3-errors/" class="post-link">boto / S3 errors</a></h3>
    <p class="post-meta">@Robin Moffatt · Oct 14, 2016 · 1 min read</p>
  </header>
  
  <p class="post-summary">Presented without comment, warranty, or context - other than these might help a wandering code hacker.
When using SigV4, you must specify a ‘host’ parameter boto.s3.connection.HostRequiredError: BotoClientError: When using SigV4, you must specify a &#39;host&#39; parameter.  To fix, switch
conn_s3 = boto.connect_s3()  for
conn_s3 = boto.connect_s3(host=&#39;s3.amazonaws.com&#39;)  You can see a list of endpoints here.
boto.exception.S3ResponseError: S3ResponseError: 400 Bad Request Make sure you’re specifying the correct hostname (see above) for the bucket’s region.</p>
  <footer class="post-footer">
    <a class="read-more" href="https://rmoff.github.io/2016/10/14/boto-s3-errors/">Read More →</a>
  </footer>
</article>

      
        <article class="post-entry">
  <header class="post-header">
    <h3 class="post-title"><a href="https://rmoff.github.io/2016/07/29/ogg-15051-oracle.goldengate.util.ggexception-class-not-found-kafkahandler/" class="post-link">OGG-15051 oracle.goldengate.util.GGException:  Class not found: &#34;kafkahandler&#34;</a></h3>
    <p class="post-meta">@Robin Moffatt · Jul 29, 2016 · 1 min read</p>
  </header>
  
  <p class="post-summary">Similar to the previous issue, the sample config in the docs causes another snafu:
OGG-15051 Java or JNI exception: oracle.goldengate.util.GGException: Class not found: &#34;kafkahandler&#34;. kafkahandler Class not found: &#34;kafkahandler&#34;. kafkahandler  This time it’s in the kafka.props file:
gg.handler.kafkahandler.Type = kafka  Should be
gg.handler.kafkahandler.type = kafka  No capital T in Type!
(Image credit: https://unsplash.com/@vanschneider)</p>
  <footer class="post-footer">
    <a class="read-more" href="https://rmoff.github.io/2016/07/29/ogg-15051-oracle.goldengate.util.ggexception-class-not-found-kafkahandler/">Read More →</a>
  </footer>
</article>

      
        <article class="post-entry">
  <header class="post-header">
    <h3 class="post-title"><a href="https://rmoff.github.io/2016/07/28/ogg-class-not-found-com.company.kafka.customproducerrecord/" class="post-link">OGG -  Class not found: &#34;com.company.kafka.CustomProducerRecord&#34;</a></h3>
    <p class="post-meta">@Robin Moffatt · Jul 28, 2016 · 1 min read</p>
  </header>
  
  <p class="post-summary">In the documentation for the current release of Oracle GoldenGate for Big Data (12.2.0.1.1.011) there’s a helpful sample configuration, which isn’t so helpful …
[...] gg.handler.kafkahandler.ProducerRecordClass = com.company.kafka.CustomProducerRecord [...]  This value for gg.handler.kafkahandler.ProducerRecordClass will cause a failure when you start the replicat:
[...] Class not found: &#34;com.company.kafka.CustomProducerRecord&#34; [...]  If you comment this configuration item out, it’ll use the default (oracle.goldengate.handler.kafka.DefaultProducerRecord) and work swimingly!
(Image credit: https://unsplash.com/@vanschneider)</p>
  <footer class="post-footer">
    <a class="read-more" href="https://rmoff.github.io/2016/07/28/ogg-class-not-found-com.company.kafka.customproducerrecord/">Read More →</a>
  </footer>
</article>

      
        <article class="post-entry">
  <header class="post-header">
    <h3 class="post-title"><a href="https://rmoff.github.io/2016/07/27/kafka-connect-jdbc-oracle-number-of-groups-must-be-positive/" class="post-link">Kafka Connect JDBC - Oracle - Number of groups must be positive</a></h3>
    <p class="post-meta">@Robin Moffatt · Jul 27, 2016 · 1 min read</p>
  </header>
  
  <p class="post-summary">There are various reasons for this error, but the one I hit was that the table name is case sensitive, and returned from Oracle by the JDBC driver in uppercase.
If you specify the tablename in your connecter config in lowercase, it won’t be matched, and this error is thrown. You can validate this by setting debug logging (edit etc/kafka/connect-log4j.properties to set log4j.rootLogger=DEBUG, stdout), and observe: (I’ve truncated some of the output for legibility)</p>
  <footer class="post-footer">
    <a class="read-more" href="https://rmoff.github.io/2016/07/27/kafka-connect-jdbc-oracle-number-of-groups-must-be-positive/">Read More →</a>
  </footer>
</article>

      
        <article class="post-entry">
  <header class="post-header">
    <h3 class="post-title"><a href="https://rmoff.github.io/2016/07/19/kafka-connect-hdfs-with-hive-integration-schemaprojectorexception-schema-version-required/" class="post-link">Kafka Connect - HDFS with Hive Integration - SchemaProjectorException - Schema version required</a></h3>
    <p class="post-meta">@Robin Moffatt · Jul 19, 2016 · 2 min read</p>
  </header>
  
  <p class="post-summary">I’ve been doing some noodling around with Confluent’s Kafka Connect recently, as part of gaining a wider understanding into Kafka. If you’re not familiar with Kafka Connect this page gives a good idea of the thinking behind it.
One issue that I hit defeated my Google-fu so I’m recording it here to hopefully help out fellow n00bs.
The pipeline that I’d set up looked like this:
 Eneco’s Twitter Source streaming tweets to a Kafka topic Confluent’s HDFS Sink to stream tweets to HDFS and define Hive table automagically over them  It worked great, but only if I didn’t enable the Hive integration part.</p>
  <footer class="post-footer">
    <a class="read-more" href="https://rmoff.github.io/2016/07/19/kafka-connect-hdfs-with-hive-integration-schemaprojectorexception-schema-version-required/">Read More →</a>
  </footer>
</article>

      
        <article class="post-entry">
  <header class="post-header">
    <h3 class="post-title"><a href="https://rmoff.github.io/2016/07/18/configuring-ups-apcupsd/" class="post-link">Configuring UPS/apcupsd</a></h3>
    <p class="post-meta">@Robin Moffatt · Jul 18, 2016 · 6 min read</p>
  </header>
  
  <p class="post-summary">With my new server I bought a UPS, partly just as a Good Thing, but also because I suspect a powercut fried the motherboard on a previous machine that I had, and this baby is too precious to lose ;)
The idea is that the UPS will smooth out the power supply to my server, protecting it from surges or temporarily blips in power loss. If there’s a proper power cut, the UPS is connected to my server and can initiate a graceful shutdown instead of system crash.</p>
  <footer class="post-footer">
    <a class="read-more" href="https://rmoff.github.io/2016/07/18/configuring-ups-apcupsd/">Read More →</a>
  </footer>
</article>

      
        <article class="post-entry">
  <header class="post-header">
    <h3 class="post-title"><a href="https://rmoff.github.io/2016/07/13/spark-sqlcontext.read.json-java.io.ioexception-no-input-paths-specified-in-job/" class="post-link">Spark sqlContext.read.json - java.io.IOException: No input paths specified in job</a></h3>
    <p class="post-meta">@Robin Moffatt · Jul 13, 2016 · 1 min read</p>
  </header>
  
  <p class="post-summary">Trying to use SparkSQL to read a JSON file, from either pyspark or spark-shell, I got this error:
java.io.IOException: No input paths specified in job  scala&gt; sqlContext.read.json(&#34;/u02/custom/twitter/twitter.json&#34;) java.io.IOException: No input paths specified in job at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:202)  Despite the reference articles that I found using this local path syntax (/u02/custom/twitter/twitter.json), it turned out that I needed to prefix it with file://:
scala&gt; sqlContext.read.json(&#34;file:///u02/custom/twitter/twitter.json&#34;) res3: org.apache.spark.sql.DataFrame = [@timestamp: string, @version: string, contributors: string, coordinates: string, created_at: string, entities: struct&lt;hashtags:array&lt;struct&lt;indices:array&lt;bigint&gt;,text:string&gt;&gt;,media:array&lt;struct&lt;display_url:string,expanded_url:string,id:bigint,id_str:string,indices:array&lt;bigint&gt;,media_url:string,media_url_https:string,sizes:struct&lt;large:struct&lt;h:bigint,resize:string,w:bigint&gt;,medium:struct&lt;h:bigint,resize:string,w:bigint&gt;,small:struct&lt;h:bigint,resize:string,w:bigint&gt;,thumb:struct&lt;h:bigint,resize:string,w:bigint&gt;&gt;,source_status_id:bigint,source_status_id_str:string,source_user_id:bigint,source_user_id_str:string,type:string,url:string&gt;&gt;,symbols:array&lt;struct&lt;indices:array&lt;bigint&gt;,text:string&gt;&gt;,urls:array&lt;struct&lt;display_url:string,expanded_url:string.</p>
  <footer class="post-footer">
    <a class="read-more" href="https://rmoff.github.io/2016/07/13/spark-sqlcontext.read.json-java.io.ioexception-no-input-paths-specified-in-job/">Read More →</a>
  </footer>
</article>

      
    
    
      <footer class="list-footer">
        <nav class="pagination">
          <h3 class="offscreen">Pagination</h3>
          
            <a class="pagination-previous" href="/post/page/5/">← Newer Posts</a>
          
          
            <a class="pagination-next" href="/post/page/7/">Older Posts →</a>
          
        </nav>
      </footer>
    
  </section>
  


<footer class="site-footer">
  <p>© 2017-2018 rmoff.net</p>
  <p>Powered by <a href="https://gohugo.io/" target="_blank">Hugo</a> with theme <a href="https://github.com/laozhu/hugo-nuo" target="_blank">Nuo</a>.</p>
  
</footer>








<script src="/scripts/index.min.js"></script>








  </body>
</html>
