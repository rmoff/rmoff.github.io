<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8" />

  
  <title>Streaming geopoint data from Kafka to Elasticsearch</title>

  
  
  <link href="//cdn.jsdelivr.net" rel="dns-prefetch">
  <link href="//cdnjs.cloudflare.com" rel="dns-prefetch">
  <link href="//at.alicdn.com" rel="dns-prefetch">
  <link href="//fonts.googleapis.com" rel="dns-prefetch">
  <link href="//fonts.gstatic.com" rel="dns-prefetch">
  
  
  
  
  

  

  
  <meta name="author" content="Robin Moffatt">
  <meta name="description" content="Using the Elasticsearch Kafka Connect connector to stream events from a Kafka topic to Elasticsearch.
curl -X &amp;quot;POST&amp;quot; &amp;quot;http://kafka-connect:8083/connectors/&amp;quot; \ -H &amp;quot;Content-Type: application/json&amp;quot; \ -d &#39;{ &amp;quot;name&amp;quot;: &amp;quot;es_sink_ATM_POSSIBLE_FRAUD&amp;quot;, &amp;quot;config&amp;quot;: { &amp;quot;topics&amp;quot;: &amp;quot;ATM_POSSIBLE_FRAUD&amp;quot;, &amp;quot;key.converter&amp;quot;: &amp;quot;org.apache.kafka.connect.storage.StringConverter&amp;quot;, &amp;quot;value.converter&amp;quot;: &amp;quot;org.apache.kafka.connect.json.JsonConverter&amp;quot;, &amp;quot;value.converter.schemas.enable&amp;quot;: false, &amp;quot;connector.class&amp;quot;: &amp;quot;io.confluent.connect.elasticsearch.ElasticsearchSinkConnector&amp;quot;, &amp;quot;key.ignore&amp;quot;: &amp;quot;true&amp;quot;, &amp;quot;schema.ignore&amp;quot;: &amp;quot;true&amp;quot;, &amp;quot;type.name&amp;quot;: &amp;quot;type.name=kafkaconnect&amp;quot;, &amp;quot;topic.index.map&amp;quot;: &amp;quot;ATM_POSSIBLE_FRAUD:atm_possible_fraud&amp;quot;, &amp;quot;connection.url&amp;quot;: &amp;quot;http://elasticsearch:9200&amp;quot; } }&#39;  Dynamic mapping setup in Elasticsearch (before running the Connector) to force columns to a given type:
curl -XPUT &amp;quot;http://elasticsearch:9200/_template/kafkaconnect/&amp;quot; -H &#39;Content-Type: application/json&#39; -d&#39; { &amp;quot;index_patterns&amp;quot;: &amp;quot;*&amp;quot;, &amp;quot;settings&amp;quot;: { &amp;quot;number_of_shards&amp;quot;: 1, &amp;quot;number_of_replicas&amp;quot;: 0 }, &amp;quot;mappings&amp;quot;: { &amp;quot;_default_&amp;quot;: { &amp;quot;dynamic_templates&amp;quot;: [ { &amp;quot;dates&amp;quot;: { &amp;quot;match&amp;quot;: &amp;quot;*TIMESTAMP&amp;quot;, &amp;quot;mapping&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;date&amp;quot; } } }, { &amp;quot;geopoint&amp;quot;: { &amp;quot;match&amp;quot;: &amp;quot;*LOCATION&amp;quot;, &amp;quot;mapping&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;geo_point&amp;quot; } } }, { &amp;quot;geopoint2&amp;quot;: { &amp;quot;match&amp;quot;: &amp;quot;location&amp;quot;, &amp;quot;mapping&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;geo_point&amp;quot; } } }, { &amp;quot;non_analysed_string_template&amp;quot;: { &amp;quot;match&amp;quot;: &amp;quot;account_id, atm, transaction_id&amp;quot;, &amp;quot;match_mapping_type&amp;quot;: &amp;quot;string&amp;quot;, &amp;quot;mapping&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;keyword&amp;quot; } } } ] } } }&#39;  Sample JSON message from Kafka: (pretty-printed)">

  
  
    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="@gohugoio">
    <meta name="twitter:title" content="Streaming geopoint data from Kafka to Elasticsearch">
    <meta name="twitter:description" content="Using the Elasticsearch Kafka Connect connector to stream events from a Kafka topic to Elasticsearch.
curl -X &amp;quot;POST&amp;quot; &amp;quot;http://kafka-connect:8083/connectors/&amp;quot; \ -H &amp;quot;Content-Type: application/json&amp;quot; \ -d &#39;{ &amp;quot;name&amp;quot;: &amp;quot;es_sink_ATM_POSSIBLE_FRAUD&amp;quot;, &amp;quot;config&amp;quot;: { &amp;quot;topics&amp;quot;: &amp;quot;ATM_POSSIBLE_FRAUD&amp;quot;, &amp;quot;key.converter&amp;quot;: &amp;quot;org.apache.kafka.connect.storage.StringConverter&amp;quot;, &amp;quot;value.converter&amp;quot;: &amp;quot;org.apache.kafka.connect.json.JsonConverter&amp;quot;, &amp;quot;value.converter.schemas.enable&amp;quot;: false, &amp;quot;connector.class&amp;quot;: &amp;quot;io.confluent.connect.elasticsearch.ElasticsearchSinkConnector&amp;quot;, &amp;quot;key.ignore&amp;quot;: &amp;quot;true&amp;quot;, &amp;quot;schema.ignore&amp;quot;: &amp;quot;true&amp;quot;, &amp;quot;type.name&amp;quot;: &amp;quot;type.name=kafkaconnect&amp;quot;, &amp;quot;topic.index.map&amp;quot;: &amp;quot;ATM_POSSIBLE_FRAUD:atm_possible_fraud&amp;quot;, &amp;quot;connection.url&amp;quot;: &amp;quot;http://elasticsearch:9200&amp;quot; } }&#39;  Dynamic mapping setup in Elasticsearch (before running the Connector) to force columns to a given type:
curl -XPUT &amp;quot;http://elasticsearch:9200/_template/kafkaconnect/&amp;quot; -H &#39;Content-Type: application/json&#39; -d&#39; { &amp;quot;index_patterns&amp;quot;: &amp;quot;*&amp;quot;, &amp;quot;settings&amp;quot;: { &amp;quot;number_of_shards&amp;quot;: 1, &amp;quot;number_of_replicas&amp;quot;: 0 }, &amp;quot;mappings&amp;quot;: { &amp;quot;_default_&amp;quot;: { &amp;quot;dynamic_templates&amp;quot;: [ { &amp;quot;dates&amp;quot;: { &amp;quot;match&amp;quot;: &amp;quot;*TIMESTAMP&amp;quot;, &amp;quot;mapping&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;date&amp;quot; } } }, { &amp;quot;geopoint&amp;quot;: { &amp;quot;match&amp;quot;: &amp;quot;*LOCATION&amp;quot;, &amp;quot;mapping&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;geo_point&amp;quot; } } }, { &amp;quot;geopoint2&amp;quot;: { &amp;quot;match&amp;quot;: &amp;quot;location&amp;quot;, &amp;quot;mapping&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;geo_point&amp;quot; } } }, { &amp;quot;non_analysed_string_template&amp;quot;: { &amp;quot;match&amp;quot;: &amp;quot;account_id, atm, transaction_id&amp;quot;, &amp;quot;match_mapping_type&amp;quot;: &amp;quot;string&amp;quot;, &amp;quot;mapping&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;keyword&amp;quot; } } } ] } } }&#39;  Sample JSON message from Kafka: (pretty-printed)">
    <meta name="twitter:image" content="/images/avatar.jpg">
  

  
  <meta property="og:type" content="article">
  <meta property="og:title" content="Streaming geopoint data from Kafka to Elasticsearch">
  <meta property="og:description" content="Using the Elasticsearch Kafka Connect connector to stream events from a Kafka topic to Elasticsearch.
curl -X &amp;quot;POST&amp;quot; &amp;quot;http://kafka-connect:8083/connectors/&amp;quot; \ -H &amp;quot;Content-Type: application/json&amp;quot; \ -d &#39;{ &amp;quot;name&amp;quot;: &amp;quot;es_sink_ATM_POSSIBLE_FRAUD&amp;quot;, &amp;quot;config&amp;quot;: { &amp;quot;topics&amp;quot;: &amp;quot;ATM_POSSIBLE_FRAUD&amp;quot;, &amp;quot;key.converter&amp;quot;: &amp;quot;org.apache.kafka.connect.storage.StringConverter&amp;quot;, &amp;quot;value.converter&amp;quot;: &amp;quot;org.apache.kafka.connect.json.JsonConverter&amp;quot;, &amp;quot;value.converter.schemas.enable&amp;quot;: false, &amp;quot;connector.class&amp;quot;: &amp;quot;io.confluent.connect.elasticsearch.ElasticsearchSinkConnector&amp;quot;, &amp;quot;key.ignore&amp;quot;: &amp;quot;true&amp;quot;, &amp;quot;schema.ignore&amp;quot;: &amp;quot;true&amp;quot;, &amp;quot;type.name&amp;quot;: &amp;quot;type.name=kafkaconnect&amp;quot;, &amp;quot;topic.index.map&amp;quot;: &amp;quot;ATM_POSSIBLE_FRAUD:atm_possible_fraud&amp;quot;, &amp;quot;connection.url&amp;quot;: &amp;quot;http://elasticsearch:9200&amp;quot; } }&#39;  Dynamic mapping setup in Elasticsearch (before running the Connector) to force columns to a given type:
curl -XPUT &amp;quot;http://elasticsearch:9200/_template/kafkaconnect/&amp;quot; -H &#39;Content-Type: application/json&#39; -d&#39; { &amp;quot;index_patterns&amp;quot;: &amp;quot;*&amp;quot;, &amp;quot;settings&amp;quot;: { &amp;quot;number_of_shards&amp;quot;: 1, &amp;quot;number_of_replicas&amp;quot;: 0 }, &amp;quot;mappings&amp;quot;: { &amp;quot;_default_&amp;quot;: { &amp;quot;dynamic_templates&amp;quot;: [ { &amp;quot;dates&amp;quot;: { &amp;quot;match&amp;quot;: &amp;quot;*TIMESTAMP&amp;quot;, &amp;quot;mapping&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;date&amp;quot; } } }, { &amp;quot;geopoint&amp;quot;: { &amp;quot;match&amp;quot;: &amp;quot;*LOCATION&amp;quot;, &amp;quot;mapping&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;geo_point&amp;quot; } } }, { &amp;quot;geopoint2&amp;quot;: { &amp;quot;match&amp;quot;: &amp;quot;location&amp;quot;, &amp;quot;mapping&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;geo_point&amp;quot; } } }, { &amp;quot;non_analysed_string_template&amp;quot;: { &amp;quot;match&amp;quot;: &amp;quot;account_id, atm, transaction_id&amp;quot;, &amp;quot;match_mapping_type&amp;quot;: &amp;quot;string&amp;quot;, &amp;quot;mapping&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;keyword&amp;quot; } } } ] } } }&#39;  Sample JSON message from Kafka: (pretty-printed)">
  <meta property="og:url" content="https://rmoff.github.io/post/streaming-geopoint-data-from-kafka-to-elasticsearch/">
  <meta property="og:image" content="/images/avatar.jpg">




<meta name="generator" content="Hugo 0.52">


<link rel="canonical" href="https://rmoff.github.io/post/streaming-geopoint-data-from-kafka-to-elasticsearch/">

<meta name="renderer" content="webkit">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="format-detection" content="telephone=no,email=no,adress=no">
<meta http-equiv="Cache-Control" content="no-transform">


<meta name="robots" content="index,follow">
<meta name="referrer" content="origin-when-cross-origin">







<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="apple-mobile-web-app-title" content="rmoff.net">
<meta name="msapplication-tooltip" content="rmoff.net">
<meta name='msapplication-navbutton-color' content="#5fbf5e">
<meta name="msapplication-TileColor" content="#5fbf5e">
<meta name="msapplication-TileImage" content="/images/tile-image-windows.png">
<link rel="icon" href="/images/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
<link rel="icon" sizes="192x192" href="/images/touch-icon-android.png">
<link rel="apple-touch-icon" href="/images/touch-icon-apple.png">


<link rel="preload" href="/styles/main.min.css" as="style">
<link rel="preload" href="https://fonts.googleapis.com/css?family=Lobster" as="style">
<link rel="preload" href="/images/avatar.jpg" as="image">
<link rel="preload" href="/images/grey-prism.svg" as="image">


<style>
  body {
    background: rgb(244, 243, 241) url('/images/grey-prism.svg') repeat fixed;
  }
</style>
<link rel="stylesheet" href="/styles/main.min.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lobster">


<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.2/dist/medium-zoom.min.js"></script>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/video.js@7.3.0/dist/video-js.min.css">



  
  
<!--[if lte IE 8]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/videojs-ie8@1.1.2/dist/videojs-ie8.min.js"></script>
<![endif]-->

<!--[if lte IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/eligrey-classlist-js-polyfill@1.2.20180112/classList.min.js"></script>
<![endif]-->


<script src="https://cdn.jsdelivr.net/npm/smooth-scroll@14.2.1/dist/smooth-scroll.polyfills.min.js"></script>


</head>
  <body>
    
    <div class="suspension">
      <a title="Go to top" class="to-top is-hide"><span class="icon icon-up"></span></a>
      
        
      
    </div>
    
    
  <header class="site-header">
  <img class="avatar" src="/images/avatar.jpg" alt="Avatar">
  
  <h2 class="title">rmoff.net</h2>
  
  <p class="subtitle"></p>
  <button class="menu-toggle" type="button">
    <span class="icon icon-menu"></span>
  </button>
  <nav class="site-menu collapsed">
    <h2 class="offscreen">Main Menu</h2>
    <ul class="menu-list">
      
      
      
      
    </ul>
  </nav>
  <nav class="social-menu collapsed">
    <h2 class="offscreen">Social Networks</h2>
    <ul class="social-list"></ul>
  </nav>
</header>

  <section class="main post-detail">
    <header class="post-header">
      <h1 class="post-title">Streaming geopoint data from Kafka to Elasticsearch</h1>
      <p class="post-meta">@Robin Moffatt · Oct 5, 2018 · 3 min read</p>
    </header>
    <article class="post-content"><p>Using the <a href="https://www.confluent.io/connector/kafka-connect-elasticsearch/">Elasticsearch Kafka Connect connector</a> to stream events from a Kafka topic to Elasticsearch.</p>

<pre><code>curl -X &quot;POST&quot; &quot;http://kafka-connect:8083/connectors/&quot; \
     -H &quot;Content-Type: application/json&quot; \
     -d '{
  &quot;name&quot;: &quot;es_sink_ATM_POSSIBLE_FRAUD&quot;,
  &quot;config&quot;: {
    &quot;topics&quot;: &quot;ATM_POSSIBLE_FRAUD&quot;,
    &quot;key.converter&quot;: &quot;org.apache.kafka.connect.storage.StringConverter&quot;,
    &quot;value.converter&quot;: &quot;org.apache.kafka.connect.json.JsonConverter&quot;,
    &quot;value.converter.schemas.enable&quot;: false,
    &quot;connector.class&quot;: &quot;io.confluent.connect.elasticsearch.ElasticsearchSinkConnector&quot;,
    &quot;key.ignore&quot;: &quot;true&quot;,
    &quot;schema.ignore&quot;: &quot;true&quot;,
    &quot;type.name&quot;: &quot;type.name=kafkaconnect&quot;,
    &quot;topic.index.map&quot;: &quot;ATM_POSSIBLE_FRAUD:atm_possible_fraud&quot;,
    &quot;connection.url&quot;: &quot;http://elasticsearch:9200&quot;
  }
}'
</code></pre>

<p>Dynamic mapping setup in Elasticsearch (before running the Connector) to force columns to a given type:</p>

<pre><code>curl -XPUT &quot;http://elasticsearch:9200/_template/kafkaconnect/&quot; -H 'Content-Type: application/json' -d'
{
  &quot;index_patterns&quot;: &quot;*&quot;,
  &quot;settings&quot;: {
    &quot;number_of_shards&quot;: 1,
    &quot;number_of_replicas&quot;: 0
  },
  &quot;mappings&quot;: {
    &quot;_default_&quot;: {
      &quot;dynamic_templates&quot;: [
        {
          &quot;dates&quot;: {
            &quot;match&quot;: &quot;*TIMESTAMP&quot;,
            &quot;mapping&quot;: {
              &quot;type&quot;: &quot;date&quot;
            }
          }
        },
        {
          &quot;geopoint&quot;: {
            &quot;match&quot;: &quot;*LOCATION&quot;,
            &quot;mapping&quot;: {
              &quot;type&quot;: &quot;geo_point&quot;
            }
          }
        },
        {
          &quot;geopoint2&quot;: {
            &quot;match&quot;: &quot;location&quot;,
            &quot;mapping&quot;: {
              &quot;type&quot;: &quot;geo_point&quot;
            }
          }
        },
        {
          &quot;non_analysed_string_template&quot;: {
            &quot;match&quot;: &quot;account_id, atm, transaction_id&quot;,
            &quot;match_mapping_type&quot;: &quot;string&quot;,
            &quot;mapping&quot;: {
              &quot;type&quot;: &quot;keyword&quot;
            }
          }
        }
      ]
    }
  }
}'
</code></pre>

<p>Sample JSON message from Kafka: (pretty-printed)</p>

<pre><code>{
  &quot;ACCOUNT_ID&quot;: &quot;a898&quot;,
  &quot;TXN1_TIMESTAMP&quot;: 1538733229153,
  &quot;TXN2_TIMESTAMP&quot;: 1538733200285,
  &quot;TXN1_LOCATION&quot;: {
    &quot;LON&quot;: -122.4026113,
    &quot;LAT&quot;: 37.7911278
  },
  &quot;TXN2_LOCATION&quot;: {
    &quot;LON&quot;: -121.4943199,
    &quot;LAT&quot;: 38.5320738
  },
  &quot;TXN1_AMOUNT&quot;: 400,
  &quot;TXN2_AMOUNT&quot;: 50,
  &quot;DISTANCE_BETWEEN_TXNS&quot;: 114.42848872962888,
  &quot;MS_DIFFERENCE&quot;: -28868
}
</code></pre>

<p>Note that the case of all columns is uppercase which causes problems trying to stream this to Elasticsearch. Kafka Connect worker log shows:</p>

<pre><code>WARN Failed to execute batch 5560 of 19 records with attempt 2/6, will attempt retry after 111 ms. Failure reason: Bulk request failed: [{&quot;type&quot;:&quot;mapper_parsing_exception&quot;,&quot;reason&quot;:&quot;failed to parse&quot;,&quot;caused_by&quot;:{&quot;type&quot;:&quot;parse_exception&quot;,&quot;reason&quot;:&quot;field must be either [lat], [lon] or [geohash]&quot;}}
</code></pre>

<p>Taking the JSON message from the Kafka topic and manually sending it to Elasticsearch replicates the probem:</p>

<pre><code>curl -XPOST &quot;http://elasticsearch:9200/atm_possible_fraud/kafkaconnect&quot; -H 'Content-Type: application/json' -d'
{&quot;ACCOUNT_ID&quot;:&quot;a898&quot;,&quot;TXN1_TIMESTAMP&quot;:1538733229153,&quot;TXN2_TIMESTAMP&quot;:1538733200285,&quot;TXN1_LOCATION&quot;:{&quot;LON&quot;:-122.4026113,&quot;LAT&quot;:37.7911278},&quot;TXN2_LOCATION&quot;:{&quot;LON&quot;:-121.4943199,&quot;LAT&quot;:38.5320738},&quot;TXN1_AMOUNT&quot;:400,&quot;TXN2_AMOUNT&quot;:50,&quot;DISTANCE_BETWEEN_TXNS&quot;:114.42848872962888,&quot;MS_DIFFERENCE&quot;:-28868}'

{
&quot;error&quot;: {
    &quot;root_cause&quot;: [
    {
        &quot;type&quot;: &quot;parse_exception&quot;,
        &quot;reason&quot;: &quot;field must be either [lat], [lon] or [geohash]&quot;
    }
    ],
    &quot;type&quot;: &quot;mapper_parsing_exception&quot;,
    &quot;reason&quot;: &quot;failed to parse&quot;,
    &quot;caused_by&quot;: {
    &quot;type&quot;: &quot;parse_exception&quot;,
    &quot;reason&quot;: &quot;field must be either [lat], [lon] or [geohash]&quot;
    }
},
&quot;status&quot;: 400
}
</code></pre>

<p>So Elasticsearch is sensitive to the <em>case</em> of the <code>lat</code>, <code>lon</code> columns. The fix (<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/geo-point.html[per">https://www.elastic.co/guide/en/elasticsearch/reference/current/geo-point.html[per</a> the examples here]) is to force the column names to lower case, or concatenate the lat/long into a single string):</p>

<pre><code>curl -XPOST &quot;http://elasticsearch:9200/atm_possible_fraud/kafkaconnect&quot; -H 'Content-Type: application/json' -d'
{&quot;ACCOUNT_ID&quot;:&quot;a898&quot;,
&quot;TXN1_TIMESTAMP&quot;:1538733229153,
&quot;TXN2_TIMESTAMP&quot;:1538733200285,
&quot;TXN1_LOCATION&quot;:&quot;37.7911278,-122.4026113&quot;,
&quot;TXN2_LOCATION&quot;:{&quot;lon&quot;:-121.4943199,&quot;lat&quot;:38.5320738},
&quot;TXN1_AMOUNT&quot;:400,
&quot;TXN2_AMOUNT&quot;:50,
&quot;DISTANCE_BETWEEN_TXNS&quot;:114.42848872962888,
&quot;MS_DIFFERENCE&quot;:-28868}'
</code></pre>

<p>To implement this, I used KSQL to wrangle the data from a <code>STRUCT</code> (with uppercase names) to a lat/long string:</p>

<pre><code>CREATE STREAM ATM_POSSIBLE_FRAUD_02 AS \
SELECT CAST(X.location-&gt;lat AS STRING) + ',' + CAST(X.location-&gt;lon AS STRING) AS TXN1_LOCATION
[...]
FROM   ATM_TXNS X 
</code></pre>

<p>Now the JSON messages look like this:</p>

<pre><code>{
  &quot;ACCOUNT_ID&quot;: &quot;a182&quot;,
  &quot;TXN1_TIMESTAMP&quot;: 1538735677504,
  &quot;TXN2_TIMESTAMP&quot;: 1538735677528,
  &quot;TXN1_LOCATION&quot;: &quot;37.8002247,-122.2160293&quot;,
  &quot;TXN2_LOCATION&quot;: &quot;37.764931,-122.4232384&quot;,
  &quot;TXN1_AMOUNT&quot;: 400,
  &quot;TXN2_AMOUNT&quot;: 20,
  &quot;DISTANCE_BETWEEN_TXNS&quot;: 18.628023818908343,
  &quot;MS_DIFFERENCE&quot;: 24
}
</code></pre>

<p>And the Kafka Connect -&gt; Elasticsearch pipeline works just great. Here&rsquo;s the resulting Elasticsearch index and sample document:</p>

<pre><code>{
  &quot;atm_possible_fraud&quot;: {
    &quot;aliases&quot;: {},
    &quot;mappings&quot;: {
[...]
      &quot;type.name=kafkaconnect&quot;: {
[...]
        &quot;properties&quot;: {
          &quot;ACCOUNT_ID&quot;: {
            &quot;type&quot;: &quot;text&quot;,
            &quot;fields&quot;: {
              &quot;keyword&quot;: {
                &quot;type&quot;: &quot;keyword&quot;,
                &quot;ignore_above&quot;: 256
              }
            }
          },
          &quot;DISTANCE_BETWEEN_TXNS&quot;: {
            &quot;type&quot;: &quot;float&quot;
          },
          &quot;MS_DIFFERENCE&quot;: {
            &quot;type&quot;: &quot;long&quot;
          },
          &quot;TXN1_AMOUNT&quot;: {
            &quot;type&quot;: &quot;long&quot;
          },
          &quot;TXN1_LOCATION&quot;: {
            &quot;type&quot;: &quot;geo_point&quot;
          },
          &quot;TXN1_TIMESTAMP&quot;: {
            &quot;type&quot;: &quot;date&quot;
          },
          &quot;TXN2_AMOUNT&quot;: {
            &quot;type&quot;: &quot;long&quot;
          },
          &quot;TXN2_LOCATION&quot;: {
            &quot;type&quot;: &quot;geo_point&quot;
          },
          &quot;TXN2_TIMESTAMP&quot;: {
            &quot;type&quot;: &quot;date&quot;
          }
        }
      }
    },
    &quot;settings&quot;: {
      &quot;index&quot;: {
        &quot;creation_date&quot;: &quot;1538735883573&quot;,
        &quot;number_of_shards&quot;: &quot;1&quot;,
        &quot;number_of_replicas&quot;: &quot;0&quot;,
        &quot;uuid&quot;: &quot;ppXU3hFvS-CU9kKlFaK-NA&quot;,
        &quot;version&quot;: {
          &quot;created&quot;: &quot;6040299&quot;
        },
        &quot;provided_name&quot;: &quot;atm_possible_fraud&quot;
      }
    }
  }
}
</code></pre>

<pre><code>  {
    &quot;_index&quot;: &quot;atm_possible_fraud&quot;,
    &quot;_type&quot;: &quot;type.name=kafkaconnect&quot;,
    &quot;_id&quot;: &quot;ATM_POSSIBLE_FRAUD2+0+7742&quot;,
    &quot;_score&quot;: 1,
    &quot;_source&quot;: {
      &quot;TXN2_TIMESTAMP&quot;: 1538735677573,
      &quot;TXN2_AMOUNT&quot;: 300,
      &quot;ACCOUNT_ID&quot;: &quot;a874&quot;,
      &quot;TXN1_TIMESTAMP&quot;: 1538735677515,
      &quot;MS_DIFFERENCE&quot;: 58,
      &quot;TXN1_AMOUNT&quot;: 300,
      &quot;DISTANCE_BETWEEN_TXNS&quot;: 57.33495049372549,
      &quot;TXN1_LOCATION&quot;: &quot;37.7923185,-122.3940464&quot;,
      &quot;TXN2_LOCATION&quot;: &quot;37.3540655,-122.0512763&quot;
    }
  }
</code></pre>
</article>
    <footer class="post-footer">
      
      <ul class="post-tags">
        
          <li><a href="/tags/elasticsearch"><span class="tag">Elasticsearch</span></a></li>
        
          <li><a href="/tags/kafka"><span class="tag">Kafka</span></a></li>
        
          <li><a href="/tags/kafkaconnect"><span class="tag">Kafkaconnect</span></a></li>
        
          <li><a href="/tags/geopoint"><span class="tag">Geopoint</span></a></li>
        
      </ul>
      
      <p class="post-copyright">
        
      </p>
    </footer>
    
      
    
  </section>
  


<footer class="site-footer">
  <p>© 2017-2018 rmoff.net</p>
  <p>Powered by <a href="https://gohugo.io/" target="_blank">Hugo</a> with theme <a href="https://github.com/laozhu/hugo-nuo" target="_blank">Nuo</a>.</p>
  
</footer>



<script async src="https://cdn.jsdelivr.net/npm/video.js@7.3.0/dist/video.min.js"></script>




<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      displayMath: [['$$','$$'], ['\\[','\\]']],
      processEscapes: true,
      processEnvironments: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      TeX: { equationNumbers: { autoNumber: "AMS" },
      extensions: ["AMSmath.js", "AMSsymbols.js"] }
    },
  });
</script>
<script type="text/x-mathjax-config">
  // Fix <code> tags after MathJax finishes running. This is a
  // hack to overcome a shortcoming of Markdown. Discussion at
  // https://github.com/mojombo/jekyll/issues/199
  MathJax.Hub.Queue(() => {
    MathJax.Hub.getAllJax().map(v => v.SourceElement().parentNode.className += ' has-jax');
  });
</script>



<script src="/scripts/index.min.js"></script>








  </body>
</html>
