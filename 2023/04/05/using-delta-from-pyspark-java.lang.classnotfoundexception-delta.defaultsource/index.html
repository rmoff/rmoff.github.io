<!DOCTYPE html>
<html lang="en">
	<head>
		<meta http-equiv=X-Clacks-Overhead content="GNU Terry Pratchett">
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		
		<link rel="preconnect" href="https://fonts.googleapis.com">
		<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
		<link rel="preload" as="image" href="https://rmoff.net/images/2023/04/h_IMG_7944.jpeg" >
		
		<title>Using Delta from pySpark - &lt;code&gt;java.lang.ClassNotFoundException: delta.DefaultSource&lt;/code&gt;</title>
		<link rel="alternate" type="application/rss+xml" title="RSS" href="https://rmoff.net/index.xml">
		<link rel="canonical" href="https://rmoff.net/2023/04/05/using-delta-from-pyspark-java.lang.classnotfoundexception-delta.defaultsource/">
		
		

		
		<meta property="og:title" content="Using Delta from pySpark - java.lang.ClassNotFoundException: delta.DefaultSource" />
		<meta property="og:type" content="article" />
		<meta property="og:image" content="https://rmoff.net/images/2023/04/h_IMG_7944.jpeg" />
		<meta property="og:description" content="" />
		<meta property="og:url" content="https://rmoff.net/2023/04/05/using-delta-from-pyspark-java.lang.classnotfoundexception-delta.defaultsource/" />
		<meta property="og:site_name" content="Using Delta from pySpark - java.lang.ClassNotFoundException: delta.DefaultSource" />
		<meta name="twitter:card" content="summary_large_image" />
		<meta name="twitter:site" content="@" />


		
		<style>
			html { background-color: #FAF8F5; color: #2D2926; }
			body { opacity: 0; transition: opacity 0.1s ease; }
			body.loaded { opacity: 1; }
			.site-header { height: 60px; background-color: #FAF8F5; border-bottom: 1px solid #E8421E; }
		</style>

		
		
		<link rel="stylesheet" href="https://rmoff.net/css/redesign.css" />
		
		<link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Bricolage+Grotesque:opsz,wght@12..96,400;12..96,600;12..96,700;12..96,800&family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&family=JetBrains+Mono:wght@400;500&family=Outfit:wght@400;500;600&display=swap">
		<link href="https://fonts.googleapis.com/css2?family=Bricolage+Grotesque:opsz,wght@12..96,400;12..96,600;12..96,700;12..96,800&family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&family=JetBrains+Mono:wght@400;500&family=Outfit:wght@400;500;600&display=swap" rel="stylesheet" media="print" onload="this.media='all'">
		<noscript><link href="https://fonts.googleapis.com/css2?family=Bricolage+Grotesque:opsz,wght@12..96,400;12..96,600;12..96,700;12..96,800&family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&family=JetBrains+Mono:wght@400;500&family=Outfit:wght@400;500;600&display=swap" rel="stylesheet"></noscript>
		

		

		
		<script>
			!function(t,e){var o,n,p,r;e.__SV||(window.posthog=e,e._i=[],e.init=function(i,s,a){function g(t,e){var o=e.split(".");2==o.length&&(t=t[o[0]],e=o[1]),t[e]=function(){t.push([e].concat(Array.prototype.slice.call(arguments,0)))}}(p=t.createElement("script")).type="text/javascript",p.crossOrigin="anonymous",p.async=!0,p.src=s.api_host.replace(".i.posthog.com","-assets.i.posthog.com")+"/static/array.js",(r=t.getElementsByTagName("script")[0]).parentNode.insertBefore(p,r);var u=e;for(void 0!==a?u=e[a]=[]:a="posthog",u.people=u.people||[],u.toString=function(t){var e="posthog";return"posthog"!==a&&(e+="."+a),t||(e+=" (stub)"),e},u.people.toString=function(){return u.toString(1)+".people (stub)"},o="init capture register register_once register_for_session unregister unregister_for_session getFeatureFlag getFeatureFlagPayload isFeatureEnabled reloadFeatureFlags updateEarlyAccessFeatureEnrollment getEarlyAccessFeatures on onFeatureFlags onSessionId getSurveys getActiveMatchingSurveys renderSurvey canRenderSurvey getNextSurveyStep identify setPersonProperties group resetGroups setPersonPropertiesForFlags resetPersonPropertiesForFlags setGroupPropertiesForFlags resetGroupPropertiesForFlags reset get_distinct_id getGroups get_session_id get_session_replay_url alias set_config startSessionRecording stopSessionRecording sessionRecordingStarted captureException loadToolbar get_property getSessionProperty createPersonProfile opt_in_capturing opt_out_capturing has_opted_in_capturing has_opted_out_capturing clear_opt_in_out_capturing debug".split(" "),n=0;n<o.length;n++)g(u,o[n]);e._i.push([i,s,a])},e.__SV=1)}(document,window.posthog||[]);
            posthog.init('phc_93NEP79Ju4xqXYWXnoLbr4HMW0Iaepj1BGOVoEXYX6P',{api_host:'https://eu.i.posthog.com', person_profiles: 'identified_only'})
		</script>

		
		<script src="https://rmoff.net/js/story.js"></script>
		<script src="https://rmoff.net/js/toc.js"></script>
		<script src="https://rmoff.net/js/medium-mirror.js"></script>
	</head>
	<body class="ma0 section-post page-kind-page is-page-true ">
		<script>document.body.classList.add('loaded');</script>

		<header class="site-header hide-print">
	<div class="site-header-inner">
		<a href="https://rmoff.net/" class="site-title">rmoff's random ramblings</a>
		<nav class="site-nav">
			<a href="/categories/interesting-links/" class="nav-il"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"/><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"/></svg> Interesting Links</a>
			<span class="nav-sep"></span>
			<a href="/categories/"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"/><line x1="7" y1="7" x2="7.01" y2="7"/></svg> Categories</a>
			<a href="https://rmoff.net/search/"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="11" cy="11" r="8"/><line x1="21" y1="21" x2="16.65" y2="16.65"/></svg> Search</a>
			<a href="https://rmoff.net/index.xml"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 11a9 9 0 0 1 9 9"/><path d="M4 4a16 16 0 0 1 16 16"/><circle cx="5" cy="19" r="1"/></svg> RSS</a>
			<div class="nav-social">
				<a href="https://www.linkedin.com/in/robinmoffatt/" title="linkedin"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433a2.062 2.062 0 0 1-2.063-2.065 2.064 2.064 0 1 1 2.063 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg></a>
				<a href="https://twitter.com/rmoff/" title="twitter"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"/></svg></a>
				<a href="https://bsky.app/profile/rmoff.net" title="bluesky"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 568 501" fill="currentColor"><path d="M123.121 33.664C188.241 82.553 258.281 181.68 284 234.873c25.719-53.192 95.759-152.32 160.879-201.21C491.866-1.611 568-28.906 568 57.947c0 17.346-9.945 145.713-15.778 166.555-20.275 72.453-94.155 90.933-159.875 79.748C507.222 323.8 536.444 388.56 473.333 453.32c-119.86 122.992-172.272-30.859-185.702-70.281-2.462-7.227-3.614-10.608-3.631-7.733-.017-2.875-1.169.506-3.631 7.733-13.43 39.422-65.842 193.273-185.702 70.281-63.111-64.76-33.89-129.52 80.986-149.071-65.72 11.185-139.6-7.295-159.875-79.748C10.945 203.659 1 75.291 1 57.946 1-28.906 76.135-1.612 123.121 33.664z"/></svg></a>
				<a href="https://www.youtube.com/c/rmoff" title="youtube"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M23.498 6.186a3.016 3.016 0 0 0-2.122-2.136C19.505 3.545 12 3.545 12 3.545s-7.505 0-9.377.505A3.017 3.017 0 0 0 .502 6.186C0 8.07 0 12 0 12s0 3.93.502 5.814a3.016 3.016 0 0 0 2.122 2.136c1.871.505 9.376.505 9.376.505s7.505 0 9.377-.505a3.015 3.015 0 0 0 2.122-2.136C24 15.93 24 12 24 12s0-3.93-.502-5.814zM9.545 15.568V8.432L15.818 12l-6.273 3.568z"/></svg></a>
				<a href="https://talks.rmoff.net" title="talks"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><rect x="2" y="3" width="20" height="14" rx="0"/><line x1="12" y1="17" x2="12" y2="22"/><line x1="8" y1="22" x2="16" y2="22"/><polyline points="7 8 12 12 17 8"/></svg></a>
				<a href="https://github.com/rmoff/" title="github"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a>
			</div>
		</nav>
		<button class="nav-toggle" onclick="document.querySelector('.mobile-nav').classList.toggle('open')" aria-label="Menu">
			<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="18" x2="21" y2="18"/></svg>
		</button>
	</div>
	<nav class="mobile-nav">
		<a href="https://rmoff.net/">Home</a>
		<a href="/categories/">Categories</a>
		<a href="/categories/interesting-links/">Interesting Links</a>
		<a href="https://rmoff.net/search/">Search</a>
		<a href="https://rmoff.net/index.xml">RSS</a>
		<a href="https://www.linkedin.com/in/robinmoffatt/">linkedin</a>
		<a href="https://twitter.com/rmoff/">twitter</a>
		<a href="https://bsky.app/profile/rmoff.net">bluesky</a>
		<a href="https://www.youtube.com/c/rmoff">youtube</a>
		<a href="https://talks.rmoff.net">talks</a>
		<a href="https://github.com/rmoff/">github</a>
	</nav>
</header>


		<main role="main">
		

<div class="article-hero" style="background-image: url('https://rmoff.net/images/2023/04/h_IMG_7944.jpeg');">
	<div class="article-hero-overlay">
		<div class="article-hero-content">
			<h1>Using Delta from pySpark - <code>java.lang.ClassNotFoundException: delta.DefaultSource</code></h1>
			<p class="article-hero-meta">
				
					<time datetime="2023-04-05T15:51:41Z">05 Apr 2023</time>
					<span class="display-print">by </span>
					 &middot; <a href="https://rmoff.net/categories/pyspark">PySpark</a>, <a href="https://rmoff.net/categories/delta-lake">Delta Lake</a>
					<span class="display-print">at https://rmoff.net/2023/04/05/using-delta-from-pyspark-java.lang.classnotfoundexception-delta.defaultsource/</span>
				
			</p>
		</div>
	</div>
</div>


<details class="toc-mobile">
	<summary>Table of Contents</summary>
	<nav id="TableOfContents">
  <ul>
    <li><a href="#versions-and-stuff">Versions and stuff</a></li>
    <li><a href="#this-worked">This worked</a>
      <ul>
        <li><a href="#initialise-spark-with-delta-lake-config">Initialise Spark with Delta Lake config</a></li>
        <li><a href="#test-delta">Test delta</a></li>
      </ul>
    </li>
    <li><a href="#this-didnt-work">This didn&rsquo;t work</a>
      <ul>
        <li><a href="#initialise-spark-with-delta-lake-config-1">Initialise Spark with Delta Lake config</a></li>
        <li><a href="#test-delta-1">Test delta</a></li>
      </ul>
    </li>
    <li><a href="#notebook-log">Notebook Log</a></li>
    <li><a href="#why-did-it-do-what-it-did">Why Did It Do What It Did?</a></li>
    <li><a href="#proving-it-to-myself">Proving It To Myself</a></li>
    <li><a href="#spark-context-and-session---no-config-to-pick-up">Spark Context and Session - no config to pick up</a></li>
    <li><a href="#no-explicit-spark-context---picks-up-config-as-expected">No explicit Spark Context - picks up config as expected</a></li>
    <li><a href="#existing-spark-context-with-attempted-config-for-the-session-">Existing Spark Context with attempted config for the Session ðŸ’€</a></li>
  </ul>
</nav>
</details>

<div class="container-fluid docs">
	<div class="row">
		<main class="docs-content" role="main">

<article class="article" data-pagefind-body>
	<span data-pagefind-filter="category" style="display:none">PySpark</span><span data-pagefind-filter="category" style="display:none">Delta Lake</span>
	<img data-pagefind-meta="image[src]" src="https://rmoff.net/images/2023/04/h_IMG_7944.jpeg" style="display:none" alt="">
	<p>No great insights in this post, just something for folk who Google this error after me and don&rsquo;t want to waste three hours chasing their tailsâ€¦ ðŸ˜„</p>
<p>I wanted to use Delta Lake with <a href="https://spark.apache.org/docs/latest/api/python/">PySpark</a> from within a Jupyter Notebook. Easy, right? Not if you&rsquo;re like me and perhaps are new to it and rely on copy and paste of snippets you find across the internet to start with.</p>
<p>Whatever I tried, I kept hitting this error:</p>
<pre tabindex="0"><code>Py4JJavaError: An error occurred while calling o45.save.
: java.lang.ClassNotFoundException: 
Failed to find data source: delta.
</code></pre><p><strong>In short, the problem was that I was creating both a <code>SparkSession</code> <em>and</em> a <code>SparkContext</code></strong>. I honestly don&rsquo;t understand enough about Spark to tell you why this causes the error, but through a lot of painful trial and error I can tell you that it does. <em>Someone more knowledgable than me can perhaps tell me (<a href="mailto:robin@rmoff.net">email</a>) why this is and if what I&rsquo;ve ended up with is the right code</em>. <strong>UPDATE: Damon Cortesi explained it to me :) See <a href="#why-did-it-do-what-it-did">below</a> for details.</strong></p>
<p>Here&rsquo;re the salient points of the Jupyter notebook:</p>
<h2 id="versions-and-stuff">Versions and stuff&nbsp;<a class="headline-hash" href="#versions-and-stuff">ðŸ”—</a> </h2>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">import</span> <span style="color:#00f;font-weight:bold">sys</span>
</span></span><span style="display:flex;"><span><span style="color:#008000">print</span>(<span style="color:#ba2121">&#34;Kernel:&#34;</span>, sys<span style="color:#666">.</span>executable)
</span></span><span style="display:flex;"><span><span style="color:#008000">print</span>(<span style="color:#ba2121">&#34;Python version:&#34;</span>, sys<span style="color:#666">.</span>version)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">import</span> <span style="color:#00f;font-weight:bold">pyspark</span>
</span></span><span style="display:flex;"><span><span style="color:#008000">print</span>(<span style="color:#ba2121">&#34;PySpark version:&#34;</span>, pyspark<span style="color:#666">.</span>__version__)
</span></span></code></pre></div><pre><code>Kernel: /opt/conda/bin/python
Python version: 3.9.7 | packaged by conda-forge | (default, Oct 10 2021, 15:08:54)
[GCC 9.4.0]
PySpark version: 3.2.0
</code></pre>
<h2 id="this-worked">This worked&nbsp;<a class="headline-hash" href="#this-worked">ðŸ”—</a> </h2>
<h3 id="initialise-spark-with-delta-lake-config">Initialise Spark with Delta Lake config&nbsp;<a class="headline-hash" href="#initialise-spark-with-delta-lake-config">ðŸ”—</a> </h3>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">from</span> <span style="color:#00f;font-weight:bold">pyspark.context</span> <span style="color:#008000;font-weight:bold">import</span> SparkContext
</span></span><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">from</span> <span style="color:#00f;font-weight:bold">pyspark</span> <span style="color:#008000;font-weight:bold">import</span> SparkFiles
</span></span><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">from</span> <span style="color:#00f;font-weight:bold">pyspark.sql.session</span> <span style="color:#008000;font-weight:bold">import</span> SparkSession
</span></span><span style="display:flex;"><span>spark <span style="color:#666">=</span> (
</span></span><span style="display:flex;"><span>    SparkSession<span style="color:#666">.</span>builder<span style="color:#666">.</span>master(<span style="color:#ba2121">&#34;local[*]&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#666">.</span>config(<span style="color:#ba2121">&#34;spark.jars.packages&#34;</span>, <span style="color:#ba2121">&#34;io.delta:delta-core_2.12:2.0.0&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#666">.</span>config(<span style="color:#ba2121">&#34;spark.sql.extensions&#34;</span>, <span style="color:#ba2121">&#34;io.delta.sql.DeltaSparkSessionExtension&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#666">.</span>config(<span style="color:#ba2121">&#34;spark.sql.catalog.spark_catalog&#34;</span>, <span style="color:#ba2121">&#34;org.apache.spark.sql.delta.catalog.DeltaCatalog&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#666">.</span>config(<span style="color:#ba2121">&#34;spark.delta.logStore.class&#34;</span>, <span style="color:#ba2121">&#34;org.apache.spark.sql.delta.storage.S3SingleDriverLogStore&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#666">.</span>getOrCreate()
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><h3 id="test-delta">Test delta&nbsp;<a class="headline-hash" href="#test-delta">ðŸ”—</a> </h3>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>data <span style="color:#666">=</span> spark<span style="color:#666">.</span>range(<span style="color:#666">0</span>, <span style="color:#666">5</span>)
</span></span><span style="display:flex;"><span>data<span style="color:#666">.</span>write<span style="color:#666">.</span>format(<span style="color:#ba2121">&#34;delta&#34;</span>)<span style="color:#666">.</span>save(<span style="color:#ba2121">&#34;/tmp/delta-table2&#34;</span>)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>df <span style="color:#666">=</span> spark<span style="color:#666">.</span>read<span style="color:#666">.</span>format(<span style="color:#ba2121">&#34;delta&#34;</span>)<span style="color:#666">.</span>load(<span style="color:#ba2121">&#34;/tmp/delta-table2&#34;</span>)
</span></span><span style="display:flex;"><span>df<span style="color:#666">.</span>show()
</span></span></code></pre></div><pre><code>+---+
| id|
+---+
|  2|
|  1|
|  4|
|  3|
|  0|
+---+
</code></pre>
<h2 id="this-didnt-work">This didn&rsquo;t work&nbsp;<a class="headline-hash" href="#this-didnt-work">ðŸ”—</a> </h2>
<h3 id="initialise-spark-with-delta-lake-config-1">Initialise Spark with Delta Lake config&nbsp;<a class="headline-hash" href="#initialise-spark-with-delta-lake-config-1">ðŸ”—</a> </h3>
<p>(notice line 5 sets the <code>SparkContext</code>, unlike the example above)</p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">from</span> <span style="color:#00f;font-weight:bold">pyspark.context</span> <span style="color:#008000;font-weight:bold">import</span> SparkContext
</span></span><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">from</span> <span style="color:#00f;font-weight:bold">pyspark</span> <span style="color:#008000;font-weight:bold">import</span> SparkFiles
</span></span><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">from</span> <span style="color:#00f;font-weight:bold">pyspark.sql.session</span> <span style="color:#008000;font-weight:bold">import</span> SparkSession
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sc <span style="color:#666">=</span> SparkContext(<span style="color:#ba2121">&#39;local[*]&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>spark <span style="color:#666">=</span> (
</span></span><span style="display:flex;"><span>    SparkSession<span style="color:#666">.</span>builder<span style="color:#666">.</span>master(<span style="color:#ba2121">&#34;local[*]&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#666">.</span>config(<span style="color:#ba2121">&#34;spark.jars.packages&#34;</span>, <span style="color:#ba2121">&#34;io.delta:delta-core_2.12:2.0.0&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#666">.</span>config(<span style="color:#ba2121">&#34;spark.sql.extensions&#34;</span>, <span style="color:#ba2121">&#34;io.delta.sql.DeltaSparkSessionExtension&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#666">.</span>config(<span style="color:#ba2121">&#34;spark.sql.catalog.spark_catalog&#34;</span>, <span style="color:#ba2121">&#34;org.apache.spark.sql.delta.catalog.DeltaCatalog&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#666">.</span>config(<span style="color:#ba2121">&#34;spark.delta.logStore.class&#34;</span>, <span style="color:#ba2121">&#34;org.apache.spark.sql.delta.storage.S3SingleDriverLogStore&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#666">.</span>getOrCreate()
</span></span><span style="display:flex;"><span>)        
</span></span></code></pre></div><h3 id="test-delta-1">Test delta&nbsp;<a class="headline-hash" href="#test-delta-1">ðŸ”—</a> </h3>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>data <span style="color:#666">=</span> spark<span style="color:#666">.</span>range(<span style="color:#666">0</span>, <span style="color:#666">5</span>)
</span></span><span style="display:flex;"><span>data<span style="color:#666">.</span>write<span style="color:#666">.</span>format(<span style="color:#ba2121">&#34;delta&#34;</span>)<span style="color:#666">.</span>save(<span style="color:#ba2121">&#34;/tmp/delta-table&#34;</span>)
</span></span></code></pre></div><pre><code>---------------------------------------------------------------------------

Py4JJavaError                             Traceback (most recent call last)

/tmp/ipykernel_983/939553335.py in &lt;module&gt;
      1 data = spark.range(0, 5)
----&gt; 2 data.write.format(&quot;delta&quot;).save(&quot;/tmp/delta-table&quot;)


/usr/local/spark/python/pyspark/sql/readwriter.py in save(self, path, format, mode, partitionBy, **options)
    738             self._jwrite.save()
    739         else:
--&gt; 740             self._jwrite.save(path)
    741 
    742     @since(1.4)


/usr/local/spark/python/lib/py4j-0.10.9.2-src.zip/py4j/java_gateway.py in __call__(self, *args)
   1307 
   1308         answer = self.gateway_client.send_command(command)
-&gt; 1309         return_value = get_return_value(
   1310             answer, self.gateway_client, self.target_id, self.name)
   1311 


/usr/local/spark/python/pyspark/sql/utils.py in deco(*a, **kw)
    109     def deco(*a, **kw):
    110         try:
--&gt; 111             return f(*a, **kw)
    112         except py4j.protocol.Py4JJavaError as e:
    113             converted = convert_exception(e.java_exception)


/usr/local/spark/python/lib/py4j-0.10.9.2-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name)
    324             value = OUTPUT_CONVERTER[type](answer[2:], gateway_client)
    325             if answer[1] == REFERENCE_TYPE:
--&gt; 326                 raise Py4JJavaError(
    327                     &quot;An error occurred while calling {0}{1}{2}.\n&quot;.
    328                     format(target_id, &quot;.&quot;, name), value)


Py4JJavaError: An error occurred while calling o45.save.
: java.lang.ClassNotFoundException: 
Failed to find data source: delta. Please find packages at
http://spark.apache.org/third-party-projects.html
       
	at org.apache.spark.sql.errors.QueryExecutionErrors$.failedToFindDataSourceError(QueryExecutionErrors.scala:443)
	at org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:670)
	at org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:720)
	at org.apache.spark.sql.DataFrameWriter.lookupV2Provider(DataFrameWriter.scala:852)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:256)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.lang.ClassNotFoundException: delta.DefaultSource
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:476)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:589)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)
	at org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:656)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:656)
	at scala.util.Failure.orElse(Try.scala:224)
	at org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:656)
	... 16 more
</code></pre>
<h2 id="notebook-log">Notebook Log&nbsp;<a class="headline-hash" href="#notebook-log">ðŸ”—</a> </h2>
<p>I did notice in the notebook that in the version I ran without setting <code>SparkContext</code> the Delta library was downloaded:</p>
<pre tabindex="0"><code>WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
:: loading settings :: url = jar:file:/usr/local/spark-3.2.0-bin-hadoop3.2/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /home/jovyan/.ivy2/cache
The jars for the packages stored in: /home/jovyan/.ivy2/jars
io.delta#delta-core_2.12 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-86ca6813-f39f-472c-b6a2-dfe988ab0404;1.0
    confs: [default]
    found io.delta#delta-core_2.12;2.0.0 in central
    found io.delta#delta-storage;2.0.0 in central
    found org.antlr#antlr4-runtime;4.8 in central
    found org.codehaus.jackson#jackson-core-asl;1.9.13 in central
:: resolution report :: resolve 94ms :: artifacts dl 4ms
    :: modules in use:
    io.delta#delta-core_2.12;2.0.0 from central in [default]
    io.delta#delta-storage;2.0.0 from central in [default]
    org.antlr#antlr4-runtime;4.8 from central in [default]
    org.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]
    ---------------------------------------------------------------------
    |                  |            modules            ||   artifacts   |
    |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
    ---------------------------------------------------------------------
    |      default     |   4   |   0   |   0   |   0   ||   4   |   0   |
    ---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-86ca6813-f39f-472c-b6a2-dfe988ab0404
    confs: [default]
    0 artifacts copied, 4 already retrieved (0kB/3ms)
23/04/05 16:29:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark&#39;s default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to &#34;WARN&#34;.
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
</code></pre><p>whilst the version that did set <code>SparkContext</code> didn&rsquo;t.</p>
<pre tabindex="0"><code>WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
Using Spark&#39;s default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to &#34;WARN&#34;.
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
23/04/05 16:30:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/04/05 16:30:36 WARN Utils: Service &#39;SparkUI&#39; could not bind on port 4040. Attempting port 4041.
</code></pre><h2 id="why-did-it-do-what-it-did">Why Did It Do What It Did?&nbsp;<a class="headline-hash" href="#why-did-it-do-what-it-did">ðŸ”—</a> </h2>
<p>Courtesy of <a href="https://www.linkedin.com/feed/update/urn:li:activity:7049423288099319809?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7049423288099319809%2C7049433950406021120%29&amp;dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287049433950406021120%2Curn%3Ali%3Aactivity%3A7049423288099319809%29">Damon Cortesi</a>:</p>
<blockquote>
<p>In the example that doesn&rsquo;t work, you explicitly create a <code>SparkContext</code> first with <code>sc = SparkContext('local[*]')</code>.</p>
<p>When you use <code>SparkSession.builder</code>&hellip;<code>getOrCreate()</code>, it reuses the <code>SparkContext</code> you already created. You should be able to see this by running <code>spark.sparkContext</code>. That <code>SparkContext</code> unfortunately doesn&rsquo;t have the config variables you specified and, based on some reason I don&rsquo;t totally understand, the config variables you specify later are not updated. I&rsquo;m guessing this is because <code>SparkContext</code> spins up a JVM and some options (like <code>spark.jars.packages</code>) would need to be specified before you spin up the JVM.</p>
<p>In the example that works, it doesn&rsquo;t have a <code>SparkContext</code> to reuse, so it creates a one using the config you provided.</p>
<p>ðŸ˜… I love Spark! /s</p>
<p>This post does a pretty good job of explaining what&rsquo;s going on: <a href="https://medium.com/@achilleus/spark-session-10d0d66d1d24">A tale of Spark Session and Spark Context</a></p>
</blockquote>
<h2 id="proving-it-to-myself">Proving It To Myself&nbsp;<a class="headline-hash" href="#proving-it-to-myself">ðŸ”—</a> </h2>
<p>Damon&rsquo;s explanation and the linked blog were good, so to close the loop I wanted to prove to myself that I could reproduce this explanation locally. Here&rsquo;s <a href="https://gist.github.com/rmoff/1d86204b559f8ffce83be4b3206b1fa0">the notebook itself if you want to try it</a> and reproduced here too:</p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">import</span> <span style="color:#00f;font-weight:bold">sys</span>
</span></span><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">import</span> <span style="color:#00f;font-weight:bold">pyspark</span>
</span></span><span style="display:flex;"><span><span style="color:#008000">print</span>(<span style="color:#ba2121">&#34;Kernel:&#34;</span>, sys<span style="color:#666">.</span>executable)
</span></span><span style="display:flex;"><span><span style="color:#008000">print</span>(<span style="color:#ba2121">&#34;Python version:&#34;</span>, sys<span style="color:#666">.</span>version)
</span></span><span style="display:flex;"><span><span style="color:#008000">print</span>(<span style="color:#ba2121">&#34;PySpark version:&#34;</span>, pyspark<span style="color:#666">.</span>__version__)
</span></span></code></pre></div><pre><code>Kernel: /opt/conda/bin/python
Python version: 3.9.7 | packaged by conda-forge | (default, Oct 10 2021, 15:08:54) 
[GCC 9.4.0]
PySpark version: 3.2.0
</code></pre>
<h2 id="spark-context-and-session---no-config-to-pick-up">Spark Context and Session - no config to pick up&nbsp;<a class="headline-hash" href="#spark-context-and-session---no-config-to-pick-up">ðŸ”—</a> </h2>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">from</span> <span style="color:#00f;font-weight:bold">pyspark.context</span> <span style="color:#008000;font-weight:bold">import</span> SparkContext
</span></span><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">from</span> <span style="color:#00f;font-weight:bold">pyspark</span> <span style="color:#008000;font-weight:bold">import</span> SparkFiles
</span></span><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">from</span> <span style="color:#00f;font-weight:bold">pyspark.sql.session</span> <span style="color:#008000;font-weight:bold">import</span> SparkSession
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>sc <span style="color:#666">=</span> SparkContext(<span style="color:#ba2121">&#39;local&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>spark <span style="color:#666">=</span> SparkSession(sc)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>spark<span style="color:#666">.</span>sparkContext<span style="color:#666">.</span>getConf()<span style="color:#666">.</span>getAll()
</span></span></code></pre></div><pre><code>[('spark.master', 'local'),
 ('spark.app.startTime', '1680720996903'),
 ('spark.executor.id', 'driver'),
 ('spark.app.name', 'pyspark-shell'),
 ('spark.driver.extraJavaOptions',
  '-Dio.netty.tryReflectionSetAccessible=true'),
 ('spark.driver.port', '33339'),
 ('spark.driver.host', '358d949974bd'),
 ('spark.rdd.compress', 'True'),
 ('spark.serializer.objectStreamReset', '100'),
 ('spark.app.id', 'local-1680720997412'),
 ('spark.submit.pyFiles', ''),
 ('spark.submit.deployMode', 'client'),
 ('spark.executor.extraJavaOptions',
  '-Dio.netty.tryReflectionSetAccessible=true'),
 ('spark.ui.showConsoleProgress', 'true')]
</code></pre>
<p><em>Now restart the kernel</em></p>
<hr>
<h2 id="no-explicit-spark-context---picks-up-config-as-expected">No explicit Spark Context - picks up config as expected&nbsp;<a class="headline-hash" href="#no-explicit-spark-context---picks-up-config-as-expected">ðŸ”—</a> </h2>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">from</span> <span style="color:#00f;font-weight:bold">pyspark.context</span> <span style="color:#008000;font-weight:bold">import</span> SparkContext
</span></span><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">from</span> <span style="color:#00f;font-weight:bold">pyspark</span> <span style="color:#008000;font-weight:bold">import</span> SparkFiles
</span></span><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">from</span> <span style="color:#00f;font-weight:bold">pyspark.sql.session</span> <span style="color:#008000;font-weight:bold">import</span> SparkSession
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>spark <span style="color:#666">=</span> (
</span></span><span style="display:flex;"><span>    SparkSession<span style="color:#666">.</span>builder<span style="color:#666">.</span>master(<span style="color:#ba2121">&#34;local[*]&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#666">.</span>config(<span style="color:#ba2121">&#34;spark.jars.packages&#34;</span>, <span style="color:#ba2121">&#34;io.delta:delta-core_2.12:2.2.0&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#666">.</span>config(<span style="color:#ba2121">&#34;spark.sql.extensions&#34;</span>, <span style="color:#ba2121">&#34;io.delta.sql.DeltaSparkSessionExtension&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#666">.</span>config(<span style="color:#ba2121">&#34;spark.sql.catalog.spark_catalog&#34;</span>, <span style="color:#ba2121">&#34;org.apache.spark.sql.delta.catalog.DeltaCatalog&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#666">.</span>getOrCreate()
</span></span><span style="display:flex;"><span>)        
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>spark<span style="color:#666">.</span>sparkContext<span style="color:#666">.</span>getConf()<span style="color:#666">.</span>getAll()
</span></span></code></pre></div><pre><code>[('spark.repl.local.jars',
  'file:///home/jovyan/.ivy2/jars/io.delta_delta-core_2.12-2.2.0.jar,file:///home/jovyan/.ivy2/jars/io.delta_delta-storage-2.2.0.jar,file:///home/jovyan/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar'),
 ('spark.app.id', 'local-1680721007128'),
 ('spark.app.startTime', '1680721006667'),
 ('spark.files',
  'file:///home/jovyan/.ivy2/jars/io.delta_delta-core_2.12-2.2.0.jar,file:///home/jovyan/.ivy2/jars/io.delta_delta-storage-2.2.0.jar,file:///home/jovyan/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar'),
 ('spark.app.initial.file.urls',
  'file:///home/jovyan/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar,file:///home/jovyan/.ivy2/jars/io.delta_delta-core_2.12-2.2.0.jar,file:///home/jovyan/.ivy2/jars/io.delta_delta-storage-2.2.0.jar'),
 ('spark.executor.id', 'driver'),
 ('spark.app.name', 'pyspark-shell'),
 ('spark.driver.extraJavaOptions',
  '-Dio.netty.tryReflectionSetAccessible=true'),
 ('spark.app.initial.jar.urls',
  'spark://358d949974bd:41145/jars/io.delta_delta-core_2.12-2.2.0.jar,spark://358d949974bd:41145/jars/io.delta_delta-storage-2.2.0.jar,spark://358d949974bd:41145/jars/org.antlr_antlr4-runtime-4.8.jar'),
 ('spark.jars.packages', 'io.delta:delta-core_2.12:2.2.0'),
 ('spark.driver.host', '358d949974bd'),
 ('spark.sql.warehouse.dir', 'file:/home/jovyan/spark-warehouse'),
 ('spark.sql.extensions', 'io.delta.sql.DeltaSparkSessionExtension'),
 ('spark.rdd.compress', 'True'),
 ('spark.submit.pyFiles',
  '/home/jovyan/.ivy2/jars/io.delta_delta-core_2.12-2.2.0.jar,/home/jovyan/.ivy2/jars/io.delta_delta-storage-2.2.0.jar,/home/jovyan/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar'),
 ('spark.driver.port', '41145'),
 ('spark.jars',
  'file:///home/jovyan/.ivy2/jars/io.delta_delta-core_2.12-2.2.0.jar,file:///home/jovyan/.ivy2/jars/io.delta_delta-storage-2.2.0.jar,file:///home/jovyan/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar'),
 ('spark.serializer.objectStreamReset', '100'),
 ('spark.master', 'local[*]'),
 ('spark.submit.deployMode', 'client'),
 ('spark.executor.extraJavaOptions',
  '-Dio.netty.tryReflectionSetAccessible=true'),
 ('spark.ui.showConsoleProgress', 'true'),
 ('spark.sql.catalog.spark_catalog',
  'org.apache.spark.sql.delta.catalog.DeltaCatalog')]
</code></pre>
<hr>
<p><em>Now restart the kernel</em></p>
<hr>
<h2 id="existing-spark-context-with-attempted-config-for-the-session-">Existing Spark Context with attempted config for the Session ðŸ’€&nbsp;<a class="headline-hash" href="#existing-spark-context-with-attempted-config-for-the-session-">ðŸ”—</a> </h2>
<p><em>SparkContext gets implictly reused by the Spark Session and so config is ignored</em></p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">from</span> <span style="color:#00f;font-weight:bold">pyspark.context</span> <span style="color:#008000;font-weight:bold">import</span> SparkContext
</span></span><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">from</span> <span style="color:#00f;font-weight:bold">pyspark</span> <span style="color:#008000;font-weight:bold">import</span> SparkFiles
</span></span><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">from</span> <span style="color:#00f;font-weight:bold">pyspark.sql.session</span> <span style="color:#008000;font-weight:bold">import</span> SparkSession
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>sc <span style="color:#666">=</span> SparkContext(<span style="color:#ba2121">&#39;local&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>spark <span style="color:#666">=</span> (
</span></span><span style="display:flex;"><span>    SparkSession<span style="color:#666">.</span>builder<span style="color:#666">.</span>master(<span style="color:#ba2121">&#34;local[*]&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#666">.</span>config(<span style="color:#ba2121">&#34;spark.jars.packages&#34;</span>, <span style="color:#ba2121">&#34;io.delta:delta-core_2.12:2.2.0&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#666">.</span>config(<span style="color:#ba2121">&#34;spark.sql.extensions&#34;</span>, <span style="color:#ba2121">&#34;io.delta.sql.DeltaSparkSessionExtension&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#666">.</span>config(<span style="color:#ba2121">&#34;spark.sql.catalog.spark_catalog&#34;</span>, <span style="color:#ba2121">&#34;org.apache.spark.sql.delta.catalog.DeltaCatalog&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#666">.</span>getOrCreate()
</span></span><span style="display:flex;"><span>)        
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>spark<span style="color:#666">.</span>sparkContext<span style="color:#666">.</span>getConf()<span style="color:#666">.</span>getAll()
</span></span></code></pre></div><pre><code>[('spark.master', 'local'),
 ('spark.app.startTime', '1680721019537'),
 ('spark.executor.id', 'driver'),
 ('spark.app.name', 'pyspark-shell'),
 ('spark.app.id', 'local-1680721020036'),
 ('spark.driver.extraJavaOptions',
  '-Dio.netty.tryReflectionSetAccessible=true'),
 ('spark.driver.host', '358d949974bd'),
 ('spark.sql.warehouse.dir', 'file:/home/jovyan/spark-warehouse'),
 ('spark.rdd.compress', 'True'),
 ('spark.serializer.objectStreamReset', '100'),
 ('spark.submit.pyFiles', ''),
 ('spark.driver.port', '46397'),
 ('spark.submit.deployMode', 'client'),
 ('spark.executor.extraJavaOptions',
  '-Dio.netty.tryReflectionSetAccessible=true'),
 ('spark.ui.showConsoleProgress', 'true')]
</code></pre>
	<hr>
	<div class="giscus-container">
		<script src="https://giscus.app/client.js"
				data-repo="rmoff/rmoff-blog"
				data-repo-id="MDEwOlJlcG9zaXRvcnkxNTE3NDg2MTE="
				data-category="Announcements"
				data-category-id="DIC_kwDOCQuAA84CvP5T"
				data-mapping="pathname"
				data-strict="1"
				data-reactions-enabled="1"
				data-emit-metadata="0"
				data-input-position="bottom"
				data-theme="light"
				data-lang="en"
				crossorigin="anonymous"
				async>
		</script>
	</div>
</article>
      </main>
    
      
      <div class="docs-toc">
        <ul class="nav toc-top">
          <li><a href="#" id="back_to_top" class="docs-toc-title">On this page</a></li>
        </ul>
        <nav id="TableOfContents">
  <ul>
    <li><a href="#versions-and-stuff">Versions and stuff</a></li>
    <li><a href="#this-worked">This worked</a>
      <ul>
        <li><a href="#initialise-spark-with-delta-lake-config">Initialise Spark with Delta Lake config</a></li>
        <li><a href="#test-delta">Test delta</a></li>
      </ul>
    </li>
    <li><a href="#this-didnt-work">This didn&rsquo;t work</a>
      <ul>
        <li><a href="#initialise-spark-with-delta-lake-config-1">Initialise Spark with Delta Lake config</a></li>
        <li><a href="#test-delta-1">Test delta</a></li>
      </ul>
    </li>
    <li><a href="#notebook-log">Notebook Log</a></li>
    <li><a href="#why-did-it-do-what-it-did">Why Did It Do What It Did?</a></li>
    <li><a href="#proving-it-to-myself">Proving It To Myself</a></li>
    <li><a href="#spark-context-and-session---no-config-to-pick-up">Spark Context and Session - no config to pick up</a></li>
    <li><a href="#no-explicit-spark-context---picks-up-config-as-expected">No explicit Spark Context - picks up config as expected</a></li>
    <li><a href="#existing-spark-context-with-attempted-config-for-the-session-">Existing Spark Context with attempted config for the Session ðŸ’€</a></li>
  </ul>
</nav>
      </div>
      
    
    </div>
  </div>
</div>


		</main>

		

		
		<footer class="site-footer hide-print" role="contentinfo">
			<span>&copy; 2026 </span>
		</footer>
		

		
	</body>
</html>
