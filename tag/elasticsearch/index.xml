<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Elasticsearch on rmoff&#39;s random ramblings</title>
    <link>https://rmoff.net/tag/elasticsearch/</link>
    <description>Recent content in Elasticsearch on rmoff&#39;s random ramblings</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 03 Sep 2018 16:16:30 +0000</lastBuildDate>
    <atom:link href="https://rmoff.net/tag/elasticsearch/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Window Timestamps in KSQL / Integration with Elasticsearch</title>
      <link>https://rmoff.net/2018/09/03/window-timestamps-in-ksql-/-integration-with-elasticsearch/</link>
      <pubDate>Mon, 03 Sep 2018 16:16:30 +0000</pubDate>
      <guid>https://rmoff.net/2018/09/03/window-timestamps-in-ksql-/-integration-with-elasticsearch/</guid>
      <description>&lt;p&gt;KSQL provides the ability to create windowed aggregations. For example,&#xA;count the number of messages in a 1 minute window, grouped by a&#xA;particular column:&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;CREATE TABLE RATINGS_BY_CLUB_STATUS AS \&#xA;SELECT CLUB_STATUS, COUNT(*) AS RATING_COUNT \&#xA;FROM RATINGS_WITH_CUSTOMER_DATA \&#xA;     WINDOW TUMBLING (SIZE 1 MINUTES) \&#xA;GROUP BY CLUB_STATUS;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;How KSQL, and Kafka Streams, stores the window timestamp associated with&#xA;an aggregate, has recently changed. &lt;a href=&#34;https://github.com/confluentinc/ksql/issues/1497&#34;&gt;See #1497 for&#xA;details&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Whereas previously the &lt;em&gt;Kafka message timestamp&lt;/em&gt; (accessible through the&#xA;KSQL &lt;code&gt;ROWTIME&lt;/code&gt; system column) stored the start of the window for which&#xA;the aggregate had been calculated, this changed in July 2018 to instead&#xA;be the timestamp of the latest message to update that aggregate value.&#xA;This was in Apache Kafka 2.0 and Confluent Platform 5.0, and back-ported&#xA;to previous versions.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Analysing Network Data with Apache Kafka, KSQL, and Elasticsearch</title>
      <link>https://rmoff.net/2018/06/17/analysing-network-data-with-apache-kafka-ksql-and-elasticsearch/</link>
      <pubDate>Sun, 17 Jun 2018 11:35:20 +0000</pubDate>
      <guid>https://rmoff.net/2018/06/17/analysing-network-data-with-apache-kafka-ksql-and-elasticsearch/</guid>
      <description>&lt;p&gt;In &lt;a href=&#34;http://cnfl.io/syslogs-filtering&#34;&gt;this article&lt;/a&gt; I demonstrated how to use KSQL to filter streams of network event data. As well as filtering, KSQL can be used to easily &lt;a href=&#34;https://www.confluent.io/blog/real-time-syslog-processing-apache-kafka-ksql-enriching-events-with-external-data/&#34;&gt;enrich streams&lt;/a&gt;. In this article we&amp;rsquo;ll see how this enriched data can be used to drive analysis in Elasticsearch and Kibana—and how KSQL again came into use for building some stream processing as a result of the discovery made.&lt;/p&gt;&#xA;&lt;p&gt;The data came from my home &lt;a href=&#34;https://www.ubnt.com/&#34;&gt;Ubiquiti&lt;/a&gt; router, and took two forms:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Monitoring Logstash Ingest Rates with Elasticsearch, Kibana, and Timelion</title>
      <link>https://rmoff.net/2016/05/13/monitoring-logstash-ingest-rates-with-elasticsearch-kibana-and-timelion/</link>
      <pubDate>Fri, 13 May 2016 05:45:19 +0000</pubDate>
      <guid>https://rmoff.net/2016/05/13/monitoring-logstash-ingest-rates-with-elasticsearch-kibana-and-timelion/</guid>
      <description>&lt;p&gt;Yesterday I wrote about &lt;a href=&#34;https://rmoff.net/2016/05/12/monitoring-logstash-ingest-rates-with-influxdb-and-grafana/&#34;&gt;Monitoring Logstash Ingest Rates with InfluxDB and Grafana&lt;/a&gt;, in which InfluxDB provided the data store for the ingest rate data, and Grafana the frontend.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://twitter.com/warkolm/&#34;&gt;Mark Walkom&lt;/a&gt; reminded me on twitter that the next release of Logstash will add more functionality in this area - and that it&amp;rsquo;ll integrate back into the Elastic stack:&lt;/p&gt;&#xA;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;en&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://twitter.com/rmoff&#34;&gt;@rmoff&lt;/a&gt; nice, LS 5.0 will have APIs exposing metrics too. they’ll be integrated back into Marvel/Monitoring! :)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Using R to Denormalise Data for Analysis in Kibana</title>
      <link>https://rmoff.net/2016/04/24/using-r-to-denormalise-data-for-analysis-in-kibana/</link>
      <pubDate>Sun, 24 Apr 2016 12:22:12 +0000</pubDate>
      <guid>https://rmoff.net/2016/04/24/using-r-to-denormalise-data-for-analysis-in-kibana/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/products/kibana&#34;&gt;Kibana&lt;/a&gt; is a tool from &lt;a href=&#34;https://www.elastic.co/&#34;&gt;Elastic&lt;/a&gt; that makes analysis of data held in &lt;a href=&#34;https://www.elastic.co/products/elasticsearch&#34;&gt;Elasticsearch&lt;/a&gt; really easy and very powerful. Because Elasticsearch has very loose schema that can evolve on demand it makes it very quick to get up and running with some cool visualisations and analysis on any set of data. I demonstrated this in a &lt;a href=&#34;http://www.rittmanmead.com/2015/04/using-the-elk-stack-to-analyse-donors-choose-data/&#34;&gt;blog post last year&lt;/a&gt;, taking a CSV file and loading it into Elasticsearch via Logstash.&lt;/p&gt;&#xA;&lt;p&gt;This is all great, but the one real sticking point with analytics in Elasticsearch/Kibana is that it needs the data to be &lt;strong&gt;denormalised&lt;/strong&gt;. That is, you can&amp;rsquo;t give it a bunch of sources of data and it perform the joins for you in Kibana - it just doesn&amp;rsquo;t work like that. If you&amp;rsquo;re using Elasticsearch alone for analytics, maybe with a bespoke application, &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/guide/current/relations.html&#34;&gt;there are ways of approaching it&lt;/a&gt;, but not through Kibana. Now, depending on where the data is coming from, this may not be a problem. For example, if you use the &lt;a href=&#34;https://www.elastic.co/guide/en/logstash/current/plugins-inputs-jdbc.html&#34;&gt;JDBC Logstash input&lt;/a&gt; to pull from an RDBMS source you can specify a complex SQL query going across multiple tables, so that the data when it hits Elasticsearch is nice and denormalised and ready for fun in Kibana. But, source data doesn&amp;rsquo;t always come this way, and it&amp;rsquo;s useful to have a way to work with the data still when it is like this.&lt;/p&gt;</description>
    </item>
    <item>
      <title>My latest IRC client : Kibana</title>
      <link>https://rmoff.net/2016/03/24/my-latest-irc-client-kibana/</link>
      <pubDate>Thu, 24 Mar 2016 21:38:02 +0000</pubDate>
      <guid>https://rmoff.net/2016/03/24/my-latest-irc-client-kibana/</guid>
      <description>&lt;p&gt;OK, maybe that&amp;rsquo;s not entirely true. But my &lt;em&gt;read-only&lt;/em&gt; client, certainly.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://rmoff.net/images/2016/03/2016-03-24_21-15-30.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;I was perusing the &lt;a href=&#34;https://www.elastic.co/guide/en/logstash/current/input-plugins.html&#34;&gt;Logstash input plugins&lt;/a&gt; recently when I noticed that there was one for &lt;a href=&#34;https://www.elastic.co/guide/en/logstash/current/plugins-inputs-irc.html&#34;&gt;IRC&lt;/a&gt;. Being a fan of IRC and a regular on the &lt;a href=&#34;https://rmoff.net/2016/03/03/obihackers-irc-channel/&#34;&gt;#obihackers&lt;/a&gt; channel, I thought this could be fun and yet another great example of how easy &lt;a href=&#34;http://elastic.co&#34;&gt;the Elastic stack&lt;/a&gt; is to work with.&lt;/p&gt;&#xA;&lt;p&gt;Installation is a piece of cake:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wget https://download.elasticsearch.org/elasticsearch/release/org/elasticsearch/distribution/zip/elasticsearch/2.2.1/elasticsearch-2.2.1.zip&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wget https://download.elastic.co/logstash/logstash/logstash-2.2.2.zip&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wget https://download.elastic.co/kibana/kibana/kibana-4.4.2-linux-x64.tar.gz&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;unzip &lt;span style=&#34;color:#b62;font-weight:bold&#34;&gt;\*&lt;/span&gt;.zip&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tar -xf kibana-4.4.2-linux-x64.tar.gz&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo mv elasticsearch-2.2.1 logstash-2.2.2 kibana-4.4.2-linux-x64 /opt&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;(you&amp;rsquo;ll also need Oracle JDK installed if not already, &lt;a href=&#34;http://www.jamescoyle.net/how-to/1897-download-oracle-java-from-the-terminal-with-wget&#34;&gt;here&amp;rsquo;s a handy way to get it from the CLI&lt;/a&gt;).&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
