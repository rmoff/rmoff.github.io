<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Grafana on rmoff&#39;s random ramblings</title>
    <link>https://rmoff.net/tag/grafana/</link>
    <description>Recent content in Grafana on rmoff&#39;s random ramblings</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 08 Aug 2017 19:32:00 +0000</lastBuildDate>
    <atom:link href="https://rmoff.net/tag/grafana/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Simple export/import of Data Sources in Grafana</title>
      <link>https://rmoff.net/2017/08/08/simple-export/import-of-data-sources-in-grafana/</link>
      <pubDate>Tue, 08 Aug 2017 19:32:00 +0000</pubDate>
      <guid>https://rmoff.net/2017/08/08/simple-export/import-of-data-sources-in-grafana/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://docs.grafana.org/http_api/data_source/&#34;&gt;Grafana API Reference&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;export-all-grafana-data-sources-to-data_sources-folder&#34;&gt;Export all Grafana data sources to data_sources folder&lt;/h3&gt;&#xA;&lt;pre&gt;&lt;code&gt;mkdir -p data_sources &amp;amp;&amp;amp; curl -s &amp;quot;http://localhost:3000/api/datasources&amp;quot;  -u admin:admin|jq -c -M &#39;.[]&#39;|split -l 1 - data_sources/&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;This exports each data source to a separate JSON file in the &lt;code&gt;data_sources&lt;/code&gt; folder.&lt;/p&gt;&#xA;&lt;h3 id=&#34;load-data-sources-back-in-from-folder&#34;&gt;Load data sources back in from folder&lt;/h3&gt;&#xA;&lt;p&gt;This submits every file that exists in the &lt;code&gt;data_sources&lt;/code&gt; folder to Grafana as a new data source definition.&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;for i in data_sources/*; do \&#xA;&#x9;curl -X &amp;quot;POST&amp;quot; &amp;quot;http://localhost:3000/api/datasources&amp;quot; \&#xA;    -H &amp;quot;Content-Type: application/json&amp;quot; \&#xA;     --user admin:admin \&#xA;     --data-binary @$i&#xA;done&#xA;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>Monitoring Logstash Ingest Rates with InfluxDB and Grafana</title>
      <link>https://rmoff.net/2016/05/12/monitoring-logstash-ingest-rates-with-influxdb-and-grafana/</link>
      <pubDate>Thu, 12 May 2016 20:56:38 +0000</pubDate>
      <guid>https://rmoff.net/2016/05/12/monitoring-logstash-ingest-rates-with-influxdb-and-grafana/</guid>
      <description>&lt;p&gt;In this article I&amp;rsquo;m going to show you how to easily monitor the rate at which Logstash is ingesting data, as well as in future articles the rate at which Elasticsearch is indexing it. It&amp;rsquo;s a nice little touch to add to any project involving Logstash, and it&amp;rsquo;s easy to do.&lt;/p&gt;&#xA;&lt;p&gt;Logstash is powerful tool for data ingest, processing, and distribution. It originated as simply the pipe to slurp at log files and put them into Elasticsearch, but has evolved into a whole bunch more. With connectors to JDBC and Kafka, as well as many other &lt;a href=&#34;https://www.elastic.co/guide/en/logstash/current/input-plugins.html&#34;&gt;input&lt;/a&gt; and &lt;a href=&#34;https://www.elastic.co/guide/en/logstash/current/output-plugins.html&#34;&gt;output&lt;/a&gt; options (not to mention the &lt;a href=&#34;https://www.elastic.co/guide/en/logstash/current/filter-plugins.html&#34;&gt;filtering&lt;/a&gt; possibilities), it really is a great bit of software to use. I&amp;rsquo;ve used it over the years with &lt;a href=&#34;http://www.rittmanmead.com/2014/10/monitoring-obiee-with-elasticsearch-logstash-and-kibana/&#34;&gt;OBIEE&lt;/a&gt;, as well as more recently to &lt;a href=&#34;https://www.elastic.co/blog/visualising-oracle-performance-data-with-the-elastic-stack&#34;&gt;pull data from Oracle&lt;/a&gt;, and even &lt;a href=&#34;https://rmoff.net/2016/03/24/my-latest-irc-client-kibana/&#34;&gt;IRC&lt;/a&gt;. Another great set of tools is &lt;a href=&#34;http://influxdb.com&#34;&gt;InfluxDB&lt;/a&gt; and &lt;a href=&#34;http://grafana.org&#34;&gt;Grafana&lt;/a&gt;, which for me really round off the standalone Elastic platform (previously known as ELK - Elasticsearch, Logstash, and Kibana). What InfluxDB and Grafana give is a powerful dedicated time series database and flexible time series-based dashboarding tool respectively. A topic for another day is the Elasticsearch vs InfluxDB overlap, and Kibana vs Grafana - but for now, just take it as read that it&amp;rsquo;s horses for course, right tool for the right job, etc.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Streaming data to InfluxDB from any bash command</title>
      <link>https://rmoff.net/2016/02/27/streaming-data-to-influxdb-from-any-bash-command/</link>
      <pubDate>Sat, 27 Feb 2016 21:05:00 +0000</pubDate>
      <guid>https://rmoff.net/2016/02/27/streaming-data-to-influxdb-from-any-bash-command/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://influxdata.com/time-series-platform/influxdb/&#34;&gt;InfluxDB&lt;/a&gt; is a great time series database, that&amp;rsquo;s recently been rebranded as part of the &amp;ldquo;&lt;a href=&#34;https://influxdata.com/&#34;&gt;TICK&lt;/a&gt;&amp;rdquo; stack, including data collectors, visualisation, and ETL/Alerting. I&amp;rsquo;ve yet to really look at the other components, but InfluxDB alone works just great with my favourite visualisation/analysis tool for time series metrics, &lt;a href=&#34;http://grafana.org/&#34;&gt;Grafana&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Getting data into InfluxDB is easy, with many tools supporting the native InfluxDB &lt;a href=&#34;https://docs.influxdata.com/influxdb/v0.10/guides/writing_data/&#34;&gt;line input protocol&lt;/a&gt;, and those that don&amp;rsquo;t often supporting the &lt;a href=&#34;https://docs.influxdata.com/influxdb/v0.10/write_protocols/graphite/&#34;&gt;carbon protocol&lt;/a&gt; (from Graphite), which InfluxDB also supports (&lt;a href=&#34;https://docs.influxdata.com/influxdb/v0.10/write_protocols/&#34;&gt;along with others&lt;/a&gt;). So for collecting broad ranges of OS stats, for example, &lt;a href=&#34;http://collectl.sourceforge.net/&#34;&gt;collectl&lt;/a&gt; via carbon and nmon via &lt;a href=&#34;https://github.com/adejoux/nmon2influxdb&#34;&gt;nmon2influxdb&lt;/a&gt; are both viable options.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
