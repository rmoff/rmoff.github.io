<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on rmoff&#39;s random ramblings</title>
    <link>https://rmoff.net/tag/python/</link>
    <description>Recent content in Python on rmoff&#39;s random ramblings</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 17 Jun 2018 11:35:20 +0000</lastBuildDate>
    <atom:link href="https://rmoff.net/tag/python/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Analysing Network Data with Apache Kafka, KSQL, and Elasticsearch</title>
      <link>https://rmoff.net/2018/06/17/analysing-network-data-with-apache-kafka-ksql-and-elasticsearch/</link>
      <pubDate>Sun, 17 Jun 2018 11:35:20 +0000</pubDate>
      <guid>https://rmoff.net/2018/06/17/analysing-network-data-with-apache-kafka-ksql-and-elasticsearch/</guid>
      <description>&lt;p&gt;In &lt;a href=&#34;http://cnfl.io/syslogs-filtering&#34;&gt;this article&lt;/a&gt; I demonstrated how to use KSQL to filter streams of network event data. As well as filtering, KSQL can be used to easily &lt;a href=&#34;https://www.confluent.io/blog/real-time-syslog-processing-apache-kafka-ksql-enriching-events-with-external-data/&#34;&gt;enrich streams&lt;/a&gt;. In this article we&amp;rsquo;ll see how this enriched data can be used to drive analysis in Elasticsearch and Kibanaâ€”and how KSQL again came into use for building some stream processing as a result of the discovery made.&lt;/p&gt;&#xA;&lt;p&gt;The data came from my home &lt;a href=&#34;https://www.ubnt.com/&#34;&gt;Ubiquiti&lt;/a&gt; router, and took two forms:&lt;/p&gt;</description>
    </item>
    <item>
      <title>boto / S3 errors</title>
      <link>https://rmoff.net/2016/10/14/boto-/-s3-errors/</link>
      <pubDate>Fri, 14 Oct 2016 08:41:30 +0000</pubDate>
      <guid>https://rmoff.net/2016/10/14/boto-/-s3-errors/</guid>
      <description>&lt;p&gt;Presented without comment, warranty, or context -  other than these might help a wandering code hacker.&lt;/p&gt;&#xA;&lt;h3 id=&#34;when-using-sigv4-you-must-specify-a-host-parameter&#34;&gt;When using SigV4, you must specify a &amp;lsquo;host&amp;rsquo; parameter&lt;/h3&gt;&#xA;&lt;pre&gt;&lt;code&gt;boto.s3.connection.HostRequiredError: BotoClientError: When using SigV4, you must specify a &#39;host&#39; parameter.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;To fix, switch&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conn_s3 &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; boto&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;connect_s3()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;for&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conn_s3 &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; boto&lt;span style=&#34;color:#666&#34;&gt;.&lt;/span&gt;connect_s3(host&lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ba2121&#34;&gt;&amp;#39;s3.amazonaws.com&amp;#39;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You can see a list of endpoints &lt;a href=&#34;http://docs.aws.amazon.com/general/latest/gr/rande.html#s3_region&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h3 id=&#34;botoexceptions3responseerror-s3responseerror-400-bad-request&#34;&gt;boto.exception.S3ResponseError: S3ResponseError: 400 Bad Request&lt;/h3&gt;&#xA;&lt;p&gt;Make sure you&amp;rsquo;re specifying the correct hostname (see above) for the bucket&amp;rsquo;s region. Determine the bucket&amp;rsquo;s region from the S3 control panel, and then use the &lt;a href=&#34;http://docs.aws.amazon.com/general/latest/gr/rande.html#s3_region&#34;&gt;endpoint listed here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Reset Hue password</title>
      <link>https://rmoff.net/2016/07/05/reset-hue-password/</link>
      <pubDate>Tue, 05 Jul 2016 13:27:06 +0000</pubDate>
      <guid>https://rmoff.net/2016/07/05/reset-hue-password/</guid>
      <description>&lt;p&gt;(&lt;a href=&#34;http://gethue.com/password-management-in-hue/&#34;&gt;Ref&lt;/a&gt;)&lt;/p&gt;&#xA;&lt;p&gt;The bit that caught me out was this kept failing with&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Error: Password not present&#x9;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;and a Python stack trace that ended with&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;subprocess.CalledProcessError: Command &#39;/var/run/cloudera-scm-agent/process/78-hue-HUE_SERVER/altscript.sh sec-1-secret_key&#39; returned non-zero exit status 1&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;The answer (it &lt;em&gt;seems&lt;/em&gt;) is to ensure that &lt;code&gt;HUE_SECRET_KEY&lt;/code&gt; is set (to any value!)&lt;/p&gt;&#xA;&lt;p&gt;Launch shell:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;export HUE_SECRET_KEY=foobar&#xA;/opt/cloudera/parcels/CDH-5.7.1-1.cdh5.7.1.p0.11/lib/hue/build/env/bin/hue shell&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Reset password for &lt;code&gt;hue&lt;/code&gt;, activate account and make it superuser&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;from django.contrib.auth.models import User&#xA;user = User.objects.get(username=&#39;hue&#39;)&#xA;user.is_active=True&#xA;user.save()&#xA;user.is_superuser=True&#xA;user.save()&#xA;user.set_password(&#39;hue&#39;)&#xA;user.save()&#xA;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
  </channel>
</rss>
