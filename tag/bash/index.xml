<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bash on rmoff&#39;s random ramblings</title>
    <link>https://rmoff.net/tag/bash/</link>
    <description>Recent content in Bash on rmoff&#39;s random ramblings</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 03 Dec 2018 14:50:45 +0000</lastBuildDate>
    <atom:link href="https://rmoff.net/tag/bash/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Kafka Connect CLI tricks</title>
      <link>https://rmoff.net/2018/12/03/kafka-connect-cli-tricks/</link>
      <pubDate>Mon, 03 Dec 2018 14:50:45 +0000</pubDate>
      <guid>https://rmoff.net/2018/12/03/kafka-connect-cli-tricks/</guid>
      <description>&lt;p&gt;I do lots of work with Kafka Connect, almost entirely in &lt;a href=&#34;https://docs.confluent.io/current/connect/concepts.html#distributed-workers&#34;&gt;Distributed mode&lt;/a&gt;â€”even just with 1 node -&amp;gt; makes scaling out much easier when/if needed. Because I&amp;rsquo;m using Distributed mode, I use the &lt;a href=&#34;https://docs.confluent.io/current/connect/references/restapi.html&#34;&gt;Kafka Connect REST API&lt;/a&gt; to configure and manage it. Whilst others might use GUI REST tools like Postman etc, I tend to just use the commandline. Here are some useful snippets that I use all the time.&lt;/p&gt;&#xA;&lt;p&gt;I&amp;rsquo;m showing the commands split with a line continuation character (&lt;code&gt;\&lt;/code&gt;) but you can of course run them on a single line. You might also choose to get fancy and set the Connect host and port as environment variables etc, but I leave that as an exercise for the reader :)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Simple export/import of Data Sources in Grafana</title>
      <link>https://rmoff.net/2017/08/08/simple-export/import-of-data-sources-in-grafana/</link>
      <pubDate>Tue, 08 Aug 2017 19:32:00 +0000</pubDate>
      <guid>https://rmoff.net/2017/08/08/simple-export/import-of-data-sources-in-grafana/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://docs.grafana.org/http_api/data_source/&#34;&gt;Grafana API Reference&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;export-all-grafana-data-sources-to-data_sources-folder&#34;&gt;Export all Grafana data sources to data_sources folder&lt;/h3&gt;&#xA;&lt;pre&gt;&lt;code&gt;mkdir -p data_sources &amp;amp;&amp;amp; curl -s &amp;quot;http://localhost:3000/api/datasources&amp;quot;  -u admin:admin|jq -c -M &#39;.[]&#39;|split -l 1 - data_sources/&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;This exports each data source to a separate JSON file in the &lt;code&gt;data_sources&lt;/code&gt; folder.&lt;/p&gt;&#xA;&lt;h3 id=&#34;load-data-sources-back-in-from-folder&#34;&gt;Load data sources back in from folder&lt;/h3&gt;&#xA;&lt;p&gt;This submits every file that exists in the &lt;code&gt;data_sources&lt;/code&gt; folder to Grafana as a new data source definition.&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;for i in data_sources/*; do \&#xA;&#x9;curl -X &amp;quot;POST&amp;quot; &amp;quot;http://localhost:3000/api/datasources&amp;quot; \&#xA;    -H &amp;quot;Content-Type: application/json&amp;quot; \&#xA;     --user admin:admin \&#xA;     --data-binary @$i&#xA;done&#xA;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>Streaming data to InfluxDB from any bash command</title>
      <link>https://rmoff.net/2016/02/27/streaming-data-to-influxdb-from-any-bash-command/</link>
      <pubDate>Sat, 27 Feb 2016 21:05:00 +0000</pubDate>
      <guid>https://rmoff.net/2016/02/27/streaming-data-to-influxdb-from-any-bash-command/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://influxdata.com/time-series-platform/influxdb/&#34;&gt;InfluxDB&lt;/a&gt; is a great time series database, that&amp;rsquo;s recently been rebranded as part of the &amp;ldquo;&lt;a href=&#34;https://influxdata.com/&#34;&gt;TICK&lt;/a&gt;&amp;rdquo; stack, including data collectors, visualisation, and ETL/Alerting. I&amp;rsquo;ve yet to really look at the other components, but InfluxDB alone works just great with my favourite visualisation/analysis tool for time series metrics, &lt;a href=&#34;http://grafana.org/&#34;&gt;Grafana&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Getting data into InfluxDB is easy, with many tools supporting the native InfluxDB &lt;a href=&#34;https://docs.influxdata.com/influxdb/v0.10/guides/writing_data/&#34;&gt;line input protocol&lt;/a&gt;, and those that don&amp;rsquo;t often supporting the &lt;a href=&#34;https://docs.influxdata.com/influxdb/v0.10/write_protocols/graphite/&#34;&gt;carbon protocol&lt;/a&gt; (from Graphite), which InfluxDB also supports (&lt;a href=&#34;https://docs.influxdata.com/influxdb/v0.10/write_protocols/&#34;&gt;along with others&lt;/a&gt;). So for collecting broad ranges of OS stats, for example, &lt;a href=&#34;http://collectl.sourceforge.net/&#34;&gt;collectl&lt;/a&gt; via carbon and nmon via &lt;a href=&#34;https://github.com/adejoux/nmon2influxdb&#34;&gt;nmon2influxdb&lt;/a&gt; are both viable options.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
