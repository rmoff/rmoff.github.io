<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Streaming on rmoff&#39;s random ramblings</title>
    <link>https://rmoff.net/tag/streaming/</link>
    <description>Recent content in Streaming on rmoff&#39;s random ramblings</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 06 Mar 2018 22:18:00 +0000</lastBuildDate>
    <atom:link href="https://rmoff.net/tag/streaming/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Why Do We Need Streaming ETL?</title>
      <link>https://rmoff.net/2018/03/06/why-do-we-need-streaming-etl/</link>
      <pubDate>Tue, 06 Mar 2018 22:18:00 +0000</pubDate>
      <guid>https://rmoff.net/2018/03/06/why-do-we-need-streaming-etl/</guid>
      <description>&lt;p&gt;&lt;em&gt;(This is an expanded version of the intro to an article I posted over on the &lt;a href=&#34;https://www.confluent.io/blog/ksql-in-action-real-time-streaming-etl-from-oracle-transactional-data&#34;&gt;Confluent blog&lt;/a&gt;. Here I get to be as verbose as I like &lt;code&gt;;)&lt;/code&gt;)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;My first job from university was building a datawarehouse for a retailer in the UK. Back then, it was writing COBOL jobs to load tables in DB2. We waited for all the shops to close and do their end of day system processing, and send their data back to the central mainframe. From there it was checked and loaded, and then reports generated on it. This was nearly twenty years ago as my greying beard will attestâ€”and not a lot has changed in the large majority of reporting and analytics systems since then. COBOL is maybe less common, but what has remained constant is the batch-driven nature of processing. Sometimes batches are run more frequently, and get given fancy names like intra-day ETL or even micro-batching. But batch processing it is, and as such latency is built into our reporting &lt;em&gt;by design&lt;/em&gt;. When we opt for batch processing we voluntarily inject delays into the availability of data to our end users. Much better is to build our systems around a streaming platform instead.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
